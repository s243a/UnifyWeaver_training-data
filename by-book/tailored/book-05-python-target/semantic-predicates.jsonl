{"pair_id": "b5-c5-semantic-overview_p0", "cluster_id": "b5-c5-semantic-overview", "question": "What are semantic predicates in the Python target?", "question_type": "medium", "answer": "Semantic predicates in the Python target are built-in predicates that connect Prolog logic with AI and data processing capabilities. They provide access to vector search, knowledge graphs, web crawling, database operations, and language models.\n\nThe key semantic predicates include:\n\n- `semantic_search/3` - Performs vector similarity search using the PtSearcher runtime component\n- `graph_search/4` - Executes graph-based retrieval-augmented generation (RAG) queries via PtSearcher\n- `crawler_run/2` - Handles web and XML crawling operations through PtCrawler\n- `upsert_object/3` - Manages database storage operations using PtImporter\n- `llm_ask/3` - Interfaces with language models through LLMProvider\n\nThese predicates are implemented through a layered runtime architecture. The generated Python script sits at the top, utilizing runtime components (PtSearcher, PtCrawler, PtImporter) that in turn leverage OnnxEmbeddingProvider and LLMProvider, all backed by a SQLite database for persistent storage.\n\nFor implementation details and examples, see education/book-05-python-target/05_semantic_predicates.md.", "answer_variant": "default", "answer_source": "education/book-05-python-target/05_semantic_predicates.md", "topics": ["semantic-predicates", "ai-features", "python-runtime"], "original_answer": "## Semantic Predicates\n\nSemantic predicates bridge Prolog logic with AI capabilities.\n\n| Predicate | Purpose | Runtime Component |\n|-----------|---------|-------------------|\n| `semantic_search/3` | Vector similarity | PtSearcher |\n| `graph_search/4` | Graph RAG | PtSearcher |\n| `crawler_run/2` | Web/XML crawling | PtCrawler |\n| `upsert_object/3` | Database storage | PtImporter |\n| `llm_ask/3` | LLM Q&A | LLMProvider |\n\n### Runtime Architecture\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    Generated Python Script      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 PtSearcher  PtCrawler  PtImporter\u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 OnnxEmbeddingProvider  LLMProvider\u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502        SQLite Database          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```", "answer_tailored": true}
{"pair_id": "b5-c5-semantic-overview_p1", "cluster_id": "b5-c5-semantic-overview", "question": "What AI capabilities does the Python runtime provide?", "question_type": "medium", "answer": "The Python runtime provides several AI capabilities through semantic predicates:\n\n**Vector Search**: The `semantic_search/3` predicate performs similarity searches using vector embeddings, powered by the PtSearcher component with OnnxEmbeddingProvider for encoding.\n\n**Graph RAG**: Use `graph_search/4` for graph-based retrieval augmented generation, combining semantic similarity with graph traversal through PtSearcher.\n\n**LLM Integration**: The `llm_ask/3` predicate enables direct question-answering with language models via the LLMProvider component.\n\n**Data Ingestion**: `upsert_object/3` stores structured data in SQLite through PtImporter, while `crawler_run/2` handles web and XML crawling via PtCrawler.\n\nThe runtime architecture layers these capabilities: generated Python scripts call searcher/crawler/importer components, which use embedding and LLM providers backed by SQLite storage. For implementation details, see education/book-05-python-target/05_semantic_predicates.md.", "answer_variant": "default", "answer_source": "education/book-05-python-target/05_semantic_predicates.md", "topics": ["semantic-predicates", "ai-features", "python-runtime"], "original_answer": "## Semantic Predicates\n\nSemantic predicates bridge Prolog logic with AI capabilities.\n\n| Predicate | Purpose | Runtime Component |\n|-----------|---------|-------------------|\n| `semantic_search/3` | Vector similarity | PtSearcher |\n| `graph_search/4` | Graph RAG | PtSearcher |\n| `crawler_run/2` | Web/XML crawling | PtCrawler |\n| `upsert_object/3` | Database storage | PtImporter |\n| `llm_ask/3` | LLM Q&A | LLMProvider |\n\n### Runtime Architecture\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    Generated Python Script      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 PtSearcher  PtCrawler  PtImporter\u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 OnnxEmbeddingProvider  LLMProvider\u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502        SQLite Database          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```", "answer_tailored": true}
{"pair_id": "b5-c5-semantic-overview_p2", "cluster_id": "b5-c5-semantic-overview", "question": "How do semantic predicates work?", "question_type": "medium", "answer": "Semantic predicates connect Prolog queries to AI-powered operations through specialized runtime components. When you use predicates like `semantic_search/3`, `graph_search/4`, or `llm_ask/3` in your Prolog code, UnifyWeaver compiles them to Python code that leverages the runtime system.\n\nThe system provides five main semantic predicates:\n- `semantic_search/3` - performs vector similarity search via PtSearcher\n- `graph_search/4` - executes graph-based retrieval augmented generation (RAG) using PtSearcher\n- `crawler_run/2` - handles web and XML crawling through PtCrawler\n- `upsert_object/3` - manages database storage operations via PtImporter\n- `llm_ask/3` - interfaces with language models through LLMProvider\n\nThe runtime architecture layers these components: your generated Python script sits on top, using PtSearcher, PtCrawler, and PtImporter for data operations. These components rely on OnnxEmbeddingProvider for vector embeddings and LLMProvider for language model interactions, with SQLite serving as the underlying database.\n\nFor implementation details and examples, see education/book-05-python-target/05_semantic_predicates.md.", "answer_variant": "default", "answer_source": "education/book-05-python-target/05_semantic_predicates.md", "topics": ["semantic-predicates", "ai-features", "python-runtime"], "original_answer": "## Semantic Predicates\n\nSemantic predicates bridge Prolog logic with AI capabilities.\n\n| Predicate | Purpose | Runtime Component |\n|-----------|---------|-------------------|\n| `semantic_search/3` | Vector similarity | PtSearcher |\n| `graph_search/4` | Graph RAG | PtSearcher |\n| `crawler_run/2` | Web/XML crawling | PtCrawler |\n| `upsert_object/3` | Database storage | PtImporter |\n| `llm_ask/3` | LLM Q&A | LLMProvider |\n\n### Runtime Architecture\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    Generated Python Script      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 PtSearcher  PtCrawler  PtImporter\u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 OnnxEmbeddingProvider  LLMProvider\u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502        SQLite Database          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```", "answer_tailored": true}
{"pair_id": "b5-c5-vector-search_p0", "cluster_id": "b5-c5-vector-search", "question": "How does semantic_search/3 work?", "question_type": "medium", "answer": "The `semantic_search/3` predicate performs vector-based similarity search across stored embeddings. It takes three arguments: a query string, the number of results to return (K), and an output variable for the results.\n\nWhen called, it follows these steps:\n\n1. **Query embedding** - Converts the input text to a vector representation using an ONNX model\n2. **Cosine similarity computation** - Calculates similarity scores between the query vector and all stored document embeddings\n3. **Top-K ranking** - Selects the K highest-scoring matches\n4. **Result enrichment** - Retrieves complete object data for the matched items\n\nResults are returned as a list of dictionaries, each containing:\n- `id`: Document identifier\n- `score`: Similarity score (0-1 range)\n- `type`: Object type classification\n- `data`: Full document metadata and content\n\nThe system supports multiple ONNX embedding models including `all-MiniLM-L6-v2` (384 dimensions, optimized for speed) and `all-mpnet-base-v2` (768 dimensions, better accuracy).\n\nFor implementation examples, see `education/book-05-python-target/05_semantic_predicates.md`.", "answer_variant": "default", "answer_source": "education/book-05-python-target/05_semantic_predicates.md", "topics": ["semantic-search", "vector-search", "cosine-similarity"], "original_answer": "## Vector Search (semantic_search/3)\n\nPerforms vector similarity search against stored embeddings.\n\n### Prolog\n\n```prolog\nfind_physics_content(Results) :-\n    semantic_search('quantum physics', 10, Results).\n```\n\n### How It Works\n\n1. **Query embedding** - Convert query text to vector using ONNX\n2. **Cosine similarity** - Compare query vector against stored embeddings\n3. **Top-K selection** - Return K most similar items\n4. **Result enrichment** - Fetch full object data\n\n### Result Format\n\n```python\n[\n    {\n        'id': 'doc_123',\n        'score': 0.89,\n        'type': 'article',\n        'data': {'title': 'Quantum Entanglement', ...}\n    }\n]\n```\n\n### ONNX Models\n\n- `all-MiniLM-L6-v2` (384 dims, fast)\n- `all-mpnet-base-v2` (768 dims, higher quality)", "answer_tailored": true}
{"pair_id": "b5-c5-vector-search_p1", "cluster_id": "b5-c5-vector-search", "question": "What is vector similarity search?", "question_type": "medium", "answer": "Vector similarity search is a technique for finding semantically similar content by comparing vector representations of text. In UnifyWeaver, the `semantic_search/3` predicate implements this functionality.\n\n**How It Works:**\n\n1. **Query Embedding** - Your search text is converted into a numerical vector using an ONNX model\n2. **Similarity Calculation** - The query vector is compared against stored document embeddings using cosine similarity\n3. **Ranking** - Documents are ranked by similarity score, and the top K matches are returned\n4. **Data Retrieval** - Full object data is fetched for the matching results\n\n**Example Usage:**\n\n```prolog\nfind_physics_content(Results) :-\n    semantic_search('quantum physics', 10, Results).\n```\n\nThis returns up to 10 documents most semantically similar to \"quantum physics\", with results structured as:\n\n```python\n[\n    {\n        'id': 'doc_123',\n        'score': 0.89,\n        'type': 'article',\n        'data': {'title': 'Quantum Entanglement', ...}\n    }\n]\n```\n\n**Supported Models:**\n\n- `all-MiniLM-L6-v2` - 384 dimensions, optimized for speed\n- `all-mpnet-base-v2` - 768 dimensions, better accuracy\n\nFor implementation details, see education/book-05-python-target/05_semantic_predicates.md.", "answer_variant": "default", "answer_source": "education/book-05-python-target/05_semantic_predicates.md", "topics": ["semantic-search", "vector-search", "cosine-similarity"], "original_answer": "## Vector Search (semantic_search/3)\n\nPerforms vector similarity search against stored embeddings.\n\n### Prolog\n\n```prolog\nfind_physics_content(Results) :-\n    semantic_search('quantum physics', 10, Results).\n```\n\n### How It Works\n\n1. **Query embedding** - Convert query text to vector using ONNX\n2. **Cosine similarity** - Compare query vector against stored embeddings\n3. **Top-K selection** - Return K most similar items\n4. **Result enrichment** - Fetch full object data\n\n### Result Format\n\n```python\n[\n    {\n        'id': 'doc_123',\n        'score': 0.89,\n        'type': 'article',\n        'data': {'title': 'Quantum Entanglement', ...}\n    }\n]\n```\n\n### ONNX Models\n\n- `all-MiniLM-L6-v2` (384 dims, fast)\n- `all-mpnet-base-v2` (768 dims, higher quality)", "answer_tailored": true}
{"pair_id": "b5-c5-vector-search_p2", "cluster_id": "b5-c5-vector-search", "question": "How are query embeddings generated?", "question_type": "medium", "answer": "Query embeddings are generated using ONNX models that convert text into vector representations. When you call `semantic_search/3`, the query string is first passed through an ONNX embedding model to produce a numerical vector.\n\nUnifyWeaver supports two primary models:\n- `all-MiniLM-L6-v2` - Creates 384-dimensional vectors, optimized for speed\n- `all-mpnet-base-v2` - Produces 768-dimensional vectors with better accuracy\n\nThe embedding process transforms your query text (e.g., \"quantum physics\") into a dense vector that captures semantic meaning. This query vector is then compared against pre-computed embeddings of stored documents using cosine similarity to find the most relevant matches.\n\nFor implementation details and examples, see `education/book-05-python-target/05_semantic_predicates.md`.", "answer_variant": "default", "answer_source": "education/book-05-python-target/05_semantic_predicates.md", "topics": ["semantic-search", "vector-search", "cosine-similarity"], "original_answer": "## Vector Search (semantic_search/3)\n\nPerforms vector similarity search against stored embeddings.\n\n### Prolog\n\n```prolog\nfind_physics_content(Results) :-\n    semantic_search('quantum physics', 10, Results).\n```\n\n### How It Works\n\n1. **Query embedding** - Convert query text to vector using ONNX\n2. **Cosine similarity** - Compare query vector against stored embeddings\n3. **Top-K selection** - Return K most similar items\n4. **Result enrichment** - Fetch full object data\n\n### Result Format\n\n```python\n[\n    {\n        'id': 'doc_123',\n        'score': 0.89,\n        'type': 'article',\n        'data': {'title': 'Quantum Entanglement', ...}\n    }\n]\n```\n\n### ONNX Models\n\n- `all-MiniLM-L6-v2` (384 dims, fast)\n- `all-mpnet-base-v2` (768 dims, higher quality)", "answer_tailored": true}
{"pair_id": "b5-c5-graph-rag_p0", "cluster_id": "b5-c5-graph-rag", "question": "What is Graph RAG?", "question_type": "medium", "answer": "Graph RAG (Retrieval-Augmented Generation) is a multi-hop graph-based retrieval technique implemented in UnifyWeaver through the `graph_search/4` predicate. Unlike simple vector search, it traverses relationships between documents to gather richer context.\n\n### How It Works\n\nGraph RAG operates in four stages:\n\n1. **Anchor search** - Identifies top-K most relevant nodes using vector similarity to the query\n2. **Expansion** - Discovers nodes connected to each anchor (parents and children)\n3. **Hop iteration** - Recursively expands outward for the specified number of hops\n4. **Context assembly** - Aggregates all discovered nodes into a structured result\n\n### Usage in Prolog\n\n```prolog\nfind_context(Query, Context) :-\n    graph_search(Query, 5, 2, Context).\n```\n\nThis searches for 5 anchor nodes and expands 2 hops outward.\n\n### Output Format\n\n```python\n{\n    'anchors': [...],    # Initial matches from vector search\n    'parents': [...],    # Parent nodes (1 hop)\n    'children': [...],   # Child nodes (1 hop)\n    'hop_2': {\n        'parents': [...],  # Grandparent nodes\n        'children': [...]  # Grandchild nodes\n    }\n}\n```\n\n### Choosing Hop Depth\n\n- **1 hop**: Quick retrieval with immediate neighbors\n- **2 hops**: Balanced coverage (recommended)\n- **3+ hops**: Comprehensive but slower, risks irrelevant content\n\nSee education/book-05-python-target/05_semantic_predicates.md for implementation details.", "answer_variant": "default", "answer_source": "education/book-05-python-target/05_semantic_predicates.md", "topics": ["graph-search", "graph-rag", "multi-hop"], "original_answer": "## Graph Search (Graph RAG)\n\n`graph_search/4` performs multi-hop graph-based retrieval.\n\n### Prolog\n\n```prolog\nfind_context(Query, Context) :-\n    graph_search(Query, 5, 2, Context).\n```\n\n### How Graph Search Works\n\n1. **Anchor search** - Find top-K nodes via vector similarity\n2. **Expansion** - For each anchor, find connected nodes\n3. **Hop iteration** - Repeat expansion for specified hops\n4. **Context assembly** - Combine into structured result\n\n### Result Structure\n\n```python\n{\n    'anchors': [...],    # Most similar nodes\n    'parents': [...],    # Parent nodes\n    'children': [...],   # Child nodes\n    'hop_2': {\n        'parents': [...],\n        'children': [...]\n    }\n}\n```\n\n### Hop Guidelines\n\n- 1 hop: Fast, focused\n- 2 hops: Good balance\n- 3+ hops: Slow, may include noise", "answer_tailored": true}
{"pair_id": "b5-c5-graph-rag_p1", "cluster_id": "b5-c5-graph-rag", "question": "How does graph_search/4 work?", "question_type": "medium", "answer": "`graph_search/4` performs multi-hop graph-based retrieval to find relevant context by exploring connected nodes in a knowledge graph.\n\n**How It Works**\n\nThe predicate takes four arguments and executes these steps:\n\n1. **Anchor identification** - Uses vector similarity to locate the top-K most relevant nodes matching the query\n2. **Node expansion** - From each anchor, traverses to connected parent and child nodes\n3. **Multi-hop traversal** - Repeats the expansion process for the specified number of hops\n4. **Result compilation** - Aggregates all discovered nodes into a structured context object\n\n**Usage Example**\n\n```prolog\nfind_context(Query, Context) :-\n    graph_search(Query, 5, 2, Context).\n```\n\nThis searches for 5 anchor nodes and explores 2 hops deep.\n\n**Output Format**\n\nThe Context unifies with a structure containing:\n\n```python\n{\n    'anchors': [...],    # Initial matching nodes\n    'parents': [...],    # Parent nodes from hop 1\n    'children': [...],   # Child nodes from hop 1\n    'hop_2': {\n        'parents': [...],\n        'children': [...]\n    }\n}\n```\n\n**Hop Count Considerations**\n\n- 1 hop: Quick retrieval, narrow scope\n- 2 hops: Balanced coverage and performance\n- 3+ hops: Comprehensive but slower, risk of irrelevant nodes\n\nFor implementation details, see education/book-05-python-target/05_semantic_predicates.md.", "answer_variant": "default", "answer_source": "education/book-05-python-target/05_semantic_predicates.md", "topics": ["graph-search", "graph-rag", "multi-hop"], "original_answer": "## Graph Search (Graph RAG)\n\n`graph_search/4` performs multi-hop graph-based retrieval.\n\n### Prolog\n\n```prolog\nfind_context(Query, Context) :-\n    graph_search(Query, 5, 2, Context).\n```\n\n### How Graph Search Works\n\n1. **Anchor search** - Find top-K nodes via vector similarity\n2. **Expansion** - For each anchor, find connected nodes\n3. **Hop iteration** - Repeat expansion for specified hops\n4. **Context assembly** - Combine into structured result\n\n### Result Structure\n\n```python\n{\n    'anchors': [...],    # Most similar nodes\n    'parents': [...],    # Parent nodes\n    'children': [...],   # Child nodes\n    'hop_2': {\n        'parents': [...],\n        'children': [...]\n    }\n}\n```\n\n### Hop Guidelines\n\n- 1 hop: Fast, focused\n- 2 hops: Good balance\n- 3+ hops: Slow, may include noise", "answer_tailored": true}
{"pair_id": "b5-c5-graph-rag_p2", "cluster_id": "b5-c5-graph-rag", "question": "What are hops in graph search?", "question_type": "medium", "answer": "In graph search, **hops** refer to iterations of expanding from connected nodes to gather related context. Starting from anchor nodes (found via vector similarity), each hop expands to neighboring nodes:\n\n- **Hop 1**: Direct parents and children of anchors\n- **Hop 2**: Parents and children of hop-1 nodes\n- **Hop 3+**: Further expansions outward\n\nThe `graph_search/4` predicate takes a hop count parameter:\n\n```prolog\ngraph_search(Query, TopK, Hops, Context).\n```\n\n**Choosing hop depth:**\n- 1 hop: Fast, tightly focused on immediate neighbors\n- 2 hops: Balanced performance and coverage (recommended)\n- 3+ hops: Slower, may introduce irrelevant noise\n\nEach hop level appears in the result structure:\n\n```python\n{\n    'anchors': [...],\n    'parents': [...],    # Hop 1\n    'children': [...],   # Hop 1\n    'hop_2': {\n        'parents': [...],\n        'children': [...]\n    }\n}\n```\n\nSee `education/book-05-python-target/05_semantic_predicates.md` for complete graph search details.", "answer_variant": "default", "answer_source": "education/book-05-python-target/05_semantic_predicates.md", "topics": ["graph-search", "graph-rag", "multi-hop"], "original_answer": "## Graph Search (Graph RAG)\n\n`graph_search/4` performs multi-hop graph-based retrieval.\n\n### Prolog\n\n```prolog\nfind_context(Query, Context) :-\n    graph_search(Query, 5, 2, Context).\n```\n\n### How Graph Search Works\n\n1. **Anchor search** - Find top-K nodes via vector similarity\n2. **Expansion** - For each anchor, find connected nodes\n3. **Hop iteration** - Repeat expansion for specified hops\n4. **Context assembly** - Combine into structured result\n\n### Result Structure\n\n```python\n{\n    'anchors': [...],    # Most similar nodes\n    'parents': [...],    # Parent nodes\n    'children': [...],   # Child nodes\n    'hop_2': {\n        'parents': [...],\n        'children': [...]\n    }\n}\n```\n\n### Hop Guidelines\n\n- 1 hop: Fast, focused\n- 2 hops: Good balance\n- 3+ hops: Slow, may include noise", "answer_tailored": true}
{"pair_id": "b5-c5-crawling-llm_p0", "cluster_id": "b5-c5-crawling-llm", "question": "How do I crawl web pages with semantic predicates?", "question_type": "medium", "answer": "To crawl web pages with semantic predicates, use the `crawler_run/2` predicate:\n\n```prolog\ncrawl_documentation(Seeds) :-\n    crawler_run(['https://docs.example.com/'], 3).\n```\n\nThis predicate handles web crawling with built-in semantic capabilities:\n- Performs streaming XML parsing using lxml for efficient processing\n- Automatically generates embeddings for crawled content\n- Constructs a graph structure from discovered links\n- The second argument (3) controls the crawl depth\n\nCrawled data is stored in a database with three main tables:\n- `objects` - stores page content (id, type, data as JSON)\n- `embeddings` - stores semantic vectors (id, vector as BLOB)\n- `links` - captures the graph structure (source_id, target_id)\n\nYou can persist crawled data using `upsert_object/3`:\n\n```prolog\nstore_article(Id, Title, Content) :-\n    upsert_object(Id, 'article', _{title: Title, content: Content}).\n```\n\nOnce crawled, you can query the semantic graph with `graph_search/4` and integrate with LLMs using `llm_ask/3` for question answering. See education/book-05-python-target/05_semantic_predicates.md for complete implementation details.", "answer_variant": "default", "answer_source": "education/book-05-python-target/05_semantic_predicates.md", "topics": ["crawler", "llm-integration", "upsert"], "original_answer": "## Crawling and LLM Integration\n\n### Crawling (crawler_run/2)\n\n```prolog\ncrawl_documentation(Seeds) :-\n    crawler_run(['https://docs.example.com/'], 3).\n```\n\n- Streaming XML parsing with lxml\n- Automatic embedding generation\n- Graph construction from links\n\n### LLM Integration (llm_ask/3)\n\n```prolog\nanswer_question(Question, Answer) :-\n    graph_search(Question, 5, 2, Context),\n    llm_ask(Question, Context, Answer).\n```\n\nDefault implementation uses `gemini` CLI.\n\n### Database Storage (upsert_object/3)\n\n```prolog\nstore_article(Id, Title, Content) :-\n    upsert_object(Id, 'article', _{title: Title, content: Content}).\n```\n\n### Database Schema\n\n- `objects` - id, type, data (JSON)\n- `embeddings` - id, vector (BLOB)\n- `links` - source_id, target_id", "answer_tailored": true}
{"pair_id": "b5-c5-crawling-llm_p1", "cluster_id": "b5-c5-crawling-llm", "question": "How does LLM integration work?", "question_type": "medium", "answer": "LLM integration in UnifyWeaver is handled through the `llm_ask/3` predicate, which takes a question, context, and produces an answer. The typical workflow combines semantic search with LLM querying:\n\n```prolog\nanswer_question(Question, Answer) :-\n    graph_search(Question, 5, 2, Context),\n    llm_ask(Question, Context, Answer).\n```\n\nFirst, `graph_search/4` retrieves relevant context from the knowledge base using semantic similarity (finding 5 documents with depth 2). Then `llm_ask/3` sends both the question and retrieved context to the LLM for answer generation.\n\nThe default implementation uses the `gemini` CLI tool, though this can be customized. The LLM receives structured context from your crawled documentation and stored embeddings to provide informed responses.\n\nThis integrates with the crawler system (`crawler_run/2`) which performs streaming XML parsing with lxml, generates embeddings automatically, and builds a searchable graph from documentation links. All data is stored in a SQLite database with three tables: `objects` (id, type, JSON data), `embeddings` (id, vector BLOB), and `links` (source_id, target_id).\n\nFor implementation details, see education/book-05-python-target/05_semantic_predicates.md.", "answer_variant": "default", "answer_source": "education/book-05-python-target/05_semantic_predicates.md", "topics": ["crawler", "llm-integration", "upsert"], "original_answer": "## Crawling and LLM Integration\n\n### Crawling (crawler_run/2)\n\n```prolog\ncrawl_documentation(Seeds) :-\n    crawler_run(['https://docs.example.com/'], 3).\n```\n\n- Streaming XML parsing with lxml\n- Automatic embedding generation\n- Graph construction from links\n\n### LLM Integration (llm_ask/3)\n\n```prolog\nanswer_question(Question, Answer) :-\n    graph_search(Question, 5, 2, Context),\n    llm_ask(Question, Context, Answer).\n```\n\nDefault implementation uses `gemini` CLI.\n\n### Database Storage (upsert_object/3)\n\n```prolog\nstore_article(Id, Title, Content) :-\n    upsert_object(Id, 'article', _{title: Title, content: Content}).\n```\n\n### Database Schema\n\n- `objects` - id, type, data (JSON)\n- `embeddings` - id, vector (BLOB)\n- `links` - source_id, target_id", "answer_tailored": true}
{"pair_id": "b5-c5-crawling-llm_p2", "cluster_id": "b5-c5-crawling-llm", "question": "How do I store objects in the database?", "question_type": "medium", "answer": "To store objects in the database, use the `upsert_object/3` predicate:\n\n```prolog\nstore_article(Id, Title, Content) :-\n    upsert_object(Id, 'article', _{title: Title, content: Content}).\n```\n\nThe predicate takes three arguments:\n- Object ID (unique identifier)\n- Object type (string categorizing the object)\n- Data dictionary (JSON-compatible structure with your fields)\n\nObjects are stored in the `objects` table with columns: id, type, and data (JSON). This schema supports flexible storage of different object types while maintaining queryability through the type field.\n\nRelated tables include `embeddings` (for semantic search vectors) and `links` (for relationship tracking between objects). For complete database schema details and integration with crawling/LLM features, see education/book-05-python-target/05_semantic_predicates.md.", "answer_variant": "default", "answer_source": "education/book-05-python-target/05_semantic_predicates.md", "topics": ["crawler", "llm-integration", "upsert"], "original_answer": "## Crawling and LLM Integration\n\n### Crawling (crawler_run/2)\n\n```prolog\ncrawl_documentation(Seeds) :-\n    crawler_run(['https://docs.example.com/'], 3).\n```\n\n- Streaming XML parsing with lxml\n- Automatic embedding generation\n- Graph construction from links\n\n### LLM Integration (llm_ask/3)\n\n```prolog\nanswer_question(Question, Answer) :-\n    graph_search(Question, 5, 2, Context),\n    llm_ask(Question, Context, Answer).\n```\n\nDefault implementation uses `gemini` CLI.\n\n### Database Storage (upsert_object/3)\n\n```prolog\nstore_article(Id, Title, Content) :-\n    upsert_object(Id, 'article', _{title: Title, content: Content}).\n```\n\n### Database Schema\n\n- `objects` - id, type, data (JSON)\n- `embeddings` - id, vector (BLOB)\n- `links` - source_id, target_id", "answer_tailored": true}
