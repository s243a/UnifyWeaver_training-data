{"pair_id": "b5-c4-recursion-overview_p0", "cluster_id": "b5-c4-recursion-overview", "question": "What recursion patterns does the Python target support?", "question_type": "medium", "answer": "The Python target supports three main recursion patterns, each with specific optimizations:\n\n**Tail Recursion**: Converted to while loops for O(1) space complexity. Best for accumulator-based computations and iterative processes.\n\n**Linear Recursion**: Optimized using `@functools.cache` decorator for memoization, with O(n) space usage. Suitable when predicates make a single recursive call.\n\n**Mutual Recursion**: Handled through a shared dispatcher mechanism with O(n) space. Used when multiple predicates call each other recursively.\n\nThe compiler automatically detects which pattern applies by analyzing the predicate structure. For tail-recursive predicates, it generates while loops; for linear recursion, it applies memoization; and for mutual recursion, it creates a shared dispatcher. Deep or unbounded recursion cases fall back to generator mode for streaming results.\n\nFor implementation details and examples, see education/book-05-python-target/04_recursion_patterns.md.", "answer_variant": "default", "answer_source": "education/book-05-python-target/04_recursion_patterns.md", "topics": ["recursion", "optimization", "tail-recursion", "memoization"], "original_answer": "## Recursion Patterns\n\nThe Python target recognizes and optimizes three recursion patterns:\n\n| Pattern | Optimization | Space | Use Case |\n|---------|-------------|-------|----------|\n| Tail | While loops | O(1) | Accumulators, iterative |\n| Linear | Memoization | O(n) | Single recursive call |\n| Mutual | Shared dispatcher | O(n) | Predicates calling each other |\n\n### Pattern Detection\n\nThe compiler automatically detects patterns:\n\n```\nIs the predicate recursive?\n\u251c\u2500\u2500 No \u2192 Simple streaming\n\u2514\u2500\u2500 Yes \u2192 What kind?\n    \u251c\u2500\u2500 Tail recursive? \u2192 while loop\n    \u251c\u2500\u2500 Linear recursive? \u2192 @functools.cache\n    \u251c\u2500\u2500 Mutual recursive? \u2192 shared dispatcher\n    \u2514\u2500\u2500 Deep/unbounded? \u2192 Generator mode\n```", "answer_tailored": true}
{"pair_id": "b5-c4-recursion-overview_p1", "cluster_id": "b5-c4-recursion-overview", "question": "How does UnifyWeaver optimize different recursion types?", "question_type": "medium", "answer": "UnifyWeaver's Python target optimizes different recursion types through pattern-specific strategies:\n\n**Tail recursion** is transformed into while loops, achieving O(1) space complexity. This works well for accumulator-based patterns and iterative algorithms.\n\n**Linear recursion** (containing a single recursive call) uses `@functools.cache` for memoization, requiring O(n) space but avoiding redundant computation.\n\n**Mutual recursion** (predicates calling each other) employs a shared dispatcher pattern with O(n) space complexity.\n\nThe compiler automatically detects which pattern applies by analyzing the predicate structure. For non-recursive predicates, it uses simple streaming. For recursive ones, it checks if the recursion is tail-positioned (\u2192 while loop), linear (\u2192 memoization decorator), mutual (\u2192 dispatcher), or deep/unbounded (\u2192 generator mode).\n\nThese optimizations are described in detail in education/book-05-python-target/04_recursion_patterns.md.", "answer_variant": "default", "answer_source": "education/book-05-python-target/04_recursion_patterns.md", "topics": ["recursion", "optimization", "tail-recursion", "memoization"], "original_answer": "## Recursion Patterns\n\nThe Python target recognizes and optimizes three recursion patterns:\n\n| Pattern | Optimization | Space | Use Case |\n|---------|-------------|-------|----------|\n| Tail | While loops | O(1) | Accumulators, iterative |\n| Linear | Memoization | O(n) | Single recursive call |\n| Mutual | Shared dispatcher | O(n) | Predicates calling each other |\n\n### Pattern Detection\n\nThe compiler automatically detects patterns:\n\n```\nIs the predicate recursive?\n\u251c\u2500\u2500 No \u2192 Simple streaming\n\u2514\u2500\u2500 Yes \u2192 What kind?\n    \u251c\u2500\u2500 Tail recursive? \u2192 while loop\n    \u251c\u2500\u2500 Linear recursive? \u2192 @functools.cache\n    \u251c\u2500\u2500 Mutual recursive? \u2192 shared dispatcher\n    \u2514\u2500\u2500 Deep/unbounded? \u2192 Generator mode\n```", "answer_tailored": true}
{"pair_id": "b5-c4-recursion-overview_p2", "cluster_id": "b5-c4-recursion-overview", "question": "What is the difference between tail and linear recursion?", "question_type": "medium", "answer": "The key difference is in optimization and space complexity:\n\n**Tail recursion** occurs when the recursive call is the last operation in a predicate. The Python target optimizes this into a while loop, using O(1) constant space. This makes it ideal for accumulator-based patterns and iterative algorithms.\n\n**Linear recursion** has a single recursive call but performs additional operations after the call returns. The Python target optimizes this using `@functools.cache` memoization, which trades O(n) space for avoiding redundant computation.\n\nThe compiler automatically detects which pattern your predicate follows and applies the appropriate optimization. For example, factorial with an accumulator would be tail-recursive (while loop), whereas naive Fibonacci would be linear recursive (memoized). See education/book-05-python-target/04_recursion_patterns.md for pattern detection details.", "answer_variant": "default", "answer_source": "education/book-05-python-target/04_recursion_patterns.md", "topics": ["recursion", "optimization", "tail-recursion", "memoization"], "original_answer": "## Recursion Patterns\n\nThe Python target recognizes and optimizes three recursion patterns:\n\n| Pattern | Optimization | Space | Use Case |\n|---------|-------------|-------|----------|\n| Tail | While loops | O(1) | Accumulators, iterative |\n| Linear | Memoization | O(n) | Single recursive call |\n| Mutual | Shared dispatcher | O(n) | Predicates calling each other |\n\n### Pattern Detection\n\nThe compiler automatically detects patterns:\n\n```\nIs the predicate recursive?\n\u251c\u2500\u2500 No \u2192 Simple streaming\n\u2514\u2500\u2500 Yes \u2192 What kind?\n    \u251c\u2500\u2500 Tail recursive? \u2192 while loop\n    \u251c\u2500\u2500 Linear recursive? \u2192 @functools.cache\n    \u251c\u2500\u2500 Mutual recursive? \u2192 shared dispatcher\n    \u2514\u2500\u2500 Deep/unbounded? \u2192 Generator mode\n```", "answer_tailored": true}
{"pair_id": "b5-c4-tail-recursion_p0", "cluster_id": "b5-c4-tail-recursion", "question": "How is tail recursion compiled to Python?", "question_type": "medium", "answer": "Tail recursion in Prolog compiles to Python `while` loops to achieve constant space complexity. The compiler recognizes when a recursive call occurs in tail position (as the final goal) and transforms it into iteration.\n\nThe transformation works by:\n- Converting the recursive predicate into a loop\n- Using tuple assignment to update variables in place\n- Replacing the recursive call with `continue`\n- Returning the accumulator when the base case matches\n\nFor example, this tail-recursive factorial:\n\n```prolog\nfactorial_acc(0, Acc, Acc).\nfactorial_acc(N, Acc, F) :-\n    N > 0, N1 is N - 1, Acc1 is Acc * N,\n    factorial_acc(N1, Acc1, F).\n```\n\nBecomes:\n\n```python\ndef _factorial_acc_worker(n, acc):\n    while True:\n        if n == 0:\n            return acc\n        if n > 0:\n            n, acc = n - 1, acc * n\n            continue\n        return None\n```\n\nThis approach eliminates stack growth (O(1) space), avoids Python's recursion limit, and improves performance by removing function call overhead. See education/book-05-python-target/04_recursion_patterns.md for the full pattern catalog.", "answer_variant": "default", "answer_source": "education/book-05-python-target/04_recursion_patterns.md", "topics": ["tail-recursion", "while-loop", "accumulator"], "original_answer": "## Tail Recursion\n\nTail recursion is converted to `while` loops for O(1) space.\n\n### Pattern Recognition\n\n- Recursive call is in tail position (last goal)\n- Base case that doesn't recurse\n- Accumulator variables pass results downward\n\n### Example\n\n```prolog\nfactorial_acc(0, Acc, Acc).\nfactorial_acc(N, Acc, F) :-\n    N > 0, N1 is N - 1, Acc1 is Acc * N,\n    factorial_acc(N1, Acc1, F).\n```\n\n```python\ndef _factorial_acc_worker(n, acc):\n    while True:\n        if n == 0:\n            return acc\n        if n > 0:\n            n, acc = n - 1, acc * n\n            continue\n        return None\n```\n\n### Benefits\n\n- O(1) space - no stack growth\n- No recursion limit\n- Fast - no function call overhead", "answer_tailored": true}
{"pair_id": "b5-c4-tail-recursion_p1", "cluster_id": "b5-c4-tail-recursion", "question": "What is the accumulator pattern?", "question_type": "medium", "answer": "The accumulator pattern is a technique used in recursive predicates where intermediate results are passed downward through an accumulator variable, allowing the recursive call to be in tail position. In the factorial example, `Acc` accumulates the running product as we count down from N to 0:\n\n```prolog\nfactorial_acc(0, Acc, Acc).\nfactorial_acc(N, Acc, F) :-\n    N > 0, N1 is N - 1, Acc1 is Acc * N,\n    factorial_acc(N1, Acc1, F).\n```\n\nWhen compiled to Python, UnifyWeaver recognizes this tail-recursive pattern and converts it to an efficient `while` loop:\n\n```python\ndef _factorial_acc_worker(n, acc):\n    while True:\n        if n == 0:\n            return acc\n        if n > 0:\n            n, acc = n - 1, acc * n\n            continue\n        return None\n```\n\nThis transformation provides O(1) space complexity (no stack growth), avoids recursion limits, and eliminates function call overhead. The key is that the recursive call happens last (tail position) and all computation occurs before the recursive step. For more details on recursion patterns, see education/book-05-python-target/04_recursion_patterns.md.", "answer_variant": "default", "answer_source": "education/book-05-python-target/04_recursion_patterns.md", "topics": ["tail-recursion", "while-loop", "accumulator"], "original_answer": "## Tail Recursion\n\nTail recursion is converted to `while` loops for O(1) space.\n\n### Pattern Recognition\n\n- Recursive call is in tail position (last goal)\n- Base case that doesn't recurse\n- Accumulator variables pass results downward\n\n### Example\n\n```prolog\nfactorial_acc(0, Acc, Acc).\nfactorial_acc(N, Acc, F) :-\n    N > 0, N1 is N - 1, Acc1 is Acc * N,\n    factorial_acc(N1, Acc1, F).\n```\n\n```python\ndef _factorial_acc_worker(n, acc):\n    while True:\n        if n == 0:\n            return acc\n        if n > 0:\n            n, acc = n - 1, acc * n\n            continue\n        return None\n```\n\n### Benefits\n\n- O(1) space - no stack growth\n- No recursion limit\n- Fast - no function call overhead", "answer_tailored": true}
{"pair_id": "b5-c4-tail-recursion_p2", "cluster_id": "b5-c4-tail-recursion", "question": "Why do while loops have O(1) space?", "question_type": "medium", "answer": "While loops have O(1) space complexity because they reuse the same stack frame throughout execution, rather than creating new stack frames for each iteration. Unlike recursive function calls that push a new frame onto the call stack for each invocation, a while loop maintains a constant amount of memory by updating variables in place.\n\nThis is why UnifyWeaver converts tail-recursive Prolog predicates into while loops in Python. For example, the tail-recursive factorial predicate:\n\n```prolog\nfactorial_acc(0, Acc, Acc).\nfactorial_acc(N, Acc, F) :-\n    N > 0, N1 is N - 1, Acc1 is Acc * N,\n    factorial_acc(N1, Acc1, F).\n```\n\nCompiles to:\n\n```python\ndef _factorial_acc_worker(n, acc):\n    while True:\n        if n == 0:\n            return acc\n        if n > 0:\n            n, acc = n - 1, acc * n\n            continue\n        return None\n```\n\nThe while loop version achieves O(1) space by updating `n` and `acc` in the same scope instead of making recursive calls. This eliminates stack growth, avoids Python's recursion limit, and removes function call overhead for better performance.\n\nSee education/book-05-python-target/04_recursion_patterns.md for more details on tail recursion optimization.", "answer_variant": "default", "answer_source": "education/book-05-python-target/04_recursion_patterns.md", "topics": ["tail-recursion", "while-loop", "accumulator"], "original_answer": "## Tail Recursion\n\nTail recursion is converted to `while` loops for O(1) space.\n\n### Pattern Recognition\n\n- Recursive call is in tail position (last goal)\n- Base case that doesn't recurse\n- Accumulator variables pass results downward\n\n### Example\n\n```prolog\nfactorial_acc(0, Acc, Acc).\nfactorial_acc(N, Acc, F) :-\n    N > 0, N1 is N - 1, Acc1 is Acc * N,\n    factorial_acc(N1, Acc1, F).\n```\n\n```python\ndef _factorial_acc_worker(n, acc):\n    while True:\n        if n == 0:\n            return acc\n        if n > 0:\n            n, acc = n - 1, acc * n\n            continue\n        return None\n```\n\n### Benefits\n\n- O(1) space - no stack growth\n- No recursion limit\n- Fast - no function call overhead", "answer_tailored": true}
{"pair_id": "b5-c4-memoization_p0", "cluster_id": "b5-c4-memoization", "question": "How does memoization work in the Python target?", "question_type": "medium", "answer": "The Python target implements memoization for linear recursive predicates using Python's `@functools.cache` decorator. This decorator automatically caches function results based on input arguments, avoiding redundant computations.\n\nFor example, consider the Fibonacci predicate:\n\n```prolog\nfib(0, 0).\nfib(1, 1).\nfib(N, F) :-\n    N > 1, N1 is N - 1, N2 is N - 2,\n    fib(N1, F1), fib(N2, F2), F is F1 + F2.\n```\n\nUnifyWeaver compiles this to Python with automatic memoization:\n\n```python\n@functools.cache\ndef _fib_worker(n):\n    if n == 0: return 0\n    if n == 1: return 1\n    if n > 1:\n        f1 = _fib_worker(n - 1)\n        f2 = _fib_worker(n - 2)\n        if f1 is not None and f2 is not None:\n            return f1 + f2\n    return None\n```\n\nThe `@functools.cache` decorator stores results from previous calls, so when `_fib_worker(5)` calls `_fib_worker(3)` and `_fib_worker(4)`, and then `_fib_worker(4)` also calls `_fib_worker(3)`, the second call to `_fib_worker(3)` returns immediately from cache.\n\nThis optimization is most effective for predicates with:\n- Multiple recursive calls with overlapping inputs\n- Repeated evaluation of identical subproblems\n- Branching recursion patterns (like fib(N-1) and fib(N-2))\n\nThe performance improvement is dramatic: Fibonacci without memoization runs in O(2^n) time, but with `@functools.cache` it reduces to O(n) time with O(n) space for the cache.\n\nFor more on Python target recursion patterns, see education/book-05-python-target/04_recursion_patterns.md.", "answer_variant": "default", "answer_source": "education/book-05-python-target/04_recursion_patterns.md", "topics": ["memoization", "functools-cache", "linear-recursion"], "original_answer": "## Memoization for Linear Recursion\n\nLinear recursion uses `@functools.cache` for memoization.\n\n### Example: Fibonacci\n\n```prolog\nfib(0, 0).\nfib(1, 1).\nfib(N, F) :-\n    N > 1, N1 is N - 1, N2 is N - 2,\n    fib(N1, F1), fib(N2, F2), F is F1 + F2.\n```\n\n```python\n@functools.cache\ndef _fib_worker(n):\n    if n == 0: return 0\n    if n == 1: return 1\n    if n > 1:\n        f1 = _fib_worker(n - 1)\n        f2 = _fib_worker(n - 2)\n        if f1 is not None and f2 is not None:\n            return f1 + f2\n    return None\n```\n\n### Complexity\n\n- Without memoization: O(2^n)\n- With memoization: O(n) time, O(n) space\n\n### When Memoization Helps\n\n- Multiple recursive calls (fib(N-1) + fib(N-2))\n- Overlapping subproblems\n- Same inputs called multiple times", "answer_tailored": true}
{"pair_id": "b5-c4-memoization_p1", "cluster_id": "b5-c4-memoization", "question": "When is memoization most effective?", "question_type": "medium", "answer": "Memoization is most effective when working with linear recursion that has:\n\n1. **Multiple recursive calls per invocation** - Functions like Fibonacci that make 2+ recursive calls (e.g., `fib(N-1)` and `fib(N-2)`)\n2. **Overlapping subproblems** - The same inputs are computed repeatedly through different call paths\n3. **Exponential time complexity without caching** - Problems that would be O(2^n) become O(n) with memoization\n\nFor example, Fibonacci without memoization recomputes the same values many times, leading to O(2^n) complexity. Adding `@functools.cache` reduces this to O(n) time with O(n) space by storing previously computed results.\n\nMemoization provides minimal benefit for simple linear recursion with single recursive calls (like factorial) where each subproblem is only visited once. See education/book-05-python-target/04_recursion_patterns.md for implementation patterns.", "answer_variant": "default", "answer_source": "education/book-05-python-target/04_recursion_patterns.md", "topics": ["memoization", "functools-cache", "linear-recursion"], "original_answer": "## Memoization for Linear Recursion\n\nLinear recursion uses `@functools.cache` for memoization.\n\n### Example: Fibonacci\n\n```prolog\nfib(0, 0).\nfib(1, 1).\nfib(N, F) :-\n    N > 1, N1 is N - 1, N2 is N - 2,\n    fib(N1, F1), fib(N2, F2), F is F1 + F2.\n```\n\n```python\n@functools.cache\ndef _fib_worker(n):\n    if n == 0: return 0\n    if n == 1: return 1\n    if n > 1:\n        f1 = _fib_worker(n - 1)\n        f2 = _fib_worker(n - 2)\n        if f1 is not None and f2 is not None:\n            return f1 + f2\n    return None\n```\n\n### Complexity\n\n- Without memoization: O(2^n)\n- With memoization: O(n) time, O(n) space\n\n### When Memoization Helps\n\n- Multiple recursive calls (fib(N-1) + fib(N-2))\n- Overlapping subproblems\n- Same inputs called multiple times", "answer_tailored": true}
{"pair_id": "b5-c4-memoization_p2", "cluster_id": "b5-c4-memoization", "question": "How is Fibonacci compiled with memoization?", "question_type": "medium", "answer": "## Fibonacci with Memoization\n\nThe Python target compiles Fibonacci using `@functools.cache` decorator for automatic memoization.\n\n### Prolog Source\n\n```prolog\nfib(0, 0).\nfib(1, 1).\nfib(N, F) :-\n    N > 1, N1 is N - 1, N2 is N - 2,\n    fib(N1, F1), fib(N2, F2), F is F1 + F2.\n```\n\n### Compiled Python with Memoization\n\n```python\n@functools.cache\ndef _fib_worker(n):\n    if n == 0: return 0\n    if n == 1: return 1\n    if n > 1:\n        f1 = _fib_worker(n - 1)\n        f2 = _fib_worker(n - 2)\n        if f1 is not None and f2 is not None:\n            return f1 + f2\n    return None\n```\n\nThe `@functools.cache` decorator caches results from previous calls, reducing complexity from O(2^n) to O(n) time with O(n) space overhead.\n\n### Why Memoization Matters Here\n\nFibonacci has overlapping subproblems\u2014`fib(5)` calls `fib(4)` and `fib(3)`, but `fib(4)` also calls `fib(3)`. Caching prevents redundant computation of the same values.\n\nSee education/book-05-python-target/04_recursion_patterns.md for more recursion compilation patterns.", "answer_variant": "default", "answer_source": "education/book-05-python-target/04_recursion_patterns.md", "topics": ["memoization", "functools-cache", "linear-recursion"], "original_answer": "## Memoization for Linear Recursion\n\nLinear recursion uses `@functools.cache` for memoization.\n\n### Example: Fibonacci\n\n```prolog\nfib(0, 0).\nfib(1, 1).\nfib(N, F) :-\n    N > 1, N1 is N - 1, N2 is N - 2,\n    fib(N1, F1), fib(N2, F2), F is F1 + F2.\n```\n\n```python\n@functools.cache\ndef _fib_worker(n):\n    if n == 0: return 0\n    if n == 1: return 1\n    if n > 1:\n        f1 = _fib_worker(n - 1)\n        f2 = _fib_worker(n - 2)\n        if f1 is not None and f2 is not None:\n            return f1 + f2\n    return None\n```\n\n### Complexity\n\n- Without memoization: O(2^n)\n- With memoization: O(n) time, O(n) space\n\n### When Memoization Helps\n\n- Multiple recursive calls (fib(N-1) + fib(N-2))\n- Overlapping subproblems\n- Same inputs called multiple times", "answer_tailored": true}
{"pair_id": "b5-c4-mutual-recursion_p0", "cluster_id": "b5-c4-mutual-recursion", "question": "How is mutual recursion compiled to Python?", "question_type": "medium", "answer": "Mutual recursion in Prolog compiles to Python using a shared dispatcher function with built-in memoization. The dispatcher routes calls between mutually recursive predicates, enabling efficient cross-predicate recursion.\n\nFor instance, consider even/odd checking in Prolog:\n\n```prolog\nis_even(0).\nis_even(N) :- N > 0, N1 is N - 1, is_odd(N1).\n\nis_odd(N) :- N > 0, N1 is N - 1, is_even(N1).\n```\n\nThis generates Python code with a cached dispatcher:\n\n```python\n@functools.cache\ndef _mutual_dispatch(pred_name, arg):\n    if pred_name == 'is_even':\n        return _is_even_impl(arg)\n    elif pred_name == 'is_odd':\n        return _is_odd_impl(arg)\n    return None\n\ndef _is_even_impl(n):\n    if n == 0: return True\n    if n > 0:\n        return _mutual_dispatch('is_odd', n - 1)\n    return None\n```\n\nThe dispatcher accepts a predicate name and argument, routing to the appropriate implementation function. Each implementation calls back through the dispatcher for cross-predicate recursion.\n\n**Current constraint:** Only arity-1 predicates are supported. For predicates with multiple arguments, wrap them as a tuple when calling the dispatcher.\n\nSee education/book-05-python-target/04_recursion_patterns.md for additional recursion compilation patterns.", "answer_variant": "default", "answer_source": "education/book-05-python-target/04_recursion_patterns.md", "topics": ["mutual-recursion", "shared-dispatcher", "even-odd"], "original_answer": "## Mutual Recursion\n\nMutual recursion compiles to a shared dispatcher with memoization.\n\n### Example: Even/Odd\n\n```prolog\nis_even(0).\nis_even(N) :- N > 0, N1 is N - 1, is_odd(N1).\n\nis_odd(N) :- N > 0, N1 is N - 1, is_even(N1).\n```\n\n```python\n@functools.cache\ndef _mutual_dispatch(pred_name, arg):\n    if pred_name == 'is_even':\n        return _is_even_impl(arg)\n    elif pred_name == 'is_odd':\n        return _is_odd_impl(arg)\n    return None\n\ndef _is_even_impl(n):\n    if n == 0: return True\n    if n > 0:\n        return _mutual_dispatch('is_odd', n - 1)\n    return None\n```\n\n### Limitation\n\nCurrently supports **arity 1 predicates only**. For multi-argument mutual recursion, encode arguments as a tuple.", "answer_tailored": true}
{"pair_id": "b5-c4-mutual-recursion_p1", "cluster_id": "b5-c4-mutual-recursion", "question": "What is the shared dispatcher pattern?", "question_type": "medium", "answer": "The shared dispatcher pattern is UnifyWeaver's compilation strategy for mutually recursive predicates in Python. It creates a single dispatching function that routes calls between mutually recursive predicates and applies memoization to the entire call graph.\n\nFor example, when compiling mutually recursive `is_even/1` and `is_odd/1` predicates:\n\n```prolog\nis_even(0).\nis_even(N) :- N > 0, N1 is N - 1, is_odd(N1).\n\nis_odd(N) :- N > 0, N1 is N - 1, is_even(N1).\n```\n\nThe compiler generates a centralized `_mutual_dispatch` function decorated with `@functools.cache` for memoization:\n\n```python\n@functools.cache\ndef _mutual_dispatch(pred_name, arg):\n    if pred_name == 'is_even':\n        return _is_even_impl(arg)\n    elif pred_name == 'is_odd':\n        return _is_odd_impl(arg)\n    return None\n\ndef _is_even_impl(n):\n    if n == 0: return True\n    if n > 0:\n        return _mutual_dispatch('is_odd', n - 1)\n    return None\n```\n\nThis approach ensures that all cross-predicate recursive calls go through the same memoized dispatcher, preventing redundant computation across the mutual recursion cycle.\n\n**Current limitation**: The dispatcher only supports arity-1 predicates. For mutual recursion with multiple arguments, encode them as a tuple.\n\nSee education/book-05-python-target/04_recursion_patterns.md for complete details.", "answer_variant": "default", "answer_source": "education/book-05-python-target/04_recursion_patterns.md", "topics": ["mutual-recursion", "shared-dispatcher", "even-odd"], "original_answer": "## Mutual Recursion\n\nMutual recursion compiles to a shared dispatcher with memoization.\n\n### Example: Even/Odd\n\n```prolog\nis_even(0).\nis_even(N) :- N > 0, N1 is N - 1, is_odd(N1).\n\nis_odd(N) :- N > 0, N1 is N - 1, is_even(N1).\n```\n\n```python\n@functools.cache\ndef _mutual_dispatch(pred_name, arg):\n    if pred_name == 'is_even':\n        return _is_even_impl(arg)\n    elif pred_name == 'is_odd':\n        return _is_odd_impl(arg)\n    return None\n\ndef _is_even_impl(n):\n    if n == 0: return True\n    if n > 0:\n        return _mutual_dispatch('is_odd', n - 1)\n    return None\n```\n\n### Limitation\n\nCurrently supports **arity 1 predicates only**. For multi-argument mutual recursion, encode arguments as a tuple.", "answer_tailored": true}
{"pair_id": "b5-c4-mutual-recursion_p2", "cluster_id": "b5-c4-mutual-recursion", "question": "What are the limitations of mutual recursion support?", "question_type": "medium", "answer": "The current implementation of mutual recursion in UnifyWeaver's Python target has a key constraint: it only supports **predicates with arity 1** (single-argument predicates). \n\nWhen predicates in a mutually recursive group need multiple arguments, you must encode them as a tuple. For example, if you have mutually recursive predicates that take two arguments each, you would pass those arguments as `(arg1, arg2)` to the shared dispatcher.\n\nThis limitation exists because the mutual recursion compiler generates a shared dispatcher function that uses `@functools.cache` for memoization, and the current design accepts a single argument parameter alongside the predicate name. Multi-argument predicates require tuple encoding to fit this structure.\n\nFor more details on Python target recursion patterns, see `education/book-05-python-target/04_recursion_patterns.md`.", "answer_variant": "default", "answer_source": "education/book-05-python-target/04_recursion_patterns.md", "topics": ["mutual-recursion", "shared-dispatcher", "even-odd"], "original_answer": "## Mutual Recursion\n\nMutual recursion compiles to a shared dispatcher with memoization.\n\n### Example: Even/Odd\n\n```prolog\nis_even(0).\nis_even(N) :- N > 0, N1 is N - 1, is_odd(N1).\n\nis_odd(N) :- N > 0, N1 is N - 1, is_even(N1).\n```\n\n```python\n@functools.cache\ndef _mutual_dispatch(pred_name, arg):\n    if pred_name == 'is_even':\n        return _is_even_impl(arg)\n    elif pred_name == 'is_odd':\n        return _is_odd_impl(arg)\n    return None\n\ndef _is_even_impl(n):\n    if n == 0: return True\n    if n > 0:\n        return _mutual_dispatch('is_odd', n - 1)\n    return None\n```\n\n### Limitation\n\nCurrently supports **arity 1 predicates only**. For multi-argument mutual recursion, encode arguments as a tuple.", "answer_tailored": true}
