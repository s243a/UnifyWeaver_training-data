{"pair_id": "b6-c6-generator-mode_p0", "cluster_id": "b6-c6-generator-mode", "question": "What is generator mode in Go target?", "question_type": "medium", "answer": "Generator mode in Go target creates a complete Datalog engine that evaluates predicates using fixpoint iteration. When you use `mode(generator)`, UnifyWeaver compiles your Prolog predicate into Go code that iteratively computes facts until no new results are found.\n\nThis mode includes:\n- **Fixpoint computation**: Repeats evaluation rounds until reaching a stable state with no new facts\n- **Hash-indexed joins**: O(1) lookup performance using hash-based indexing\n- **Stratified negation**: Supports `\\+ goal` with proper validation\n- **Aggregation operations**: Built-in count, sum, min, max, and avg functions\n- **HAVING filters**: Post-aggregation filtering capabilities\n- **Concurrent execution**: Parallel processing across multiple goroutines\n- **Persistent storage**: Incremental BoltDB backend for fact persistence\n\nTo compile a predicate in generator mode:\n```prolog\ncompile_predicate_to_go(ancestor/2, [mode(generator)], Code).\n```\n\nCommon options include `workers(N)` for parallel goroutines, `db_backend(bbolt)` for BoltDB persistence, and `json_input(true)` to load facts from stdin.\n\nSee education/book-06-go-target/06_generator_mode.md for complete details on implementation and advanced usage.", "answer_variant": "default", "answer_source": "education/book-06-go-target/06_generator_mode.md", "topics": ["generator-mode", "fixpoint", "datalog"], "original_answer": "## Generator Mode (Fixpoint Datalog)\n\nGenerator mode creates a complete Datalog engine in Go.\n\n### Features\n\n| Feature | Description |\n|---------|-------------|\n| Core fixpoint | Iterative until no new facts |\n| Indexed joins | O(1) hash-based lookups |\n| Stratified negation | `\\+ goal` with validation |\n| Aggregation | count, sum, min, max, avg |\n| HAVING clause | Post-aggregation filtering |\n| Parallel execution | Multi-goroutine processing |\n| Database persistence | BoltDB incremental |\n\n### Basic Usage\n\n```prolog\ncompile_predicate_to_go(ancestor/2, [mode(generator)], Code).\n```\n\n### Options\n\n| Option | Description |\n|--------|-------------|\n| `workers(N)` | N parallel goroutines |\n| `db_backend(bbolt)` | BoltDB persistence |\n| `json_input(true)` | Load facts from stdin |", "answer_tailored": true}
{"pair_id": "b6-c6-generator-mode_p1", "cluster_id": "b6-c6-generator-mode", "question": "How does fixpoint evaluation work in Go?", "question_type": "medium", "answer": "Fixpoint evaluation in Go uses an iterative algorithm that repeatedly applies rules until no new facts can be derived. The generator mode implements this core fixpoint loop with several optimizations:\n\n**Iteration Process**: The engine cycles through all rules, generating new facts each iteration, and continues until a fixpoint is reached (no new facts are produced).\n\n**Performance Optimizations**:\n- **Indexed joins**: Hash-based lookups provide O(1) access to facts during rule evaluation\n- **Parallel execution**: Multiple goroutines can process rules concurrently using the `workers(N)` option\n- **Incremental persistence**: BoltDB backend saves facts incrementally with `db_backend(bbolt)`\n\n**Advanced Features**:\n- **Stratified negation**: Supports `\\+ goal` with proper stratification validation to ensure sound negation\n- **Aggregation**: Built-in support for count, sum, min, max, and avg operations\n- **HAVING clauses**: Post-aggregation filtering to refine results\n\nTo enable fixpoint evaluation, compile predicates with `mode(generator)`:\n```prolog\ncompile_predicate_to_go(ancestor/2, [mode(generator)], Code).\n```\n\nAdditional configuration options include `json_input(true)` for loading initial facts from stdin. For complete implementation details, see education/book-06-go-target/06_generator_mode.md.", "answer_variant": "default", "answer_source": "education/book-06-go-target/06_generator_mode.md", "topics": ["generator-mode", "fixpoint", "datalog"], "original_answer": "## Generator Mode (Fixpoint Datalog)\n\nGenerator mode creates a complete Datalog engine in Go.\n\n### Features\n\n| Feature | Description |\n|---------|-------------|\n| Core fixpoint | Iterative until no new facts |\n| Indexed joins | O(1) hash-based lookups |\n| Stratified negation | `\\+ goal` with validation |\n| Aggregation | count, sum, min, max, avg |\n| HAVING clause | Post-aggregation filtering |\n| Parallel execution | Multi-goroutine processing |\n| Database persistence | BoltDB incremental |\n\n### Basic Usage\n\n```prolog\ncompile_predicate_to_go(ancestor/2, [mode(generator)], Code).\n```\n\n### Options\n\n| Option | Description |\n|--------|-------------|\n| `workers(N)` | N parallel goroutines |\n| `db_backend(bbolt)` | BoltDB persistence |\n| `json_input(true)` | Load facts from stdin |", "answer_tailored": true}
{"pair_id": "b6-c6-generator-mode_p2", "cluster_id": "b6-c6-generator-mode", "question": "What features does Go generator mode support?", "question_type": "medium", "answer": "Go generator mode supports a comprehensive set of Datalog engine features:\n\n**Core Capabilities:**\n- **Fixpoint computation**: Iterates until no new facts are derived\n- **Indexed joins**: Hash-based O(1) lookups for efficient query processing\n- **Stratified negation**: Supports `\\+ goal` with proper validation\n- **Aggregation functions**: count, sum, min, max, and avg operations\n- **HAVING clauses**: Enables post-aggregation filtering\n\n**Performance & Scalability:**\n- **Parallel execution**: Multi-goroutine processing with configurable workers via `workers(N)` option\n- **Database persistence**: Incremental storage using BoltDB (enabled with `db_backend(bbolt)`)\n\n**Data Integration:**\n- **JSON input**: Load facts from stdin using `json_input(true)` option\n\nTo use generator mode, call `compile_predicate_to_go/3` with the `mode(generator)` option. For detailed examples and implementation guidance, see education/book-06-go-target/06_generator_mode.md.", "answer_variant": "default", "answer_source": "education/book-06-go-target/06_generator_mode.md", "topics": ["generator-mode", "fixpoint", "datalog"], "original_answer": "## Generator Mode (Fixpoint Datalog)\n\nGenerator mode creates a complete Datalog engine in Go.\n\n### Features\n\n| Feature | Description |\n|---------|-------------|\n| Core fixpoint | Iterative until no new facts |\n| Indexed joins | O(1) hash-based lookups |\n| Stratified negation | `\\+ goal` with validation |\n| Aggregation | count, sum, min, max, avg |\n| HAVING clause | Post-aggregation filtering |\n| Parallel execution | Multi-goroutine processing |\n| Database persistence | BoltDB incremental |\n\n### Basic Usage\n\n```prolog\ncompile_predicate_to_go(ancestor/2, [mode(generator)], Code).\n```\n\n### Options\n\n| Option | Description |\n|--------|-------------|\n| `workers(N)` | N parallel goroutines |\n| `db_backend(bbolt)` | BoltDB persistence |\n| `json_input(true)` | Load facts from stdin |", "answer_tailored": true}
{"pair_id": "b6-c6-aggregation-negation_p0", "cluster_id": "b6-c6-aggregation-negation", "question": "How do I use aggregation in Go generator mode?", "question_type": "medium", "answer": "In Go generator mode, you can use aggregation functions with `aggregate_all/4`. The basic pattern groups results and applies aggregate operations:\n\n```prolog\n% Sum salaries by department\ndept_total(Dept, Total) :-\n    aggregate_all(sum(S), salary(Dept, S), Dept, Total).\n```\n\nThe syntax is `aggregate_all(Function, GoalWithVariable, GroupByVariable, ResultVariable)`.\n\n### Supported Functions\n\nUnifyWeaver supports: `count`, `sum`, `min`, `max`, `avg`\n\n### Filtering Aggregated Results\n\nYou can add conditions after aggregation (similar to SQL's HAVING):\n\n```prolog\n% Only departments with total > 1000\ndept_high(Dept, Total) :-\n    aggregate_all(sum(S), salary(Dept, S), Dept, Total),\n    Total > 1000.\n```\n\n### Related Features\n\nGenerator mode also supports stratified negation with `\\+` (see education/book-06-go-target/06_generator_mode.md for the complete coverage).", "answer_variant": "default", "answer_source": "education/book-06-go-target/06_generator_mode.md", "topics": ["aggregation", "negation", "stratification"], "original_answer": "## Aggregation and Negation\n\n### Stratified Negation\n\n```prolog\n% Find paths that aren't blocked\npath(X, Y) :- edge(X, Y), \\+ blocked(X, Y).\npath(X, Z) :- edge(X, Y), \\+ blocked(X, Y), path(Y, Z).\n```\n\nCompiler validates no cycles in negation (stratification check).\n\n### Grouped Aggregation\n\n```prolog\n% Sum salaries by department\ndept_total(Dept, Total) :-\n    aggregate_all(sum(S), salary(Dept, S), Dept, Total).\n```\n\n### HAVING Clause\n\n```prolog\n% Only departments with total > 1000\ndept_high(Dept, Total) :-\n    aggregate_all(sum(S), salary(Dept, S), Dept, Total),\n    Total > 1000.\n```\n\n### Supported Aggregations\n\n`count`, `sum`, `min`, `max`, `avg`", "answer_tailored": true}
{"pair_id": "b6-c6-aggregation-negation_p1", "cluster_id": "b6-c6-aggregation-negation", "question": "How does stratified negation work?", "question_type": "medium", "answer": "Stratified negation in UnifyWeaver allows you to use negation-as-failure (`\\+`) in queries while ensuring logical consistency. The compiler performs stratification checks to verify there are no cycles involving negation.\n\nExample usage:\n\n```prolog\n% Find paths that aren't blocked\npath(X, Y) :- edge(X, Y), \\+ blocked(X, Y).\npath(X, Z) :- edge(X, Y), \\+ blocked(X, Y), path(Y, Z).\n```\n\nThe key requirement is that negated predicates must be fully defined before they're used in a negation context. This prevents logical contradictions where a predicate's truth value depends on its own negation.\n\nThe stratification validation happens at compile time, ensuring your negation usage forms a valid dependency hierarchy. See education/book-06-go-target/06_generator_mode.md for implementation details across different target languages.", "answer_variant": "default", "answer_source": "education/book-06-go-target/06_generator_mode.md", "topics": ["aggregation", "negation", "stratification"], "original_answer": "## Aggregation and Negation\n\n### Stratified Negation\n\n```prolog\n% Find paths that aren't blocked\npath(X, Y) :- edge(X, Y), \\+ blocked(X, Y).\npath(X, Z) :- edge(X, Y), \\+ blocked(X, Y), path(Y, Z).\n```\n\nCompiler validates no cycles in negation (stratification check).\n\n### Grouped Aggregation\n\n```prolog\n% Sum salaries by department\ndept_total(Dept, Total) :-\n    aggregate_all(sum(S), salary(Dept, S), Dept, Total).\n```\n\n### HAVING Clause\n\n```prolog\n% Only departments with total > 1000\ndept_high(Dept, Total) :-\n    aggregate_all(sum(S), salary(Dept, S), Dept, Total),\n    Total > 1000.\n```\n\n### Supported Aggregations\n\n`count`, `sum`, `min`, `max`, `avg`", "answer_tailored": true}
{"pair_id": "b6-c6-aggregation-negation_p2", "cluster_id": "b6-c6-aggregation-negation", "question": "What is the HAVING clause?", "question_type": "medium", "answer": "The HAVING clause in UnifyWeaver filters aggregated results based on computed values. It's implemented by placing conditions after the aggregation operation:\n\n```prolog\n% Filter departments where total salary exceeds 1000\ndept_high(Dept, Total) :-\n    aggregate_all(sum(S), salary(Dept, S), Dept, Total),\n    Total > 1000.\n```\n\nThis is equivalent to SQL's HAVING clause - the condition `Total > 1000` filters the grouped results after aggregation. Unlike WHERE clauses that filter rows before grouping, HAVING operates on the aggregated output.\n\nThe pattern works with any aggregation function (`count`, `sum`, `min`, `max`, `avg`) and can use multiple conditions on the computed values.\n\nFor more details on aggregation and grouping, see education/book-06-go-target/06_generator_mode.md.", "answer_variant": "default", "answer_source": "education/book-06-go-target/06_generator_mode.md", "topics": ["aggregation", "negation", "stratification"], "original_answer": "## Aggregation and Negation\n\n### Stratified Negation\n\n```prolog\n% Find paths that aren't blocked\npath(X, Y) :- edge(X, Y), \\+ blocked(X, Y).\npath(X, Z) :- edge(X, Y), \\+ blocked(X, Y), path(Y, Z).\n```\n\nCompiler validates no cycles in negation (stratification check).\n\n### Grouped Aggregation\n\n```prolog\n% Sum salaries by department\ndept_total(Dept, Total) :-\n    aggregate_all(sum(S), salary(Dept, S), Dept, Total).\n```\n\n### HAVING Clause\n\n```prolog\n% Only departments with total > 1000\ndept_high(Dept, Total) :-\n    aggregate_all(sum(S), salary(Dept, S), Dept, Total),\n    Total > 1000.\n```\n\n### Supported Aggregations\n\n`count`, `sum`, `min`, `max`, `avg`", "answer_tailored": true}
{"pair_id": "b6-c6-parallel-persistence_p0", "cluster_id": "b6-c6-parallel-persistence", "question": "How do I run Go generator mode in parallel?", "question_type": "medium", "answer": "To run Go generator mode in parallel, use the `workers(N)` option:\n\n```prolog\ncompile_predicate_to_go(ancestor/2, [\n    mode(generator),\n    workers(4)\n], Code).\n```\n\nThis distributes facts across multiple goroutines and collects results via channels. Set `N` to match your CPU core count for optimal performance.\n\nYou can combine parallel execution with database persistence:\n\n```prolog\ncompile_predicate_to_go(ancestor/2, [\n    mode(generator),\n    workers(4),\n    db_backend(bbolt),\n    db_file('ancestry.db')\n], Code).\n```\n\nThe first run computes and saves state to the database. Subsequent runs resume from the saved state, enabling incremental computation across parallel workers.\n\nFor more details on Go generator mode, see education/book-06-go-target/06_generator_mode.md.", "answer_variant": "default", "answer_source": "education/book-06-go-target/06_generator_mode.md", "topics": ["parallel", "goroutines", "boltdb", "persistence"], "original_answer": "## Parallel Execution and Persistence\n\n### Parallel Execution\n\n```prolog\ncompile_predicate_to_go(ancestor/2, [\n    mode(generator),\n    workers(4)\n], Code).\n```\n\nDistributes facts across goroutines, collects via channels.\n\n**Tip:** Use `workers(N)` where N = CPU cores.\n\n### Database Persistence\n\n```prolog\ncompile_predicate_to_go(ancestor/2, [\n    mode(generator),\n    db_backend(bbolt),\n    db_file('ancestry.db')\n], Code).\n```\n\n### Workflow\n\n```bash\n# First run - computes and saves\n./ancestor\n\n# Later runs - continue from saved state\necho '{\"relation\":\"parent\",...}' | ./ancestor\n```\n\nSubsequent runs start from existing database state (incremental computation).", "answer_tailored": true}
{"pair_id": "b6-c6-parallel-persistence_p1", "cluster_id": "b6-c6-parallel-persistence", "question": "How does database persistence work?", "question_type": "medium", "answer": "Database persistence in UnifyWeaver's Go target allows generator-mode predicates to save their state to disk and resume computation incrementally. You configure it using the `db_backend` and `db_file` options:\n\n```prolog\ncompile_predicate_to_go(ancestor/2, [\n    mode(generator),\n    db_backend(bbolt),\n    db_file('ancestry.db')\n], Code).\n```\n\nOn the first execution, the generated Go program computes results and persists them to the specified database file. Subsequent runs load the existing state and continue from where they left off, enabling incremental computation:\n\n```bash\n# Initial run - computes and stores results\n./ancestor\n\n# Follow-up runs - resume from saved state\necho '{\"relation\":\"parent\",...}' | ./ancestor\n```\n\nThis approach is particularly useful for long-running computations or when processing data in multiple stages. The `bbolt` backend provides efficient key-value storage for fact databases.", "answer_variant": "default", "answer_source": "education/book-06-go-target/06_generator_mode.md", "topics": ["parallel", "goroutines", "boltdb", "persistence"], "original_answer": "## Parallel Execution and Persistence\n\n### Parallel Execution\n\n```prolog\ncompile_predicate_to_go(ancestor/2, [\n    mode(generator),\n    workers(4)\n], Code).\n```\n\nDistributes facts across goroutines, collects via channels.\n\n**Tip:** Use `workers(N)` where N = CPU cores.\n\n### Database Persistence\n\n```prolog\ncompile_predicate_to_go(ancestor/2, [\n    mode(generator),\n    db_backend(bbolt),\n    db_file('ancestry.db')\n], Code).\n```\n\n### Workflow\n\n```bash\n# First run - computes and saves\n./ancestor\n\n# Later runs - continue from saved state\necho '{\"relation\":\"parent\",...}' | ./ancestor\n```\n\nSubsequent runs start from existing database state (incremental computation).", "answer_tailored": true}
{"pair_id": "b6-c6-parallel-persistence_p2", "cluster_id": "b6-c6-parallel-persistence", "question": "What is BoltDB persistence?", "question_type": "medium", "answer": "BoltDB (bbolt) is a persistence backend for UnifyWeaver's Go target that stores generator results to disk. When you specify `db_backend(bbolt)` and `db_file('ancestry.db')` in your compilation options, the generated Go code saves computed facts to a BoltDB database file.\n\nThis enables incremental computation across runs: the first execution computes and persists results, while subsequent runs resume from the saved state rather than recomputing everything. For example, running `./ancestor` initially builds the database, then later invocations like `echo '{\"relation\":\"parent\",...}' | ./ancestor` continue from where the previous run left off.\n\nThe persistence layer integrates with generator mode and can work alongside parallel execution (using `workers(N)` for goroutine distribution). See education/book-06-go-target/06_generator_mode.md for implementation details.", "answer_variant": "default", "answer_source": "education/book-06-go-target/06_generator_mode.md", "topics": ["parallel", "goroutines", "boltdb", "persistence"], "original_answer": "## Parallel Execution and Persistence\n\n### Parallel Execution\n\n```prolog\ncompile_predicate_to_go(ancestor/2, [\n    mode(generator),\n    workers(4)\n], Code).\n```\n\nDistributes facts across goroutines, collects via channels.\n\n**Tip:** Use `workers(N)` where N = CPU cores.\n\n### Database Persistence\n\n```prolog\ncompile_predicate_to_go(ancestor/2, [\n    mode(generator),\n    db_backend(bbolt),\n    db_file('ancestry.db')\n], Code).\n```\n\n### Workflow\n\n```bash\n# First run - computes and saves\n./ancestor\n\n# Later runs - continue from saved state\necho '{\"relation\":\"parent\",...}' | ./ancestor\n```\n\nSubsequent runs start from existing database state (incremental computation).", "answer_tailored": true}
