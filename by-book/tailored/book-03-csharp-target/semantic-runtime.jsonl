{"pair_id": "semantic-crawling_p0", "cluster_id": "semantic-crawling", "question": "What is semantic crawling in UnifyWeaver?", "question_type": "medium", "answer": "Semantic crawling in UnifyWeaver is an intelligent content discovery approach that uses **vector embeddings** to understand and filter content by meaning, rather than just following links indiscriminately.\n\nThe system consists of four core components working together:\n\n1. **`PtCrawler`**: Fetches and parses content from sources\n2. **`PtImporter`**: Stores objects and their embeddings in LiteDB\n3. **`OnnxEmbeddingProvider`**: Generates vector embeddings using a local ONNX transformer model\n4. **`PtSearcher`**: Performs cosine similarity search to find relevant content\n\nThe workflow starts with a source (XML or HTTP), which `PtCrawler` fetches and sends to `OnnxEmbeddingProvider` for vectorization. The resulting object and vector are stored via `PtImporter` in LiteDB. When users query, `PtSearcher` uses vector similarity to retrieve matching results.\n\n**Focused crawling** is a key feature: you provide a seed topic, the crawler fetches and embeds candidate pages, then only follows links where cosine similarity exceeds a threshold (typically 0.4). This creates highly targeted datasets without exhaustive downloading.\n\nThe embedder is configured by pointing to your ONNX model and vocabulary files:\n\n```csharp\nvar embedder = new OnnxEmbeddingProvider(\n    modelPath: \"models/model.onnx\",\n    vocabPath: \"models/vocab.txt\"\n);\n```\n\nFor implementation details, see education/book-03-csharp-target/05_semantic_crawling.md.", "answer_variant": "default", "answer_source": "education/book-03-csharp-target/05_semantic_crawling.md", "topics": ["semantic", "crawling", "embeddings", "onnx"], "original_answer": "## Semantic Crawling\n\nUnlike traditional crawlers, semantic crawlers use **vector embeddings** to understand content meaning.\n\n### Architecture Components\n\n1. **`PtCrawler`**: Orchestrator - fetches and parses content\n2. **`PtImporter`**: Storage - wraps LiteDB for objects + embeddings\n3. **`OnnxEmbeddingProvider`**: Brain - runs local ONNX transformer model\n4. **`PtSearcher`**: Retriever - cosine similarity search\n\n### Data Flow\n\n```\nSource (XML/HTTP) \u2192 PtCrawler \u2192 OnnxEmbeddingProvider\n                            \u2193\n              Object + Vector \u2192 PtImporter/LiteDB\n                            \u2193\nUser Query \u2192 PtSearcher \u2192 Vector Similarity \u2192 Results\n```\n\n### Configuring the Embedder\n\n```csharp\nvar embedder = new OnnxEmbeddingProvider(\n    modelPath: \"models/model.onnx\",\n    vocabPath: \"models/vocab.txt\"\n);\n```\n\n### Focused Crawling\n\n1. **Seed**: Start with topic category\n2. **Crawl**: Fetch children, embed titles\n3. **Filter**: Only follow if `CosineSimilarity > 0.4`\n4. **Store**: Save relevant pages\n\nCreates highly focused datasets without downloading everything.", "answer_tailored": true}
{"pair_id": "semantic-crawling_p1", "cluster_id": "semantic-crawling", "question": "How does the semantic runtime work?", "question_type": "medium", "answer": "The semantic runtime in UnifyWeaver's C# target uses vector embeddings to understand and match content by meaning rather than keywords. Here's how it operates:\n\n**Core Components**\n\n- **`OnnxEmbeddingProvider`**: Runs a local ONNX transformer model to convert text into vector embeddings\n- **`PtImporter`**: Handles storage using LiteDB, managing both objects and their embedding vectors\n- **`PtSearcher`**: Performs retrieval through cosine similarity matching\n- **`PtCrawler`**: Coordinates the fetching and parsing workflow\n\n**Runtime Flow**\n\nWhen processing content, the system:\n1. Fetches source material (XML/HTTP) via `PtCrawler`\n2. Generates embeddings through `OnnxEmbeddingProvider`\n3. Stores objects with their vectors in LiteDB via `PtImporter`\n4. Matches user queries by computing vector similarity in `PtSearcher`\n\n**Configuration Example**\n\n```csharp\nvar embedder = new OnnxEmbeddingProvider(\n    modelPath: \"models/model.onnx\",\n    vocabPath: \"models/vocab.txt\"\n);\n```\n\n**Intelligent Filtering**\n\nDuring crawling, the runtime uses semantic similarity (threshold typically 0.4) to decide which links to follow, creating focused datasets without exhaustive downloads. See education/book-03-csharp-target/05_semantic_crawling.md for the complete implementation details.", "answer_variant": "default", "answer_source": "education/book-03-csharp-target/05_semantic_crawling.md", "topics": ["semantic", "crawling", "embeddings", "onnx"], "original_answer": "## Semantic Crawling\n\nUnlike traditional crawlers, semantic crawlers use **vector embeddings** to understand content meaning.\n\n### Architecture Components\n\n1. **`PtCrawler`**: Orchestrator - fetches and parses content\n2. **`PtImporter`**: Storage - wraps LiteDB for objects + embeddings\n3. **`OnnxEmbeddingProvider`**: Brain - runs local ONNX transformer model\n4. **`PtSearcher`**: Retriever - cosine similarity search\n\n### Data Flow\n\n```\nSource (XML/HTTP) \u2192 PtCrawler \u2192 OnnxEmbeddingProvider\n                            \u2193\n              Object + Vector \u2192 PtImporter/LiteDB\n                            \u2193\nUser Query \u2192 PtSearcher \u2192 Vector Similarity \u2192 Results\n```\n\n### Configuring the Embedder\n\n```csharp\nvar embedder = new OnnxEmbeddingProvider(\n    modelPath: \"models/model.onnx\",\n    vocabPath: \"models/vocab.txt\"\n);\n```\n\n### Focused Crawling\n\n1. **Seed**: Start with topic category\n2. **Crawl**: Fetch children, embed titles\n3. **Filter**: Only follow if `CosineSimilarity > 0.4`\n4. **Store**: Save relevant pages\n\nCreates highly focused datasets without downloading everything.", "answer_tailored": true}
{"pair_id": "semantic-crawling_p2", "cluster_id": "semantic-crawling", "question": "What is OnnxEmbeddingProvider?", "question_type": "medium", "answer": "`OnnxEmbeddingProvider` is the component in UnifyWeaver's C# semantic crawling system that generates vector embeddings from text using a local ONNX transformer model. It acts as the \"brain\" of the crawler, converting textual content into numerical vectors that capture semantic meaning.\n\n### Configuration\n\nYou instantiate it by providing paths to the ONNX model and vocabulary files:\n\n```csharp\nvar embedder = new OnnxEmbeddingProvider(\n    modelPath: \"models/model.onnx\",\n    vocabPath: \"models/vocab.txt\"\n);\n```\n\n### Role in the Pipeline\n\nIn the semantic crawling workflow, `OnnxEmbeddingProvider` receives text from `PtCrawler` (the orchestrator that fetches and parses content) and produces embeddings that are stored alongside the original objects in LiteDB via `PtImporter`. These embeddings enable `PtSearcher` to perform cosine similarity searches for semantic retrieval.\n\n### Focused Crawling Usage\n\nDuring focused crawling, `OnnxEmbeddingProvider` embeds page titles so the crawler can filter links based on semantic relevance (e.g., only following links where `CosineSimilarity > 0.4` with the target topic), creating highly targeted datasets without exhaustive downloads.\n\nFor implementation details, see education/book-03-csharp-target/05_semantic_crawling.md.", "answer_variant": "default", "answer_source": "education/book-03-csharp-target/05_semantic_crawling.md", "topics": ["semantic", "crawling", "embeddings", "onnx"], "original_answer": "## Semantic Crawling\n\nUnlike traditional crawlers, semantic crawlers use **vector embeddings** to understand content meaning.\n\n### Architecture Components\n\n1. **`PtCrawler`**: Orchestrator - fetches and parses content\n2. **`PtImporter`**: Storage - wraps LiteDB for objects + embeddings\n3. **`OnnxEmbeddingProvider`**: Brain - runs local ONNX transformer model\n4. **`PtSearcher`**: Retriever - cosine similarity search\n\n### Data Flow\n\n```\nSource (XML/HTTP) \u2192 PtCrawler \u2192 OnnxEmbeddingProvider\n                            \u2193\n              Object + Vector \u2192 PtImporter/LiteDB\n                            \u2193\nUser Query \u2192 PtSearcher \u2192 Vector Similarity \u2192 Results\n```\n\n### Configuring the Embedder\n\n```csharp\nvar embedder = new OnnxEmbeddingProvider(\n    modelPath: \"models/model.onnx\",\n    vocabPath: \"models/vocab.txt\"\n);\n```\n\n### Focused Crawling\n\n1. **Seed**: Start with topic category\n2. **Crawl**: Fetch children, embed titles\n3. **Filter**: Only follow if `CosineSimilarity > 0.4`\n4. **Store**: Save relevant pages\n\nCreates highly focused datasets without downloading everything.", "answer_tailored": true}
{"pair_id": "semantic-crawling_p3", "cluster_id": "semantic-crawling", "question": "How does focused crawling work?", "question_type": "medium", "answer": "Focused crawling in UnifyWeaver uses semantic similarity to selectively navigate content:\n\n1. **Seed Topic**: Begin with an initial category or subject area\n2. **Fetch & Embed**: Retrieve child pages and generate vector embeddings for their titles\n3. **Similarity Filter**: Only follow links where cosine similarity exceeds a threshold (e.g., 0.4) against the target topic\n4. **Store Relevant Content**: Save pages that pass the filter to your dataset\n\nThis approach avoids downloading irrelevant content by using the **OnnxEmbeddingProvider** to evaluate each potential page before crawling it. The **PtCrawler** orchestrates the process, checking vector similarity at each step to stay on-topic.\n\nThe result is a highly targeted dataset focused on your specific subject matter, rather than a broad scrape of everything. For implementation details, see education/book-03-csharp-target/05_semantic_crawling.md.", "answer_variant": "default", "answer_source": "education/book-03-csharp-target/05_semantic_crawling.md", "topics": ["semantic", "crawling", "embeddings", "onnx"], "original_answer": "## Semantic Crawling\n\nUnlike traditional crawlers, semantic crawlers use **vector embeddings** to understand content meaning.\n\n### Architecture Components\n\n1. **`PtCrawler`**: Orchestrator - fetches and parses content\n2. **`PtImporter`**: Storage - wraps LiteDB for objects + embeddings\n3. **`OnnxEmbeddingProvider`**: Brain - runs local ONNX transformer model\n4. **`PtSearcher`**: Retriever - cosine similarity search\n\n### Data Flow\n\n```\nSource (XML/HTTP) \u2192 PtCrawler \u2192 OnnxEmbeddingProvider\n                            \u2193\n              Object + Vector \u2192 PtImporter/LiteDB\n                            \u2193\nUser Query \u2192 PtSearcher \u2192 Vector Similarity \u2192 Results\n```\n\n### Configuring the Embedder\n\n```csharp\nvar embedder = new OnnxEmbeddingProvider(\n    modelPath: \"models/model.onnx\",\n    vocabPath: \"models/vocab.txt\"\n);\n```\n\n### Focused Crawling\n\n1. **Seed**: Start with topic category\n2. **Crawl**: Fetch children, embed titles\n3. **Filter**: Only follow if `CosineSimilarity > 0.4`\n4. **Store**: Save relevant pages\n\nCreates highly focused datasets without downloading everything.", "answer_tailored": true}
{"pair_id": "vector-search_p0", "cluster_id": "vector-search", "question": "How does vector search work in UnifyWeaver?", "question_type": "medium", "answer": "UnifyWeaver's vector search finds documents based on conceptual similarity rather than exact keyword matches. Here's how it works:\n\n**Query Processing Flow:**\n1. Your query text gets converted into a 384-dimensional vector by the embedding model\n2. This query vector is compared against all stored document vectors using cosine similarity\n3. The system returns the top-K most similar documents ranked by similarity score\n\n**Default Embedding Model:**\n- Uses `all-MiniLM-L6-v2` from HuggingFace sentence-transformers\n- Produces 384-dimensional vector representations\n- Runs locally via ONNX Runtime (no external API calls)\n\n**Example in C#:**\n```csharp\nvar searcher = new PtSearcher(\"data.db\", embedder);\nvar results = searcher.SearchSimilar(\n    \"quantum physics applications\",\n    topK: 5\n);\n\nforeach (var result in results)\n{\n    Console.WriteLine($\"{result.Score:F4}: {result.Title}\");\n}\n```\n\n**Prolog Integration:**\n```prolog\nfind_relevant_seeds(Query, Seeds) :-\n    semantic_search(Query, 10, Results),\n    extract_ids(Results, Seeds).\n\ncrawl_topic(Topic) :-\n    find_relevant_seeds(Topic, Seeds),\n    crawler_run(Seeds, 3).  % Depth 3\n```\n\nThis allows queries like \"quantum physics applications\" to match documents about quantum computing, quantum mechanics, or quantum cryptography even without exact keyword overlap. For implementation details, see education/book-03-csharp-target/05_semantic_crawling.md.", "answer_variant": "default", "answer_source": "education/book-03-csharp-target/05_semantic_crawling.md", "topics": ["vector-search", "embeddings", "cosine-similarity", "litedb"], "original_answer": "## Vector Search\n\nFind documents **conceptually similar** to your query, not just keyword matches.\n\n### Performing a Search\n\n```csharp\nvar searcher = new PtSearcher(\"data.db\", embedder);\nvar results = searcher.SearchSimilar(\n    \"quantum physics applications\",\n    topK: 5\n);\n\nforeach (var result in results)\n{\n    Console.WriteLine($\"{result.Score:F4}: {result.Title}\");\n}\n```\n\n### Embedding Model\n\nDefault: `all-MiniLM-L6-v2`\n- 384-dimensional vectors\n- From HuggingFace sentence-transformers\n- Runs locally via ONNX Runtime\n\n### How It Works\n\n1. Query text \u2192 Embedder \u2192 384-dim vector\n2. Compare to stored vectors using cosine similarity\n3. Return top-K most similar documents\n\n### Prolog Definition\n\n```prolog\nfind_relevant_seeds(Query, Seeds) :-\n    semantic_search(Query, 10, Results),\n    extract_ids(Results, Seeds).\n\ncrawl_topic(Topic) :-\n    find_relevant_seeds(Topic, Seeds),\n    crawler_run(Seeds, 3).  % Depth 3\n```", "answer_tailored": true}
{"pair_id": "vector-search_p1", "cluster_id": "vector-search", "question": "What is cosine similarity search?", "question_type": "medium", "answer": "Cosine similarity search measures the conceptual similarity between your query and stored documents by comparing their vector representations. Rather than matching keywords, it finds documents that are semantically related.\n\n### How It Works\n\n1. Your query text is converted to a 384-dimensional vector using an embedding model (default: `all-MiniLM-L6-v2` from HuggingFace)\n2. This query vector is compared against all stored document vectors using cosine similarity\n3. Documents with the highest similarity scores are returned as the top-K results\n\nThe cosine similarity metric ranges from -1 to 1, where values closer to 1 indicate stronger semantic similarity. This approach catches conceptually related documents even when they use different terminology.\n\n### Example Usage\n\n```csharp\nvar searcher = new PtSearcher(\"data.db\", embedder);\nvar results = searcher.SearchSimilar(\n    \"quantum physics applications\",\n    topK: 5\n);\n\nforeach (var result in results)\n{\n    Console.WriteLine($\"{result.Score:F4}: {result.Title}\");\n}\n```\n\nThe embedding model runs locally via ONNX Runtime, producing 384-dimensional vectors for both queries and documents. See education/book-03-csharp-target/05_semantic_crawling.md for implementation details.", "answer_variant": "default", "answer_source": "education/book-03-csharp-target/05_semantic_crawling.md", "topics": ["vector-search", "embeddings", "cosine-similarity", "litedb"], "original_answer": "## Vector Search\n\nFind documents **conceptually similar** to your query, not just keyword matches.\n\n### Performing a Search\n\n```csharp\nvar searcher = new PtSearcher(\"data.db\", embedder);\nvar results = searcher.SearchSimilar(\n    \"quantum physics applications\",\n    topK: 5\n);\n\nforeach (var result in results)\n{\n    Console.WriteLine($\"{result.Score:F4}: {result.Title}\");\n}\n```\n\n### Embedding Model\n\nDefault: `all-MiniLM-L6-v2`\n- 384-dimensional vectors\n- From HuggingFace sentence-transformers\n- Runs locally via ONNX Runtime\n\n### How It Works\n\n1. Query text \u2192 Embedder \u2192 384-dim vector\n2. Compare to stored vectors using cosine similarity\n3. Return top-K most similar documents\n\n### Prolog Definition\n\n```prolog\nfind_relevant_seeds(Query, Seeds) :-\n    semantic_search(Query, 10, Results),\n    extract_ids(Results, Seeds).\n\ncrawl_topic(Topic) :-\n    find_relevant_seeds(Topic, Seeds),\n    crawler_run(Seeds, 3).  % Depth 3\n```", "answer_tailored": true}
{"pair_id": "vector-search_p2", "cluster_id": "vector-search", "question": "How do I search embedded data?", "question_type": "medium", "answer": "To search embedded data in UnifyWeaver's C# target, use the `PtSearcher` class for vector-based similarity search:\n\n```csharp\nvar searcher = new PtSearcher(\"data.db\", embedder);\nvar results = searcher.SearchSimilar(\n    \"quantum physics applications\",\n    topK: 5\n);\n\nforeach (var result in results)\n{\n    Console.WriteLine($\"{result.Score:F4}: {result.Title}\");\n}\n```\n\nThis performs **semantic search** rather than keyword matching\u2014finding documents conceptually related to your query.\n\n### Embedding Process\n\nThe system uses `all-MiniLM-L6-v2` (a HuggingFace sentence-transformer model) to convert text into 384-dimensional vectors. It runs locally through ONNX Runtime.\n\n**Search workflow:**\n1. Your query text gets embedded into a 384-dim vector\n2. Cosine similarity compares it against stored document vectors\n3. Top-K most similar results are returned\n\n### From Prolog\n\nYou can also trigger semantic search from Prolog queries:\n\n```prolog\nfind_relevant_seeds(Query, Seeds) :-\n    semantic_search(Query, 10, Results),\n    extract_ids(Results, Seeds).\n\ncrawl_topic(Topic) :-\n    find_relevant_seeds(Topic, Seeds),\n    crawler_run(Seeds, 3).  % Depth 3\n```\n\nFor implementation details, see education/book-03-csharp-target/05_semantic_crawling.md.", "answer_variant": "default", "answer_source": "education/book-03-csharp-target/05_semantic_crawling.md", "topics": ["vector-search", "embeddings", "cosine-similarity", "litedb"], "original_answer": "## Vector Search\n\nFind documents **conceptually similar** to your query, not just keyword matches.\n\n### Performing a Search\n\n```csharp\nvar searcher = new PtSearcher(\"data.db\", embedder);\nvar results = searcher.SearchSimilar(\n    \"quantum physics applications\",\n    topK: 5\n);\n\nforeach (var result in results)\n{\n    Console.WriteLine($\"{result.Score:F4}: {result.Title}\");\n}\n```\n\n### Embedding Model\n\nDefault: `all-MiniLM-L6-v2`\n- 384-dimensional vectors\n- From HuggingFace sentence-transformers\n- Runs locally via ONNX Runtime\n\n### How It Works\n\n1. Query text \u2192 Embedder \u2192 384-dim vector\n2. Compare to stored vectors using cosine similarity\n3. Return top-K most similar documents\n\n### Prolog Definition\n\n```prolog\nfind_relevant_seeds(Query, Seeds) :-\n    semantic_search(Query, 10, Results),\n    extract_ids(Results, Seeds).\n\ncrawl_topic(Topic) :-\n    find_relevant_seeds(Topic, Seeds),\n    crawler_run(Seeds, 3).  % Depth 3\n```", "answer_tailored": true}
{"pair_id": "vector-search_p3", "cluster_id": "vector-search", "question": "What model is used for embeddings?", "question_type": "medium", "answer": "The embedding model is `all-MiniLM-L6-v2` from HuggingFace's sentence-transformers library. It generates 384-dimensional vectors and runs locally using ONNX Runtime, so no external API calls are needed.\n\nThis model is used to convert both your query text and stored documents into vector representations, which are then compared using cosine similarity to find semantically related content.\n\nFor implementation details and examples of how the embedder integrates with UnifyWeaver's semantic search, see `education/book-03-csharp-target/05_semantic_crawling.md`.", "answer_variant": "default", "answer_source": "education/book-03-csharp-target/05_semantic_crawling.md", "topics": ["vector-search", "embeddings", "cosine-similarity", "litedb"], "original_answer": "## Vector Search\n\nFind documents **conceptually similar** to your query, not just keyword matches.\n\n### Performing a Search\n\n```csharp\nvar searcher = new PtSearcher(\"data.db\", embedder);\nvar results = searcher.SearchSimilar(\n    \"quantum physics applications\",\n    topK: 5\n);\n\nforeach (var result in results)\n{\n    Console.WriteLine($\"{result.Score:F4}: {result.Title}\");\n}\n```\n\n### Embedding Model\n\nDefault: `all-MiniLM-L6-v2`\n- 384-dimensional vectors\n- From HuggingFace sentence-transformers\n- Runs locally via ONNX Runtime\n\n### How It Works\n\n1. Query text \u2192 Embedder \u2192 384-dim vector\n2. Compare to stored vectors using cosine similarity\n3. Return top-K most similar documents\n\n### Prolog Definition\n\n```prolog\nfind_relevant_seeds(Query, Seeds) :-\n    semantic_search(Query, 10, Results),\n    extract_ids(Results, Seeds).\n\ncrawl_topic(Topic) :-\n    find_relevant_seeds(Topic, Seeds),\n    crawler_run(Seeds, 3).  % Depth 3\n```", "answer_tailored": true}
{"pair_id": "powershell-semantic_p0", "cluster_id": "powershell-semantic", "question": "What is the PowerShell Semantic Target?", "question_type": "medium", "answer": "The PowerShell Semantic Target provides a bridge between Prolog logic and the .NET ecosystem, particularly suited for enterprise Windows environments. While Python excels at \"Scripted AI,\" PowerShell focuses on \"Enterprise Integration.\"\n\n### Streaming XML with .NET Classes\n\nPowerShell leverages .NET's XmlReader for memory-efficient streaming:\n\n```powershell\nfunction Get-XmlStream {\n    param($Path, $Tags)\n    $reader = [System.Xml.XmlReader]::Create($Path)\n    try {\n        while ($reader.Read()) {\n            if ($reader.NodeType -eq 'Element' -and\n                $Tags -contains $reader.Name) {\n                $subReader = $reader.ReadSubtree()\n                $doc = [System.Xml.XmlDocument]::new()\n                $doc.Load($subReader)\n                # Emit to pipeline\n                @{ 'tag' = $doc.DocumentElement.Name }\n            }\n        }\n    } finally {\n        $reader.Dispose()\n    }\n}\n```\n\n### Approaches to Vector Similarity Search\n\n**Native PowerShell Approach (datasets under 10k)**\n```powershell\nfunction Get-CosineSimilarity ($v1, $v2) {\n    $dot = 0.0; $mag1 = 0.0; $mag2 = 0.0\n    for ($i = 0; $i -lt $v1.Count; $i++) {\n        $dot += $v1[$i] * $v2[$i]\n        $mag1 += $v1[$i] * $v1[$i]\n        $mag2 += $v2[$i] * $v2[$i]\n    }\n    return $dot / ([Math]::Sqrt($mag1) * [Math]::Sqrt($mag2))\n}\n```\n\n**ONNX Runtime Integration (production scale)**\n```powershell\nAdd-Type -Path \"bin/Microsoft.ML.OnnxRuntime.dll\"\n$session = [Microsoft.ML.OnnxRuntime.InferenceSession]::new(\"model.onnx\")\n```\n\nFor comprehensive coverage, see education/book-03-csharp-target/06_powershell_semantic.md.", "answer_variant": "default", "answer_source": "education/book-03-csharp-target/06_powershell_semantic.md", "topics": ["powershell", "xml", "vector", "dotnet"], "original_answer": "## PowerShell Semantic Target\n\nBridges Prolog logic with .NET ecosystem on Windows.\n\n**Python:** \"Scripted AI\"\n**PowerShell:** \"Enterprise Integration\"\n\n### XML Streaming with .NET\n\n```powershell\nfunction Get-XmlStream {\n    param($Path, $Tags)\n    $reader = [System.Xml.XmlReader]::Create($Path)\n    try {\n        while ($reader.Read()) {\n            if ($reader.NodeType -eq 'Element' -and\n                $Tags -contains $reader.Name) {\n                $subReader = $reader.ReadSubtree()\n                $doc = [System.Xml.XmlDocument]::new()\n                $doc.Load($subReader)\n                # Emit to pipeline\n                @{ 'tag' = $doc.DocumentElement.Name }\n            }\n        }\n    } finally {\n        $reader.Dispose()\n    }\n}\n```\n\n### Vector Search Strategies\n\n**Strategy A: Pure PowerShell (< 10k items)**\n```powershell\nfunction Get-CosineSimilarity ($v1, $v2) {\n    $dot = 0.0; $mag1 = 0.0; $mag2 = 0.0\n    for ($i = 0; $i -lt $v1.Count; $i++) {\n        $dot += $v1[$i] * $v2[$i]\n        $mag1 += $v1[$i] * $v1[$i]\n        $mag2 += $v2[$i] * $v2[$i]\n    }\n    return $dot / ([Math]::Sqrt($mag1) * [Math]::Sqrt($mag2))\n}\n```\n\n**Strategy B: ONNX Runtime (Production)**\n```powershell\nAdd-Type -Path \"bin/Microsoft.ML.OnnxRuntime.dll\"\n$session = [Microsoft.ML.OnnxRuntime.InferenceSession]::new(\"model.onnx\")\n```", "answer_tailored": true}
{"pair_id": "powershell-semantic_p1", "cluster_id": "powershell-semantic", "question": "How does PowerShell handle XML streaming?", "question_type": "medium", "answer": "PowerShell leverages .NET's `System.Xml.XmlReader` API for memory-efficient XML streaming. This approach allows processing large XML files without loading the entire document into memory.\n\n**Streaming Implementation:**\n\n```powershell\nfunction Get-XmlStream {\n    param($Path, $Tags)\n    $reader = [System.Xml.XmlReader]::Create($Path)\n    try {\n        while ($reader.Read()) {\n            if ($reader.NodeType -eq 'Element' -and\n                $Tags -contains $reader.Name) {\n                $subReader = $reader.ReadSubtree()\n                $doc = [System.Xml.XmlDocument]::new()\n                $doc.Load($subReader)\n                # Emit to pipeline\n                @{ 'tag' = $doc.DocumentElement.Name }\n            }\n        }\n    } finally {\n        $reader.Dispose()\n    }\n}\n```\n\nThe `XmlReader` moves forward through the document one node at a time. When it encounters a matching element tag, it reads just that subtree into an `XmlDocument` for processing, then continues streaming. The `try`/`finally` block ensures proper disposal of the reader resource.\n\nThis pattern is essential for UnifyWeaver's PowerShell target when handling large XML data sources, enabling efficient data extraction from enterprise systems. For more details on PowerShell's .NET integration, see education/book-03-csharp-target/.", "answer_variant": "default", "answer_source": "education/book-03-csharp-target/06_powershell_semantic.md", "topics": ["powershell", "xml", "vector", "dotnet"], "original_answer": "## PowerShell Semantic Target\n\nBridges Prolog logic with .NET ecosystem on Windows.\n\n**Python:** \"Scripted AI\"\n**PowerShell:** \"Enterprise Integration\"\n\n### XML Streaming with .NET\n\n```powershell\nfunction Get-XmlStream {\n    param($Path, $Tags)\n    $reader = [System.Xml.XmlReader]::Create($Path)\n    try {\n        while ($reader.Read()) {\n            if ($reader.NodeType -eq 'Element' -and\n                $Tags -contains $reader.Name) {\n                $subReader = $reader.ReadSubtree()\n                $doc = [System.Xml.XmlDocument]::new()\n                $doc.Load($subReader)\n                # Emit to pipeline\n                @{ 'tag' = $doc.DocumentElement.Name }\n            }\n        }\n    } finally {\n        $reader.Dispose()\n    }\n}\n```\n\n### Vector Search Strategies\n\n**Strategy A: Pure PowerShell (< 10k items)**\n```powershell\nfunction Get-CosineSimilarity ($v1, $v2) {\n    $dot = 0.0; $mag1 = 0.0; $mag2 = 0.0\n    for ($i = 0; $i -lt $v1.Count; $i++) {\n        $dot += $v1[$i] * $v2[$i]\n        $mag1 += $v1[$i] * $v1[$i]\n        $mag2 += $v2[$i] * $v2[$i]\n    }\n    return $dot / ([Math]::Sqrt($mag1) * [Math]::Sqrt($mag2))\n}\n```\n\n**Strategy B: ONNX Runtime (Production)**\n```powershell\nAdd-Type -Path \"bin/Microsoft.ML.OnnxRuntime.dll\"\n$session = [Microsoft.ML.OnnxRuntime.InferenceSession]::new(\"model.onnx\")\n```", "answer_tailored": true}
{"pair_id": "powershell-semantic_p2", "cluster_id": "powershell-semantic", "question": "How does vector search work in PowerShell?", "question_type": "medium", "answer": "PowerShell offers two approaches for vector search depending on your scale needs:\n\n**For smaller datasets (under 10k items)**, you can use pure PowerShell with cosine similarity:\n\n```powershell\nfunction Get-CosineSimilarity ($v1, $v2) {\n    $dot = 0.0; $mag1 = 0.0; $mag2 = 0.0\n    for ($i = 0; $i -lt $v1.Count; $i++) {\n        $dot += $v1[$i] * $v2[$i]\n        $mag1 += $v1[$i] * $v1[$i]\n        $mag2 += $v2[$i] * $v2[$i]\n    }\n    return $dot / ([Math]::Sqrt($mag1) * [Math]::Sqrt($mag2))\n}\n```\n\nThis calculates similarity scores between embedding vectors by computing the dot product normalized by vector magnitudes.\n\n**For production workloads**, leverage ONNX Runtime with .NET integration:\n\n```powershell\nAdd-Type -Path \"bin/Microsoft.ML.OnnxRuntime.dll\"\n$session = [Microsoft.ML.OnnxRuntime.InferenceSession]::new(\"model.onnx\")\n```\n\nThis bridges PowerShell with optimized ML inference engines, enabling efficient semantic search at scale.\n\nThe PowerShell target excels at enterprise integration, combining Windows automation with .NET's rich ecosystem. For XML data pipelines often used in semantic workflows, you can stream large files efficiently using `System.Xml.XmlReader` (see education/book-03-csharp-target/06_powershell_semantic.md for streaming examples).", "answer_variant": "default", "answer_source": "education/book-03-csharp-target/06_powershell_semantic.md", "topics": ["powershell", "xml", "vector", "dotnet"], "original_answer": "## PowerShell Semantic Target\n\nBridges Prolog logic with .NET ecosystem on Windows.\n\n**Python:** \"Scripted AI\"\n**PowerShell:** \"Enterprise Integration\"\n\n### XML Streaming with .NET\n\n```powershell\nfunction Get-XmlStream {\n    param($Path, $Tags)\n    $reader = [System.Xml.XmlReader]::Create($Path)\n    try {\n        while ($reader.Read()) {\n            if ($reader.NodeType -eq 'Element' -and\n                $Tags -contains $reader.Name) {\n                $subReader = $reader.ReadSubtree()\n                $doc = [System.Xml.XmlDocument]::new()\n                $doc.Load($subReader)\n                # Emit to pipeline\n                @{ 'tag' = $doc.DocumentElement.Name }\n            }\n        }\n    } finally {\n        $reader.Dispose()\n    }\n}\n```\n\n### Vector Search Strategies\n\n**Strategy A: Pure PowerShell (< 10k items)**\n```powershell\nfunction Get-CosineSimilarity ($v1, $v2) {\n    $dot = 0.0; $mag1 = 0.0; $mag2 = 0.0\n    for ($i = 0; $i -lt $v1.Count; $i++) {\n        $dot += $v1[$i] * $v2[$i]\n        $mag1 += $v1[$i] * $v1[$i]\n        $mag2 += $v2[$i] * $v2[$i]\n    }\n    return $dot / ([Math]::Sqrt($mag1) * [Math]::Sqrt($mag2))\n}\n```\n\n**Strategy B: ONNX Runtime (Production)**\n```powershell\nAdd-Type -Path \"bin/Microsoft.ML.OnnxRuntime.dll\"\n$session = [Microsoft.ML.OnnxRuntime.InferenceSession]::new(\"model.onnx\")\n```", "answer_tailored": true}
{"pair_id": "powershell-semantic_p3", "cluster_id": "powershell-semantic", "question": "When should I use PowerShell vs C#?", "question_type": "medium", "answer": "**Use PowerShell when:**\n- Working in Windows enterprise environments with Active Directory, Exchange, or Azure\n- You need tight .NET framework integration without compilation overhead\n- The task involves system administration, automation, or orchestration\n- Your team is already familiar with PowerShell scripting\n\n**Use C# when:**\n- You need maximum performance for compute-intensive operations\n- Building compiled applications or libraries that will be deployed\n- Type safety and compile-time checking are critical\n- You're developing cross-platform services or APIs\n\n**Performance considerations:**\n- For vector search with < 10k items, PowerShell's pure implementation works fine\n- For production workloads, both can leverage ONNX Runtime for ML inference\n- C# compiles to native code; PowerShell interprets at runtime\n\n**Integration patterns:**\nPowerShell excels at XML streaming and .NET ecosystem integration (see example implementations in education/book-03-csharp-target/06_powershell_semantic.md). C# provides better performance for computational tasks while PowerShell offers faster prototyping and script-based deployment.\n\n**In UnifyWeaver context:**\nThe Prolog compiler targets both - use PowerShell for enterprise automation scripts and C# for performance-critical runtime components. See education/book-02-bash-target/ for bash alternatives on Unix systems.", "answer_variant": "default", "answer_source": "education/book-03-csharp-target/06_powershell_semantic.md", "topics": ["powershell", "xml", "vector", "dotnet"], "original_answer": "## PowerShell Semantic Target\n\nBridges Prolog logic with .NET ecosystem on Windows.\n\n**Python:** \"Scripted AI\"\n**PowerShell:** \"Enterprise Integration\"\n\n### XML Streaming with .NET\n\n```powershell\nfunction Get-XmlStream {\n    param($Path, $Tags)\n    $reader = [System.Xml.XmlReader]::Create($Path)\n    try {\n        while ($reader.Read()) {\n            if ($reader.NodeType -eq 'Element' -and\n                $Tags -contains $reader.Name) {\n                $subReader = $reader.ReadSubtree()\n                $doc = [System.Xml.XmlDocument]::new()\n                $doc.Load($subReader)\n                # Emit to pipeline\n                @{ 'tag' = $doc.DocumentElement.Name }\n            }\n        }\n    } finally {\n        $reader.Dispose()\n    }\n}\n```\n\n### Vector Search Strategies\n\n**Strategy A: Pure PowerShell (< 10k items)**\n```powershell\nfunction Get-CosineSimilarity ($v1, $v2) {\n    $dot = 0.0; $mag1 = 0.0; $mag2 = 0.0\n    for ($i = 0; $i -lt $v1.Count; $i++) {\n        $dot += $v1[$i] * $v2[$i]\n        $mag1 += $v1[$i] * $v1[$i]\n        $mag2 += $v2[$i] * $v2[$i]\n    }\n    return $dot / ([Math]::Sqrt($mag1) * [Math]::Sqrt($mag2))\n}\n```\n\n**Strategy B: ONNX Runtime (Production)**\n```powershell\nAdd-Type -Path \"bin/Microsoft.ML.OnnxRuntime.dll\"\n$session = [Microsoft.ML.OnnxRuntime.InferenceSession]::new(\"model.onnx\")\n```", "answer_tailored": true}
