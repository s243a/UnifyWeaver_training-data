{"pair_id": "b5-c5-semantic-overview_p0", "cluster_id": "b5-c5-semantic-overview", "question": "What are semantic predicates in the Python target?", "question_type": "medium", "answer": "In the UnifyWeaver Python target, **semantic predicates** serve as the interface between Prolog's logical framework and modern AI capabilities. They allow compiled logic to trigger sophisticated data retrieval and generation tasks through a specialized Python runtime.\n\nThe following predicates are core to the Python target's semantic features:\n\n*   **`semantic_search/3`**: Performs vector similarity searches using the `PtSearcher` component.\n*   **`graph_search/4`**: Executes Graph RAG (Retrieval-Augmented Generation) queries via `PtSearcher`.\n*   **`crawler_run/2`**: Orchestrates web and XML data ingestion through the `PtCrawler`.\n*   **`upsert_object/3`**: Handles structured data persistence using the `PtImporter` component.\n*   **`llm_ask/3`**: Connects logic to Large Language Models via the `LLMProvider`.\n\nThe runtime architecture is structured to support these predicates by layering the generated Python script over specialized modules such as the `OnnxEmbeddingProvider` and `LLMProvider`, all backed by a SQLite database for efficient local storage and retrieval.\n\nDetailed technical specifications and usage examples can be found in `education/book-05-python-target/05_semantic_predicates.md`.", "answer_variant": "default", "answer_source": "education/book-05-python-target/05_semantic_predicates.md", "topics": ["semantic-predicates", "ai-features", "python-runtime"], "original_answer": "## Semantic Predicates\n\nSemantic predicates bridge Prolog logic with AI capabilities.\n\n| Predicate | Purpose | Runtime Component |\n|-----------|---------|-------------------|\n| `semantic_search/3` | Vector similarity | PtSearcher |\n| `graph_search/4` | Graph RAG | PtSearcher |\n| `crawler_run/2` | Web/XML crawling | PtCrawler |\n| `upsert_object/3` | Database storage | PtImporter |\n| `llm_ask/3` | LLM Q&A | LLMProvider |\n\n### Runtime Architecture\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    Generated Python Script      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 PtSearcher  PtCrawler  PtImporter\u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 OnnxEmbeddingProvider  LLMProvider\u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502        SQLite Database          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```", "answer_tailored": true}
{"pair_id": "b5-c5-semantic-overview_p1", "cluster_id": "b5-c5-semantic-overview", "question": "What AI capabilities does the Python runtime provide?", "question_type": "medium", "answer": "The UnifyWeaver Python runtime provides AI capabilities by bridging Prolog logic with specialized runtime components through semantic predicates. These features include:\n\n*   **Vector and Graph Retrieval**: `semantic_search/3` and `graph_search/4` leverage the `PtSearcher` component and `OnnxEmbeddingProvider` to perform similarity-based lookups and Graph RAG.\n*   **LLM Integration**: The `llm_ask/3` predicate allows for direct Q&A and reasoning via an `LLMProvider`.\n*   **Knowledge Acquisition**: Web and XML crawling is facilitated by `crawler_run/2` (`PtCrawler`), with data persisted using `upsert_object/3` (`PtImporter`) into a SQLite-backed store.\n\nThe runtime architecture integrates these components (PtSearcher, PtCrawler, PtImporter) alongside an OnnxEmbeddingProvider to support a robust, AI-enhanced execution environment. Detailed documentation on these predicates is available in `education/book-05-python-target/`.", "answer_variant": "default", "answer_source": "education/book-05-python-target/05_semantic_predicates.md", "topics": ["semantic-predicates", "ai-features", "python-runtime"], "original_answer": "## Semantic Predicates\n\nSemantic predicates bridge Prolog logic with AI capabilities.\n\n| Predicate | Purpose | Runtime Component |\n|-----------|---------|-------------------|\n| `semantic_search/3` | Vector similarity | PtSearcher |\n| `graph_search/4` | Graph RAG | PtSearcher |\n| `crawler_run/2` | Web/XML crawling | PtCrawler |\n| `upsert_object/3` | Database storage | PtImporter |\n| `llm_ask/3` | LLM Q&A | LLMProvider |\n\n### Runtime Architecture\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    Generated Python Script      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 PtSearcher  PtCrawler  PtImporter\u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 OnnxEmbeddingProvider  LLMProvider\u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502        SQLite Database          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```", "answer_tailored": true}
{"pair_id": "b5-c5-semantic-overview_p2", "cluster_id": "b5-c5-semantic-overview", "question": "How do semantic predicates work?", "question_type": "medium", "answer": "Semantic predicates work by mapping high-level Prolog logic to specialized AI and data-processing components within the Python runtime. They serve as the functional bridge that allows logical queries to trigger vector searches, web crawling, and LLM interactions.\n\nWhen compiled to Python, these predicates invoke specific runtime modules:\n\n| Predicate | Purpose | Runtime Component |\n|-----------|---------|-------------------|\n| `semantic_search/3` | Executes vector similarity lookups | PtSearcher |\n| `graph_search/4` | Performs Graph RAG operations | PtSearcher |\n| `crawler_run/2` | Initiates Web or XML data ingestion | PtCrawler |\n| `upsert_object/3` | Manages object storage in the database | PtImporter |\n| `llm_ask/3` | Directs queries to an LLM provider | LLMProvider |\n\nThe architecture relies on a generated Python script that orchestrates these components. It typically utilizes an `OnnxEmbeddingProvider` for local vectorization and a SQLite database for persistent storage. This setup ensures that semantic operations remain integrated with the project's broader logical framework.\n\nFor further implementation details, see the documentation in `education/book-05-python-target/`.", "answer_variant": "default", "answer_source": "education/book-05-python-target/05_semantic_predicates.md", "topics": ["semantic-predicates", "ai-features", "python-runtime"], "original_answer": "## Semantic Predicates\n\nSemantic predicates bridge Prolog logic with AI capabilities.\n\n| Predicate | Purpose | Runtime Component |\n|-----------|---------|-------------------|\n| `semantic_search/3` | Vector similarity | PtSearcher |\n| `graph_search/4` | Graph RAG | PtSearcher |\n| `crawler_run/2` | Web/XML crawling | PtCrawler |\n| `upsert_object/3` | Database storage | PtImporter |\n| `llm_ask/3` | LLM Q&A | LLMProvider |\n\n### Runtime Architecture\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    Generated Python Script      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 PtSearcher  PtCrawler  PtImporter\u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 OnnxEmbeddingProvider  LLMProvider\u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502        SQLite Database          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```", "answer_tailored": true}
{"pair_id": "b5-c5-vector-search_p0", "cluster_id": "b5-c5-vector-search", "question": "How does semantic_search/3 work?", "question_type": "medium", "answer": "`semantic_search/3` is the primary predicate used within the Python target to execute vector similarity searches against stored embeddings. It transforms a text query into a high-dimensional vector to find the most relevant records in the data store.\n\n### Operational Workflow\nThe predicate functions through a four-step process:\n1.  **Embedding Generation**: The query string is converted into a vector using an ONNX model (typically `all-MiniLM-L6-v2` for speed or `all-mpnet-base-v2` for accuracy).\n2.  **Cosine Similarity**: The system calculates the similarity between the query vector and the pre-computed embeddings of the stored documents.\n3.  **Top-K Selection**: The results are ranked, and the top $K$ items (as specified by the second argument) are selected.\n4.  **Data Enrichment**: The system fetches the full metadata for each matching record to populate the results.\n\n### Prolog Example\n```prolog\n% Find up to 10 records matching 'quantum physics'\nfind_physics_content(Results) :-\n    semantic_search('quantum physics', 10, Results).\n```\n\n### Result Structure\nThe matches are returned as a list of dictionaries containing the identifier, similarity score, and the original record data:\n```python\n[\n    {\n        'id': 'doc_123',\n        'score': 0.89,\n        'type': 'article',\n        'data': {'title': 'Quantum Entanglement', ...}\n    }\n]\n```\n\nDetailed documentation on vector search predicates can be found in `education/book-05-python-target/05_semantic_predicates.md`.", "answer_variant": "default", "answer_source": "education/book-05-python-target/05_semantic_predicates.md", "topics": ["semantic-search", "vector-search", "cosine-similarity"], "original_answer": "## Vector Search (semantic_search/3)\n\nPerforms vector similarity search against stored embeddings.\n\n### Prolog\n\n```prolog\nfind_physics_content(Results) :-\n    semantic_search('quantum physics', 10, Results).\n```\n\n### How It Works\n\n1. **Query embedding** - Convert query text to vector using ONNX\n2. **Cosine similarity** - Compare query vector against stored embeddings\n3. **Top-K selection** - Return K most similar items\n4. **Result enrichment** - Fetch full object data\n\n### Result Format\n\n```python\n[\n    {\n        'id': 'doc_123',\n        'score': 0.89,\n        'type': 'article',\n        'data': {'title': 'Quantum Entanglement', ...}\n    }\n]\n```\n\n### ONNX Models\n\n- `all-MiniLM-L6-v2` (384 dims, fast)\n- `all-mpnet-base-v2` (768 dims, higher quality)", "answer_tailored": true}
{"pair_id": "b5-c5-vector-search_p1", "cluster_id": "b5-c5-vector-search", "question": "What is vector similarity search?", "question_type": "medium", "answer": "Vector similarity search in UnifyWeaver is a mechanism for retrieving relevant information by comparing the mathematical representation (embedding) of a query against stored content. This allows the system to find documents based on meaning rather than just keyword matches, and it is implemented via the `semantic_search/3` predicate.\n\nIn Prolog, you can query the system like this:\n\n```prolog\nfind_physics_content(Results) :-\n    semantic_search('quantum physics', 10, Results).\n```\n\nThe search process involves four distinct stages:\n1. **Embedding Generation**: The query text is transformed into a numerical vector using an ONNX-based model.\n2. **Cosine Similarity**: The system calculates the distance between the query vector and pre-stored embeddings.\n3. **Top-K Ranking**: The 'K' most similar items are selected based on their similarity scores.\n4. **Data Enrichment**: The full object data associated with those vectors is retrieved.\n\nMatches are returned as a list of dictionary objects:\n\n```python\n[\n    {\n        'id': 'doc_123',\n        'score': 0.89,\n        'type': 'article',\n        'data': {'title': 'Quantum Entanglement', 'content': '...'}\n    }\n]\n```\n\nThe system typically utilizes ONNX models such as `all-MiniLM-L6-v2` for high-speed searches (384 dimensions) or `all-mpnet-base-v2` for higher-quality semantic mapping (768 dimensions). For a detailed breakdown of semantic predicates, refer to `education/book-05-python-target/05_semantic_predicates.md`.", "answer_variant": "default", "answer_source": "education/book-05-python-target/05_semantic_predicates.md", "topics": ["semantic-search", "vector-search", "cosine-similarity"], "original_answer": "## Vector Search (semantic_search/3)\n\nPerforms vector similarity search against stored embeddings.\n\n### Prolog\n\n```prolog\nfind_physics_content(Results) :-\n    semantic_search('quantum physics', 10, Results).\n```\n\n### How It Works\n\n1. **Query embedding** - Convert query text to vector using ONNX\n2. **Cosine similarity** - Compare query vector against stored embeddings\n3. **Top-K selection** - Return K most similar items\n4. **Result enrichment** - Fetch full object data\n\n### Result Format\n\n```python\n[\n    {\n        'id': 'doc_123',\n        'score': 0.89,\n        'type': 'article',\n        'data': {'title': 'Quantum Entanglement', ...}\n    }\n]\n```\n\n### ONNX Models\n\n- `all-MiniLM-L6-v2` (384 dims, fast)\n- `all-mpnet-base-v2` (768 dims, higher quality)", "answer_tailored": true}
{"pair_id": "b5-c5-vector-search_p2", "cluster_id": "b5-c5-vector-search", "question": "How are query embeddings generated?", "question_type": "medium", "answer": "Query embeddings are generated by transforming input text into numerical vectors using ONNX-optimized models within the Python target runtime. This process occurs automatically when executing semantic predicates like `semantic_search/3`.\n\n### The Generation Workflow\n1. **Model Inference**: The system passes the query string through an ONNX transformer model.\n2. **Vectorization**: The model converts the text into a high-dimensional vector that captures its semantic meaning.\n3. **Similarity Matching**: This query vector is then compared against stored document embeddings using cosine similarity to identify the top-K relevant results.\n\n### Supported Models\nThe runtime supports different ONNX models depending on the required balance between speed and accuracy:\n- **all-MiniLM-L6-v2**: Produces 384-dimensional vectors and is optimized for low latency.\n- **all-mpnet-base-v2**: Produces 768-dimensional vectors for higher retrieval quality.\n\nIn a Prolog query, the generation is handled transparently:\n```prolog\nfind_physics_content(Results) :-\n    semantic_search('quantum physics', 10, Results).\n```\n\nFor detailed implementation specifics regarding semantic predicates and vector generation, refer to `education/book-05-python-target/05_semantic_predicates.md`.", "answer_variant": "default", "answer_source": "education/book-05-python-target/05_semantic_predicates.md", "topics": ["semantic-search", "vector-search", "cosine-similarity"], "original_answer": "## Vector Search (semantic_search/3)\n\nPerforms vector similarity search against stored embeddings.\n\n### Prolog\n\n```prolog\nfind_physics_content(Results) :-\n    semantic_search('quantum physics', 10, Results).\n```\n\n### How It Works\n\n1. **Query embedding** - Convert query text to vector using ONNX\n2. **Cosine similarity** - Compare query vector against stored embeddings\n3. **Top-K selection** - Return K most similar items\n4. **Result enrichment** - Fetch full object data\n\n### Result Format\n\n```python\n[\n    {\n        'id': 'doc_123',\n        'score': 0.89,\n        'type': 'article',\n        'data': {'title': 'Quantum Entanglement', ...}\n    }\n]\n```\n\n### ONNX Models\n\n- `all-MiniLM-L6-v2` (384 dims, fast)\n- `all-mpnet-base-v2` (768 dims, higher quality)", "answer_tailored": true}
{"pair_id": "b5-c5-graph-rag_p0", "cluster_id": "b5-c5-graph-rag", "question": "What is Graph RAG?", "question_type": "medium", "answer": "Graph RAG (Graph Retrieval-Augmented Generation) in UnifyWeaver is implemented through the `graph_search/4` predicate, which facilitates multi-hop, relationship-aware retrieval. It goes beyond simple vector similarity by traversing the connections between data nodes to assemble a more comprehensive context.\n\n### Prolog Implementation\n\n```prolog\nget_graph_context(Query, Result) :-\n    graph_search(Query, 5, 2, Result).\n```\n\n### The Graph Retrieval Process\n\n1. **Anchor Selection**: Identifying the top-K nodes most similar to the query via vector search.\n2. **Neighbor Expansion**: Navigating the graph to find nodes directly connected to the anchors.\n3. **Hop Iteration**: Repeating the expansion process for a designated number of \"hops\" or steps.\n4. **Context Synthesis**: Gathering all discovered nodes into a hierarchical data structure.\n\n### Result Structure\n\nThe predicate returns a structured object (mapped to Python dictionaries) that categorizes the retrieved context:\n\n```python\n{\n    'anchors': [...],    # Primary vector search results\n    'parents': [...],    # Immediate parent nodes\n    'children': [...],   # Immediate child nodes\n    'hop_2': {           # Results from the second expansion level\n        'parents': [...],\n        'children': [...]\n    }\n}\n```\n\n### Configuration Guidelines\n\n* **1 Hop**: Fast and precise; best for simple relational lookups.\n* **2 Hops**: Often the optimal balance between depth and performance.\n* **3+ Hops**: Increases context richness but may introduce noise and higher latency.\n\nFor more details on implementing semantic search, refer to `education/book-05-python-target/05_semantic_predicates.md`.", "answer_variant": "default", "answer_source": "education/book-05-python-target/05_semantic_predicates.md", "topics": ["graph-search", "graph-rag", "multi-hop"], "original_answer": "## Graph Search (Graph RAG)\n\n`graph_search/4` performs multi-hop graph-based retrieval.\n\n### Prolog\n\n```prolog\nfind_context(Query, Context) :-\n    graph_search(Query, 5, 2, Context).\n```\n\n### How Graph Search Works\n\n1. **Anchor search** - Find top-K nodes via vector similarity\n2. **Expansion** - For each anchor, find connected nodes\n3. **Hop iteration** - Repeat expansion for specified hops\n4. **Context assembly** - Combine into structured result\n\n### Result Structure\n\n```python\n{\n    'anchors': [...],    # Most similar nodes\n    'parents': [...],    # Parent nodes\n    'children': [...],   # Child nodes\n    'hop_2': {\n        'parents': [...],\n        'children': [...]\n    }\n}\n```\n\n### Hop Guidelines\n\n- 1 hop: Fast, focused\n- 2 hops: Good balance\n- 3+ hops: Slow, may include noise", "answer_tailored": true}
{"pair_id": "b5-c5-graph-rag_p1", "cluster_id": "b5-c5-graph-rag", "question": "How does graph_search/4 work?", "question_type": "medium", "answer": "`graph_search/4` is a multi-hop retrieval predicate used for Graph RAG that combines vector similarity with graph traversal to gather deep context. It processes queries through a four-stage pipeline:\n\n1. **Anchor Identification**: The system finds the top-K nodes most similar to the query using vector embeddings.\n2. **Neighbor Expansion**: It identifies immediate parents and children for each anchor node.\n3. **Hop Iteration**: The expansion process repeats recursively based on the hop count specified in the predicate.\n4. **Context Assembly**: All retrieved nodes are organized into a hierarchical structure.\n\n### Prolog Implementation\nIn Prolog, you define the query, the number of anchors, and the hop depth:\n\n```prolog\n% Search with 5 anchors and 2 hops\nfind_context(Query, Context) :-\n    graph_search(Query, 5, 2, Context).\n```\n\n### Result Structure\nThe retrieved context is returned as a structured object (typically a Python dictionary):\n- `anchors`: The initial nodes found via similarity.\n- `parents` / `children`: Immediate graph neighbors.\n- `hop_2`: Additional layers of connectivity for deeper searches.\n\n### Hop Guidelines\n* **1 Hop**: Fast and highly relevant; best for direct lookups.\n* **2 Hops**: The recommended balance between performance and context breadth.\n* **3+ Hops**: Increases the risk of including irrelevant noise and increases latency.\n\nFor more information on implementing graph-based retrieval, refer to `education/book-05-python-target/05_semantic_predicates.md`.", "answer_variant": "default", "answer_source": "education/book-05-python-target/05_semantic_predicates.md", "topics": ["graph-search", "graph-rag", "multi-hop"], "original_answer": "## Graph Search (Graph RAG)\n\n`graph_search/4` performs multi-hop graph-based retrieval.\n\n### Prolog\n\n```prolog\nfind_context(Query, Context) :-\n    graph_search(Query, 5, 2, Context).\n```\n\n### How Graph Search Works\n\n1. **Anchor search** - Find top-K nodes via vector similarity\n2. **Expansion** - For each anchor, find connected nodes\n3. **Hop iteration** - Repeat expansion for specified hops\n4. **Context assembly** - Combine into structured result\n\n### Result Structure\n\n```python\n{\n    'anchors': [...],    # Most similar nodes\n    'parents': [...],    # Parent nodes\n    'children': [...],   # Child nodes\n    'hop_2': {\n        'parents': [...],\n        'children': [...]\n    }\n}\n```\n\n### Hop Guidelines\n\n- 1 hop: Fast, focused\n- 2 hops: Good balance\n- 3+ hops: Slow, may include noise", "answer_tailored": true}
{"pair_id": "b5-c5-graph-rag_p2", "cluster_id": "b5-c5-graph-rag", "question": "What are hops in graph search?", "question_type": "medium", "answer": "In UnifyWeaver's graph search, \"hops\" refer to the traversal steps taken to expand the retrieval context from initial anchor nodes through their relationships. Using the `graph_search/4` predicate, the system performs multi-hop Graph RAG by first finding similar nodes and then following graph edges (parents and children) to gather additional context.\n\n### The Multi-Hop Process\n1. **Anchor Search**: Locate the most relevant nodes via vector similarity.\n2. **Expansion**: Identify parents and children connected to the anchors.\n3. **Hop Iteration**: Repeat the expansion for the number of hops specified in the predicate.\n4. **Assembly**: Organize the gathered nodes into a structured context object.\n\n### Context Data Structure\n```python\n{\n    'anchors': [...],    # Core similarity matches\n    'parents': [...],    # Nodes one hop above\n    'children': [...],   # Nodes one hop below\n    'hop_2': {           # Second-level expansion\n        'parents': [...],\n        'children': [...]\n    }\n}\n```\n\n### Implementation Guidelines\n- **1 Hop**: Fast and highly focused.\n- **2 Hops**: Recommended for a balanced retrieval context.\n- **3+ Hops**: Slower execution and higher risk of including irrelevant data (noise).\n\nFor more information on implementing graph-based semantic predicates, see `education/book-05-python-target/05_semantic_predicates.md`.", "answer_variant": "default", "answer_source": "education/book-05-python-target/05_semantic_predicates.md", "topics": ["graph-search", "graph-rag", "multi-hop"], "original_answer": "## Graph Search (Graph RAG)\n\n`graph_search/4` performs multi-hop graph-based retrieval.\n\n### Prolog\n\n```prolog\nfind_context(Query, Context) :-\n    graph_search(Query, 5, 2, Context).\n```\n\n### How Graph Search Works\n\n1. **Anchor search** - Find top-K nodes via vector similarity\n2. **Expansion** - For each anchor, find connected nodes\n3. **Hop iteration** - Repeat expansion for specified hops\n4. **Context assembly** - Combine into structured result\n\n### Result Structure\n\n```python\n{\n    'anchors': [...],    # Most similar nodes\n    'parents': [...],    # Parent nodes\n    'children': [...],   # Child nodes\n    'hop_2': {\n        'parents': [...],\n        'children': [...]\n    }\n}\n```\n\n### Hop Guidelines\n\n- 1 hop: Fast, focused\n- 2 hops: Good balance\n- 3+ hops: Slow, may include noise", "answer_tailored": true}
{"pair_id": "b5-c5-crawling-llm_p0", "cluster_id": "b5-c5-crawling-llm", "question": "How do I crawl web pages with semantic predicates?", "question_type": "medium", "answer": "To crawl web pages using semantic predicates in UnifyWeaver, you use the `crawler_run/2` predicate. This initiates a multi-depth crawl starting from a list of seed URLs.\n\n```prolog\ncrawl_docs(Seeds) :-\n    crawler_run(['https://docs.example.com/'], 3).\n```\n\nThe crawling engine performs several automated tasks:\n- **Streaming Parsing**: Utilizes `lxml` for memory-efficient XML and HTML processing.\n- **Embedding Generation**: Automatically generates vector embeddings for discovered content.\n- **Graph Construction**: Maps the relationships between pages based on link structures.\n\nData is persisted in the underlying database using the following schema:\n- `objects`: Stores metadata and content in JSON format.\n- `embeddings`: Stores the associated vectors as BLOBs.\n- `links`: Tracks source and target IDs for graph traversal.\n\nYou can also manually store data using `upsert_object/3`:\n```prolog\nstore_item(Id, Label, Data) :-\n    upsert_object(Id, Label, _{text: Data}).\n```\n\nOnce the crawl is complete, you can query the gathered data using `graph_search/4` to retrieve context for an LLM via `llm_ask/3`:\n```prolog\nsemantic_query(Question, Answer) :-\n    graph_search(Question, 5, 2, Context),\n    llm_ask(Question, Context, Answer).\n```\n\nFor more implementation details on Python-based semantic predicates, see `education/book-05-python-target/05_semantic_predicates.md`.", "answer_variant": "default", "answer_source": "education/book-05-python-target/05_semantic_predicates.md", "topics": ["crawler", "llm-integration", "upsert"], "original_answer": "## Crawling and LLM Integration\n\n### Crawling (crawler_run/2)\n\n```prolog\ncrawl_documentation(Seeds) :-\n    crawler_run(['https://docs.example.com/'], 3).\n```\n\n- Streaming XML parsing with lxml\n- Automatic embedding generation\n- Graph construction from links\n\n### LLM Integration (llm_ask/3)\n\n```prolog\nanswer_question(Question, Answer) :-\n    graph_search(Question, 5, 2, Context),\n    llm_ask(Question, Context, Answer).\n```\n\nDefault implementation uses `gemini` CLI.\n\n### Database Storage (upsert_object/3)\n\n```prolog\nstore_article(Id, Title, Content) :-\n    upsert_object(Id, 'article', _{title: Title, content: Content}).\n```\n\n### Database Schema\n\n- `objects` - id, type, data (JSON)\n- `embeddings` - id, vector (BLOB)\n- `links` - source_id, target_id", "answer_tailored": true}
{"pair_id": "b5-c5-crawling-llm_p1", "cluster_id": "b5-c5-crawling-llm", "question": "How does LLM integration work?", "question_type": "medium", "answer": "LLM integration in UnifyWeaver's Python target is primarily handled through the `llm_ask/3` predicate, which allows Prolog logic to query large language models using retrieved context.\n\n### Core Implementation (llm_ask/3)\nThe standard pattern involves first performing a semantic retrieval to gather relevant background information, then passing that context along with the query to the LLM:\n\n```prolog\nanswer_question(Question, Answer) :-\n    graph_search(Question, 5, 2, Context),\n    llm_ask(Question, Context, Answer).\n```\nThe default execution environment utilizes the `gemini` CLI for these interactions.\n\n### Knowledge Base Preparation\nTo support effective LLM prompting, the system utilizes specialized predicates for data ingestion and retrieval:\n\n*   **Crawling (`crawler_run/2`)**: Automates the collection of documentation (e.g., `crawler_run(['https://docs.example.com/'], 3)`). This process includes streaming XML parsing with `lxml`, automatic generation of embeddings, and the construction of a link-based knowledge graph.\n*   **Data Persistence (`upsert_object/3`)**: Manages the storage of processed information into a structured schema consisting of `objects` (JSON metadata), `embeddings` (vector blobs), and `links` (relationship mappings).\n\nFor more details on implementing these semantic predicates and configuring the Python runtime, see `education/book-05-python-target/05_semantic_predicates.md`.", "answer_variant": "default", "answer_source": "education/book-05-python-target/05_semantic_predicates.md", "topics": ["crawler", "llm-integration", "upsert"], "original_answer": "## Crawling and LLM Integration\n\n### Crawling (crawler_run/2)\n\n```prolog\ncrawl_documentation(Seeds) :-\n    crawler_run(['https://docs.example.com/'], 3).\n```\n\n- Streaming XML parsing with lxml\n- Automatic embedding generation\n- Graph construction from links\n\n### LLM Integration (llm_ask/3)\n\n```prolog\nanswer_question(Question, Answer) :-\n    graph_search(Question, 5, 2, Context),\n    llm_ask(Question, Context, Answer).\n```\n\nDefault implementation uses `gemini` CLI.\n\n### Database Storage (upsert_object/3)\n\n```prolog\nstore_article(Id, Title, Content) :-\n    upsert_object(Id, 'article', _{title: Title, content: Content}).\n```\n\n### Database Schema\n\n- `objects` - id, type, data (JSON)\n- `embeddings` - id, vector (BLOB)\n- `links` - source_id, target_id", "answer_tailored": true}
{"pair_id": "b5-c5-crawling-llm_p2", "cluster_id": "b5-c5-crawling-llm", "question": "How do I store objects in the database?", "question_type": "medium", "answer": "To store objects in the database within the UnifyWeaver environment, you use the `upsert_object/3` predicate. This allows you to persist data by providing a unique identifier, an object type, and a Prolog dict representing the JSON data.\n\n### Implementation Example\n\n```prolog\nstore_article(Id, Title, Content) :-\n    upsert_object(Id, 'article', _{title: Title, content: Content}).\n```\n\n### Database Schema Structure\n\nThe system manages storage through three primary tables:\n- **objects**: Contains the `id`, `type`, and the actual `data` stored in JSON format.\n- **embeddings**: Associates the object `id` with its high-dimensional `vector` (stored as a BLOB).\n- **links**: Tracks relationships between objects using `source_id` and `target_id`.\n\nFor a complete guide on semantic predicates and database interactions, see `education/book-05-python-target/05_semantic_predicates.md`.", "answer_variant": "default", "answer_source": "education/book-05-python-target/05_semantic_predicates.md", "topics": ["crawler", "llm-integration", "upsert"], "original_answer": "## Crawling and LLM Integration\n\n### Crawling (crawler_run/2)\n\n```prolog\ncrawl_documentation(Seeds) :-\n    crawler_run(['https://docs.example.com/'], 3).\n```\n\n- Streaming XML parsing with lxml\n- Automatic embedding generation\n- Graph construction from links\n\n### LLM Integration (llm_ask/3)\n\n```prolog\nanswer_question(Question, Answer) :-\n    graph_search(Question, 5, 2, Context),\n    llm_ask(Question, Context, Answer).\n```\n\nDefault implementation uses `gemini` CLI.\n\n### Database Storage (upsert_object/3)\n\n```prolog\nstore_article(Id, Title, Content) :-\n    upsert_object(Id, 'article', _{title: Title, content: Content}).\n```\n\n### Database Schema\n\n- `objects` - id, type, data (JSON)\n- `embeddings` - id, vector (BLOB)\n- `links` - source_id, target_id", "answer_tailored": true}
