{"pair_id": "semantic-adversarial-001_p0", "cluster_id": "semantic-adversarial-001", "question": "How does UnifyWeaver protect against adversarial nodes?", "question_type": "medium", "answer": "UnifyWeaver protects the system from adversarial nodes through a combination of statistical filtering, ownership verification, and consensus-based validation:\n\n1. **Outlier Detection (Soft Collisions):** The system filters out results that are statistically anomalous compared to the rest of the embedding set.\n```python\ndef detect_outliers(embeddings, threshold=2.5):\n    distances = pairwise_distances(embeddings)\n    z_scores = (distances - distances.mean()) / distances.std()\n    return z_scores > threshold\n```\n\n2. **Region Locking (Hard Collisions):** Using a KSK-style registry, nodes are assigned specific embedding regions. The system verifies that a node is the legitimate \"owner\" of the region it is reporting on.\n```python\ndef verify_region_ownership(node_id, embedding, region_registry):\n    claimed_region = region_registry.get(node_id)\n    return claimed_region.contains(embedding)\n```\n\n3. **Consensus Voting:** To ensure integrity, the system requires a quorum of nodes to agree on a result before it is accepted.\n```python\ndef requires_quorum(result, min_agreeing_nodes=3):\n    agreeing = [n for n in nodes if n.agrees(result)]\n    return len(agreeing) >= min_agreeing_nodes\n```\n\nAdditionally, UnifyWeaver utilizes a two-dimensional trust management model (evaluating competence and benevolence) to adjust node weightings over time. Detailed implementation strategies are available in `education/book-13-semantic-search/`.", "answer_variant": "default", "answer_source": "book-13-semantic-search/11_adversarial_robustness.md", "topics": [], "original_answer": "Three defense mechanisms:\n\n**1. Soft Collisions (Outlier Detection):**\nReject results that are statistically anomalous:\n```python\ndef detect_outliers(embeddings, threshold=2.5):\n    distances = pairwise_distances(embeddings)\n    z_scores = (distances - distances.mean()) / distances.std()\n    return z_scores > threshold\n```\n\n**2. Hard Collisions (KSK-style Region Locking):**\nNodes claim responsibility for specific embedding regions:\n```python\ndef verify_region_ownership(node_id, embedding, region_registry):\n    claimed_region = region_registry.get(node_id)\n    return claimed_region.contains(embedding)\n```\n\n**3. Consensus Voting with Quorum:**\n```python\ndef requires_quorum(result, min_agreeing_nodes=3):\n    agreeing = [n for n in nodes if n.agrees(result)]\n    return len(agreeing) >= min_agreeing_nodes\n```\n\n**Trust management:** Direct trust + FMS two-dimensional (competence, benevolence).", "answer_tailored": true}
{"pair_id": "semantic-routing-001_p0", "cluster_id": "semantic-routing-001", "question": "What's the difference between greedy routing and Kleinberg routing?", "question_type": "medium", "answer": "The primary difference between greedy routing and Kleinberg routing lies in the required network topology and the resulting path length guarantees. While **greedy routing** is a simple mechanism that forwards a query to the closest neighbor without ensuring an efficient path, **Kleinberg routing** leverages a specific **small-world network structure** to achieve an expected path length of $O(\\log^2 n)$.\n\nTo function effectively, Kleinberg routing requires:\n*   **k_local**: Nearest-neighbor connections to ensure local connectivity.\n*   **k_long**: Long-range shortcuts assigned based on a probability distribution ($P \\sim 1/\\text{distance}^\\alpha$).\n\nWithout these structured shortcuts, the system defaults to basic greedy routing with no efficiency guarantees. When the proper structure is present, the routing becomes significantly more scalable.\n\n```prolog\n% Generating a proper small-world network for Kleinberg routing\n?- compile_small_world_proper_python([\n       k_local(10),\n       k_long(5),\n       alpha(2.0),\n       angle_ordering(cosine_based)\n   ], Code).\n```\n\nWhile Kleinberg routing relies on these specific shortcuts, modern implementations often use **HNSW (Hierarchical Navigable Small World)** to achieve $O(\\log n)$ scaling through layered structures and tunable $M$ parameters. Detailed implementation strategies can be found in `education/book-13-semantic-search/13_advanced_routing.md`.", "answer_variant": "default", "answer_source": "book-13-semantic-search/13_advanced_routing.md", "topics": [], "original_answer": "**Greedy routing:** Forward to the closest neighbor. Simple but no path length guarantees.\n\n**Kleinberg routing:** Requires proper **small-world network structure**:\n- `k_local`: Nearest-neighbor connections for local connectivity\n- `k_long`: Probability-weighted long-range shortcuts (P ~ 1/distance^\u03b1)\n\n**Without proper structure:** Only greedy routing\n**With proper structure:** O(log\u00b2n) expected path length\n\n```prolog\n% Generate proper small-world network\n?- compile_small_world_proper_python([\n       k_local(10),\n       k_long(5),\n       alpha(2.0),\n       angle_ordering(cosine_based)\n   ], Code).\n```\n\n**HNSW (Hierarchical Navigable Small World):**\nLayered structure with tunable M parameter:\n- Higher M = better recall, more memory\n- Lower M = faster search, less recall\n\nO(log n) scaling for both search and construction.", "answer_tailored": true}
{"pair_id": "semantic-scalefree-001_p0", "cluster_id": "semantic-scalefree-001", "question": "What are scale-free multi-interface nodes?", "question_type": "medium", "answer": "Scale-free multi-interface nodes are architectural components in UnifyWeaver where the number of interfaces per node follows a power-law distribution ($P(k) \\propto k^{-\\gamma}$). This structure mirrors real-world scale-free networks, such as web traffic patterns, where a small number of high-capacity \"hubs\" coexist with a large population of specialized \"leaf\" nodes.\n\nUsing a typical distribution ($\\gamma = 2.5$), the node hierarchy consists of:\n*   **Leaf Specialists (1-2 interfaces):** Approximately 60% of nodes.\n*   **Mid-tier (3-5 interfaces):** Approximately 25% of nodes.\n*   **Regional Hubs (6-20 interfaces):** Approximately 12% of nodes.\n*   **Major Hubs (20+ interfaces):** Approximately 3% of nodes.\n\nThis design provides several technical advantages:\n1.  **Capacity-Proportional Sizing:** Resources are allocated based on traffic demands, with hubs handling high-volume routing while leaves focus on specialized tasks.\n2.  **Unified Binary Search:** Enables $O(\\log n)$ lookup performance across all interfaces within a node.\n3.  **Internal Shortcuts:** Facilitates efficient routing between related interfaces co-located on the same node.\n\nYou can generate these nodes using the Go target compiler in Prolog:\n```prolog\n?- compile_multi_interface_node_go([\n       gamma(2.5),\n       min_interfaces(1),\n       max_interfaces(100),\n       unified_search(true)\n   ], Code).\n```\n\nFor more details on network topology and semantic scaling, refer to `education/book-13-semantic-search/`.", "answer_variant": "default", "answer_source": "book-13-semantic-search/14_scale_free_networks.md", "topics": [], "original_answer": "Power-law distribution of interfaces per node:\n\n```\nP(k) \u221d k^(-\u03b3)  where k = interface count\n```\n\n**Distribution with gamma=2.5:**\n- ~60% nodes: 1-2 interfaces (leaf specialists)\n- ~25% nodes: 3-5 interfaces (mid-tier)\n- ~12% nodes: 6-20 interfaces (regional hubs)\n- ~3% nodes: 20+ interfaces (major hubs)\n\n**Benefits:**\n1. **Capacity-proportional sizing:** Hubs handle more traffic, leaves specialize\n2. **Unified binary search:** O(log n) lookup across all interfaces\n3. **Internal shortcuts:** Related interfaces on same node\n\n```prolog\n?- compile_multi_interface_node_go([\n       gamma(2.5),\n       min_interfaces(1),\n       max_interfaces(100),\n       unified_search(true)\n   ], Code).\n```\n\nMirrors web traffic patterns: few high-traffic hubs, many specialized sites.", "answer_tailored": true}
