{"pair_id": "ai-multihead-001_p0", "cluster_id": "ai-multihead-001", "question": "What is multi-head routing in LDA?", "question_type": "medium", "answer": "Multi-head routing is a retrieval strategy in UnifyWeaver\u2019s LDA system that utilizes multiple specialized \"heads\" instead of a single global projection. Each head is optimized for a specific cluster of related topics\u2014such as authentication, data handling, or performance\u2014allowing for more granular and accurate semantic mapping.\n\n```\n                    Query\n                      \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u25bc             \u25bc             \u25bc\n   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n   \u2502 Head 1  \u2502   \u2502 Head 2  \u2502   \u2502 Head 3  \u2502\n   \u2502 (Auth)  \u2502   \u2502 (Data)  \u2502   \u2502 (Perf)  \u2502\n   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518\n        \u2502             \u2502             \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                      \u25bc\n              Weighted Combination\n                      \u2502\n                      \u25bc\n               Projected Query\n```\n\nIn this architecture, each individual head stores:\n1. **Centroid**: The mean embedding of the questions associated with that specific cluster.\n2. **Answer embedding**: The embedding for the corresponding answer in that cluster.\n\n```python\nhead = {\n    'centroid': np.mean(question_embeddings, axis=0),  # (d,)\n    'answer_emb': answer_embedding                      # (d,)\n}\n```\n\nThe system generates the final projected query by calculating a weighted combination of these heads. This approach ensures that the retrieval mechanism is sensitive to the distinct semantic regions of the codebase and documentation. For a deeper dive into this architecture, see `education/book-14-ai-training/04_multi_head_routing.md`.", "answer_variant": "default", "answer_source": "book-14-ai-training/04_multi_head_routing.md", "topics": [], "original_answer": "Instead of one global projection, **multiple heads** each specialized for a cluster of related questions:\n\n```\n                    Query\n                      \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u25bc             \u25bc             \u25bc\n   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n   \u2502 Head 1  \u2502   \u2502 Head 2  \u2502   \u2502 Head 3  \u2502\n   \u2502 (Auth)  \u2502   \u2502 (Data)  \u2502   \u2502 (Perf)  \u2502\n   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518\n        \u2502             \u2502             \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                      \u25bc\n              Weighted Combination\n                      \u2502\n                      \u25bc\n               Projected Query\n```\n\n**Each head stores:**\n1. **Centroid**: Mean embedding of questions in this cluster\n2. **Answer embedding**: The answer for this cluster\n\n```python\nhead = {\n    'centroid': np.mean(question_embeddings, axis=0),  # (d,)\n    'answer_emb': answer_embedding                      # (d,)\n}\n```", "answer_tailored": true}
{"pair_id": "ai-multihead-001_p0", "cluster_id": "ai-multihead-001", "question": "How does temperature control routing sharpness?", "question_type": "medium", "answer": "Temperature ($\\tau$) determines the sharpness of query routing by scaling the similarity scores between a query and head centroids before they are processed by the softmax function. By modulating this parameter, you can transition between \"winner-take-all\" behavior and uniform distribution:\n\n| Temperature ($\\tau$) | Routing Sharpness | Primary Use Case |\n| :--- | :--- | :--- |\n| 0.01 | Nearly hard routing | Strictly distinct clusters |\n| 0.1 | Sharp but soft | **Recommended default** |\n| 1.0 | Soft blending | Significant cluster overlap |\n| 10.0 | Nearly uniform | High regularization |\n\n**Impact on Weight Distribution:**\n*   **Sharp Routing ($\\tau=0.1$):** Assigns high confidence to the primary match (e.g., `[0.85, 0.10, 0.05]`).\n*   **Soft Routing ($\\tau=1.0$):** Spreads influence across multiple candidates (e.g., `[0.45, 0.30, 0.25]`).\n\n**Softmax Implementation with Temperature:**\n```python\ndef route_query(query_emb, heads, temperature=0.1):\n    # Scale similarities by temperature to control distribution contrast\n    similarities = [np.dot(query_norm, centroid_norm) for head in heads]\n    scaled = similarities / temperature\n    \n    # Stable softmax calculation\n    exp_scaled = np.exp(scaled - np.max(scaled))\n    weights = exp_scaled / np.sum(exp_scaled)\n    return weights\n```\n\nFor more details on configuring routing behavior and head specialization, see `education/book-14-ai-training/04_multi_head_routing.md`.", "answer_variant": "default", "answer_source": "book-14-ai-training/04_multi_head_routing.md", "topics": [], "original_answer": "Temperature \u03c4 controls how sharply queries route to heads:\n\n| Temperature | Behavior | Use Case |\n|-------------|----------|----------|\n| \u03c4 = 0.01 | Nearly hard routing (winner-take-all) | Distinct clusters |\n| \u03c4 = 0.1 | Sharp but soft | **Recommended default** |\n| \u03c4 = 1.0 | Soft blending | Overlapping clusters |\n| \u03c4 = 10.0 | Nearly uniform | Regularization |\n\n**Example weights:**\n```python\n# Sharp routing (\u03c4=0.1): weights = [0.85, 0.10, 0.05]\n# Soft routing (\u03c4=1.0):  weights = [0.45, 0.30, 0.25]\n```\n\n**Temperature-controlled softmax:**\n```python\ndef route_query(query_emb, heads, temperature=0.1):\n    similarities = [np.dot(query_norm, centroid_norm) for head in heads]\n    scaled = similarities / temperature\n    exp_scaled = np.exp(scaled - np.max(scaled))  # stability\n    weights = exp_scaled / np.sum(exp_scaled)\n    return weights\n```", "answer_tailored": true}
{"pair_id": "ai-multihead-001_p0", "cluster_id": "ai-multihead-001", "question": "How is multi-head LDA related to transformer attention?", "question_type": "medium", "answer": "Multi-head LDA shares a direct structural relationship with transformer attention, as both serve as learned routing mechanisms for information retrieval and projection. The components map as follows:\n\n| LDA Multi-Head Component | Transformer Attention Equivalent |\n|--------------------------|----------------------------------|\n| Centroids                | Keys (K)                         |\n| Answer Embeddings        | Values (V)                       |\n| Query Embedding          | Query (Q)                        |\n| softmax(sim/\u03c4)           | softmax(QK^T/\u221ad)                 |\n| \u03a3 weights \u00d7 answers      | Attention Output                 |\n\nIn practice, the multi-head projection calculates a weighted combination of answer embeddings based on the query's similarity to the head centroids:\n\n```python\ndef project_multi_head(query_emb, heads, temperature=0.1):\n    weights = route_query(query_emb, heads, temperature)\n    \n    # Weighted aggregation of head-specific answer embeddings\n    projected = np.zeros_like(query_emb)\n    for i, head in enumerate(heads):\n        projected += weights[i] * head['answer_emb']\n    \n    return projected\n```\n\nFor further details on these architectural parallels and their implementation, see `education/book-14-ai-training/04_multi_head_routing.md`.", "answer_variant": "default", "answer_source": "book-14-ai-training/04_multi_head_routing.md", "topics": [], "original_answer": "Multi-head LDA is structurally identical to attention:\n\n| LDA Multi-Head | Transformer Attention |\n|----------------|----------------------|\n| Centroids | Keys (K) |\n| Answer embeddings | Values (V) |\n| Query embedding | Query (Q) |\n| softmax(sim/\u03c4) | softmax(QK^T/\u221ad) |\n| \u03a3 weights \u00d7 answers | Attention output |\n\nThis isn't coincidence\u2014both are learned routing mechanisms!\n\n**Multi-head projection formula:**\n```python\ndef project_multi_head(query_emb, heads, temperature=0.1):\n    weights = route_query(query_emb, heads, temperature)\n    \n    # Weighted combination of answer embeddings\n    projected = np.zeros_like(query_emb)\n    for i, head in enumerate(heads):\n        projected += weights[i] * head['answer_emb']\n    \n    return projected\n```", "answer_tailored": true}
