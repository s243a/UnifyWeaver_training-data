{"pair_id": "ai-deploy-001_p0", "cluster_id": "ai-deploy-001", "question": "How do I deploy LDA models across different runtimes?", "question_type": "medium", "answer": "To deploy LDA models across different runtimes in UnifyWeaver, you use a \"train once, deploy anywhere\" workflow where models developed in Python are exported to a universal storage format compatible with Python, Go, and Rust.\n\n**Universal Storage Format:**\nThe deployment structure relies on SQLite for metadata and NPY files for numerical data, as NPY acts as a cross-platform binary \"lingua franca\":\n*   `lda.db`: SQLite database for schema and metadata.\n*   `embeddings/{model_name}/`: Contains `.npy` files for cluster centroids (`mh_{id}_cluster_{n}_centroid.npy`) and answer embeddings (`mh_{id}_cluster_{n}_answer.npy`).\n\n**Runtime Selection:**\n*   **Python (NumPy):** Best for training, notebooks, and rapid experimentation.\n*   **Go (ONNX):** Ideal for microservices, CLIs, and easy cross-compilation.\n*   **Rust (ndarray):** Optimized for performance-critical applications, embedded systems, or WASM.\n\n**Performance Overview (18 heads, 1000 queries):**\n| Runtime | Single Query | Batch (32) |\n|---------|-------------|------------|\n| Python (NumPy) | 0.046 ms | 0.046 ms |\n| Go (ONNX) | 0.12 ms | 0.08 ms |\n| Rust (ndarray) | 0.03 ms | 0.02 ms |\n\nFor comprehensive details on cross-target deployment strategies, refer to `education/book-14-ai-training/07_cross_target_deployment.md`.", "answer_variant": "default", "answer_source": "book-14-ai-training/07_cross_target_deployment.md", "topics": [], "original_answer": "Train once in Python, deploy in Python/Go/Rust:\n\n**Universal storage format:**\n```\nlda.db                    # SQLite (schema, metadata)\nembeddings/\n\u2514\u2500\u2500 {model_name}/\n    \u251c\u2500\u2500 mh_{id}_cluster_{n}_centroid.npy  # Cluster centroids\n    \u2514\u2500\u2500 mh_{id}_cluster_{n}_answer.npy    # Answer embeddings\n```\n\n**NPY files are the lingua franca** - simple binary format readable by all targets.\n\n| Runtime | Best For |\n|---------|---------|\n| Python | Training, experimentation, notebooks |\n| Go | Microservices, CLIs, cross-compilation |\n| Rust | Performance-critical apps, embedded, WASM |\n\n**Performance (18 heads, 1000 queries):**\n| Runtime | Single Query | Batch (32) |\n|---------|-------------|------------|\n| Python (NumPy) | 0.046 ms | 0.046 ms |\n| Go (ONNX) | 0.12 ms | 0.08 ms |\n| Rust (ndarray) | 0.03 ms | 0.02 ms |", "answer_tailored": true}
{"pair_id": "ai-deploy-001_p0", "cluster_id": "ai-deploy-001", "question": "How do I load multi-head projections in Go and Rust?", "question_type": "medium", "answer": "Loading multi-head projections in Go and Rust follows a standardized discovery pattern that uses a projection ID to locate and initialize cluster centroids from NPY files.\n\n**The Unified Discovery Pattern:**\n1. Fetch the `mh_projection_id` from your environment or configuration file.\n2. Perform a glob search for files following the naming convention: `mh_{id}_cluster_*_centroid.npy`.\n3. Extract the cluster IDs directly from the discovered filenames.\n4. Load the centroid and answer NPY data for every identified cluster.\n\n**Go Implementation:**\nUtilize the `projection.LoadMultiHead` function with the appropriate configuration:\n```go\n// Initialize the multi-head projection from the embeddings directory\nproj, err := projection.LoadMultiHead(projection.Config{\n    DataDir:        \"embeddings/all-MiniLM-L6-v2\",\n    MHProjectionID: 1,\n    Temperature:    0.1,\n})\nif err != nil {\n    panic(err)\n}\n\nqueryEmb := embedder.Embed(\"How do I authenticate?\")\nprojected, weights := proj.Project(queryEmb)\nresults := searcher.Search(projected, 10)\n```\n\n**Rust Implementation:**\nIn Rust, the `MultiHeadProjection::load_unified` method simplifies the initialization process:\n```rust\n// Load the unified model using the projection ID and temperature settings\nlet proj = MultiHeadProjection::load_unified(\n    \"embeddings/all-MiniLM-L6-v2\",\n    1,    // mh_projection_id\n    0.1   // temperature\n)?;\n\nlet query_emb = embedder.embed(\"How do I authenticate?\")?;\nlet (projected, weights) = proj.project(&query_emb);\nlet results = searcher.vector_search_with_projection(&query_emb, Some(&proj), 10)?;\n```\n\nFor more details on managing multi-head projections across different platforms, see the documentation in `education/book-14-ai-training/`.", "answer_variant": "default", "answer_source": "book-14-ai-training/07_cross_target_deployment.md", "topics": [], "original_answer": "**Unified model discovery pattern:**\n1. Read mh_projection_id from config\n2. Glob for: `mh_{id}_cluster_*_centroid.npy`\n3. Extract cluster IDs from filenames\n4. Load centroid and answer NPY for each cluster\n\n**Go implementation:**\n```go\nproj, err := projection.LoadMultiHead(projection.Config{\n    DataDir:        \"embeddings/all-MiniLM-L6-v2\",\n    MHProjectionID: 1,\n    Temperature:    0.1,\n})\nif err != nil {\n    panic(err)\n}\n\nqueryEmb := embedder.Embed(\"How do I authenticate?\")\nprojected, weights := proj.Project(queryEmb)\nresults := searcher.Search(projected, 10)\n```\n\n**Rust implementation:**\n```rust\nlet proj = MultiHeadProjection::load_unified(\n    \"embeddings/all-MiniLM-L6-v2\",\n    1,    // mh_projection_id\n    0.1   // temperature\n)?;\n\nlet query_emb = embedder.embed(\"How do I authenticate?\")?;\nlet (projected, weights) = proj.project(&query_emb);\nlet results = searcher.vector_search_with_projection(&query_emb, Some(&proj), 10)?;\n```", "answer_tailored": true}
