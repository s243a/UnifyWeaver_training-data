{"pair_id": "ai-foundations-001_p0", "cluster_id": "ai-foundations-001", "question": "What is the asymmetric semantics problem?", "question_type": "medium", "answer": "The asymmetric semantics problem occurs because users ask questions differently than how documentation provides answers. When someone queries \"How do I log in?\" the relevant docs might say \"Authentication requires valid credentials...\" - the phrasing is completely different even though they're semantically related.\n\n**The mismatch:**\n- **Queries** are questions: brief, informal, problem-focused (\"Why is my code slow?\")\n- **Documents** are explanations: comprehensive, formal, solution-focused (\"Performance optimization involves...\")\n\nThis asymmetry means direct cosine similarity between query and document embeddings often fails to surface the best matches.\n\n**The solution:** Train a projection matrix W that transforms question embeddings into the semantic space of their corresponding answers:\n\n```\nquestion_emb \u2500\u2500\u25ba W \u2500\u2500\u25ba projected_emb \u2248 answer_emb\n```\n\nThis learned projection bridges the gap between how users ask and how documentation answers. For more on the training process, see `education/book-14-ai-training/`.", "answer_variant": "default", "answer_source": "book-14-ai-training/01_introduction.md", "topics": [], "original_answer": "Users phrase queries differently than how answers are written:\n\n| User Query | Document Text |\n|------------|---------------|\n| \"How do I log in?\" | \"Authentication requires valid credentials...\" |\n| \"What's the syntax for loops?\" | \"The `for` statement iterates over...\" |\n| \"Why is my code slow?\" | \"Performance optimization involves...\" |\n\n**Key insight:**\n- Queries are **questions** - short, informal, seeking\n- Documents are **answers** - detailed, formal, providing\n\nDirect cosine similarity between query and document embeddings often misses the best matches.\n\n**Solution:** Learn a projection matrix W that maps question embeddings toward their corresponding answer embeddings:\n\n```\nquestion_emb \u2500\u2500\u25ba W \u2500\u2500\u25ba projected_emb \u2248 answer_emb\n```", "answer_tailored": true}
{"pair_id": "ai-foundations-001_p0", "cluster_id": "ai-foundations-001", "question": "What embedding models does UnifyWeaver support?", "question_type": "medium", "answer": "UnifyWeaver supports two embedding models for semantic search:\n\n**all-MiniLM-L6-v2 (Default):**\n- 384-dimensional embeddings\n- 256 token context window\n- Optimized for speed\n- Suitable for most general purposes\n\n```python\nfrom sentence_transformers import SentenceTransformer\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\nembedding = model.encode(\"How do I log in?\")\n```\n\n**nomic-embed-text-v1.5 (Extended Context):**\n- 768-dimensional embeddings\n- 8192 token context window\n- Supports asymmetric search with prefixes for queries vs documents\n\n```python\nmodel = SentenceTransformer('nomic-ai/nomic-embed-text-v1.5', trust_remote_code=True)\nquery_emb = model.encode(\"search_query: How do I log in?\")\ndoc_emb = model.encode(\"search_document: Authentication requires...\")\n```\n\n| Use Case | Best Choice |\n|----------|-------------|\n| Short queries | all-MiniLM-L6-v2 |\n| Long documents | nomic-embed-text-v1.5 |\n| Query-document asymmetry | nomic with prefixes |\n\nFor implementation details, see education/book-14-ai-training/02_embedding_providers.md", "answer_variant": "default", "answer_source": "book-14-ai-training/02_embedding_providers.md", "topics": [], "original_answer": "Two main embedding models:\n\n**all-MiniLM-L6-v2 (Default):**\n- 384 dimensions\n- 256 tokens context\n- Very fast\n- Good for general use\n\n```python\nfrom sentence_transformers import SentenceTransformer\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\nembedding = model.encode(\"How do I log in?\")\n```\n\n**nomic-embed-text-v1.5 (Large Context):**\n- 768 dimensions\n- 8192 tokens context\n- Supports asymmetric prefixes\n\n```python\nmodel = SentenceTransformer('nomic-ai/nomic-embed-text-v1.5', trust_remote_code=True)\nquery_emb = model.encode(\"search_query: How do I log in?\")\ndoc_emb = model.encode(\"search_document: Authentication requires...\")\n```\n\n| Use Case | Recommended |\n|----------|-------------|\n| Short queries | all-MiniLM-L6-v2 |\n| Long documents | nomic-embed-text-v1.5 |\n| Asymmetric search | nomic with prefixes |", "answer_tailored": true}
{"pair_id": "ai-foundations-001_p0", "cluster_id": "ai-foundations-001", "question": "How do I choose between embedding models?", "question_type": "medium", "answer": "Choosing an embedding model depends on your specific constraints and requirements:\n\n**For short queries (under 256 tokens)**: Use all-MiniLM-L6-v2 for its speed and quality balance.\n\n**For long documents**: Choose nomic-embed-text-v1.5 with its 8K context window.\n\n**For asymmetric search** (where queries differ from documents): nomic-embed-text-v1.5 with query/document prefixes provides the best results.\n\n**When resources are limited**: all-MiniLM-L6-v2 offers smaller model size and faster inference.\n\n**For maximum quality**: nomic-embed-text-v1.5 delivers superior semantic representations.\n\n**Implementation considerations by target:**\n- Python offers full GPU support via sentence-transformers\n- Go uses ONNX Runtime without Python dependencies\n- Rust provides zero-copy ONNX implementation, ideal for CLI tools\n\nAll implementations support NPY format for embedding exchange across targets. See education/book-14-ai-training/02_embedding_providers.md for detailed configuration examples.", "answer_variant": "default", "answer_source": "book-14-ai-training/02_embedding_providers.md", "topics": [], "original_answer": "| Use Case | Recommended Model | Why |\n|----------|------------------|-----|\n| Short queries (<256 tokens) | all-MiniLM-L6-v2 | Fast, good quality |\n| Long documents | nomic-embed-text-v1.5 | 8K context |\n| Asymmetric search | nomic with prefixes | Query/doc distinction |\n| Resource constrained | all-MiniLM-L6-v2 | Smaller, faster |\n| Maximum quality | nomic-embed-text-v1.5 | Better representations |\n\n**Multi-target support:**\n- **Python**: Full-featured with GPU (sentence-transformers)\n- **Go**: ONNX Runtime (pure Go, no Python dependency)\n- **Rust**: ONNX (zero-copy, excellent for CLI tools)\n\nAll targets can read NPY files for cross-target compatibility.", "answer_tailored": true}
