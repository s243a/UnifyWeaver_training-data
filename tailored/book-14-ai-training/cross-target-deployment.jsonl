{"pair_id": "ai-deploy-001_p0", "cluster_id": "ai-deploy-001", "question": "How do I deploy LDA models across different runtimes?", "question_type": "medium", "answer": "LDA models trained in Python can be deployed across Python, Go, and Rust runtimes using a universal storage format. The key is using **NPY files as the lingua franca** - this simple binary format is readable by all target languages.\n\n**Storage Structure:**\n```\nlda.db                    # SQLite for schema and metadata\nembeddings/\n\u2514\u2500\u2500 {model_name}/\n    \u251c\u2500\u2500 mh_{id}_cluster_{n}_centroid.npy  # Cluster centroids\n    \u2514\u2500\u2500 mh_{id}_cluster_{n}_answer.npy    # Answer embeddings\n```\n\n**Deployment Strategy by Runtime:**\n- **Python**: Ideal for training workflows, experimentation, and notebook environments\n- **Go**: Best for microservices, command-line tools, and cross-platform compilation\n- **Rust**: Optimal for performance-critical applications, embedded systems, and WebAssembly targets\n\n**Cross-Runtime Performance** (18 heads, 1000 queries):\n| Runtime | Single Query | Batch (32) |\n|---------|-------------|------------|\n| Python (NumPy) | 0.046 ms | 0.046 ms |\n| Go (ONNX) | 0.12 ms | 0.08 ms |\n| Rust (ndarray) | 0.03 ms | 0.02 ms |\n\nTrain your model once in Python, then deploy the same NPY files wherever needed. For implementation details, see education/book-14-ai-training/07_cross_target_deployment.md.", "answer_variant": "default", "answer_source": "book-14-ai-training/07_cross_target_deployment.md", "topics": [], "original_answer": "Train once in Python, deploy in Python/Go/Rust:\n\n**Universal storage format:**\n```\nlda.db                    # SQLite (schema, metadata)\nembeddings/\n\u2514\u2500\u2500 {model_name}/\n    \u251c\u2500\u2500 mh_{id}_cluster_{n}_centroid.npy  # Cluster centroids\n    \u2514\u2500\u2500 mh_{id}_cluster_{n}_answer.npy    # Answer embeddings\n```\n\n**NPY files are the lingua franca** - simple binary format readable by all targets.\n\n| Runtime | Best For |\n|---------|---------|\n| Python | Training, experimentation, notebooks |\n| Go | Microservices, CLIs, cross-compilation |\n| Rust | Performance-critical apps, embedded, WASM |\n\n**Performance (18 heads, 1000 queries):**\n| Runtime | Single Query | Batch (32) |\n|---------|-------------|------------|\n| Python (NumPy) | 0.046 ms | 0.046 ms |\n| Go (ONNX) | 0.12 ms | 0.08 ms |\n| Rust (ndarray) | 0.03 ms | 0.02 ms |", "answer_tailored": true}
{"pair_id": "ai-deploy-001_p0", "cluster_id": "ai-deploy-001", "question": "How do I load multi-head projections in Go and Rust?", "question_type": "medium", "answer": "Both Go and Rust use the same unified model discovery pattern for loading multi-head projections:\n\n**Loading process:**\n1. Specify the `mh_projection_id` in your configuration\n2. The loader automatically globs for files matching `mh_{id}_cluster_*_centroid.npy`\n3. Cluster IDs are extracted from the filenames\n4. Both centroid and answer NPY files are loaded for each discovered cluster\n\n**Go example:**\n```go\nproj, err := projection.LoadMultiHead(projection.Config{\n    DataDir:        \"embeddings/all-MiniLM-L6-v2\",\n    MHProjectionID: 1,\n    Temperature:    0.1,\n})\nif err != nil {\n    panic(err)\n}\n\nqueryEmb := embedder.Embed(\"How do I authenticate?\")\nprojected, weights := proj.Project(queryEmb)\nresults := searcher.Search(projected, 10)\n```\n\n**Rust example:**\n```rust\nlet proj = MultiHeadProjection::load_unified(\n    \"embeddings/all-MiniLM-L6-v2\",\n    1,    // mh_projection_id\n    0.1   // temperature\n)?;\n\nlet query_emb = embedder.embed(\"How do I authenticate?\")?;\nlet (projected, weights) = proj.project(&query_emb);\nlet results = searcher.vector_search_with_projection(&query_emb, Some(&proj), 10)?;\n```\n\nFor complete deployment examples across all targets, see education/book-14-ai-training/07_cross_target_deployment.md.", "answer_variant": "default", "answer_source": "book-14-ai-training/07_cross_target_deployment.md", "topics": [], "original_answer": "**Unified model discovery pattern:**\n1. Read mh_projection_id from config\n2. Glob for: `mh_{id}_cluster_*_centroid.npy`\n3. Extract cluster IDs from filenames\n4. Load centroid and answer NPY for each cluster\n\n**Go implementation:**\n```go\nproj, err := projection.LoadMultiHead(projection.Config{\n    DataDir:        \"embeddings/all-MiniLM-L6-v2\",\n    MHProjectionID: 1,\n    Temperature:    0.1,\n})\nif err != nil {\n    panic(err)\n}\n\nqueryEmb := embedder.Embed(\"How do I authenticate?\")\nprojected, weights := proj.Project(queryEmb)\nresults := searcher.Search(projected, 10)\n```\n\n**Rust implementation:**\n```rust\nlet proj = MultiHeadProjection::load_unified(\n    \"embeddings/all-MiniLM-L6-v2\",\n    1,    // mh_projection_id\n    0.1   // temperature\n)?;\n\nlet query_emb = embedder.embed(\"How do I authenticate?\")?;\nlet (projected, weights) = proj.project(&query_emb);\nlet results = searcher.vector_search_with_projection(&query_emb, Some(&proj), 10)?;\n```", "answer_tailored": true}
