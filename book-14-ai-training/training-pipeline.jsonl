{"cluster_id": "ai-pipeline-001", "question": "What's the database schema for LDA training?", "answer": "SQLite + NPY files for vectors:\n\n```\nplaybooks/lda-training-data/\n├── lda.db                    # SQLite database\n└── embeddings/\n    └── all-MiniLM-L6-v2/\n        ├── q_001.npy         # Question embeddings\n        ├── a_001.npy         # Answer embeddings\n        └── mh_1_cluster_0_centroid.npy  # Cluster centroids\n```\n\n**Core tables:**\n```sql\nCREATE TABLE models (\n    model_id INTEGER PRIMARY KEY,\n    name TEXT UNIQUE,           -- 'all-MiniLM-L6-v2'\n    dimensions INTEGER          -- 384\n);\n\nCREATE TABLE clusters (\n    cluster_id INTEGER PRIMARY KEY,\n    answer_text TEXT,\n    answer_record_id TEXT,\n    model_id INTEGER REFERENCES models\n);\n\nCREATE TABLE questions (\n    question_id INTEGER PRIMARY KEY,\n    cluster_id INTEGER REFERENCES clusters,\n    question_text TEXT\n);\n\nCREATE TABLE embeddings (\n    embedding_id INTEGER PRIMARY KEY,\n    entity_type TEXT,           -- 'question', 'answer', 'centroid'\n    entity_id INTEGER,\n    model_id INTEGER REFERENCES models,\n    vector_path TEXT            -- Path to .npy file\n);\n```", "source_file": "book-14-ai-training/05_training_pipeline.md", "prerequisites": ["ai-multihead-001"]}
{"cluster_id": "ai-pipeline-001", "question": "How does batch tracking work for incremental training?", "answer": "Track which data files have been processed:\n\n```sql\nCREATE TABLE training_batches (\n    batch_id INTEGER PRIMARY KEY,\n    file_path TEXT,\n    file_hash TEXT,             -- SHA256 for change detection\n    status TEXT,                -- 'pending', 'importing', 'embedding', 'completed', 'failed'\n    error_message TEXT,\n    created_at TIMESTAMP\n);\n```\n\n**Workflow:**\n```bash\n# Day 1: Initial training\npython3 scripts/migrate_to_lda_db.py --scan --input raw/\npython3 scripts/migrate_to_lda_db.py --process-pending\npython3 scripts/train_multi_head_projection.py --db lda.db\n\n# Day 2: New data added\npython3 scripts/migrate_to_lda_db.py --scan --input raw/\n# Only new files are marked pending\n\npython3 scripts/migrate_to_lda_db.py --process-pending\n# Only new batches processed\n\npython3 scripts/train_multi_head_projection.py --db lda.db\n# Re-trains with all data\n```\n\n**Failed batch handling:**\n```bash\npython3 scripts/migrate_to_lda_db.py --retry-failed\n```", "source_file": "book-14-ai-training/05_training_pipeline.md", "prerequisites": ["ai-pipeline-001"]}
