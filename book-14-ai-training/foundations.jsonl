{"cluster_id": "ai-foundations-001", "question": "What is the asymmetric semantics problem?", "answer": "Users phrase queries differently than how answers are written:\n\n| User Query | Document Text |\n|------------|---------------|\n| \"How do I log in?\" | \"Authentication requires valid credentials...\" |\n| \"What's the syntax for loops?\" | \"The `for` statement iterates over...\" |\n| \"Why is my code slow?\" | \"Performance optimization involves...\" |\n\n**Key insight:**\n- Queries are **questions** - short, informal, seeking\n- Documents are **answers** - detailed, formal, providing\n\nDirect cosine similarity between query and document embeddings often misses the best matches.\n\n**Solution:** Learn a projection matrix W that maps question embeddings toward their corresponding answer embeddings:\n\n```\nquestion_emb ──► W ──► projected_emb ≈ answer_emb\n```", "source_file": "book-14-ai-training/01_introduction.md", "prerequisites": []}
{"cluster_id": "ai-foundations-001", "question": "What embedding models does UnifyWeaver support?", "answer": "Two main embedding models:\n\n**all-MiniLM-L6-v2 (Default):**\n- 384 dimensions\n- 256 tokens context\n- Very fast\n- Good for general use\n\n```python\nfrom sentence_transformers import SentenceTransformer\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\nembedding = model.encode(\"How do I log in?\")\n```\n\n**nomic-embed-text-v1.5 (Large Context):**\n- 768 dimensions\n- 8192 tokens context\n- Supports asymmetric prefixes\n\n```python\nmodel = SentenceTransformer('nomic-ai/nomic-embed-text-v1.5', trust_remote_code=True)\nquery_emb = model.encode(\"search_query: How do I log in?\")\ndoc_emb = model.encode(\"search_document: Authentication requires...\")\n```\n\n| Use Case | Recommended |\n|----------|-------------|\n| Short queries | all-MiniLM-L6-v2 |\n| Long documents | nomic-embed-text-v1.5 |\n| Asymmetric search | nomic with prefixes |", "source_file": "book-14-ai-training/02_embedding_providers.md", "prerequisites": ["ai-foundations-001"]}
{"cluster_id": "ai-foundations-001", "question": "How do I choose between embedding models?", "answer": "| Use Case | Recommended Model | Why |\n|----------|------------------|-----|\n| Short queries (<256 tokens) | all-MiniLM-L6-v2 | Fast, good quality |\n| Long documents | nomic-embed-text-v1.5 | 8K context |\n| Asymmetric search | nomic with prefixes | Query/doc distinction |\n| Resource constrained | all-MiniLM-L6-v2 | Smaller, faster |\n| Maximum quality | nomic-embed-text-v1.5 | Better representations |\n\n**Multi-target support:**\n- **Python**: Full-featured with GPU (sentence-transformers)\n- **Go**: ONNX Runtime (pure Go, no Python dependency)\n- **Rust**: ONNX (zero-copy, excellent for CLI tools)\n\nAll targets can read NPY files for cross-target compatibility.", "source_file": "book-14-ai-training/02_embedding_providers.md", "prerequisites": ["ai-foundations-001"]}
