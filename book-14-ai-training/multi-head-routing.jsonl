{"cluster_id": "ai-multihead-001", "question": "What is multi-head routing in LDA?", "answer": "Instead of one global projection, **multiple heads** each specialized for a cluster of related questions:\n\n```\n                    Query\n                      │\n        ┌─────────────┼─────────────┐\n        ▼             ▼             ▼\n   ┌─────────┐   ┌─────────┐   ┌─────────┐\n   │ Head 1  │   │ Head 2  │   │ Head 3  │\n   │ (Auth)  │   │ (Data)  │   │ (Perf)  │\n   └────┬────┘   └────┬────┘   └────┬────┘\n        │             │             │\n        └─────────────┼─────────────┘\n                      ▼\n              Weighted Combination\n                      │\n                      ▼\n               Projected Query\n```\n\n**Each head stores:**\n1. **Centroid**: Mean embedding of questions in this cluster\n2. **Answer embedding**: The answer for this cluster\n\n```python\nhead = {\n    'centroid': np.mean(question_embeddings, axis=0),  # (d,)\n    'answer_emb': answer_embedding                      # (d,)\n}\n```", "source_file": "book-14-ai-training/04_multi_head_routing.md", "prerequisites": ["ai-lda-001"]}
{"cluster_id": "ai-multihead-001", "question": "How does temperature control routing sharpness?", "answer": "Temperature τ controls how sharply queries route to heads:\n\n| Temperature | Behavior | Use Case |\n|-------------|----------|----------|\n| τ = 0.01 | Nearly hard routing (winner-take-all) | Distinct clusters |\n| τ = 0.1 | Sharp but soft | **Recommended default** |\n| τ = 1.0 | Soft blending | Overlapping clusters |\n| τ = 10.0 | Nearly uniform | Regularization |\n\n**Example weights:**\n```python\n# Sharp routing (τ=0.1): weights = [0.85, 0.10, 0.05]\n# Soft routing (τ=1.0):  weights = [0.45, 0.30, 0.25]\n```\n\n**Temperature-controlled softmax:**\n```python\ndef route_query(query_emb, heads, temperature=0.1):\n    similarities = [np.dot(query_norm, centroid_norm) for head in heads]\n    scaled = similarities / temperature\n    exp_scaled = np.exp(scaled - np.max(scaled))  # stability\n    weights = exp_scaled / np.sum(exp_scaled)\n    return weights\n```", "source_file": "book-14-ai-training/04_multi_head_routing.md", "prerequisites": ["ai-multihead-001"]}
{"cluster_id": "ai-multihead-001", "question": "How is multi-head LDA related to transformer attention?", "answer": "Multi-head LDA is structurally identical to attention:\n\n| LDA Multi-Head | Transformer Attention |\n|----------------|----------------------|\n| Centroids | Keys (K) |\n| Answer embeddings | Values (V) |\n| Query embedding | Query (Q) |\n| softmax(sim/τ) | softmax(QK^T/√d) |\n| Σ weights × answers | Attention output |\n\nThis isn't coincidence—both are learned routing mechanisms!\n\n**Multi-head projection formula:**\n```python\ndef project_multi_head(query_emb, heads, temperature=0.1):\n    weights = route_query(query_emb, heads, temperature)\n    \n    # Weighted combination of answer embeddings\n    projected = np.zeros_like(query_emb)\n    for i, head in enumerate(heads):\n        projected += weights[i] * head['answer_emb']\n    \n    return projected\n```", "source_file": "book-14-ai-training/04_multi_head_routing.md", "prerequisites": ["ai-multihead-001"]}
