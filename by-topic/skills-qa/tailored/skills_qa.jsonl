{"pair_id": "skill_extract_records_001_q0", "cluster_id": "skill_extract_records_001", "question": "How do I extract structured data from Markdown example files?", "answer": "To extract structured data from Markdown example files, use the `scripts/utils/extract_records.pl` script. This tool parses Markdown files conforming to UnifyWeaver Example Record Format and outputs structured data.\n\nBasic usage:\n```\nperl scripts/utils/extract_records.pl [OPTIONS] [PATH...]\n```\n\nKey options for structured data extraction:\n- `-f json` - Output as JSON objects for programmatic processing\n- `-f content` - Extract only the code block content\n- `-f full` - Output entire Markdown block (default)\n- `-q <pattern>` - Filter records by name using regex\n- `--file-filter <key=value>` - Filter by YAML frontmatter metadata\n\nFor example, to extract a specific record as JSON:\n```\nperl scripts/utils/extract_records.pl -f json -q \"record_name\" path/to/file.md\n```\n\nThis approach is more robust than `grep` because it reliably handles multi-line content blocks and parses metadata fields.", "question_type": "medium", "topics": ["Data Processing", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["data-processing", "parsing", "markdown"], "related_skills": ["skill_extract_records.md"], "related_docs": ["docs/playbooks/parsing/README.md"], "original_answer": "Use the Extract Records skill with `scripts/utils/extract_records.pl`. This parses Markdown files that conform to UnifyWeaver Example Record Format and outputs structured data.\n\n```bash\nperl scripts/utils/extract_records.pl [OPTIONS] [PATH...]\n```\n\nCommon options:\n- `-f json` - Output as JSON objects (recommended for processing)\n- `-q <pattern>` - Filter by record name\n- `-f content` - Extract just the code block content\n\nThis is more robust than `grep` for multi-line records and metadata.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_extract_records_001_q1", "cluster_id": "skill_extract_records_001", "question": "extract records from markdown", "answer": "To extract records from markdown files, use the Extract Records skill with the `scripts/utils/extract_records.pl` script. This tool parses Markdown files conforming to the UnifyWeaver Example Record Format and outputs structured data.\n\nBasic usage:\n```bash\nperl scripts/utils/extract_records.pl [OPTIONS] [PATH...]\n```\n\nKey options:\n- `-f json` - Output as JSON objects (best for processing)\n- `-f content` - Extract only the code block content\n- `-f full` - Output entire Markdown block (default)\n- `-q <pattern>` - Filter records by name using regex\n- `--file-filter <key=value>` - Filter files by YAML frontmatter\n\nExample:\n```bash\nperl scripts/utils/extract_records.pl -f json -q \"pattern\" path/to/file.md\n```\n\nThis approach is more reliable than grep for handling multi-line content blocks and parsing metadata like record IDs and names.", "question_type": "medium", "topics": ["Data Processing", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["data-processing", "parsing", "markdown"], "related_skills": ["skill_extract_records.md"], "related_docs": ["docs/playbooks/parsing/README.md"], "original_answer": "Use the Extract Records skill with `scripts/utils/extract_records.pl`. This parses Markdown files that conform to UnifyWeaver Example Record Format and outputs structured data.\n\n```bash\nperl scripts/utils/extract_records.pl [OPTIONS] [PATH...]\n```\n\nCommon options:\n- `-f json` - Output as JSON objects (recommended for processing)\n- `-q <pattern>` - Filter by record name\n- `-f content` - Extract just the code block content\n\nThis is more robust than `grep` for multi-line records and metadata.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_extract_records_001_q2", "cluster_id": "skill_extract_records_001", "question": "parse example records", "answer": "To parse example records, use the Extract Records skill with `scripts/utils/extract_records.pl`. This Perl script parses Markdown files conforming to the UnifyWeaver Example Record Format and outputs structured data.\n\nBasic usage:\n```bash\nperl scripts/utils/extract_records.pl [OPTIONS] [PATH...]\n```\n\nKey options:\n- `-f json` - Output as JSON objects (best for programmatic processing)\n- `-f content` - Extract only the code block content\n- `-f full` - Output entire Markdown block (default)\n- `-q <pattern>` - Filter records by name using regex\n- `--file-filter <key=value>` - Filter files by YAML frontmatter\n\nExample: Extract all JSON records matching a pattern:\n```bash\nperl scripts/utils/extract_records.pl -f json -q \"pattern\" path/to/file.md\n```\n\nThis tool is more robust than `grep` for handling multi-line content blocks and metadata.", "question_type": "medium", "topics": ["Data Processing", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["data-processing", "parsing", "markdown"], "related_skills": ["skill_extract_records.md"], "related_docs": ["docs/playbooks/parsing/README.md"], "original_answer": "Use the Extract Records skill with `scripts/utils/extract_records.pl`. This parses Markdown files that conform to UnifyWeaver Example Record Format and outputs structured data.\n\n```bash\nperl scripts/utils/extract_records.pl [OPTIONS] [PATH...]\n```\n\nCommon options:\n- `-f json` - Output as JSON objects (recommended for processing)\n- `-q <pattern>` - Filter by record name\n- `-f content` - Extract just the code block content\n\nThis is more robust than `grep` for multi-line records and metadata.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_extract_records_001_q3", "cluster_id": "skill_extract_records_001", "question": "get data from markdown files", "answer": "To get data from markdown files, use the Extract Records skill with `scripts/utils/extract_records.pl`. This tool parses Markdown files conforming to UnifyWeaver Example Record Format and outputs structured data:\n\n```bash\nperl scripts/utils/extract_records.pl [OPTIONS] [PATH...]\n```\n\nKey options:\n- `-f json` - Output as JSON objects (best for programmatic processing)\n- `-f content` - Extract only the code block content\n- `-f full` - Output entire original Markdown block (default)\n- `-q <pattern>` - Filter records by name\n- `--file-filter` - Filter files by YAML frontmatter metadata\n\nThis approach is more reliable than grep for handling multi-line content blocks and extracting metadata.", "question_type": "medium", "topics": ["Data Processing", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["data-processing", "parsing", "markdown"], "related_skills": ["skill_extract_records.md"], "related_docs": ["docs/playbooks/parsing/README.md"], "original_answer": "Use the Extract Records skill with `scripts/utils/extract_records.pl`. This parses Markdown files that conform to UnifyWeaver Example Record Format and outputs structured data.\n\n```bash\nperl scripts/utils/extract_records.pl [OPTIONS] [PATH...]\n```\n\nCommon options:\n- `-f json` - Output as JSON objects (recommended for processing)\n- `-q <pattern>` - Filter by record name\n- `-f content` - Extract just the code block content\n\nThis is more robust than `grep` for multi-line records and metadata.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_extract_records_002_q0", "cluster_id": "skill_extract_records_002", "question": "What's the difference between bash and Prolog records when extracting?", "answer": "The key difference is the code interpreter required:\n\n**Bash records** (```bash markers):\n- Extract with: `perl scripts/utils/extract_records.pl -f content -q 'record.name' file.md > script.sh`\n- Run with: `bash script.sh`\n\n**Prolog records** (```prolog markers):\n- Extract with: `perl scripts/utils/extract_records.pl -f content -q 'record.name' file.md > code.pl`\n- Run with: `swipl -f init.pl -g \"consult('code.pl'), goal, halt\"`\n\nAlways identify the code fence language marker to determine which interpreter to use.", "question_type": "long", "topics": ["Data Processing", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["parsing", "prolog", "bash", "execution"], "related_skills": ["skill_extract_records.md"], "related_docs": ["docs/playbooks/parsing/README.md"], "original_answer": "Records contain different code types - you must run them with the correct interpreter:\n\n**Bash records** (marked with ```bash):\n```bash\nperl scripts/utils/extract_records.pl -f content -q 'record.name' file.md > script.sh\nbash script.sh\n```\n\n**Prolog records** (marked with ```prolog):\n```bash\nperl scripts/utils/extract_records.pl -f content -q 'record.name' file.md > code.pl\nswipl -f init.pl -g \"consult('code.pl'), goal, halt\"\n```\n\nAlways check the code fence language (```bash vs ```prolog) to know which interpreter to use.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_extract_records_002_q1", "cluster_id": "skill_extract_records_002", "question": "run extracted bash script", "answer": "To run an extracted bash script:\n\n1. Extract the bash script from a record:\n```bash\nperl scripts/utils/extract_records.pl -f content -q 'record.name' file.md > script.sh\n```\n\n2. Execute it with bash:\n```bash\nbash script.sh\n```\n\nEnsure the record is marked with ```bash (not ```prolog or another language). If you're uncertain which interpreter to use, check the code fence language identifier in the original record.", "question_type": "long", "topics": ["Data Processing", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["parsing", "prolog", "bash", "execution"], "related_skills": ["skill_extract_records.md"], "related_docs": ["docs/playbooks/parsing/README.md"], "original_answer": "Records contain different code types - you must run them with the correct interpreter:\n\n**Bash records** (marked with ```bash):\n```bash\nperl scripts/utils/extract_records.pl -f content -q 'record.name' file.md > script.sh\nbash script.sh\n```\n\n**Prolog records** (marked with ```prolog):\n```bash\nperl scripts/utils/extract_records.pl -f content -q 'record.name' file.md > code.pl\nswipl -f init.pl -g \"consult('code.pl'), goal, halt\"\n```\n\nAlways check the code fence language (```bash vs ```prolog) to know which interpreter to use.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_extract_records_002_q2", "cluster_id": "skill_extract_records_002", "question": "execute prolog record", "answer": "To execute a Prolog record, first extract it using the extract_records.pl script with the `-f content` flag to get just the code block, then save it to a `.pl` file, and finally run it with the SWI-Prolog interpreter using `swipl`. Example: `perl scripts/utils/extract_records.pl -f content -q 'record.name' file.md > code.pl && swipl -f init.pl -g \"consult('code.pl'), goal, halt\"`", "question_type": "long", "topics": ["Data Processing", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["parsing", "prolog", "bash", "execution"], "related_skills": ["skill_extract_records.md"], "related_docs": ["docs/playbooks/parsing/README.md"], "original_answer": "Records contain different code types - you must run them with the correct interpreter:\n\n**Bash records** (marked with ```bash):\n```bash\nperl scripts/utils/extract_records.pl -f content -q 'record.name' file.md > script.sh\nbash script.sh\n```\n\n**Prolog records** (marked with ```prolog):\n```bash\nperl scripts/utils/extract_records.pl -f content -q 'record.name' file.md > code.pl\nswipl -f init.pl -g \"consult('code.pl'), goal, halt\"\n```\n\nAlways check the code fence language (```bash vs ```prolog) to know which interpreter to use.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_extract_records_002_q3", "cluster_id": "skill_extract_records_002", "question": "which interpreter to use", "answer": "Check the code fence language in the extracted record. Use `bash` for records marked with ```bash, and use `swipl` for records marked with ```prolog. Extract the record content with `perl scripts/utils/extract_records.pl -f content`, save it to the appropriate file type (.sh for bash, .pl for prolog), then run it with the corresponding interpreter: `bash script.sh` or `swipl -f init.pl -g \"consult('code.pl'), goal, halt\"`.", "question_type": "long", "topics": ["Data Processing", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["parsing", "prolog", "bash", "execution"], "related_skills": ["skill_extract_records.md"], "related_docs": ["docs/playbooks/parsing/README.md"], "original_answer": "Records contain different code types - you must run them with the correct interpreter:\n\n**Bash records** (marked with ```bash):\n```bash\nperl scripts/utils/extract_records.pl -f content -q 'record.name' file.md > script.sh\nbash script.sh\n```\n\n**Prolog records** (marked with ```prolog):\n```bash\nperl scripts/utils/extract_records.pl -f content -q 'record.name' file.md > code.pl\nswipl -f init.pl -g \"consult('code.pl'), goal, halt\"\n```\n\nAlways check the code fence language (```bash vs ```prolog) to know which interpreter to use.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_extract_records_002_q4", "cluster_id": "skill_extract_records_002", "question": "bash script vs prolog code", "answer": "Records in UnifyWeaver contain different code types requiring different interpreters. Bash records (marked with ```bash) must be extracted, saved to a .sh file, and executed with `bash`. Prolog records (marked with ```prolog) must be extracted, saved to a .pl file, and executed with `swipl` (the Prolog interpreter). Always check the code fence language marker to determine which interpreter to use. For example: bash records use `bash script.sh`, while Prolog records use `swipl -f init.pl -g \"consult('code.pl'), goal, halt\"`.", "question_type": "long", "topics": ["Data Processing", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["parsing", "prolog", "bash", "execution"], "related_skills": ["skill_extract_records.md"], "related_docs": ["docs/playbooks/parsing/README.md"], "original_answer": "Records contain different code types - you must run them with the correct interpreter:\n\n**Bash records** (marked with ```bash):\n```bash\nperl scripts/utils/extract_records.pl -f content -q 'record.name' file.md > script.sh\nbash script.sh\n```\n\n**Prolog records** (marked with ```prolog):\n```bash\nperl scripts/utils/extract_records.pl -f content -q 'record.name' file.md > code.pl\nswipl -f init.pl -g \"consult('code.pl'), goal, halt\"\n```\n\nAlways check the code fence language (```bash vs ```prolog) to know which interpreter to use.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_extract_records_003_q0", "cluster_id": "skill_extract_records_003", "question": "When should I use Extract Records instead of grep?", "answer": "Use Extract Records instead of grep when you need to parse metadata (like `id` or `name`), handle multi-line content blocks reliably, get output in structured formats like JSON, or filter files by YAML frontmatter such as `file_type=UnifyWeaver Example Library`. Choose grep for simple text search; choose Extract Records for semantic parsing of UnifyWeaver record files that require structured extraction.", "question_type": "medium", "topics": ["Data Processing", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["parsing", "tools", "comparison"], "related_skills": ["skill_extract_records.md"], "related_docs": ["docs/playbooks/parsing/README.md"], "original_answer": "Use Extract Records when you need to:\n- Parse metadata like `id` or `name` from records\n- Handle multi-line content blocks reliably\n- Get output in structured formats like JSON\n- Filter files by YAML frontmatter (like `file_type=UnifyWeaver Example Library`)\n\nUse `grep` for simple text search. Use Extract Records for semantic parsing of UnifyWeaver record files.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_extract_records_003_q1", "cluster_id": "skill_extract_records_003", "question": "extract records vs grep", "answer": "Extract Records is a specialized tool for parsing UnifyWeaver Example Record Format files. Choose it over grep when you need to: parse metadata (id, name), reliably handle multi-line content blocks, output structured JSON, or filter by YAML frontmatter. Use grep for simple text searches; use Extract Records for semantic parsing of UnifyWeaver record files.", "question_type": "medium", "topics": ["Data Processing", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["parsing", "tools", "comparison"], "related_skills": ["skill_extract_records.md"], "related_docs": ["docs/playbooks/parsing/README.md"], "original_answer": "Use Extract Records when you need to:\n- Parse metadata like `id` or `name` from records\n- Handle multi-line content blocks reliably\n- Get output in structured formats like JSON\n- Filter files by YAML frontmatter (like `file_type=UnifyWeaver Example Library`)\n\nUse `grep` for simple text search. Use Extract Records for semantic parsing of UnifyWeaver record files.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_extract_records_003_q2", "cluster_id": "skill_extract_records_003", "question": "when to use extract records tool", "answer": "Use the Extract Records tool when you need to parse and extract structured data from Markdown files that conform to the UnifyWeaver Example Record Format. Specifically, use it when you need to: (1) parse metadata like `id` or `name` from records, (2) handle multi-line content blocks reliably, (3) output results in structured formats like JSON, or (4) filter files by YAML frontmatter such as `file_type=UnifyWeaver Example Library`. For simple text searches, use `grep` instead. Extract Records is the preferred tool for semantic parsing of UnifyWeaver record files because it's more robust than generic tools for this specific task.", "question_type": "medium", "topics": ["Data Processing", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["parsing", "tools", "comparison"], "related_skills": ["skill_extract_records.md"], "related_docs": ["docs/playbooks/parsing/README.md"], "original_answer": "Use Extract Records when you need to:\n- Parse metadata like `id` or `name` from records\n- Handle multi-line content blocks reliably\n- Get output in structured formats like JSON\n- Filter files by YAML frontmatter (like `file_type=UnifyWeaver Example Library`)\n\nUse `grep` for simple text search. Use Extract Records for semantic parsing of UnifyWeaver record files.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_extract_records_003_q3", "cluster_id": "skill_extract_records_003", "question": "why use extract records", "answer": "Use Extract Records when you need to parse structured data from UnifyWeaver Markdown files with metadata extraction, multi-line content handling, or JSON output. It's more robust than grep for processing records programmatically, handling metadata fields like `id` or `name`, filtering by YAML frontmatter, and ensuring reliable parsing of multi-line content blocks. Choose Extract Records over grep when you need semantic awareness of the record format rather than simple text matching.", "question_type": "medium", "topics": ["Data Processing", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["parsing", "tools", "comparison"], "related_skills": ["skill_extract_records.md"], "related_docs": ["docs/playbooks/parsing/README.md"], "original_answer": "Use Extract Records when you need to:\n- Parse metadata like `id` or `name` from records\n- Handle multi-line content blocks reliably\n- Get output in structured formats like JSON\n- Filter files by YAML frontmatter (like `file_type=UnifyWeaver Example Library`)\n\nUse `grep` for simple text search. Use Extract Records for semantic parsing of UnifyWeaver record files.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_extract_records_004_q0", "cluster_id": "skill_extract_records_004", "question": "How do I filter extracted records by name?", "answer": "Use the `-q` (query) flag with a regex pattern to filter extracted records by their `name` metadata. For example: `perl scripts/utils/extract_records.pl -f json -q 'pattern' path/to/file.md` will extract only records whose name matches the regex pattern. The `-q` flag accepts any valid regex, allowing flexible filtering of record names.", "question_type": "long", "topics": ["Data Processing", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["parsing", "filtering", "queries"], "related_skills": ["skill_extract_records.md"], "related_docs": ["docs/playbooks/parsing/README.md"], "original_answer": "Use the `-q` (query) flag with a regex pattern to filter by record name:\n\n```bash\nperl scripts/utils/extract_records.pl \\\n  -f json \\\n  -q 'unifyweaver.execution.xml_data_source' \\\n  path/to/file.md\n```\n\nThis extracts only records whose `name` metadata matches the pattern. Combine with `-f json` to get structured output for processing.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_extract_records_004_q1", "cluster_id": "skill_extract_records_004", "question": "filter records by pattern", "answer": "Use the `-q` (query) flag with a regex pattern to filter records by their name metadata:\n\n```bash\nperl scripts/utils/extract_records.pl -q 'your_pattern_here' path/to/file.md\n```\n\nThe pattern matches against the `name` field in each record's metadata. For example, `-q 'xml_data_source'` filters to records with names containing that string. Combine with `-f json` for structured output or `-f content` for raw code.", "question_type": "long", "topics": ["Data Processing", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["parsing", "filtering", "queries"], "related_skills": ["skill_extract_records.md"], "related_docs": ["docs/playbooks/parsing/README.md"], "original_answer": "Use the `-q` (query) flag with a regex pattern to filter by record name:\n\n```bash\nperl scripts/utils/extract_records.pl \\\n  -f json \\\n  -q 'unifyweaver.execution.xml_data_source' \\\n  path/to/file.md\n```\n\nThis extracts only records whose `name` metadata matches the pattern. Combine with `-f json` to get structured output for processing.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_extract_records_004_q2", "cluster_id": "skill_extract_records_004", "question": "query records by name", "answer": "Use the `-q` (query) flag with a regex pattern to filter records by their `name` metadata:\n\n```bash\nperl scripts/utils/extract_records.pl \\\n  -q 'pattern' \\\n  path/to/file.md\n```\n\nReplace 'pattern' with a regex to match record names. For example, `-q 'unifyweaver.execution'` matches all records whose name starts with that prefix. Combine with `-f json` for structured output or `-f content` for just the code blocks.", "question_type": "long", "topics": ["Data Processing", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["parsing", "filtering", "queries"], "related_skills": ["skill_extract_records.md"], "related_docs": ["docs/playbooks/parsing/README.md"], "original_answer": "Use the `-q` (query) flag with a regex pattern to filter by record name:\n\n```bash\nperl scripts/utils/extract_records.pl \\\n  -f json \\\n  -q 'unifyweaver.execution.xml_data_source' \\\n  path/to/file.md\n```\n\nThis extracts only records whose `name` metadata matches the pattern. Combine with `-f json` to get structured output for processing.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_extract_records_004_q3", "cluster_id": "skill_extract_records_004", "question": "search specific records", "answer": "Use the `-q` (query) flag with a regex pattern to filter records by their name metadata. For example:\n\n```bash\nperl scripts/utils/extract_records.pl \\\n  -f json \\\n  -q 'pattern_to_match' \\\n  path/to/file.md\n```\n\nThe pattern is matched against the `name` field in each record's metadata. You can combine this with different output formats (`-f json`, `-f content`, or `-f full`) depending on whether you need structured output, raw content, or the complete record block.", "question_type": "long", "topics": ["Data Processing", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["parsing", "filtering", "queries"], "related_skills": ["skill_extract_records.md"], "related_docs": ["docs/playbooks/parsing/README.md"], "original_answer": "Use the `-q` (query) flag with a regex pattern to filter by record name:\n\n```bash\nperl scripts/utils/extract_records.pl \\\n  -f json \\\n  -q 'unifyweaver.execution.xml_data_source' \\\n  path/to/file.md\n```\n\nThis extracts only records whose `name` metadata matches the pattern. Combine with `-f json` to get structured output for processing.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_find_executable_001_q0", "cluster_id": "skill_find_executable_001", "question": "How do I run a command that's not found in my system PATH?", "answer": "To find an executable not in your PATH, use the Find Executable skill. It searches common installation directories per OS: Windows (C:\\Program Files, C:\\Strawberry), Linux (/usr/bin, /usr/local/bin, /snap/bin), macOS (/opt/homebrew/bin, /Applications). If found, it returns the absolute path you can use to run the command.", "question_type": "medium", "topics": ["Execution", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["command-not-found", "executable", "path"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "When a command fails with a 'command not found' error, you can use the Find Executable skill to search for the executable in common installation directories. The skill searches OS-specific paths and returns the full path to the executable if found, which you can then use to run the command directly.", "answer_tailored": true, "confidence": 0.85, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_find_executable_001_q1", "cluster_id": "skill_find_executable_001", "question": "What should I do when I get a 'command not found' error?", "answer": "When you get a 'command not found' error, use the Find Executable skill to search for the executable in common installation directories specific to your operating system. The skill will return the full path if found, which you can then use to run the command directly instead of relying on PATH lookup.", "question_type": "medium", "topics": ["Execution", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["command-not-found", "executable", "path"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "When a command fails with a 'command not found' error, you can use the Find Executable skill to search for the executable in common installation directories. The skill searches OS-specific paths and returns the full path to the executable if found, which you can then use to run the command directly.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_find_executable_001_q2", "cluster_id": "skill_find_executable_001", "question": "How can I locate an executable that isn't in my PATH?", "answer": "You can use the Find Executable skill to locate executables not in your PATH. This skill searches common installation directories on your operating system\u2014such as /usr/local/bin and /opt/homebrew/bin on macOS, or C:\\Program Files directories on Windows. Provide the executable name, and the skill will return its full path if found, which you can then use to run the command directly (for example, /path/to/perl script.pl).", "question_type": "medium", "topics": ["Execution", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["command-not-found", "executable", "path"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "When a command fails with a 'command not found' error, you can use the Find Executable skill to search for the executable in common installation directories. The skill searches OS-specific paths and returns the full path to the executable if found, which you can then use to run the command directly.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_find_executable_002_q0", "cluster_id": "skill_find_executable_002", "question": "Where does the agent look for executables on different operating systems?", "answer": "The Find Executable skill searches for executables in OS-specific directories. On Windows, it checks C:\\Strawberry\\perl\\bin, C:\\Program Files\\swipl\\bin, and C:\\Program Files (x86)\\swipl\\bin. On Linux, it searches /usr/bin, /usr/local/bin, and /snap/bin. On macOS, it checks /usr/bin, /usr/local/bin, /opt/homebrew/bin, and /Applications/SWI-Prolog.app/Contents/MacOS.", "question_type": "medium", "topics": ["Execution", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["directories", "operating-system", "search-paths"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "The Find Executable skill searches OS-specific directories: On Windows, it checks Strawberry Perl and SWI-Prolog installation paths. On Linux, it searches /usr/bin, /usr/local/bin, and /snap/bin. On macOS, it checks /usr/bin, /usr/local/bin, /opt/homebrew/bin, and the SWI-Prolog application path.", "answer_tailored": true, "confidence": 0.98, "confidence_issues": null}
{"pair_id": "skill_find_executable_002_q1", "cluster_id": "skill_find_executable_002", "question": "Which directories are searched for executables?", "answer": "When an executable isn't in your system PATH, use the Find Executable skill which searches common installation directories. On Windows it checks C:\\Strawberry\\perl\\bin, C:\\Program Files\\swipl\\bin. On Linux: /usr/bin, /usr/local/bin, /snap/bin. On macOS: /usr/local/bin, /opt/homebrew/bin, /Applications/. The skill returns the absolute path if found, which you can use directly.", "question_type": "medium", "topics": ["Execution", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["directories", "operating-system", "search-paths"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "The Find Executable skill searches OS-specific directories: On Windows, it checks Strawberry Perl and SWI-Prolog installation paths. On Linux, it searches /usr/bin, /usr/local/bin, and /snap/bin. On macOS, it checks /usr/bin, /usr/local/bin, /opt/homebrew/bin, and the SWI-Prolog application path.", "answer_tailored": true, "confidence": 0.85, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_find_executable_002_q2", "cluster_id": "skill_find_executable_002", "question": "What are the common installation paths the agent checks?", "answer": "When a program is installed but the agent can't execute it, use the Find Executable skill to locate it. The skill searches OS-specific directories: Windows (C:\\Program Files, C:\\Strawberry), Linux (/usr/bin, /usr/local/bin, /snap/bin), macOS (/opt/homebrew/bin, /Applications). Use the returned absolute path to execute the command directly.", "question_type": "medium", "topics": ["Execution", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["directories", "operating-system", "search-paths"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "The Find Executable skill searches OS-specific directories: On Windows, it checks Strawberry Perl and SWI-Prolog installation paths. On Linux, it searches /usr/bin, /usr/local/bin, and /snap/bin. On macOS, it checks /usr/bin, /usr/local/bin, /opt/homebrew/bin, and the SWI-Prolog application path.", "answer_tailored": true, "confidence": 0.85, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_find_executable_003_q0", "cluster_id": "skill_find_executable_003", "question": "What does the Find Executable skill return if it can't locate an executable?", "answer": "If the Find Executable skill can't locate an executable, it returns an empty string.", "question_type": "long", "topics": ["Execution", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["output", "executable-path", "return-value"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "If the executable is found, the Find Executable skill returns the absolute path to it. If the executable is not found, it returns an empty string. You can then use the returned path to execute the command directly, for example: & \"C:\\Strawberry\\perl\\bin\\perl.exe\" my_script.pl on Windows.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_find_executable_003_q1", "cluster_id": "skill_find_executable_003", "question": "How do I know if an executable was found?", "answer": "Common installation directories vary by OS. Windows: C:\\Program Files, C:\\Program Files (x86), C:\\Strawberry (Perl). Linux: /usr/bin, /usr/local/bin, /snap/bin, /opt. macOS: /usr/local/bin, /opt/homebrew/bin (Homebrew), /Applications. The Find Executable skill searches these locations automatically.", "question_type": "long", "topics": ["Execution", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["output", "executable-path", "return-value"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "If the executable is found, the Find Executable skill returns the absolute path to it. If the executable is not found, it returns an empty string. You can then use the returned path to execute the command directly, for example: & \"C:\\Strawberry\\perl\\bin\\perl.exe\" my_script.pl on Windows.", "answer_tailored": true, "confidence": 0.85, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_find_executable_003_q2", "cluster_id": "skill_find_executable_003", "question": "What happens when the skill doesn't find the executable?", "answer": "When the Find Executable skill doesn't find the executable, it returns an empty string. The agent can check for this empty return value and handle it appropriately, such as by notifying the user that the executable is not available on the system.", "question_type": "long", "topics": ["Execution", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["output", "executable-path", "return-value"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "If the executable is found, the Find Executable skill returns the absolute path to it. If the executable is not found, it returns an empty string. You can then use the returned path to execute the command directly, for example: & \"C:\\Strawberry\\perl\\bin\\perl.exe\" my_script.pl on Windows.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_find_executable_004_q0", "cluster_id": "skill_find_executable_004", "question": "How do I use a found executable to run my script?", "answer": "Once you have the full path from the Find Executable skill, execute it directly with your script as an argument. On Windows, use the & operator: & \"C:\\Strawberry\\perl\\bin\\perl.exe\" my_script.pl. On Unix-like systems (Linux/macOS), run: /usr/local/bin/perl my_script.pl. The & operator on Windows allows you to invoke commands stored in variables or with dynamic paths.", "question_type": "long", "topics": ["Execution", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["execution", "full-path", "script-execution"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "Once you have the full path from the Find Executable skill, you can execute the command directly using that path. For example, on Windows you would use: & \"C:\\Strawberry\\perl\\bin\\perl.exe\" my_script.pl, and on Unix-like systems: /usr/local/bin/perl my_script.pl. The & operator on Windows allows you to invoke commands from variable paths.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_find_executable_004_q1", "cluster_id": "skill_find_executable_004", "question": "How can I execute a command using the full path returned?", "answer": "To execute a command using the full path returned by the Find Executable skill, use the path directly in your command. On Windows, use the & operator with quotes around the path: & \"C:\\Strawberry\\perl\\bin\\perl.exe\" my_script.pl. On Unix-like systems (Linux/macOS), execute the path directly: /usr/local/bin/perl my_script.pl. This allows you to run executables even when they're not in your system PATH.", "question_type": "long", "topics": ["Execution", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["execution", "full-path", "script-execution"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "Once you have the full path from the Find Executable skill, you can execute the command directly using that path. For example, on Windows you would use: & \"C:\\Strawberry\\perl\\bin\\perl.exe\" my_script.pl, and on Unix-like systems: /usr/local/bin/perl my_script.pl. The & operator on Windows allows you to invoke commands from variable paths.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_find_executable_004_q2", "cluster_id": "skill_find_executable_004", "question": "What's the syntax for running an executable from its full path?", "answer": "On Windows, use the & operator followed by the quoted path: & \"C:\\Strawberry\\perl\\bin\\perl.exe\" my_script.pl. On Unix-like systems (Linux, macOS), directly invoke the path: /usr/local/bin/perl my_script.pl. The & operator on Windows allows you to execute commands from variable paths, while Unix systems execute paths directly without a prefix.", "question_type": "long", "topics": ["Execution", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["execution", "full-path", "script-execution"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "Once you have the full path from the Find Executable skill, you can execute the command directly using that path. For example, on Windows you would use: & \"C:\\Strawberry\\perl\\bin\\perl.exe\" my_script.pl, and on Unix-like systems: /usr/local/bin/perl my_script.pl. The & operator on Windows allows you to invoke commands from variable paths.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_001_q0", "cluster_id": "skill_json_sources_001", "question": "How do I read data from a JSON file in a playbook?", "answer": "To read data from a JSON file in a playbook, use the `source/3` directive with the `json_file/1` parameter to specify the file path. For column projection mode, provide `columns/1` with field names using dot notation (e.g., 'order.customer.name') or array indices (e.g., 'items[0].product'). The number of columns must match your predicate's arity. Example:\n```prolog\n:- source(json, my_source, [\n    json_file('data/orders.json'),\n    columns(['order.customer.name', 'items[0].product'])\n]).\n```\nFor more complex selections, use JSONPath selectors like `jsonpath('$.orders[*].total')`. Alternatively, use schema/1 mode to declare typed records with automatic C# POCO generation.", "question_type": "medium", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["JSON", "data sources", "playbooks"], "related_skills": ["skill_json_sources.md"], "related_docs": [], "original_answer": "Use the `source/3` directive with `json_file('path/to/file.json')` and `columns/1` to specify which fields to extract. For example:\n```prolog\n:- source(json, my_source, [\n    json_file('data/orders.json'),\n    columns(['order.customer.name', 'items[0].product'])\n]).\n```\nEnsure the number of columns matches your predicate's arity.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_001_q1", "cluster_id": "skill_json_sources_001", "question": "How can I load JSON data into a playbook?", "answer": "Use the `source/3` directive with `json_file('path/to/file.json')` to load JSON data into a playbook. For column projection, specify `columns/1` with field names using dot notation or array indices (e.g., `'order.customer.name'`, `'items[0].product'`). Alternatively, use `jsonpath('$.orders[*].total')` for complex selectors. For full JSON objects, use `arity(1)`, `return_object(true)`, and `type_hint/1`. For typed records, use `schema/1` with field definitions and optional `record_type/1` to generate POCOs. Example:\n```prolog\n:- source(json, my_source, [\n    json_file('data/orders.json'),\n    columns(['order.customer.name', 'items[0].product'])\n]).\n```\nEnsure column count matches your predicate's arity.", "question_type": "medium", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["JSON", "data sources", "playbooks"], "related_skills": ["skill_json_sources.md"], "related_docs": [], "original_answer": "Use the `source/3` directive with `json_file('path/to/file.json')` and `columns/1` to specify which fields to extract. For example:\n```prolog\n:- source(json, my_source, [\n    json_file('data/orders.json'),\n    columns(['order.customer.name', 'items[0].product'])\n]).\n```\nEnsure the number of columns matches your predicate's arity.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_001_q2", "cluster_id": "skill_json_sources_001", "question": "What's the syntax for reading JSON files?", "answer": "Use the `source/3` directive with `json_file('path/to/file.json')` to read JSON files. The basic syntax is:\n```prolog\n:- source(json, source_name, [\n    json_file('path/to/file.json'),\n    columns(['field.path', 'nested.field'])\n]).\n```\n\nKey points:\n- `json_file/1` specifies the file path\n- `columns/1` projects specific fields using dot notation and array indices (e.g., `items[0].product`)\n- Column count must match your predicate's arity\n- For complex selectors, use JSONPath notation: `jsonpath('$.path[*].field')`\n- For full JSON objects, use `arity(1)`, `return_object(true)`, and `type_hint/1` instead of columns\n- For typed records, use `schema/1` with field definitions", "question_type": "medium", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["JSON", "data sources", "playbooks"], "related_skills": ["skill_json_sources.md"], "related_docs": [], "original_answer": "Use the `source/3` directive with `json_file('path/to/file.json')` and `columns/1` to specify which fields to extract. For example:\n```prolog\n:- source(json, my_source, [\n    json_file('data/orders.json'),\n    columns(['order.customer.name', 'items[0].product'])\n]).\n```\nEnsure the number of columns matches your predicate's arity.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_json_sources_002_q0", "cluster_id": "skill_json_sources_002", "question": "How do I select nested fields or complex paths in JSON data?", "answer": "To select nested fields or complex paths in JSON data, use JSONPath selectors with the syntax `jsonpath('$.path.to.field')` in your `columns/1` or `schema/1` declaration. JSONPath supports: dot notation for properties (`.property`), bracket notation for properties with special characters (`['property']`), array indices (`[0]`), wildcards (`[*]`) to select all items in an array, and recursive descent (`..fieldname`) to find fields at any depth. You can also use simple dot notation directly in column declarations, and strings beginning with `$` are automatically treated as JSONPath selectors. Examples: `jsonpath('$.orders[*].total')` selects the total field from all orders, `jsonpath('$.customer.address.city')` selects nested properties, and `jsonpath('$..email')` recursively finds any email field in the document.", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["JSONPath", "nested fields", "selectors"], "related_skills": ["skill_json_sources.md"], "related_docs": [], "original_answer": "Use JSONPath selectors with `jsonpath('$.path.to.field')` in your `columns/1` or `schema/1` declaration. JSONPath supports dot notation, bracket properties, array indices, wildcards `[*]`, and recursive descent `..fieldname`. Example:\n```prolog\ncolumns([\n    jsonpath('$.orders[*].total'),\n    jsonpath('$.customer.address.city')\n])\n```\nStrings already starting with `$` are automatically treated as JSONPath.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_002_q1", "cluster_id": "skill_json_sources_002", "question": "Can I use JSONPath expressions to query JSON?", "answer": "Yes, you can use JSONPath expressions to query JSON data. Use `jsonpath('$.path.to.field')` in your `columns/1` or `schema/1` declaration. JSONPath supports: dot notation for property access, bracket properties (`['foo']`), array indices (`[0]`), wildcards (`[*]`) to match multiple values, and recursive descent (`..fieldname`) to search nested structures. Strings that begin with `$` are automatically treated as JSONPath selectors. Example: `columns(['$.orders[*].total', '$.customer.address.city'])`.", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["JSONPath", "nested fields", "selectors"], "related_skills": ["skill_json_sources.md"], "related_docs": [], "original_answer": "Use JSONPath selectors with `jsonpath('$.path.to.field')` in your `columns/1` or `schema/1` declaration. JSONPath supports dot notation, bracket properties, array indices, wildcards `[*]`, and recursive descent `..fieldname`. Example:\n```prolog\ncolumns([\n    jsonpath('$.orders[*].total'),\n    jsonpath('$.customer.address.city')\n])\n```\nStrings already starting with `$` are automatically treated as JSONPath.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_json_sources_002_q2", "cluster_id": "skill_json_sources_002", "question": "How do I extract deeply nested JSON values?", "answer": "Use JSONPath selectors with `jsonpath('$.path.to.field')` in your `columns/1` or `schema/1` declaration to extract deeply nested JSON values. JSONPath supports dot notation for nested properties (e.g., `$.customer.address.city`), bracket properties (`['foo']`), array indices (`[0]`), wildcards (`[*]`), and recursive descent (`..fieldname`). Strings beginning with `$` are automatically treated as JSONPath selectors, so you can use `columns(['$.orders[0].id'])` directly.", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["JSONPath", "nested fields", "selectors"], "related_skills": ["skill_json_sources.md"], "related_docs": [], "original_answer": "Use JSONPath selectors with `jsonpath('$.path.to.field')` in your `columns/1` or `schema/1` declaration. JSONPath supports dot notation, bracket properties, array indices, wildcards `[*]`, and recursive descent `..fieldname`. Example:\n```prolog\ncolumns([\n    jsonpath('$.orders[*].total'),\n    jsonpath('$.customer.address.city')\n])\n```\nStrings already starting with `$` are automatically treated as JSONPath.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_json_sources_003_q0", "cluster_id": "skill_json_sources_003", "question": "How do I return entire JSON objects as rows instead of selecting specific columns?", "answer": "Use return-object mode by setting `arity(1)`, `return_object(true)`, and providing a `type_hint/1` with a .NET type. Example:\n```prolog\n:- source(json, raw_data, [\n    json_file('data.json'),\n    arity(1),\n    return_object(true),\n    type_hint('System.Text.Json.Nodes.JsonObject, System.Text.Json')\n]).\n```\nThis returns the full JSON object for each row instead of projecting specific fields.", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["JSON objects", "return modes"], "related_skills": ["skill_json_sources.md"], "related_docs": [], "original_answer": "Use return-object mode by setting `arity(1)`, `return_object(true)`, and providing a `type_hint/1` with a .NET type. Example:\n```prolog\n:- source(json, raw_data, [\n    json_file('data.json'),\n    arity(1),\n    return_object(true),\n    type_hint('System.Text.Json.Nodes.JsonObject, System.Text.Json')\n]).\n```\nThis returns the full JSON object for each row instead of projecting specific fields.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_json_sources_003_q1", "cluster_id": "skill_json_sources_003", "question": "Can I get raw JSON objects from a source?", "answer": "Yes. Use return-object mode by setting `arity(1)`, `return_object(true)`, and providing a `type_hint/1` with a .NET type. Example:\n```prolog\n:- source(json, raw_data, [\n    json_file('data.json'),\n    arity(1),\n    return_object(true),\n    type_hint('System.Text.Json.Nodes.JsonObject, System.Text.Json')\n]).\n```\nThis returns the full JSON object for each row instead of projecting specific fields.", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["JSON objects", "return modes"], "related_skills": ["skill_json_sources.md"], "related_docs": [], "original_answer": "Use return-object mode by setting `arity(1)`, `return_object(true)`, and providing a `type_hint/1` with a .NET type. Example:\n```prolog\n:- source(json, raw_data, [\n    json_file('data.json'),\n    arity(1),\n    return_object(true),\n    type_hint('System.Text.Json.Nodes.JsonObject, System.Text.Json')\n]).\n```\nThis returns the full JSON object for each row instead of projecting specific fields.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_json_sources_003_q2", "cluster_id": "skill_json_sources_003", "question": "How do I work with unflattened JSON data?", "answer": "To work with unflattened JSON data, use return-object mode in your source declaration. Set `arity(1)`, `return_object(true)`, and provide a `type_hint/1` specifying the .NET type for JSON objects:\n\n```prolog\n:- source(json, raw_data, [\n    json_file('data.json'),\n    arity(1),\n    return_object(true),\n    type_hint('System.Text.Json.Nodes.JsonObject, System.Text.Json')\n]).\n```\n\nThis returns complete JSON objects as rows without flattening or projecting individual fields. Alternatively, use `schema/1` with `record/2` to define typed nested structures that preserve the JSON hierarchy while providing strongly-typed access to nested data.", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["JSON objects", "return modes"], "related_skills": ["skill_json_sources.md"], "related_docs": [], "original_answer": "Use return-object mode by setting `arity(1)`, `return_object(true)`, and providing a `type_hint/1` with a .NET type. Example:\n```prolog\n:- source(json, raw_data, [\n    json_file('data.json'),\n    arity(1),\n    return_object(true),\n    type_hint('System.Text.Json.Nodes.JsonObject, System.Text.Json')\n]).\n```\nThis returns the full JSON object for each row instead of projecting specific fields.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_004_q0", "cluster_id": "skill_json_sources_004", "question": "How do I create typed records from JSON data?", "answer": "To create typed records from JSON data, use the `schema/1` declaration with field specifications. Each field maps a name to a JSONPath or dot-notation selector and a type. Include `record_type('YourRecordName')` to name the generated POCO. Example:\n\n```prolog\n:- source(json, products, [\n    json_file('products.json'),\n    schema([\n        field(id, 'id', string),\n        field(name, 'name', string),\n        field(price, 'price', double)\n    ]),\n    record_type('ProductRecord')\n]).\n```\n\nThe predicate arity must be 1. For nested objects within the schema, use `record(TypeName, Fields)` to define sub-records. The C# backend automatically generates the POCO classes and instantiates nested records at runtime.", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["schema", "records", "typed data"], "related_skills": ["skill_json_sources.md"], "related_docs": [], "original_answer": "Use `schema/1` to declare typed fields and let the C# backend generate POCOs automatically. Example:\n```prolog\n:- source(json, products, [\n    json_file('products.json'),\n    schema([\n        field(id, 'id', string),\n        field(name, 'name', string),\n        field(price, 'price', double)\n    ]),\n    record_type('ProductRecord')\n]).\n```\nFor nested objects, use `record(TypeName, Fields)` within the schema. The arity must be 1; nested records are instantiated automatically at runtime.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_004_q1", "cluster_id": "skill_json_sources_004", "question": "Can I automatically generate C# classes from JSON sources?", "answer": "Yes, use `schema/1` to automatically generate C# POCOs from JSON sources. Declare typed fields with `field(Name, JsonPath, Type)` and specify `record_type('ClassName')`. The C# backend generates the class at runtime. For nested objects, use `record(TypeName, Fields)` within the schema definition. Arity must be 1. Example:\n\n```prolog\n:- source(json, products, [\n    json_file('products.json'),\n    schema([\n        field(id, 'id', string),\n        field(name, 'name', string),\n        field(price, 'price', double)\n    ]),\n    record_type('ProductRecord')\n]).\n```\n\nNested records are automatically instantiated at runtime.", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["schema", "records", "typed data"], "related_skills": ["skill_json_sources.md"], "related_docs": [], "original_answer": "Use `schema/1` to declare typed fields and let the C# backend generate POCOs automatically. Example:\n```prolog\n:- source(json, products, [\n    json_file('products.json'),\n    schema([\n        field(id, 'id', string),\n        field(name, 'name', string),\n        field(price, 'price', double)\n    ]),\n    record_type('ProductRecord')\n]).\n```\nFor nested objects, use `record(TypeName, Fields)` within the schema. The arity must be 1; nested records are instantiated automatically at runtime.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_004_q2", "cluster_id": "skill_json_sources_004", "question": "How do I define a schema for JSON data?", "answer": "To define a schema for JSON data, use the `schema/1` directive within a `source(json, ...)` declaration. Specify an array of `field(Name, Path, Type)` tuples where Name is the field name, Path is the JSONPath or dot-notation selector, and Type is the data type (e.g., string, double, int). Optionally use `record_type('RecordName')` to name the generated POCO. Set arity to 1. For nested objects, wrap field definitions in `record(TypeName, Fields)` or `record(Fields)` for auto-naming. Example: `source(json, products, [json_file('products.json'), schema([field(id, 'id', string), field(name, 'name', string), field(price, 'price', double)]), record_type('ProductRecord')])`. The C# backend automatically generates the typed record at runtime.", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["schema", "records", "typed data"], "related_skills": ["skill_json_sources.md"], "related_docs": [], "original_answer": "Use `schema/1` to declare typed fields and let the C# backend generate POCOs automatically. Example:\n```prolog\n:- source(json, products, [\n    json_file('products.json'),\n    schema([\n        field(id, 'id', string),\n        field(name, 'name', string),\n        field(price, 'price', double)\n    ]),\n    record_type('ProductRecord')\n]).\n```\nFor nested objects, use `record(TypeName, Fields)` within the schema. The arity must be 1; nested records are instantiated automatically at runtime.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_001_q0", "cluster_id": "skill_unifyweaver_compile_001", "question": "How do I convert Prolog rules into an executable bash script?", "answer": "Use the UnifyWeaver compiler to transpile Prolog predicates into executable bash scripts. Run: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<prolog_file>'), compile(<predicate_indicator>, [output_dir('.')]\" -t halt`. Replace `<prolog_file>` with your `.pl` file path and `<predicate_indicator>` with your main predicate in `functor/arity` format (e.g., `choose_strategy/3`). The compiler automatically handles dependencies and outputs an executable `.sh` file in your specified directory.", "question_type": "medium", "topics": ["Compilation", "Prolog-to-Bash Transpilation"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "transpilation", "bash", "prolog"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "docs/ADVANCED_RECURSION.md", "src/unifyweaver/core/compiler_driver.pl"], "original_answer": "Use the UnifyWeaver compiler to transpile Prolog predicates into executable bash scripts. Run: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<prolog_file>'), compile(<predicate_indicator>, [output_dir('.')])\" -t halt`. Specify your `.pl` file, the main predicate (e.g., `choose_strategy/3`), and output directory. The compiler will handle dependencies automatically.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_001_q1", "cluster_id": "skill_unifyweaver_compile_001", "question": "How do I transpile Prolog predicates to bash?", "answer": "To transpile Prolog predicates to bash, use the UnifyWeaver compiler with SWI-Prolog. Run: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<prolog_file>'), compile(<predicate_indicator>, [output_dir('.')])\" -t halt`. Replace `<prolog_file>` with your `.pl` file path and `<predicate_indicator>` with the main predicate in `functor/arity` format (e.g., `choose_strategy/3`). The compiler automatically resolves dependencies and generates an executable `.sh` file in the specified output directory. Note: Direct arithmetic comparison operators (>, <, =<) in predicates will cause compilation to fail.", "question_type": "medium", "topics": ["Compilation", "Prolog-to-Bash Transpilation"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "transpilation", "bash", "prolog"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "docs/ADVANCED_RECURSION.md", "src/unifyweaver/core/compiler_driver.pl"], "original_answer": "Use the UnifyWeaver compiler to transpile Prolog predicates into executable bash scripts. Run: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<prolog_file>'), compile(<predicate_indicator>, [output_dir('.')])\" -t halt`. Specify your `.pl` file, the main predicate (e.g., `choose_strategy/3`), and output directory. The compiler will handle dependencies automatically.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_001_q2", "cluster_id": "skill_unifyweaver_compile_001", "question": "What's the process for compiling Prolog to bash?", "answer": "To compile Prolog to bash using UnifyWeaver, use the `unifyweaver.compile` tool by running a swipl command that loads the compiler driver, consults your Prolog file, and invokes the compile function with your predicate indicator and output directory. The basic command format is: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<prolog_file>'), compile(<predicate_indicator>, [output_dir('.')])\" -t halt`. Replace `<prolog_file>` with your source file path (e.g., `my_rules.pl`), `<predicate_indicator>` with your main predicate in functor/arity format (e.g., `choose_strategy/3`), and set `output_dir` to your desired output location. The compiler automatically handles dependencies and generates an executable `.sh` file. Note: predicates using direct arithmetic comparison operators (`>`, `<`, `=<`) cannot currently be transpiled.", "question_type": "medium", "topics": ["Compilation", "Prolog-to-Bash Transpilation"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "transpilation", "bash", "prolog"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "docs/ADVANCED_RECURSION.md", "src/unifyweaver/core/compiler_driver.pl"], "original_answer": "Use the UnifyWeaver compiler to transpile Prolog predicates into executable bash scripts. Run: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<prolog_file>'), compile(<predicate_indicator>, [output_dir('.')])\" -t halt`. Specify your `.pl` file, the main predicate (e.g., `choose_strategy/3`), and output directory. The compiler will handle dependencies automatically.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_001_q3", "cluster_id": "skill_unifyweaver_compile_001", "question": "How do I execute Prolog logic as a bash script?", "answer": "Execute Prolog logic as a bash script using the UnifyWeaver compiler. Run the command: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<prolog_file>'), compile(<predicate_indicator>, [output_dir('.')])\" -t halt`. Replace `<prolog_file>` with your `.pl` file path and `<predicate_indicator>` with your main predicate in `functor/arity` format (e.g., `choose_strategy/3`). The compiler automatically resolves dependencies and generates an executable `.sh` file in your specified output directory.", "question_type": "medium", "topics": ["Compilation", "Prolog-to-Bash Transpilation"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "transpilation", "bash", "prolog"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "docs/ADVANCED_RECURSION.md", "src/unifyweaver/core/compiler_driver.pl"], "original_answer": "Use the UnifyWeaver compiler to transpile Prolog predicates into executable bash scripts. Run: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<prolog_file>'), compile(<predicate_indicator>, [output_dir('.')])\" -t halt`. Specify your `.pl` file, the main predicate (e.g., `choose_strategy/3`), and output directory. The compiler will handle dependencies automatically.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_002_q0", "cluster_id": "skill_unifyweaver_compile_002", "question": "What are the parameters I need to provide to compile Prolog code?", "answer": "To compile Prolog code using the UnifyWeaver transpiler, you need to provide three parameters to the `unifyweaver.compile` tool: (1) `<prolog_file>` - the path to your `.pl` file containing Prolog predicates, (2) `<predicate_indicator>` - the main predicate to compile in `functor/arity` format (e.g., `choose_strategy/3`), and (3) `<options>` - compiler options such as `output_dir('.')` to specify the output directory for the compiled `.sh` file. It is recommended to always explicitly set `output_dir` to a known location like the current directory to avoid unexpected output paths.", "question_type": "long", "topics": ["Compilation", "Prolog-to-Bash Transpilation"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "parameters", "options"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "src/unifyweaver/core/compiler_driver.pl"], "original_answer": "The compiler requires three key parameters: (1) `<prolog_file>` - path to your `.pl` file, (2) `<predicate_indicator>` - the main predicate in `functor/arity` format (e.g., `choose_strategy/3`), and (3) `<options>` - compiler options like `output_dir('.')` to specify where to save the compiled `.sh` file. Always set `output_dir` to a known location to avoid unexpected output paths.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_002_q1", "cluster_id": "skill_unifyweaver_compile_002", "question": "What options does the compiler accept?", "answer": "The compiler accepts options passed as a comma-separated list in the `compile()` call. Common options include `output_dir(Directory)` to specify where to save the compiled `.sh` file. It is highly recommended to always set `output_dir` to a known location, like `'.'`, to avoid unexpected output paths. Other options may be available depending on the compiler implementation, but `output_dir` is the primary documented option for controlling compilation behavior.", "question_type": "long", "topics": ["Compilation", "Prolog-to-Bash Transpilation"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "parameters", "options"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "src/unifyweaver/core/compiler_driver.pl"], "original_answer": "The compiler requires three key parameters: (1) `<prolog_file>` - path to your `.pl` file, (2) `<predicate_indicator>` - the main predicate in `functor/arity` format (e.g., `choose_strategy/3`), and (3) `<options>` - compiler options like `output_dir('.')` to specify where to save the compiled `.sh` file. Always set `output_dir` to a known location to avoid unexpected output paths.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "The skill document only explicitly documents `output_dir()` as a compiler option. The phrase 'other options may be available' is somewhat speculative, as the document does not provide a comprehensive list of all accepted options. The answer would be stronger with explicit enumeration of additional options if they exist."}
{"pair_id": "skill_unifyweaver_compile_002_q2", "cluster_id": "skill_unifyweaver_compile_002", "question": "How do I specify the output location for compiled scripts?", "answer": "To specify the output location for compiled scripts, use the `output_dir(Directory)` option in the compiler command. Pass it as a parameter to the `compile()` function like this: `compile(choose_strategy/3, [output_dir('.')])`. The filename will be automatically derived from the predicate name. It is highly recommended to always explicitly set `output_dir` to a known location (such as `'.'`) to avoid unexpected output paths.", "question_type": "long", "topics": ["Compilation", "Prolog-to-Bash Transpilation"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "parameters", "options"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "src/unifyweaver/core/compiler_driver.pl"], "original_answer": "The compiler requires three key parameters: (1) `<prolog_file>` - path to your `.pl` file, (2) `<predicate_indicator>` - the main predicate in `functor/arity` format (e.g., `choose_strategy/3`), and (3) `<options>` - compiler options like `output_dir('.')` to specify where to save the compiled `.sh` file. Always set `output_dir` to a known location to avoid unexpected output paths.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_002_q3", "cluster_id": "skill_unifyweaver_compile_002", "question": "What do I need to configure for compilation?", "answer": "For compilation, you need to configure three key parameters in the `unifyweaver.compile` tool: (1) `<prolog_file>` - the path to your `.pl` file containing Prolog source code, (2) `<predicate_indicator>` - the main predicate to compile in `functor/arity` format (e.g., `choose_strategy/3`), and (3) `<options>` - compiler options such as `output_dir('.')` to specify the output directory for the compiled `.sh` file. It is highly recommended to always explicitly set `output_dir` to a known location like the current directory to prevent unexpected output paths.", "question_type": "long", "topics": ["Compilation", "Prolog-to-Bash Transpilation"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "parameters", "options"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "src/unifyweaver/core/compiler_driver.pl"], "original_answer": "The compiler requires three key parameters: (1) `<prolog_file>` - path to your `.pl` file, (2) `<predicate_indicator>` - the main predicate in `functor/arity` format (e.g., `choose_strategy/3`), and (3) `<options>` - compiler options like `output_dir('.')` to specify where to save the compiled `.sh` file. Always set `output_dir` to a known location to avoid unexpected output paths.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_003_q0", "cluster_id": "skill_unifyweaver_compile_003", "question": "What are the limitations when compiling Prolog to bash?", "answer": "The current compiler has a known limitation and cannot transpile predicates that directly use arithmetic comparison operators (>, <, =<). Using these operators directly in Prolog rules will cause compilation to fail. Workarounds and supported patterns are available in the related documentation.", "question_type": "medium", "topics": ["Compilation", "Prolog-to-Bash Transpilation"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["limitations", "arithmetic", "troubleshooting"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "docs/ADVANCED_RECURSION.md"], "original_answer": "The current compiler cannot transpile predicates that directly use arithmetic comparison operators (>, <, =<). This is a known limitation that will cause compilation to fail. Avoid using these operators directly in your Prolog rules. Check the related documentation for workarounds and supported patterns.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_003_q1", "cluster_id": "skill_unifyweaver_compile_003", "question": "Why does my Prolog compilation fail?", "answer": "Your Prolog compilation fails because the compiler has a known limitation: it cannot transpile predicates that directly use arithmetic comparison operators (>, <, =<). If your Prolog code uses these operators, remove them or refactor your logic to avoid direct arithmetic comparisons. Check the documentation for supported patterns and workarounds.", "question_type": "medium", "topics": ["Compilation", "Prolog-to-Bash Transpilation"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["limitations", "arithmetic", "troubleshooting"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "docs/ADVANCED_RECURSION.md"], "original_answer": "The current compiler cannot transpile predicates that directly use arithmetic comparison operators (>, <, =<). This is a known limitation that will cause compilation to fail. Avoid using these operators directly in your Prolog rules. Check the related documentation for workarounds and supported patterns.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_003_q2", "cluster_id": "skill_unifyweaver_compile_003", "question": "Which Prolog features don't work with the bash compiler?", "answer": "The UnifyWeaver Prolog-to-Bash compiler has a known limitation: it cannot transpile predicates that directly use arithmetic comparison operators (>, <, =<). These operators will cause compilation to fail. To work around this limitation, avoid using arithmetic comparisons directly in your Prolog rules. Consult the related documentation for supported patterns and workarounds.", "question_type": "medium", "topics": ["Compilation", "Prolog-to-Bash Transpilation"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["limitations", "arithmetic", "troubleshooting"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "docs/ADVANCED_RECURSION.md"], "original_answer": "The current compiler cannot transpile predicates that directly use arithmetic comparison operators (>, <, =<). This is a known limitation that will cause compilation to fail. Avoid using these operators directly in your Prolog rules. Check the related documentation for workarounds and supported patterns.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_003_q3", "cluster_id": "skill_unifyweaver_compile_003", "question": "Can I use arithmetic operators in my Prolog rules?", "answer": "No, you cannot use arithmetic operators (>, <, =<) directly in your Prolog rules. The UnifyWeaver compiler has a known limitation and cannot transpile predicates that directly use arithmetic comparison operators. Using these operators will cause compilation to fail. You should avoid them in your Prolog source code.", "question_type": "medium", "topics": ["Compilation", "Prolog-to-Bash Transpilation"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["limitations", "arithmetic", "troubleshooting"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "docs/ADVANCED_RECURSION.md"], "original_answer": "The current compiler cannot transpile predicates that directly use arithmetic comparison operators (>, <, =<). This is a known limitation that will cause compilation to fail. Avoid using these operators directly in your Prolog rules. Check the related documentation for workarounds and supported patterns.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_004_q0", "cluster_id": "skill_unifyweaver_compile_004", "question": "How does the compiler handle dependencies in my Prolog predicates?", "answer": "The compiler automatically analyzes your main predicate and traverses its dependency tree to identify and compile all user-defined predicates it depends on. You only need to specify the main predicate (in `functor/arity` format) in the compile command, and the compiler handles including all necessary dependencies. This means you don't need to manually manage or list dependent predicates\u2014the compiler discovers and includes them automatically during transpilation.", "question_type": "long", "topics": ["Compilation", "Prolog-to-Bash Transpilation"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["dependencies", "compilation", "recursion"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/ADVANCED_RECURSION.md"], "original_answer": "The compiler automatically analyzes and includes any user-defined predicates that your main predicate depends on. You only need to specify the main predicate you want to compile, and the compiler will traverse the dependency tree and compile everything needed. This simplifies the compilation process for complex logic.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_004_q1", "cluster_id": "skill_unifyweaver_compile_004", "question": "Do I need to specify all dependent predicates?", "answer": "No, you only need to specify the main predicate you want to compile using the predicate indicator (e.g., `choose_strategy/3`). The compiler automatically analyzes and includes any user-defined predicates that your main predicate depends on by traversing the dependency tree.", "question_type": "long", "topics": ["Compilation", "Prolog-to-Bash Transpilation"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["dependencies", "compilation", "recursion"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/ADVANCED_RECURSION.md"], "original_answer": "The compiler automatically analyzes and includes any user-defined predicates that your main predicate depends on. You only need to specify the main predicate you want to compile, and the compiler will traverse the dependency tree and compile everything needed. This simplifies the compilation process for complex logic.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_004_q2", "cluster_id": "skill_unifyweaver_compile_004", "question": "Will the compiler automatically include predicates my main predicate calls?", "answer": "Yes, the compiler automatically analyzes and includes any user-defined predicates that your main predicate depends on. You only need to specify the main predicate you want to compile (e.g., `choose_strategy/3`), and the compiler will traverse the dependency tree and compile all necessary dependencies automatically.", "question_type": "long", "topics": ["Compilation", "Prolog-to-Bash Transpilation"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["dependencies", "compilation", "recursion"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/ADVANCED_RECURSION.md"], "original_answer": "The compiler automatically analyzes and includes any user-defined predicates that your main predicate depends on. You only need to specify the main predicate you want to compile, and the compiler will traverse the dependency tree and compile everything needed. This simplifies the compilation process for complex logic.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_004_q3", "cluster_id": "skill_unifyweaver_compile_004", "question": "How are recursive predicates handled during compilation?", "answer": "Recursive predicates are handled through the compiler's dependency analysis, which tracks predicate calls and ensures proper code generation order. When compiling, dependencies are resolved recursively. The transpiler generates target-language code that preserves recursion semantics (e.g., proper tail-call handling where supported).", "question_type": "long", "topics": ["Compilation", "Prolog-to-Bash Transpilation"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["dependencies", "compilation", "recursion"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/ADVANCED_RECURSION.md"], "original_answer": "The compiler automatically analyzes and includes any user-defined predicates that your main predicate depends on. You only need to specify the main predicate you want to compile, and the compiler will traverse the dependency tree and compile everything needed. This simplifies the compilation process for complex logic.", "answer_tailored": true, "confidence": 0.75, "confidence_issues": "Specific recursion optimizations depend on target language", "manually_reviewed": true}
{"pair_id": "skill_unifyweaver_environment_001_q0", "cluster_id": "skill_unifyweaver_environment_001", "question": "I'm getting an error that says 'source_sink library(...) does not exist' when running a Prolog script. How do I fix this?", "answer": "This error occurs when the module search path isn't configured. To fix it, use `init.pl` from the project root: `swipl -f init.pl -g \"use_module(library(unifyweaver/sources)), halt\"`. The `-f init.pl` flag automatically sets up the file search paths and library directories needed for UnifyWeaver modules. Alternatively, if you're using relative paths like `:- use_module('src/unifyweaver/sources').`, ensure you're running the command from the project root directory where these relative paths are valid.", "question_type": "long", "topics": ["Running UnifyWeaver", "Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["error-handling", "module-loading", "prolog-setup"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["init.pl", "src/unifyweaver/"], "original_answer": "This error means the module search path isn't configured. The best solution is to use init.pl from the project root: `swipl -f init.pl -g \"use_module(library(unifyweaver/sources)), halt\"`. Alternatively, use relative paths like `:- use_module('src/unifyweaver/sources').` and make sure you're running from the project root directory.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_001_q1", "cluster_id": "skill_unifyweaver_environment_001", "question": "How do I resolve library path errors in UnifyWeaver?", "answer": "Library path errors in UnifyWeaver occur when the module search path isn't configured. To resolve this, use `init.pl` from the project root: `swipl -f init.pl -g \"use_module(library(unifyweaver/sources)), halt\"`. This automatically sets up the file search path and library directories. Alternatively, use relative paths like `:- use_module('src/unifyweaver/sources').` but ensure you're running from the project root directory. If you see errors like \"source_sink 'library(...)' does not exist\" or \"Unknown procedure\", verify you're in the project root and using one of these approaches.", "question_type": "long", "topics": ["Running UnifyWeaver", "Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["error-handling", "module-loading", "prolog-setup"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["init.pl", "src/unifyweaver/"], "original_answer": "This error means the module search path isn't configured. The best solution is to use init.pl from the project root: `swipl -f init.pl -g \"use_module(library(unifyweaver/sources)), halt\"`. Alternatively, use relative paths like `:- use_module('src/unifyweaver/sources').` and make sure you're running from the project root directory.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_001_q2", "cluster_id": "skill_unifyweaver_environment_001", "question": "What should I do when module loading fails?", "answer": "When module loading fails, first ensure you're running from the project root directory, as UnifyWeaver modules use relative paths. The best solution is to use init.pl, which automatically configures the module search path: `swipl -f init.pl -g \"use_module(library(unifyweaver/sources)), halt\"`. If you can't use init.pl, manually set up paths by running from the project root and using relative paths like `:- use_module('src/unifyweaver/sources').` Check that the module file actually exists at the expected path relative to your working directory.", "question_type": "long", "topics": ["Running UnifyWeaver", "Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["error-handling", "module-loading", "prolog-setup"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["init.pl", "src/unifyweaver/"], "original_answer": "This error means the module search path isn't configured. The best solution is to use init.pl from the project root: `swipl -f init.pl -g \"use_module(library(unifyweaver/sources)), halt\"`. Alternatively, use relative paths like `:- use_module('src/unifyweaver/sources').` and make sure you're running from the project root directory.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_002_q0", "cluster_id": "skill_unifyweaver_environment_002", "question": "What's the recommended way to run UnifyWeaver Prolog scripts?", "answer": "The recommended way to run UnifyWeaver Prolog scripts is to use init.pl from the project root. Run `cd /path/to/UnifyWeaver && swipl -f init.pl -g \"goal, halt\"`. This automatically configures file search paths and module loading, allowing you to use `library(unifyweaver/...)` syntax without manual path setup. For playbooks requiring inline initialization, you can alternatively set paths manually with `asserta(file_search_path(unifyweaver, 'src/unifyweaver'))` before loading modules.", "question_type": "medium", "topics": ["Running UnifyWeaver", "Script Execution"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["script-execution", "best-practices", "module-loading"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["init.pl", "playbooks/"], "original_answer": "Use init.pl from the project root for automatic environment setup: `cd /path/to/UnifyWeaver && swipl -f init.pl -g \"goal, halt\"`. This automatically configures file search paths and module loading. For inline initialization in playbooks, you can also manually set paths with `asserta(file_search_path(unifyweaver, 'src/unifyweaver'))` before loading modules.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_002_q1", "cluster_id": "skill_unifyweaver_environment_002", "question": "How should I execute Prolog scripts with UnifyWeaver modules?", "answer": "Execute Prolog scripts with UnifyWeaver modules by using init.pl from the project root: `cd /path/to/UnifyWeaver && swipl -f init.pl -g \"goal, halt\"`. This automatically configures file search paths and enables `library(unifyweaver/...)` syntax. Alternatively, manually set paths with `asserta(file_search_path(unifyweaver, 'src/unifyweaver'))` before loading modules. Always ensure you're running from the project root directory where init.pl resides.", "question_type": "medium", "topics": ["Running UnifyWeaver", "Script Execution"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["script-execution", "best-practices", "module-loading"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["init.pl", "playbooks/"], "original_answer": "Use init.pl from the project root for automatic environment setup: `cd /path/to/UnifyWeaver && swipl -f init.pl -g \"goal, halt\"`. This automatically configures file search paths and module loading. For inline initialization in playbooks, you can also manually set paths with `asserta(file_search_path(unifyweaver, 'src/unifyweaver'))` before loading modules.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_002_q2", "cluster_id": "skill_unifyweaver_environment_002", "question": "What's the best method to run UnifyWeaver code?", "answer": "The best method to run UnifyWeaver code is using init.pl from the project root. Run `cd /path/to/UnifyWeaver && swipl -f init.pl -g \"goal, halt\"` to automatically configure file search paths and module loading. This is the recommended approach because init.pl handles all environment setup without manual path configuration. For interactive sessions, use `swipl -f init.pl` without the goal flag. For playbooks requiring reproducibility, you can also manually initialize paths with `asserta(file_search_path(unifyweaver, 'src/unifyweaver'))` before loading modules, but init.pl is preferred.", "question_type": "medium", "topics": ["Running UnifyWeaver", "Script Execution"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["script-execution", "best-practices", "module-loading"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["init.pl", "playbooks/"], "original_answer": "Use init.pl from the project root for automatic environment setup: `cd /path/to/UnifyWeaver && swipl -f init.pl -g \"goal, halt\"`. This automatically configures file search paths and module loading. For inline initialization in playbooks, you can also manually set paths with `asserta(file_search_path(unifyweaver, 'src/unifyweaver'))` before loading modules.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_003_q0", "cluster_id": "skill_unifyweaver_environment_003", "question": "Do I need to run UnifyWeaver commands from a specific directory?", "answer": "Yes, you must always run UnifyWeaver commands from the project root directory. This is critical because UnifyWeaver modules use relative paths from the project root (like `src/unifyweaver/`, `playbooks/`, and `templates/`). The init.pl initialization file also depends on being in the project root to properly set up the file search paths and module loading environment.", "question_type": "medium", "topics": ["Running UnifyWeaver", "Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["working-directory", "setup", "best-practices"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["init.pl", "src/unifyweaver/"], "original_answer": "Yes, always run UnifyWeaver commands from the project root directory. This is critical because UnifyWeaver modules use relative paths from the project root (like `src/unifyweaver/`, `playbooks/`, and `templates/`). The init.pl file itself must also be in the project root to work correctly.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_003_q1", "cluster_id": "skill_unifyweaver_environment_003", "question": "Where should I execute UnifyWeaver scripts from?", "answer": "Execute UnifyWeaver scripts from the project root directory. This is critical because UnifyWeaver modules use relative paths from the project root (such as `src/unifyweaver/`, `playbooks/`, and `templates/`). The init.pl initialization file must also be located in the project root to function correctly. When running commands, use `cd /path/to/UnifyWeaver` first, then execute your script or Prolog command.", "question_type": "medium", "topics": ["Running UnifyWeaver", "Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["working-directory", "setup", "best-practices"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["init.pl", "src/unifyweaver/"], "original_answer": "Yes, always run UnifyWeaver commands from the project root directory. This is critical because UnifyWeaver modules use relative paths from the project root (like `src/unifyweaver/`, `playbooks/`, and `templates/`). The init.pl file itself must also be in the project root to work correctly.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_003_q2", "cluster_id": "skill_unifyweaver_environment_003", "question": "Does the working directory matter for running UnifyWeaver?", "answer": "Yes, the working directory is critical for running UnifyWeaver. All commands must be executed from the project root directory because UnifyWeaver modules use relative paths from that location (e.g., `src/unifyweaver/`, `playbooks/`, `templates/`). The `init.pl` initialization file also must reside in and be run from the project root to properly set up the environment.", "question_type": "medium", "topics": ["Running UnifyWeaver", "Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["working-directory", "setup", "best-practices"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["init.pl", "src/unifyweaver/"], "original_answer": "Yes, always run UnifyWeaver commands from the project root directory. This is critical because UnifyWeaver modules use relative paths from the project root (like `src/unifyweaver/`, `playbooks/`, and `templates/`). The init.pl file itself must also be in the project root to work correctly.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_004_q0", "cluster_id": "skill_unifyweaver_environment_004", "question": "I'm getting an 'Unknown procedure' error when running my UnifyWeaver script. What should I check?", "answer": "An 'Unknown procedure' error means a module wasn't loaded or a procedure isn't exported. Check: (1) The module file exists at `src/unifyweaver/...`, (2) The procedure is exported by that module, (3) You're loading it with `:- use_module('src/unifyweaver/...')` or `:- use_module(library(unifyweaver/...))` if using init.pl, (4) You're running from the project root directory where relative paths resolve correctly. If using init.pl, verify you started with `swipl -f init.pl`.", "question_type": "long", "topics": ["Running UnifyWeaver", "Error Handling"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["error-handling", "module-loading", "debugging"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["src/unifyweaver/", "init.pl"], "original_answer": "This means a module wasn't loaded. First, verify the module file exists at `src/unifyweaver/...` and exports the procedure. Then ensure you're loading the module with `:- use_module('src/unifyweaver/...')` or `:- use_module(library(unifyweaver/...))` if using init.pl. Finally, confirm you're running from the project root directory where the relative paths resolve correctly.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_004_q1", "cluster_id": "skill_unifyweaver_environment_004", "question": "Why does my script say the procedure doesn't exist?", "answer": "Yes, you can create an isolated UnifyWeaver environment for testing. Run `bash scripts/testing/init_testing.sh` from the project root. Options include: `-d <dir>` to specify parent directory for test_env, `-p <path>` for custom full path, and `--force-windows` to test Windows wrapper logic. The script creates a self-contained environment with all dependencies.", "question_type": "long", "topics": ["Running UnifyWeaver", "Error Handling"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["error-handling", "module-loading", "debugging"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["src/unifyweaver/", "init.pl"], "original_answer": "This means a module wasn't loaded. First, verify the module file exists at `src/unifyweaver/...` and exports the procedure. Then ensure you're loading the module with `:- use_module('src/unifyweaver/...')` or `:- use_module(library(unifyweaver/...))` if using init.pl. Finally, confirm you're running from the project root directory where the relative paths resolve correctly.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_unifyweaver_environment_004_q2", "cluster_id": "skill_unifyweaver_environment_004", "question": "How do I debug missing procedure errors?", "answer": "Missing procedure errors typically indicate a module wasn't loaded. To debug: (1) Verify the module file exists at `src/unifyweaver/...` and that it exports the procedure you're calling, (2) Ensure you're loading the module with `:- use_module('src/unifyweaver/...')` or `:- use_module(library(unifyweaver/...))` if using init.pl, (3) Confirm you're running from the project root directory so relative paths resolve correctly, and (4) Check that the procedure name and arity match exactly in both the module definition and your call.", "question_type": "long", "topics": ["Running UnifyWeaver", "Error Handling"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["error-handling", "module-loading", "debugging"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["src/unifyweaver/", "init.pl"], "original_answer": "This means a module wasn't loaded. First, verify the module file exists at `src/unifyweaver/...` and exports the procedure. Then ensure you're loading the module with `:- use_module('src/unifyweaver/...')` or `:- use_module(library(unifyweaver/...))` if using init.pl. Finally, confirm you're running from the project root directory where the relative paths resolve correctly.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_extract_records_001_q0", "cluster_id": "skill_extract_records_001", "question": "How do I extract structured examples from UnifyWeaver markdown files?", "answer": "To extract structured examples from UnifyWeaver markdown files, use the `extract_records.pl` script:\n\n```bash\nperl scripts/utils/extract_records.pl [OPTIONS] [PATH...]\n```\n\nKey options for structured extraction:\n- `-f json`: Output as JSON objects (best for programmatic use)\n- `-f content`: Extract only the code/content blocks\n- `-f full`: Get the complete original Markdown block\n- `-q <pattern>`: Filter records by name with regex\n- `--file-filter all`: Process all files (default filters by file_type=UnifyWeaver Example Library)\n\nExample: `perl scripts/utils/extract_records.pl -f json -q \"pattern\" path/to/file.md`\n\nThis tool is more effective than `grep` because it parses metadata, handles multi-line blocks reliably, and returns structured output.", "question_type": "medium", "topics": ["Compilation", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["parsing", "markdown", "extraction", "records", "examples"], "related_skills": ["skill_extract_records.md"], "related_docs": ["docs/playbooks/parsing/README.md", "scripts/utils/extract_records.pl"], "original_answer": "Use the `extract_records.pl` script for parsing UnifyWeaver Example Record Format files:\n\n```bash\nperl scripts/utils/extract_records.pl [OPTIONS] [PATH...]\n```\n\nCommon options:\n- `-f content`: Extract just the code/content\n- `-f json`: Get structured JSON output\n- `-q <pattern>`: Filter records by name\n- `--file-filter all`: Process all files (default filters by file_type)\n\nThis is more robust than `grep` because it handles metadata, multi-line blocks, and produces structured output. See `skill_extract_records.md` for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_extract_records_001_q1", "cluster_id": "skill_extract_records_001", "question": "How can I parse data records from markdown files?", "answer": "Use the `extract_records.pl` script located at `scripts/utils/extract_records.pl` to parse data records from Markdown files that follow the UnifyWeaver Example Record Format. Run it with: `perl scripts/utils/extract_records.pl [OPTIONS] [PATH...]`. Key options include: `-f content` to extract just the code/content, `-f json` for structured JSON output, `-q <pattern>` to filter records by name, and `--file-filter all` to process all files (default filters by file_type=UnifyWeaver Example Library). This tool is more robust than `grep` because it reliably handles metadata, multi-line content blocks, and produces structured output suitable for programmatic processing.", "question_type": "medium", "topics": ["Compilation", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["parsing", "markdown", "extraction", "records", "examples"], "related_skills": ["skill_extract_records.md"], "related_docs": ["docs/playbooks/parsing/README.md", "scripts/utils/extract_records.pl"], "original_answer": "Use the `extract_records.pl` script for parsing UnifyWeaver Example Record Format files:\n\n```bash\nperl scripts/utils/extract_records.pl [OPTIONS] [PATH...]\n```\n\nCommon options:\n- `-f content`: Extract just the code/content\n- `-f json`: Get structured JSON output\n- `-q <pattern>`: Filter records by name\n- `--file-filter all`: Process all files (default filters by file_type)\n\nThis is more robust than `grep` because it handles metadata, multi-line blocks, and produces structured output. See `skill_extract_records.md` for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_extract_records_001_q2", "cluster_id": "skill_extract_records_001", "question": "What's the best way to extract examples from UnifyWeaver documentation?", "answer": "The best way to extract examples from UnifyWeaver documentation is to use the `extract_records.pl` script, which is purpose-built for parsing the UnifyWeaver Example Record Format. Run it with: `perl scripts/utils/extract_records.pl [OPTIONS] [PATH...]`. Key options: `-f content` to extract just code, `-f json` for structured output, `-q <pattern>` to filter by record name, and `--file-filter all` to process all files. This is more robust than generic tools like `grep` because it reliably handles metadata parsing, multi-line content blocks, and produces structured output. For bash scripts, extract with `-f content`, save to a `.sh` file, and run with `bash`. For Prolog code, run with `swipl`. Refer to `skill_extract_records.md` for complete documentation.", "question_type": "medium", "topics": ["Compilation", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["parsing", "markdown", "extraction", "records", "examples"], "related_skills": ["skill_extract_records.md"], "related_docs": ["docs/playbooks/parsing/README.md", "scripts/utils/extract_records.pl"], "original_answer": "Use the `extract_records.pl` script for parsing UnifyWeaver Example Record Format files:\n\n```bash\nperl scripts/utils/extract_records.pl [OPTIONS] [PATH...]\n```\n\nCommon options:\n- `-f content`: Extract just the code/content\n- `-f json`: Get structured JSON output\n- `-q <pattern>`: Filter records by name\n- `--file-filter all`: Process all files (default filters by file_type)\n\nThis is more robust than `grep` because it handles metadata, multi-line blocks, and produces structured output. See `skill_extract_records.md` for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_extract_records_001_q3", "cluster_id": "skill_extract_records_001", "question": "How do I get structured data out of markdown example files?", "answer": "Use the `extract_records.pl` script to parse structured data from UnifyWeaver Example Record Format markdown files:\n\n```bash\nperl scripts/utils/extract_records.pl [OPTIONS] [PATH...]\n```\n\nKey options for extracting structured data:\n- `-f json`: Output as JSON objects (one per record) for programmatic processing\n- `-f content`: Extract just the code/content blocks\n- `-q <pattern>`: Filter records by name using regex\n- `--file-filter all`: Process all files (default filters by file_type)\n\nThis approach is more robust than grep because it parses metadata, handles multi-line blocks reliably, and produces properly structured output suitable for data processing pipelines.", "question_type": "medium", "topics": ["Compilation", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["parsing", "markdown", "extraction", "records", "examples"], "related_skills": ["skill_extract_records.md"], "related_docs": ["docs/playbooks/parsing/README.md", "scripts/utils/extract_records.pl"], "original_answer": "Use the `extract_records.pl` script for parsing UnifyWeaver Example Record Format files:\n\n```bash\nperl scripts/utils/extract_records.pl [OPTIONS] [PATH...]\n```\n\nCommon options:\n- `-f content`: Extract just the code/content\n- `-f json`: Get structured JSON output\n- `-q <pattern>`: Filter records by name\n- `--file-filter all`: Process all files (default filters by file_type)\n\nThis is more robust than `grep` because it handles metadata, multi-line blocks, and produces structured output. See `skill_extract_records.md` for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_extract_records_002_q0", "cluster_id": "skill_extract_records_002", "question": "I need to run an example from the UnifyWeaver examples library - how do I extract and execute it?", "answer": "To extract and execute an example from the UnifyWeaver examples library:\n\n1. **Identify the record name** you want to run (e.g., `unifyweaver.execution.xml_data_source`)\n\n2. **Extract the record content** using the extract_records.pl script:\n   ```bash\n   perl scripts/utils/extract_records.pl \\\n     -f content \\\n     -q \"your.record.name\" \\\n     path/to/examples/file.md > tmp/script.sh\n   ```\n\n3. **Check the code fence type** in the extracted file:\n   - If it's `bash`: Run with `bash tmp/script.sh`\n   - If it's `prolog`: Run with `swipl -f init.pl -g \"consult('tmp/script.pl'), goal, halt\"`\n\n**Critical**: Always use the correct interpreter. Bash scripts must use `bash`, NOT `swipl`. Prolog code must use `swipl`.\n\nFor more details on record types and execution, see the skill_extract_records.md documentation section 4.", "question_type": "long", "topics": ["Compilation", "Extract Records", "Execution"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["execution", "bash", "prolog", "examples", "interpreter"], "related_skills": ["skill_extract_records.md"], "related_docs": ["scripts/utils/extract_records.pl"], "original_answer": "**CRITICAL**: Check the code fence type (```bash or ```prolog) to use the right interpreter.\n\nFor **bash scripts**:\n```bash\nperl scripts/utils/extract_records.pl \\\n  -f content \\\n  -q \"record.name.pattern\" \\\n  path/to/file.md > tmp/script.sh\n\nbash tmp/script.sh  # Use bash, NOT swipl!\n```\n\nFor **Prolog code**:\n```bash\nperl scripts/utils/extract_records.pl \\\n  -f content \\\n  -q \"prolog.record\" \\\n  path/to/file.md > tmp/code.pl\n\nswipl -f init.pl -g \"consult('tmp/code.pl'), goal, halt\"\n```\n\nSee `skill_extract_records.md` section 4 for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_extract_records_002_q1", "cluster_id": "skill_extract_records_002", "question": "How do I run bash scripts from UnifyWeaver markdown examples?", "answer": "To run bash scripts from UnifyWeaver markdown examples:\n\n1. Extract the bash script using `extract_records.pl` with the `-f content` flag:\n```bash\nperl scripts/utils/extract_records.pl \\\n  -f content \\\n  -q \"record.name.pattern\" \\\n  path/to/file.md > tmp/script.sh\n```\n\n2. Execute with `bash` (NOT `swipl`):\n```bash\nbash tmp/script.sh\n```\n\nThe critical distinction: bash scripts use `bash` as the interpreter, while Prolog code uses `swipl`. Always check the code fence type in the markdown (```bash vs ```prolog) to determine which interpreter to use.", "question_type": "long", "topics": ["Compilation", "Extract Records", "Execution"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["execution", "bash", "prolog", "examples", "interpreter"], "related_skills": ["skill_extract_records.md"], "related_docs": ["scripts/utils/extract_records.pl"], "original_answer": "**CRITICAL**: Check the code fence type (```bash or ```prolog) to use the right interpreter.\n\nFor **bash scripts**:\n```bash\nperl scripts/utils/extract_records.pl \\\n  -f content \\\n  -q \"record.name.pattern\" \\\n  path/to/file.md > tmp/script.sh\n\nbash tmp/script.sh  # Use bash, NOT swipl!\n```\n\nFor **Prolog code**:\n```bash\nperl scripts/utils/extract_records.pl \\\n  -f content \\\n  -q \"prolog.record\" \\\n  path/to/file.md > tmp/code.pl\n\nswipl -f init.pl -g \"consult('tmp/code.pl'), goal, halt\"\n```\n\nSee `skill_extract_records.md` section 4 for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_extract_records_002_q2", "cluster_id": "skill_extract_records_002", "question": "What's the correct way to execute extracted example code?", "answer": "To execute extracted example code correctly, first check the code fence type in the Markdown file. For bash scripts (```bash), extract with `perl scripts/utils/extract_records.pl -f content`, save to a .sh file, and run with `bash`. For Prolog code (```prolog), extract the same way but run with `swipl -f init.pl -g \"consult('file.pl'), goal, halt\"`. The critical rule is: match the interpreter to the code type\u2014never run bash scripts with swipl or vice versa.", "question_type": "long", "topics": ["Compilation", "Extract Records", "Execution"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["execution", "bash", "prolog", "examples", "interpreter"], "related_skills": ["skill_extract_records.md"], "related_docs": ["scripts/utils/extract_records.pl"], "original_answer": "**CRITICAL**: Check the code fence type (```bash or ```prolog) to use the right interpreter.\n\nFor **bash scripts**:\n```bash\nperl scripts/utils/extract_records.pl \\\n  -f content \\\n  -q \"record.name.pattern\" \\\n  path/to/file.md > tmp/script.sh\n\nbash tmp/script.sh  # Use bash, NOT swipl!\n```\n\nFor **Prolog code**:\n```bash\nperl scripts/utils/extract_records.pl \\\n  -f content \\\n  -q \"prolog.record\" \\\n  path/to/file.md > tmp/code.pl\n\nswipl -f init.pl -g \"consult('tmp/code.pl'), goal, halt\"\n```\n\nSee `skill_extract_records.md` section 4 for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_extract_records_002_q3", "cluster_id": "skill_extract_records_002", "question": "How do I know whether to use bash or swipl for an extracted example?", "answer": "Check the code fence type in the extracted record. If it starts with ```bash, use bash to run it. If it starts with ```prolog, use swipl. After extracting with `perl scripts/utils/extract_records.pl -f content`, save to the appropriate file type (.sh for bash, .pl for prolog) and execute with the corresponding interpreter: `bash script.sh` for bash scripts or `swipl -f init.pl -g \"consult('file.pl'), goal, halt\"` for Prolog code.", "question_type": "long", "topics": ["Compilation", "Extract Records", "Execution"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["execution", "bash", "prolog", "examples", "interpreter"], "related_skills": ["skill_extract_records.md"], "related_docs": ["scripts/utils/extract_records.pl"], "original_answer": "**CRITICAL**: Check the code fence type (```bash or ```prolog) to use the right interpreter.\n\nFor **bash scripts**:\n```bash\nperl scripts/utils/extract_records.pl \\\n  -f content \\\n  -q \"record.name.pattern\" \\\n  path/to/file.md > tmp/script.sh\n\nbash tmp/script.sh  # Use bash, NOT swipl!\n```\n\nFor **Prolog code**:\n```bash\nperl scripts/utils/extract_records.pl \\\n  -f content \\\n  -q \"prolog.record\" \\\n  path/to/file.md > tmp/code.pl\n\nswipl -f init.pl -g \"consult('tmp/code.pl'), goal, halt\"\n```\n\nSee `skill_extract_records.md` section 4 for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_extract_records_003_q0", "cluster_id": "skill_extract_records_003", "question": "How can I filter and get only specific records from a markdown file?", "answer": "Use the `-q` (query) flag to filter records by their `name` metadata with a regex pattern:\n\n```bash\nperl scripts/utils/extract_records.pl \\\n  -q \"pattern_to_match\" \\\n  path/to/markdown/file.md\n```\n\nFor example, to extract only records named \"unifyweaver.execution.xml_data_source\":\n\n```bash\nperl scripts/utils/extract_records.pl \\\n  -q \"unifyweaver.execution.xml_data_source\" \\\n  playbooks/examples_library/xml_examples.md\n```\n\nYou can also filter files by their YAML frontmatter metadata:\n\n```bash\n# Filter by file type\nperl scripts/utils/extract_records.pl \\\n  --file-filter \"file_type=UnifyWeaver Example Library\" \\\n  path/to/files/\n\n# Process all files regardless of type\nperl scripts/utils/extract_records.pl \\\n  --file-filter all \\\n  path/to/files/\n```\n\nThe `-q` flag accepts regex patterns, so you can use flexible matching like `-q \"xml.*source\"` to match multiple record names.", "question_type": "long", "topics": ["Compilation", "Extract Records", "Filtering"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["filtering", "query", "regex", "metadata", "search"], "related_skills": ["skill_extract_records.md"], "related_docs": ["scripts/utils/extract_records.pl"], "original_answer": "Use the `-q` (query) flag to filter records by their `name` metadata using regex:\n\n```bash\nperl scripts/utils/extract_records.pl \\\n  -q \"unifyweaver.execution.xml_data_source\" \\\n  playbooks/examples_library/xml_examples.md\n```\n\nYou can also filter by file frontmatter:\n```bash\n# Process only specific file types\nperl scripts/utils/extract_records.pl \\\n  --file-filter \"file_type=My Custom Type\" \\\n  path/to/files/\n\n# Process all files regardless of type\nperl scripts/utils/extract_records.pl \\\n  --file-filter all \\\n  path/to/files/\n```\n\nSee `skill_extract_records.md` section 3.1 for all filtering options.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_extract_records_003_q1", "cluster_id": "skill_extract_records_003", "question": "How do I search for particular examples by name?", "answer": "Use the `-q` (query) flag with a regex pattern to search for examples by name. For example:\n\n```bash\nperl scripts/utils/extract_records.pl \\\n  -q \"unifyweaver.execution.xml_data_source\" \\\n  playbooks/examples_library/xml_examples.md\n```\n\nThe pattern matches against the `name` metadata field. You can also filter by file type using `--file-filter` to narrow your search to specific file categories.", "question_type": "long", "topics": ["Compilation", "Extract Records", "Filtering"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["filtering", "query", "regex", "metadata", "search"], "related_skills": ["skill_extract_records.md"], "related_docs": ["scripts/utils/extract_records.pl"], "original_answer": "Use the `-q` (query) flag to filter records by their `name` metadata using regex:\n\n```bash\nperl scripts/utils/extract_records.pl \\\n  -q \"unifyweaver.execution.xml_data_source\" \\\n  playbooks/examples_library/xml_examples.md\n```\n\nYou can also filter by file frontmatter:\n```bash\n# Process only specific file types\nperl scripts/utils/extract_records.pl \\\n  --file-filter \"file_type=My Custom Type\" \\\n  path/to/files/\n\n# Process all files regardless of type\nperl scripts/utils/extract_records.pl \\\n  --file-filter all \\\n  path/to/files/\n```\n\nSee `skill_extract_records.md` section 3.1 for all filtering options.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_extract_records_003_q2", "cluster_id": "skill_extract_records_003", "question": "Can I extract only certain records matching a pattern?", "answer": "Yes, use the `-q` (query) flag to filter records by their `name` metadata using regex patterns. For example: `perl scripts/utils/extract_records.pl -q \"unifyweaver.execution.xml_data_source\" playbooks/examples_library/xml_examples.md` will extract only records matching that pattern. You can also filter by file frontmatter using `--file-filter \"file_type=My Custom Type\"` to process only specific file types, or `--file-filter all` to process all files regardless of type.", "question_type": "long", "topics": ["Compilation", "Extract Records", "Filtering"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["filtering", "query", "regex", "metadata", "search"], "related_skills": ["skill_extract_records.md"], "related_docs": ["scripts/utils/extract_records.pl"], "original_answer": "Use the `-q` (query) flag to filter records by their `name` metadata using regex:\n\n```bash\nperl scripts/utils/extract_records.pl \\\n  -q \"unifyweaver.execution.xml_data_source\" \\\n  playbooks/examples_library/xml_examples.md\n```\n\nYou can also filter by file frontmatter:\n```bash\n# Process only specific file types\nperl scripts/utils/extract_records.pl \\\n  --file-filter \"file_type=My Custom Type\" \\\n  path/to/files/\n\n# Process all files regardless of type\nperl scripts/utils/extract_records.pl \\\n  --file-filter all \\\n  path/to/files/\n```\n\nSee `skill_extract_records.md` section 3.1 for all filtering options.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_extract_records_003_q3", "cluster_id": "skill_extract_records_003", "question": "How do I query records by their metadata?", "answer": "To query records by their metadata, use the `-q` (query) flag with a regex pattern to filter records by their `name` metadata:\n\n```bash\nperl scripts/utils/extract_records.pl \\\n  -q \"unifyweaver.execution.xml_data_source\" \\\n  playbooks/examples_library/xml_examples.md\n```\n\nYou can also filter by file frontmatter using `--file-filter`:\n\n```bash\nperl scripts/utils/extract_records.pl \\\n  --file-filter \"file_type=My Custom Type\" \\\n  path/to/files/\n```\n\nUse `--file-filter all` to process all files regardless of their frontmatter type. For complete filtering options, see the tool's documentation in section 3.1 of the Extract Records skill.", "question_type": "long", "topics": ["Compilation", "Extract Records", "Filtering"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["filtering", "query", "regex", "metadata", "search"], "related_skills": ["skill_extract_records.md"], "related_docs": ["scripts/utils/extract_records.pl"], "original_answer": "Use the `-q` (query) flag to filter records by their `name` metadata using regex:\n\n```bash\nperl scripts/utils/extract_records.pl \\\n  -q \"unifyweaver.execution.xml_data_source\" \\\n  playbooks/examples_library/xml_examples.md\n```\n\nYou can also filter by file frontmatter:\n```bash\n# Process only specific file types\nperl scripts/utils/extract_records.pl \\\n  --file-filter \"file_type=My Custom Type\" \\\n  path/to/files/\n\n# Process all files regardless of type\nperl scripts/utils/extract_records.pl \\\n  --file-filter all \\\n  path/to/files/\n```\n\nSee `skill_extract_records.md` section 3.1 for all filtering options.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_extract_records_004_q0", "cluster_id": "skill_extract_records_004", "question": "What output formats are available when extracting records?", "answer": "When extracting records, three output formats are available via the `-f` flag:\n\n1. **`full`** (default): Returns the complete Markdown block including metadata and content\n2. **`content`**: Returns only the raw code or content from the record, useful for saving to executable files like `.sh` or `.pl`\n3. **`json`**: Returns structured JSON objects, one per record, for programmatic processing\n\nExample usage:\n```bash\n# Full format (default)\nperl scripts/utils/extract_records.pl -f full file.md\n\n# Content only\nperl scripts/utils/extract_records.pl -f content file.md > script.sh\n\n# JSON format\nperl scripts/utils/extract_records.pl -f json file.md\n```", "question_type": "long", "topics": ["Compilation", "Extract Records", "Output Formats"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["output", "format", "json", "content", "parsing"], "related_skills": ["skill_extract_records.md"], "related_docs": ["scripts/utils/extract_records.pl"], "original_answer": "The `-f` flag controls output format:\n\n**`-f full`** (default): Complete markdown block including metadata\n**`-f content`**: Raw code/content only (use this to save to .sh or .pl files)\n**`-f json`**: Structured JSON objects for programmatic processing\n\nExamples:\n```bash\n# Get full markdown blocks\nperl scripts/utils/extract_records.pl -f full file.md\n\n# Extract just code to run\nperl scripts/utils/extract_records.pl -f content file.md > script.sh\n\n# Get structured data for processing\nperl scripts/utils/extract_records.pl -f json file.md | jq '.'\n```\n\nChange the separator with `-s` (default is null byte \\0). See `skill_extract_records.md` section 3.1.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_extract_records_004_q1", "cluster_id": "skill_extract_records_004", "question": "Can I get JSON output from extracted records?", "answer": "Yes. Use the `-f json` flag to get JSON output from extracted records:\n\n```bash\nperl scripts/utils/extract_records.pl -f json file.md\n```\n\nThis outputs a stream of JSON objects, one for each matching record. You can pipe the output to `jq` for further processing:\n\n```bash\nperl scripts/utils/extract_records.pl -f json file.md | jq '.'\n```\n\nOther output formats available:\n- `-f full`: Complete markdown block (default)\n- `-f content`: Raw code/content only\n\nYou can also filter records by name pattern using `-q` and change the record separator with `-s`.", "question_type": "long", "topics": ["Compilation", "Extract Records", "Output Formats"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["output", "format", "json", "content", "parsing"], "related_skills": ["skill_extract_records.md"], "related_docs": ["scripts/utils/extract_records.pl"], "original_answer": "The `-f` flag controls output format:\n\n**`-f full`** (default): Complete markdown block including metadata\n**`-f content`**: Raw code/content only (use this to save to .sh or .pl files)\n**`-f json`**: Structured JSON objects for programmatic processing\n\nExamples:\n```bash\n# Get full markdown blocks\nperl scripts/utils/extract_records.pl -f full file.md\n\n# Extract just code to run\nperl scripts/utils/extract_records.pl -f content file.md > script.sh\n\n# Get structured data for processing\nperl scripts/utils/extract_records.pl -f json file.md | jq '.'\n```\n\nChange the separator with `-s` (default is null byte \\0). See `skill_extract_records.md` section 3.1.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_extract_records_004_q2", "cluster_id": "skill_extract_records_004", "question": "How do I get just the code content without the markdown formatting?", "answer": "Use the `-f content` flag to extract just the code content without markdown formatting. This outputs only the raw code from the record's code block. For example: `perl scripts/utils/extract_records.pl -f content file.md > script.sh`. You can also use `-f json` to get structured JSON objects, or keep the default `-f full` for complete markdown blocks with metadata. The `-s` flag controls the record separator (default is null byte).", "question_type": "long", "topics": ["Compilation", "Extract Records", "Output Formats"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["output", "format", "json", "content", "parsing"], "related_skills": ["skill_extract_records.md"], "related_docs": ["scripts/utils/extract_records.pl"], "original_answer": "The `-f` flag controls output format:\n\n**`-f full`** (default): Complete markdown block including metadata\n**`-f content`**: Raw code/content only (use this to save to .sh or .pl files)\n**`-f json`**: Structured JSON objects for programmatic processing\n\nExamples:\n```bash\n# Get full markdown blocks\nperl scripts/utils/extract_records.pl -f full file.md\n\n# Extract just code to run\nperl scripts/utils/extract_records.pl -f content file.md > script.sh\n\n# Get structured data for processing\nperl scripts/utils/extract_records.pl -f json file.md | jq '.'\n```\n\nChange the separator with `-s` (default is null byte \\0). See `skill_extract_records.md` section 3.1.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_extract_records_004_q3", "cluster_id": "skill_extract_records_004", "question": "What's the difference between full, content, and json formats?", "answer": "The `-f` flag controls the output format of extracted records:\n\n**`full` (default)**: Returns the complete markdown block including YAML frontmatter and metadata, preserving the original formatting.\n\n**`content`**: Returns only the raw code or content from within the code block, without any markdown wrapper or metadata. Use this format when you need to extract code for execution (e.g., saving to a .sh or .pl file).\n\n**`json`**: Returns structured JSON objects, one per record, making the data suitable for programmatic processing and parsing.\n\nExample usage:\n```bash\n# Full markdown blocks\nperl scripts/utils/extract_records.pl -f full file.md\n\n# Just the code content\nperl scripts/utils/extract_records.pl -f content file.md > script.sh\n\n# Structured JSON for processing\nperl scripts/utils/extract_records.pl -f json file.md | jq '.'\n```", "question_type": "long", "topics": ["Compilation", "Extract Records", "Output Formats"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["output", "format", "json", "content", "parsing"], "related_skills": ["skill_extract_records.md"], "related_docs": ["scripts/utils/extract_records.pl"], "original_answer": "The `-f` flag controls output format:\n\n**`-f full`** (default): Complete markdown block including metadata\n**`-f content`**: Raw code/content only (use this to save to .sh or .pl files)\n**`-f json`**: Structured JSON objects for programmatic processing\n\nExamples:\n```bash\n# Get full markdown blocks\nperl scripts/utils/extract_records.pl -f full file.md\n\n# Extract just code to run\nperl scripts/utils/extract_records.pl -f content file.md > script.sh\n\n# Get structured data for processing\nperl scripts/utils/extract_records.pl -f json file.md | jq '.'\n```\n\nChange the separator with `-s` (default is null byte \\0). See `skill_extract_records.md` section 3.1.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_find_executable_001_q0", "cluster_id": "skill_find_executable_001", "question": "How do I fix 'command not found' errors when running Perl or SWI-Prolog?", "answer": "To find an executable not in your PATH, use the Find Executable skill. It searches common installation directories per OS: Windows (C:\\Program Files, C:\\Strawberry), Linux (/usr/bin, /usr/local/bin, /snap/bin), macOS (/opt/homebrew/bin, /Applications). If found, it returns the absolute path you can use to run the command.", "question_type": "medium", "topics": ["Compilation", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["executable", "PATH", "command-not-found", "perl", "swipl"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "Use the Find Executable skill to locate executables that aren't in your system's PATH. This skill searches common installation directories on Windows, Linux, and macOS to find tools like `perl` or `swipl`. Once found, it returns the full path so your agent can execute the command directly (e.g., `& \"C:\\Strawberry\\perl\\bin\\perl.exe\" my_script.pl`).", "answer_tailored": true, "confidence": 0.85, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_find_executable_001_q1", "cluster_id": "skill_find_executable_001", "question": "My agent can't find perl even though it's installed", "answer": "If your agent can't find perl even though it's installed, use the Find Executable skill to locate it. This skill searches common installation directories across Windows, Linux, and macOS\u2014including paths like `C:\\Strawberry\\perl\\bin` on Windows, `/usr/local/bin` on Linux, and `/opt/homebrew/bin` on macOS. The skill returns the full path to perl, which your agent can then use to execute commands directly (e.g., `& \"C:\\Strawberry\\perl\\bin\\perl.exe\" my_script.pl`).", "question_type": "medium", "topics": ["Compilation", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["executable", "PATH", "command-not-found", "perl", "swipl"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "Use the Find Executable skill to locate executables that aren't in your system's PATH. This skill searches common installation directories on Windows, Linux, and macOS to find tools like `perl` or `swipl`. Once found, it returns the full path so your agent can execute the command directly (e.g., `& \"C:\\Strawberry\\perl\\bin\\perl.exe\" my_script.pl`).", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_find_executable_001_q2", "cluster_id": "skill_find_executable_001", "question": "Getting command not found for swipl, how to locate it?", "answer": "Use the Find Executable skill to locate swipl. This skill searches common installation directories on Windows, Linux, and macOS. For swipl specifically, it checks paths like `/usr/bin`, `/usr/local/bin`, `/snap/bin` on Linux; `/usr/bin`, `/usr/local/bin`, `/opt/homebrew/bin`, `/Applications/SWI-Prolog.app/Contents/MacOS` on macOS; and `C:\\Program Files\\swipl\\bin`, `C:\\Program Files (x86)\\swipl\\bin` on Windows. Once found, it returns the full path so you can execute swipl directly using that path.", "question_type": "medium", "topics": ["Compilation", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["executable", "PATH", "command-not-found", "perl", "swipl"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "Use the Find Executable skill to locate executables that aren't in your system's PATH. This skill searches common installation directories on Windows, Linux, and macOS to find tools like `perl` or `swipl`. Once found, it returns the full path so your agent can execute the command directly (e.g., `& \"C:\\Strawberry\\perl\\bin\\perl.exe\" my_script.pl`).", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_find_executable_001_q3", "cluster_id": "skill_find_executable_001", "question": "How to find executables that aren't in PATH?", "answer": "Use the Find Executable skill to locate executables not in your system's PATH. This skill searches common installation directories across Windows, Linux, and macOS (such as /usr/bin, /usr/local/bin, /opt/homebrew/bin on macOS, or C:\\Strawberry\\perl\\bin on Windows) to find tools like perl or swipl. When the executable is found, the skill returns its full path, which you can then use to execute the command directly.", "question_type": "medium", "topics": ["Compilation", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["executable", "PATH", "command-not-found", "perl", "swipl"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "Use the Find Executable skill to locate executables that aren't in your system's PATH. This skill searches common installation directories on Windows, Linux, and macOS to find tools like `perl` or `swipl`. Once found, it returns the full path so your agent can execute the command directly (e.g., `& \"C:\\Strawberry\\perl\\bin\\perl.exe\" my_script.pl`).", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_find_executable_002_q0", "cluster_id": "skill_find_executable_002", "question": "What should my agent do when a command fails because it's not in PATH?", "answer": "When a command fails with 'command not found', use the Find Executable skill to locate the executable. This skill searches OS-specific directories: Windows (`C:\\Strawberry\\perl\\bin`, `C:\\Program Files\\swipl\\bin`), Linux (`/usr/bin`, `/usr/local/bin`, `/snap/bin`), or macOS (`/usr/local/bin`, `/opt/homebrew/bin`, `/Applications/SWI-Prolog.app/Contents/MacOS`). The skill returns the absolute path if found, which you can then use to execute the command directly.", "question_type": "medium", "topics": ["Compilation", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["executable", "PATH", "system-path", "troubleshooting"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "When a command fails with 'command not found' but you know it's installed, use the Find Executable skill. It searches OS-specific directories (like `C:\\Strawberry\\perl\\bin` on Windows or `/opt/homebrew/bin` on macOS) to locate the executable and returns its absolute path for execution.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_find_executable_002_q1", "cluster_id": "skill_find_executable_002", "question": "How to handle executables not in system PATH?", "answer": "When an executable isn't in your system PATH, use the Find Executable skill which searches common installation directories. On Windows it checks C:\\Strawberry\\perl\\bin, C:\\Program Files\\swipl\\bin. On Linux: /usr/bin, /usr/local/bin, /snap/bin. On macOS: /usr/local/bin, /opt/homebrew/bin, /Applications/. The skill returns the absolute path if found, which you can use directly.", "question_type": "medium", "topics": ["Compilation", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["executable", "PATH", "system-path", "troubleshooting"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "When a command fails with 'command not found' but you know it's installed, use the Find Executable skill. It searches OS-specific directories (like `C:\\Strawberry\\perl\\bin` on Windows or `/opt/homebrew/bin` on macOS) to locate the executable and returns its absolute path for execution.", "answer_tailored": true, "confidence": 0.85, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_find_executable_002_q2", "cluster_id": "skill_find_executable_002", "question": "Agent can't execute installed programs", "answer": "When a program is installed but the agent can't execute it, use the Find Executable skill to locate it. The skill searches OS-specific directories: Windows (C:\\Program Files, C:\\Strawberry), Linux (/usr/bin, /usr/local/bin, /snap/bin), macOS (/opt/homebrew/bin, /Applications). Use the returned absolute path to execute the command directly.", "question_type": "medium", "topics": ["Compilation", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["executable", "PATH", "system-path", "troubleshooting"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "When a command fails with 'command not found' but you know it's installed, use the Find Executable skill. It searches OS-specific directories (like `C:\\Strawberry\\perl\\bin` on Windows or `/opt/homebrew/bin` on macOS) to locate the executable and returns its absolute path for execution.", "answer_tailored": true, "confidence": 0.85, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_find_executable_002_q3", "cluster_id": "skill_find_executable_002", "question": "Command exists but agent can't find it", "answer": "When a command fails with 'command not found' even though it's installed, use the Find Executable skill to locate it. The skill searches OS-specific directories: Windows (`C:\\Strawberry\\perl\\bin`, `C:\\Program Files\\swipl\\bin`), Linux (`/usr/bin`, `/usr/local/bin`, `/snap/bin`), or macOS (`/usr/local/bin`, `/opt/homebrew/bin`, `/Applications/SWI-Prolog.app/Contents/MacOS`). It returns the absolute path to the executable, which you can then use directly to run the command.", "question_type": "medium", "topics": ["Compilation", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["executable", "PATH", "system-path", "troubleshooting"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "When a command fails with 'command not found' but you know it's installed, use the Find Executable skill. It searches OS-specific directories (like `C:\\Strawberry\\perl\\bin` on Windows or `/opt/homebrew/bin` on macOS) to locate the executable and returns its absolute path for execution.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_find_executable_003_q0", "cluster_id": "skill_find_executable_003", "question": "How can I run Perl scripts when perl isn't in my PATH?", "answer": "Use the Find Executable skill to locate the `perl` executable by searching common installation directories. On Windows, it checks `C:\\Strawberry\\perl\\bin`; on Linux/macOS, it searches `/usr/bin`, `/usr/local/bin`, `/opt/homebrew/bin`, and other standard locations. Once found, execute your Perl scripts using the returned absolute path instead of relying on PATH lookup.", "question_type": "long", "topics": ["Compilation", "Find Executable", "Perl"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["perl", "executable", "strawberry-perl", "PATH"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "Use the Find Executable skill to locate the `perl` executable. It searches common installation paths like `C:\\Strawberry\\perl\\bin` (Windows), `/usr/local/bin` (Linux/macOS), and returns the full path. Your agent can then execute scripts using the absolute path.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_find_executable_003_q1", "cluster_id": "skill_find_executable_003", "question": "Perl installed but command not found", "answer": "Common installation directories vary by OS. Windows: C:\\Program Files, C:\\Program Files (x86), C:\\Strawberry (Perl). Linux: /usr/bin, /usr/local/bin, /snap/bin, /opt. macOS: /usr/local/bin, /opt/homebrew/bin (Homebrew), /Applications. The Find Executable skill searches these locations automatically.", "question_type": "long", "topics": ["Compilation", "Find Executable", "Perl"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["perl", "executable", "strawberry-perl", "PATH"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "Use the Find Executable skill to locate the `perl` executable. It searches common installation paths like `C:\\Strawberry\\perl\\bin` (Windows), `/usr/local/bin` (Linux/macOS), and returns the full path. Your agent can then execute scripts using the absolute path.", "answer_tailored": true, "confidence": 0.85, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_find_executable_003_q2", "cluster_id": "skill_find_executable_003", "question": "How to locate perl executable on Windows?", "answer": "On Windows, use the Find Executable skill to locate the `perl` executable. It searches common Windows installation paths including `C:\\Strawberry\\perl\\bin` and `C:\\Program Files\\swipl\\bin`. The skill returns the full path to the executable, which your agent can then use to run Perl scripts, for example: `& \"C:\\Strawberry\\perl\\bin\\perl.exe\" script.pl`.", "question_type": "long", "topics": ["Compilation", "Find Executable", "Perl"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["perl", "executable", "strawberry-perl", "PATH"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "Use the Find Executable skill to locate the `perl` executable. It searches common installation paths like `C:\\Strawberry\\perl\\bin` (Windows), `/usr/local/bin` (Linux/macOS), and returns the full path. Your agent can then execute scripts using the absolute path.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_find_executable_003_q3", "cluster_id": "skill_find_executable_003", "question": "Find perl binary on macOS", "answer": "Use the Find Executable skill to locate the `perl` executable on macOS. It searches common installation paths including `/usr/bin`, `/usr/local/bin`, `/opt/homebrew/bin`, and `/Applications/SWI-Prolog.app/Contents/MacOS`, then returns the full path. Your agent can then execute Perl scripts using the absolute path returned by the skill.", "question_type": "long", "topics": ["Compilation", "Find Executable", "Perl"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["perl", "executable", "strawberry-perl", "PATH"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "Use the Find Executable skill to locate the `perl` executable. It searches common installation paths like `C:\\Strawberry\\perl\\bin` (Windows), `/usr/local/bin` (Linux/macOS), and returns the full path. Your agent can then execute scripts using the absolute path.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_find_executable_004_q0", "cluster_id": "skill_find_executable_004", "question": "Where does the agent look for executables on different operating systems?", "answer": "The Find Executable skill searches different directories based on the operating system. On Windows, it checks C:\\Strawberry\\perl\\bin, C:\\Program Files\\swipl\\bin, and C:\\Program Files (x86)\\swipl\\bin. On Linux, it searches /usr/bin, /usr/local/bin, and /snap/bin. On macOS, it looks in /usr/bin, /usr/local/bin, /opt/homebrew/bin, and /Applications/SWI-Prolog.app/Contents/MacOS.", "question_type": "long", "topics": ["Compilation", "Find Executable", "Search Paths"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["search-paths", "installation-directories", "cross-platform", "windows", "linux", "macos"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "The Find Executable skill searches OS-specific directories: Windows checks `C:\\Strawberry\\perl\\bin`, `C:\\Program Files\\swipl\\bin`; Linux searches `/usr/bin`, `/usr/local/bin`, `/snap/bin`; macOS looks in `/usr/local/bin`, `/opt/homebrew/bin`, `/Applications/SWI-Prolog.app/Contents/MacOS`, and more. If found, it returns the absolute path; otherwise an empty string.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_find_executable_004_q1", "cluster_id": "skill_find_executable_004", "question": "What directories are searched for missing executables?", "answer": "The Find Executable skill searches OS-specific directories for missing executables. On Windows, it checks C:\\Strawberry\\perl\\bin, C:\\Program Files\\swipl\\bin, and C:\\Program Files (x86)\\swipl\\bin. On Linux, it searches /usr/bin, /usr/local/bin, and /snap/bin. On macOS, it looks in /usr/bin, /usr/local/bin, /opt/homebrew/bin, and /Applications/SWI-Prolog.app/Contents/MacOS.", "question_type": "long", "topics": ["Compilation", "Find Executable", "Search Paths"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["search-paths", "installation-directories", "cross-platform", "windows", "linux", "macos"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "The Find Executable skill searches OS-specific directories: Windows checks `C:\\Strawberry\\perl\\bin`, `C:\\Program Files\\swipl\\bin`; Linux searches `/usr/bin`, `/usr/local/bin`, `/snap/bin`; macOS looks in `/usr/local/bin`, `/opt/homebrew/bin`, `/Applications/SWI-Prolog.app/Contents/MacOS`, and more. If found, it returns the absolute path; otherwise an empty string.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_find_executable_004_q2", "cluster_id": "skill_find_executable_004", "question": "Common installation paths checked by Find Executable", "answer": "The Find Executable skill searches OS-specific directories for executables: Windows checks `C:\\Strawberry\\perl\\bin` and `C:\\Program Files\\swipl\\bin` (and `C:\\Program Files (x86)\\swipl\\bin`); Linux searches `/usr/bin`, `/usr/local/bin`, and `/snap/bin`; macOS looks in `/usr/bin`, `/usr/local/bin`, `/opt/homebrew/bin`, and `/Applications/SWI-Prolog.app/Contents/MacOS`. If the executable is found, it returns the full path; otherwise it returns an empty string.", "question_type": "long", "topics": ["Compilation", "Find Executable", "Search Paths"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["search-paths", "installation-directories", "cross-platform", "windows", "linux", "macos"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "The Find Executable skill searches OS-specific directories: Windows checks `C:\\Strawberry\\perl\\bin`, `C:\\Program Files\\swipl\\bin`; Linux searches `/usr/bin`, `/usr/local/bin`, `/snap/bin`; macOS looks in `/usr/local/bin`, `/opt/homebrew/bin`, `/Applications/SWI-Prolog.app/Contents/MacOS`, and more. If found, it returns the absolute path; otherwise an empty string.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_find_executable_004_q3", "cluster_id": "skill_find_executable_004", "question": "OS-specific executable search paths", "answer": "The Find Executable skill searches OS-specific directories to locate executables. On Windows, it checks C:\\Strawberry\\perl\\bin and C:\\Program Files\\swipl\\bin directories. On Linux, it searches /usr/bin, /usr/local/bin, and /snap/bin. On macOS, it looks in /usr/bin, /usr/local/bin, /opt/homebrew/bin, and /Applications/SWI-Prolog.app/Contents/MacOS. The skill returns the absolute path to the executable if found, or an empty string if not found.", "question_type": "long", "topics": ["Compilation", "Find Executable", "Search Paths"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["search-paths", "installation-directories", "cross-platform", "windows", "linux", "macos"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "The Find Executable skill searches OS-specific directories: Windows checks `C:\\Strawberry\\perl\\bin`, `C:\\Program Files\\swipl\\bin`; Linux searches `/usr/bin`, `/usr/local/bin`, `/snap/bin`; macOS looks in `/usr/local/bin`, `/opt/homebrew/bin`, `/Applications/SWI-Prolog.app/Contents/MacOS`, and more. If found, it returns the absolute path; otherwise an empty string.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_json_sources_001_q0", "cluster_id": "skill_json_sources_001", "question": "How do I read JSON data into my Prolog program?", "answer": "Use the `source/3` directive to declare JSON data sources in your Prolog program. For basic column projection, specify `columns/1` with field paths using dot notation or array indices: `:- source(json, my_source, [json_file('data/file.json'), columns(['field.subfield', 'items[0].value'])])`. For complex selections, use JSONPath selectors like `jsonpath('$.orders[*].total')`. To work with full JSON objects, add `return_object(true)` and `type_hint/1` specifying the .NET type. For typed records with automatic C# code generation, use `schema/1` to define fields with their JSON paths and types. Once declared, query the source with `?- my_source(Row)` to iterate through rows.", "question_type": "medium", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["json", "data-sources", "source-directive", "columns"], "related_skills": ["skill_json_sources.md"], "related_docs": [], "original_answer": "Use the `source/3` directive to declare JSON data sources. For basic column projection, specify `columns/1` with field paths using dot notation: `:- source(json, order_totals, [json_file('data/orders.json'), columns(['order.customer.name', 'items[0].product'])])`. For JSONPath selectors, use `jsonpath('$.orders[*].total')`. For full JSON objects, use `return_object(true)` with `type_hint/1`. See skill_json_sources.md for all options including schema-generated records and JSON Lines support.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_001_q1", "cluster_id": "skill_json_sources_001", "question": "How do I load JSON files in UnifyWeaver?", "answer": "To load JSON files in UnifyWeaver, use the `source/3` directive with the `json_file/1` parameter. For column projection, specify `columns/1` with field paths using dot notation or array indices (e.g., `columns(['order.customer.name', 'items[0].product'])`). For complex selectors, use JSONPath with `jsonpath('$.orders[*].total')`. For full JSON objects, set `return_object(true)` and provide a `type_hint/1` with the .NET type. For typed records with schema validation, use `schema/1` with field definitions and optional `record_type/1`. Example: `:- source(json, order_totals, [json_file('data/orders.json'), columns(['order.customer.name', 'items[0].product'])])`. Refer to skill_json_sources.md for additional options including nested schemas and JSON Lines support.", "question_type": "medium", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["json", "data-sources", "source-directive", "columns"], "related_skills": ["skill_json_sources.md"], "related_docs": [], "original_answer": "Use the `source/3` directive to declare JSON data sources. For basic column projection, specify `columns/1` with field paths using dot notation: `:- source(json, order_totals, [json_file('data/orders.json'), columns(['order.customer.name', 'items[0].product'])])`. For JSONPath selectors, use `jsonpath('$.orders[*].total')`. For full JSON objects, use `return_object(true)` with `type_hint/1`. See skill_json_sources.md for all options including schema-generated records and JSON Lines support.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_001_q2", "cluster_id": "skill_json_sources_001", "question": "What's the syntax for reading JSON data sources?", "answer": "Use the `source/3` directive to declare JSON data sources. The basic syntax is `:- source(json, predicate_name, [json_file('path/to/file.json'), columns(['field.path', 'nested[0].field'])])`. Column paths support dot notation for nested objects and bracket notation for array indices. For complex selections, use JSONPath syntax like `jsonpath('$.orders[*].total')`. For returning full JSON objects instead of projecting columns, use `return_object(true)` with a `type_hint/1` specifying the .NET type. For typed records with automatic C# code generation, use `schema/1` with field definitions.", "question_type": "medium", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["json", "data-sources", "source-directive", "columns"], "related_skills": ["skill_json_sources.md"], "related_docs": [], "original_answer": "Use the `source/3` directive to declare JSON data sources. For basic column projection, specify `columns/1` with field paths using dot notation: `:- source(json, order_totals, [json_file('data/orders.json'), columns(['order.customer.name', 'items[0].product'])])`. For JSONPath selectors, use `jsonpath('$.orders[*].total')`. For full JSON objects, use `return_object(true)` with `type_hint/1`. See skill_json_sources.md for all options including schema-generated records and JSON Lines support.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_001_q3", "cluster_id": "skill_json_sources_001", "question": "How do I declare a JSON source in Prolog?", "answer": "To declare a JSON source in Prolog, use the `source/3` directive with `json` as the source type. Specify the predicate name, then provide options including `json_file('path/to/file.json')`. For column projection, add `columns([...])` with field paths using dot notation (e.g., `'order.customer.name'`) or array indices (e.g., `'items[0].product'`). For complex selections, use JSONPath with `jsonpath('$.orders[*].total')`. For full JSON objects, use `arity(1)`, `return_object(true)`, and `type_hint('System.Text.Json.Nodes.JsonObject, System.Text.Json')`. For typed records, use `schema([field(...), ...])` to define fields with paths and types, optionally naming the record with `record_type('RecordName')`.", "question_type": "medium", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["json", "data-sources", "source-directive", "columns"], "related_skills": ["skill_json_sources.md"], "related_docs": [], "original_answer": "Use the `source/3` directive to declare JSON data sources. For basic column projection, specify `columns/1` with field paths using dot notation: `:- source(json, order_totals, [json_file('data/orders.json'), columns(['order.customer.name', 'items[0].product'])])`. For JSONPath selectors, use `jsonpath('$.orders[*].total')`. For full JSON objects, use `return_object(true)` with `type_hint/1`. See skill_json_sources.md for all options including schema-generated records and JSON Lines support.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_002_q0", "cluster_id": "skill_json_sources_002", "question": "How do I handle complex JSON paths with wildcards and nested arrays?", "answer": "To handle complex JSON paths with wildcards and nested arrays, use the `jsonpath/1` option with JSONPath selectors. Supported syntax includes: root `$`, dotted properties, bracket notation `['foo']`, array indices `[0]`, wildcards `[*]`, and recursive descent `..name`. For example, `jsonpath('$.orders[*].total')` selects the total field from all orders. Strings beginning with `$` are automatically treated as JSONPath selectors, so you can use `columns(['$.orders[0].id'])` directly. This works in both `columns/1` and `schema/1` declarations.", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources", "JSONPath Selectors"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["json", "jsonpath", "selectors", "wildcards", "nested-data"], "related_skills": ["skill_json_sources.md"], "related_docs": [], "original_answer": "Use `jsonpath/1` option with JSONPath selectors for complex queries. Supported features include root `$`, dotted properties, bracket notation `['foo']`, array indices `[0]`, wildcards `[*]`, and recursive descent `..name`. Example: `jsonpath('$.orders[*].total')`. Strings starting with `$` are automatically treated as JSONPath, so `columns(['$.orders[0].id'])` works too. Use in both `columns/1` and `schema/1` declarations. See skill_json_sources.md for complete JSONPath syntax.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_002_q1", "cluster_id": "skill_json_sources_002", "question": "Can I use JSONPath selectors in my JSON sources?", "answer": "Yes, you can use JSONPath selectors in your JSON sources. Use the `jsonpath/1` option with selectors like `jsonpath('$.orders[*].total')`. Supported features include root `$`, dotted properties, bracket notation `['foo']`, array indices `[0]`, wildcards `[*]`, and recursive descent `..name`. Strings already beginning with `$` are automatically treated as JSONPath selectors, so `columns(['$.orders[0].id'])` works directly. JSONPath works in both `columns/1` and `schema/1` declarations for flexible data extraction.", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources", "JSONPath Selectors"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["json", "jsonpath", "selectors", "wildcards", "nested-data"], "related_skills": ["skill_json_sources.md"], "related_docs": [], "original_answer": "Use `jsonpath/1` option with JSONPath selectors for complex queries. Supported features include root `$`, dotted properties, bracket notation `['foo']`, array indices `[0]`, wildcards `[*]`, and recursive descent `..name`. Example: `jsonpath('$.orders[*].total')`. Strings starting with `$` are automatically treated as JSONPath, so `columns(['$.orders[0].id'])` works too. Use in both `columns/1` and `schema/1` declarations. See skill_json_sources.md for complete JSONPath syntax.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_json_sources_002_q2", "cluster_id": "skill_json_sources_002", "question": "How do I select data from nested JSON structures?", "answer": "To select data from nested JSON structures, use the `jsonpath/1` option with JSONPath selectors. Supported features include: root `$`, dotted properties, bracket notation `['foo']`, array indices `[0]`, wildcards `[*]`, and recursive descent `..name`. For example, `jsonpath('$.orders[*].total')` selects the total field from all orders. Strings beginning with `$` are automatically treated as JSONPath selectors, so you can use `columns(['$.orders[0].id'])` directly. This works in both `columns/1` and `schema/1` declarations. Alternatively, use dot notation with array indices (e.g., `items[0].product`) for simpler nested paths in column projections.", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources", "JSONPath Selectors"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["json", "jsonpath", "selectors", "wildcards", "nested-data"], "related_skills": ["skill_json_sources.md"], "related_docs": [], "original_answer": "Use `jsonpath/1` option with JSONPath selectors for complex queries. Supported features include root `$`, dotted properties, bracket notation `['foo']`, array indices `[0]`, wildcards `[*]`, and recursive descent `..name`. Example: `jsonpath('$.orders[*].total')`. Strings starting with `$` are automatically treated as JSONPath, so `columns(['$.orders[0].id'])` works too. Use in both `columns/1` and `schema/1` declarations. See skill_json_sources.md for complete JSONPath syntax.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_002_q3", "cluster_id": "skill_json_sources_002", "question": "What's the syntax for wildcards in JSON column paths?", "answer": "Use the wildcard `[*]` syntax in JSONPath selectors to match all elements in an array. For example, `jsonpath('$.orders[*].total')` selects the total field from all items in the orders array. Wildcards work in both `columns/1` and `schema/1` declarations. Note that wildcards currently return the first matching value. Strings beginning with `$` are automatically treated as JSONPath, so `columns(['$.orders[*].total'])` also works without explicitly using `jsonpath/1`.", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources", "JSONPath Selectors"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["json", "jsonpath", "selectors", "wildcards", "nested-data"], "related_skills": ["skill_json_sources.md"], "related_docs": [], "original_answer": "Use `jsonpath/1` option with JSONPath selectors for complex queries. Supported features include root `$`, dotted properties, bracket notation `['foo']`, array indices `[0]`, wildcards `[*]`, and recursive descent `..name`. Example: `jsonpath('$.orders[*].total')`. Strings starting with `$` are automatically treated as JSONPath, so `columns(['$.orders[0].id'])` works too. Use in both `columns/1` and `schema/1` declarations. See skill_json_sources.md for complete JSONPath syntax.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_003_q0", "cluster_id": "skill_json_sources_003", "question": "How do I create typed records from JSON data instead of just tuples?", "answer": "Use `schema/1` to declare typed records that generate C# POCOs instead of tuples. Define fields with `field(Name, Path, Type)` and optionally name the record using `record_type('RecordName')`. Set arity to 1; `return_object(true)` is implied. Example: `:- source(json, product_rows, [json_file('data.json'), schema([field(id, 'id', string), field(price, 'price', double)]), record_type('ProductRecord')])`. For nested structures, use `record(TypeName, Fields)` within schema fields to create sub-records with their own typed properties.", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources", "Schema-Generated Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["json", "schema", "typed-records", "poco", "code-generation"], "related_skills": ["skill_json_sources.md"], "related_docs": [], "original_answer": "Use `schema/1` to declare typed records that generate C# POCOs. Specify fields with `field(Name, Path, Type)` and optionally name the record with `record_type/1`. Example: `:- source(json, product_rows, [json_file('data.json'), schema([field(id, 'id', string), field(price, 'price', double)]), record_type('ProductRecord')])`. Arity must be 1; `return_object(true)` is implied. For nested structures, use `record(TypeName, Fields)`. See skill_json_sources.md for nested schema examples.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_003_q1", "cluster_id": "skill_json_sources_003", "question": "Can I map JSON to strongly-typed objects in UnifyWeaver?", "answer": "Yes. Use `schema/1` to declare strongly-typed records that generate C# POCOs. Specify fields with `field(Name, Path, Type)` and optionally name the record with `record_type('ProductRecord')`. Set arity to 1; `return_object(true)` is implied. For nested objects, use `record(TypeName, Fields)` within field declarations. Example: `:- source(json, product_rows, [json_file('data.json'), schema([field(id, 'id', string), field(price, 'price', double)]), record_type('ProductRecord')])`. The C# backend generates the corresponding POCO automatically.", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources", "Schema-Generated Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["json", "schema", "typed-records", "poco", "code-generation"], "related_skills": ["skill_json_sources.md"], "related_docs": [], "original_answer": "Use `schema/1` to declare typed records that generate C# POCOs. Specify fields with `field(Name, Path, Type)` and optionally name the record with `record_type/1`. Example: `:- source(json, product_rows, [json_file('data.json'), schema([field(id, 'id', string), field(price, 'price', double)]), record_type('ProductRecord')])`. Arity must be 1; `return_object(true)` is implied. For nested structures, use `record(TypeName, Fields)`. See skill_json_sources.md for nested schema examples.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_003_q2", "cluster_id": "skill_json_sources_003", "question": "How do I generate POCOs from JSON sources?", "answer": "Use the `schema/1` declaration to generate C# POCOs from JSON sources. Define fields with `field(Name, Path, Type)` syntax and optionally specify a record type name using `record_type('YourRecordName')`. Set arity to 1 and the C# backend will automatically generate a POCO class. Example: `:- source(json, product_rows, [json_file('data.json'), schema([field(id, 'id', string), field(price, 'price', double)]), record_type('ProductRecord')])`. For nested objects, use `record(TypeName, Fields)` within the schema definition to generate nested POCO types.", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources", "Schema-Generated Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["json", "schema", "typed-records", "poco", "code-generation"], "related_skills": ["skill_json_sources.md"], "related_docs": [], "original_answer": "Use `schema/1` to declare typed records that generate C# POCOs. Specify fields with `field(Name, Path, Type)` and optionally name the record with `record_type/1`. Example: `:- source(json, product_rows, [json_file('data.json'), schema([field(id, 'id', string), field(price, 'price', double)]), record_type('ProductRecord')])`. Arity must be 1; `return_object(true)` is implied. For nested structures, use `record(TypeName, Fields)`. See skill_json_sources.md for nested schema examples.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_003_q3", "cluster_id": "skill_json_sources_003", "question": "What's the schema option for JSON sources?", "answer": "Use `schema/1` to declare typed records that generate C# POCOs. Specify fields with `field(Name, Path, Type)` and optionally name the record with `record_type('RecordName')`. Arity must be 1; `return_object(true)` is implied. For nested structures, use `record(TypeName, Fields)` within field definitions. Example: `:- source(json, product_rows, [json_file('data.json'), schema([field(id, 'id', string), field(price, 'price', double)]), record_type('ProductRecord')])`. JSONPath selectors work in field paths.", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources", "Schema-Generated Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["json", "schema", "typed-records", "poco", "code-generation"], "related_skills": ["skill_json_sources.md"], "related_docs": [], "original_answer": "Use `schema/1` to declare typed records that generate C# POCOs. Specify fields with `field(Name, Path, Type)` and optionally name the record with `record_type/1`. Example: `:- source(json, product_rows, [json_file('data.json'), schema([field(id, 'id', string), field(price, 'price', double)]), record_type('ProductRecord')])`. Arity must be 1; `return_object(true)` is implied. For nested structures, use `record(TypeName, Fields)`. See skill_json_sources.md for nested schema examples.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_004_q0", "cluster_id": "skill_json_sources_004", "question": "How do I handle missing or null values in JSON data?", "answer": "To handle missing or null values in JSON data, use `null_policy/1` to control the behavior. Three main options are available: `null_policy(fail)` will throw an error immediately when a null value is encountered, `null_policy(skip)` will skip entire rows containing null values, and `null_policy(default(Value))` will substitute a placeholder value (such as `'N/A'` for strings or `'0'` for numbers). For example: `:- source(json, items, [json_file('data.jsonl'), columns([jsonpath('$.items[1].product')]), null_policy(default('N/A'))])`. This approach works with both standard JSON files and newline-delimited JSON (JSONL) format using `record_format(jsonl)`.", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources", "Null Policies"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["json", "null-handling", "default-values", "error-handling", "jsonl"], "related_skills": ["skill_json_sources.md"], "related_docs": [], "original_answer": "Use `null_policy/1` to control missing/null field behavior. Options: `null_policy(fail)` throws immediately on null, `null_policy(skip)` skips rows with nulls, `null_policy(default(Value))` substitutes a placeholder (e.g., `default('N/A')` or `default('0')`). Example: `:- source(json, items, [json_file('data.jsonl'), columns([jsonpath('$.items[1].product')]), null_policy(default('N/A'))])`. Also useful with `record_format(jsonl)` for newline-delimited JSON. See skill_json_sources.md for validation rules.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_004_q1", "cluster_id": "skill_json_sources_004", "question": "What happens when JSON fields are null or missing?", "answer": "When JSON fields are null or missing, use `null_policy/1` to control the behavior. Three options are available: `null_policy(fail)` throws an error immediately when a field is null or missing, `null_policy(skip)` skips entire rows containing nulls, and `null_policy(default(Value))` substitutes a placeholder value (e.g., `default('N/A')` for strings or `default('0')` for numbers). For example: `:- source(json, items, [json_file('data.jsonl'), columns([jsonpath('$.items[1].product')]), null_policy(default('N/A'))])`. This approach works with both dot notation and JSONPath selectors, and is compatible with `record_format(jsonl)` for newline-delimited JSON files.", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources", "Null Policies"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["json", "null-handling", "default-values", "error-handling", "jsonl"], "related_skills": ["skill_json_sources.md"], "related_docs": [], "original_answer": "Use `null_policy/1` to control missing/null field behavior. Options: `null_policy(fail)` throws immediately on null, `null_policy(skip)` skips rows with nulls, `null_policy(default(Value))` substitutes a placeholder (e.g., `default('N/A')` or `default('0')`). Example: `:- source(json, items, [json_file('data.jsonl'), columns([jsonpath('$.items[1].product')]), null_policy(default('N/A'))])`. Also useful with `record_format(jsonl)` for newline-delimited JSON. See skill_json_sources.md for validation rules.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_004_q2", "cluster_id": "skill_json_sources_004", "question": "How do I set default values for missing JSON fields?", "answer": "Use `null_policy/1` to set default values for missing JSON fields. The `null_policy(default(Value))` option substitutes a placeholder when a field is null or missing. For example: `:- source(json, items, [json_file('data.json'), columns(['product_name']), null_policy(default('Unknown'))])`. This will use `'Unknown'` for any missing or null values in the `product_name` column. Other `null_policy/1` options include `fail` (throw error on null) and `skip` (exclude rows with nulls).", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources", "Null Policies"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["json", "null-handling", "default-values", "error-handling", "jsonl"], "related_skills": ["skill_json_sources.md"], "related_docs": [], "original_answer": "Use `null_policy/1` to control missing/null field behavior. Options: `null_policy(fail)` throws immediately on null, `null_policy(skip)` skips rows with nulls, `null_policy(default(Value))` substitutes a placeholder (e.g., `default('N/A')` or `default('0')`). Example: `:- source(json, items, [json_file('data.jsonl'), columns([jsonpath('$.items[1].product')]), null_policy(default('N/A'))])`. Also useful with `record_format(jsonl)` for newline-delimited JSON. See skill_json_sources.md for validation rules.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_004_q3", "cluster_id": "skill_json_sources_004", "question": "Can I skip rows with null values in JSON sources?", "answer": "Yes, you can skip rows with null values in JSON sources using `null_policy(skip)`. This option automatically excludes any rows containing null or missing fields from your result set. For example: `:- source(json, items, [json_file('data.json'), columns(['product', 'price']), null_policy(skip)]).` will only return rows where both 'product' and 'price' are non-null. Alternatively, use `null_policy(default(Value))` to substitute a placeholder value instead of skipping the row.", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources", "Null Policies"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["json", "null-handling", "default-values", "error-handling", "jsonl"], "related_skills": ["skill_json_sources.md"], "related_docs": [], "original_answer": "Use `null_policy/1` to control missing/null field behavior. Options: `null_policy(fail)` throws immediately on null, `null_policy(skip)` skips rows with nulls, `null_policy(default(Value))` substitutes a placeholder (e.g., `default('N/A')` or `default('0')`). Example: `:- source(json, items, [json_file('data.jsonl'), columns([jsonpath('$.items[1].product')]), null_policy(default('N/A'))])`. Also useful with `record_format(jsonl)` for newline-delimited JSON. See skill_json_sources.md for validation rules.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_001_q0", "cluster_id": "skill_unifyweaver_compile_001", "question": "How do I convert Prolog rules into an executable bash script?", "answer": "To convert Prolog rules into an executable bash script, use the UnifyWeaver compiler. Execute this command: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<your_file.pl>'), compile(<predicate>/<arity>, [output_dir('.')])\" -t halt`. Replace `<your_file.pl>` with your Prolog file path and `<predicate>/<arity>` with the main predicate you want to compile (e.g., `choose_strategy/3`). This generates an executable `.sh` file in the specified output directory. Note: The compiler currently does not support arithmetic comparison operators like `>`, `<`, or `=<`.", "question_type": "medium", "topics": ["Compilation", "Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "transpiler", "prolog", "bash", "compiler_driver"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "docs/ADVANCED_RECURSION.md", "src/unifyweaver/core/compiler_driver.pl", "src/unifyweaver/targets/bash/"], "original_answer": "Use the UnifyWeaver compiler to transpile Prolog to bash. Run: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<your_file.pl>'), compile(<predicate>/<arity>, [output_dir('.')])\" -t halt`. For example, to compile `choose_strategy/3` from `temp_strategy.pl`: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('temp_strategy.pl'), compile(choose_strategy/3, [output_dir('.')])\", -t halt`. This creates an executable `.sh` file. Note: arithmetic operators like `>`, `<` are not yet supported.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_001_q1", "cluster_id": "skill_unifyweaver_compile_001", "question": "How can I transpile Prolog predicates to bash?", "answer": "To transpile Prolog predicates to bash, use the UnifyWeaver compiler with the `swipl` command. Run: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<your_file.pl>'), compile(<predicate>/<arity>, [output_dir('.')])\" -t halt`. Replace `<your_file.pl>` with your Prolog file path, and `<predicate>/<arity>` with the main predicate to compile (e.g., `choose_strategy/3`). The compiler automatically handles dependencies and generates an executable `.sh` file in the specified output directory. Note: Arithmetic comparison operators (`>`, `<`, `=<`) are not yet supported.", "question_type": "medium", "topics": ["Compilation", "Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "transpiler", "prolog", "bash", "compiler_driver"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "docs/ADVANCED_RECURSION.md", "src/unifyweaver/core/compiler_driver.pl", "src/unifyweaver/targets/bash/"], "original_answer": "Use the UnifyWeaver compiler to transpile Prolog to bash. Run: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<your_file.pl>'), compile(<predicate>/<arity>, [output_dir('.')])\" -t halt`. For example, to compile `choose_strategy/3` from `temp_strategy.pl`: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('temp_strategy.pl'), compile(choose_strategy/3, [output_dir('.')])\", -t halt`. This creates an executable `.sh` file. Note: arithmetic operators like `>`, `<` are not yet supported.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_001_q2", "cluster_id": "skill_unifyweaver_compile_001", "question": "What's the process for compiling Prolog to bash in UnifyWeaver?", "answer": "To compile Prolog to bash in UnifyWeaver, use the `swipl` command with the compiler driver. Run: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<your_file.pl>'), compile(<predicate>/<arity>, [output_dir('.')])\" -t halt`. For example, to compile the predicate `choose_strategy/3` from `temp_strategy.pl`: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('temp_strategy.pl'), compile(choose_strategy/3, [output_dir('.')])\" -t halt`. This generates an executable `.sh` file in the specified output directory. The compiler automatically handles dependencies. Note: arithmetic comparison operators (`>`, `<`, `=<`) are not currently supported and will cause compilation to fail.", "question_type": "medium", "topics": ["Compilation", "Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "transpiler", "prolog", "bash", "compiler_driver"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "docs/ADVANCED_RECURSION.md", "src/unifyweaver/core/compiler_driver.pl", "src/unifyweaver/targets/bash/"], "original_answer": "Use the UnifyWeaver compiler to transpile Prolog to bash. Run: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<your_file.pl>'), compile(<predicate>/<arity>, [output_dir('.')])\" -t halt`. For example, to compile `choose_strategy/3` from `temp_strategy.pl`: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('temp_strategy.pl'), compile(choose_strategy/3, [output_dir('.')])\", -t halt`. This creates an executable `.sh` file. Note: arithmetic operators like `>`, `<` are not yet supported.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_002_q0", "cluster_id": "skill_unifyweaver_compile_002", "question": "I have Prolog predicates in a file - how do I make them executable?", "answer": "To make Prolog predicates executable, compile your `.pl` file using UnifyWeaver's compiler. Run this command: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<prolog_file>'), compile(<predicate>/<arity>, [output_dir('.')])\" -t halt`. Replace `<prolog_file>` with your file path and `<predicate>/<arity>` with your main predicate name and arity (e.g., `choose_strategy/3`). The compiler automatically includes dependencies and generates an executable `.sh` file in your specified output directory.", "question_type": "medium", "topics": ["Compilation", "Making Predicates Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "executable", "prolog", "workflow"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "src/unifyweaver/core/compiler_driver.pl", "src/unifyweaver/targets/bash/"], "original_answer": "Compile your Prolog file to an executable bash script using UnifyWeaver's compiler. The command is: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<prolog_file>'), compile(<predicate>/<arity>, [output_dir('.')])\" -t halt`. Replace `<prolog_file>` with your `.pl` file path, and `<predicate>/<arity>` with your main predicate (e.g., `choose_strategy/3`). The compiler handles dependencies automatically and outputs a `.sh` file you can execute directly.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_002_q1", "cluster_id": "skill_unifyweaver_compile_002", "question": "How do I run Prolog rules as a script?", "answer": "Use UnifyWeaver's compiler to transpile Prolog rules into executable bash scripts. Run: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<prolog_file>'), compile(<predicate>/<arity>, [output_dir('.')])\" -t halt`. Replace `<prolog_file>` with your Prolog file path and `<predicate>/<arity>` with your main predicate (e.g., `choose_strategy/3`). The compiler automatically resolves dependencies and generates an executable `.sh` file in your specified output directory.", "question_type": "medium", "topics": ["Compilation", "Making Predicates Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "executable", "prolog", "workflow"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "src/unifyweaver/core/compiler_driver.pl", "src/unifyweaver/targets/bash/"], "original_answer": "Compile your Prolog file to an executable bash script using UnifyWeaver's compiler. The command is: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<prolog_file>'), compile(<predicate>/<arity>, [output_dir('.')])\" -t halt`. Replace `<prolog_file>` with your `.pl` file path, and `<predicate>/<arity>` with your main predicate (e.g., `choose_strategy/3`). The compiler handles dependencies automatically and outputs a `.sh` file you can execute directly.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_002_q2", "cluster_id": "skill_unifyweaver_compile_002", "question": "What's the next step after writing Prolog predicates?", "answer": "The next step after writing Prolog predicates is to compile your Prolog file to an executable bash script using UnifyWeaver's compiler. Use the command: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<prolog_file>'), compile(<predicate>/<arity>, [output_dir('.')])\" -t halt`. Replace `<prolog_file>` with your `.pl` file path and `<predicate>/<arity>` with your main predicate (e.g., `choose_strategy/3`). The compiler automatically handles dependencies and outputs an executable `.sh` file.", "question_type": "medium", "topics": ["Compilation", "Making Predicates Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "executable", "prolog", "workflow"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "src/unifyweaver/core/compiler_driver.pl", "src/unifyweaver/targets/bash/"], "original_answer": "Compile your Prolog file to an executable bash script using UnifyWeaver's compiler. The command is: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<prolog_file>'), compile(<predicate>/<arity>, [output_dir('.')])\" -t halt`. Replace `<prolog_file>` with your `.pl` file path, and `<predicate>/<arity>` with your main predicate (e.g., `choose_strategy/3`). The compiler handles dependencies automatically and outputs a `.sh` file you can execute directly.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_003_q0", "cluster_id": "skill_unifyweaver_compile_003", "question": "Where does the compiled bash script get saved?", "answer": "The compiled bash script is saved to the directory specified in the `output_dir` option. Use `compile(my_predicate/2, [output_dir('.')])` to save to the current directory. The output filename is automatically derived from the predicate name (e.g., `my_predicate.sh`). If `output_dir` is not specified, the file may be saved to an unexpected default location.", "question_type": "long", "topics": ["Compilation", "Output Configuration"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "output", "configuration", "compiler_driver"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "src/unifyweaver/core/compiler_driver.pl"], "original_answer": "Use the `output_dir('<directory>')` option when compiling. For example: `compile(my_predicate/2, [output_dir('.')])` saves to the current directory. If you don't specify `output_dir`, the file may be saved to an unexpected default location. The output filename is automatically derived from the predicate name (e.g., `my_predicate.sh`).", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_003_q1", "cluster_id": "skill_unifyweaver_compile_003", "question": "How do I specify the output location for compiled scripts?", "answer": "Specify the output location using the `output_dir('<directory>')` option in the compile function. For example: `compile(my_predicate/2, [output_dir('.')])` saves the compiled script to the current directory. Without this option, the output file may be saved to an unexpected default location. The compiled filename is automatically derived from the predicate name (e.g., `my_predicate.sh`).", "question_type": "long", "topics": ["Compilation", "Output Configuration"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "output", "configuration", "compiler_driver"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "src/unifyweaver/core/compiler_driver.pl"], "original_answer": "Use the `output_dir('<directory>')` option when compiling. For example: `compile(my_predicate/2, [output_dir('.')])` saves to the current directory. If you don't specify `output_dir`, the file may be saved to an unexpected default location. The output filename is automatically derived from the predicate name (e.g., `my_predicate.sh`).", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_003_q2", "cluster_id": "skill_unifyweaver_compile_003", "question": "Can I control where the .sh file is created?", "answer": "Yes. Use the `output_dir('<directory>')` option in the compile function to control where the .sh file is created. For example: `compile(my_predicate/2, [output_dir('.')])` saves to the current directory. Without specifying `output_dir`, the file may be saved to an unexpected default location. The output filename is automatically derived from the predicate name (e.g., `my_predicate.sh`).", "question_type": "long", "topics": ["Compilation", "Output Configuration"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "output", "configuration", "compiler_driver"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "src/unifyweaver/core/compiler_driver.pl"], "original_answer": "Use the `output_dir('<directory>')` option when compiling. For example: `compile(my_predicate/2, [output_dir('.')])` saves to the current directory. If you don't specify `output_dir`, the file may be saved to an unexpected default location. The output filename is automatically derived from the predicate name (e.g., `my_predicate.sh`).", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_004_q0", "cluster_id": "skill_unifyweaver_compile_004", "question": "Why does my Prolog compilation fail with arithmetic operators?", "answer": "The UnifyWeaver compiler has a known limitation that prevents it from transpiling predicates with direct arithmetic comparison operators such as `>`, `<`, or `=<`. When these operators are used directly in your Prolog predicates, the compilation process will fail. To work around this limitation, you should restructure your logic to avoid direct arithmetic comparisons in the predicates you intend to compile. Note that the compiler automatically handles dependencies, but any predicate containing these arithmetic operators will block the entire compilation.", "question_type": "long", "topics": ["Compilation", "Limitations"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "limitations", "arithmetic", "troubleshooting", "operators"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "docs/ADVANCED_RECURSION.md", "src/unifyweaver/core/compiler_driver.pl"], "original_answer": "The current UnifyWeaver compiler has a known limitation: it cannot transpile predicates that directly use arithmetic comparison operators like `>`, `<`, or `=<`. This will cause compilation to fail. As a workaround, restructure your logic to avoid direct arithmetic comparisons in predicates you need to compile. Dependencies are handled automatically, but any predicate using these operators will block the compilation process.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_004_q1", "cluster_id": "skill_unifyweaver_compile_004", "question": "Can I use > or < in predicates I want to compile?", "answer": "No, you cannot use `>`, `<`, or `=<` arithmetic comparison operators in predicates you want to compile with UnifyWeaver. The compiler has a known limitation and will fail if these operators are used directly in your predicate logic. To work around this, you need to restructure your logic to avoid direct arithmetic comparisons in predicates intended for compilation.", "question_type": "long", "topics": ["Compilation", "Limitations"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "limitations", "arithmetic", "troubleshooting", "operators"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "docs/ADVANCED_RECURSION.md", "src/unifyweaver/core/compiler_driver.pl"], "original_answer": "The current UnifyWeaver compiler has a known limitation: it cannot transpile predicates that directly use arithmetic comparison operators like `>`, `<`, or `=<`. This will cause compilation to fail. As a workaround, restructure your logic to avoid direct arithmetic comparisons in predicates you need to compile. Dependencies are handled automatically, but any predicate using these operators will block the compilation process.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_004_q2", "cluster_id": "skill_unifyweaver_compile_004", "question": "What arithmetic operations are supported in compilation?", "answer": "The current UnifyWeaver compiler does not support arithmetic comparison operators (>, <, =<) in compilation. These operators will cause compilation to fail. Other arithmetic operations are not explicitly documented in the available materials. As a workaround, restructure your logic to avoid direct arithmetic comparisons in predicates intended for compilation.", "question_type": "long", "topics": ["Compilation", "Limitations"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "limitations", "arithmetic", "troubleshooting", "operators"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "docs/ADVANCED_RECURSION.md", "src/unifyweaver/core/compiler_driver.pl"], "original_answer": "The current UnifyWeaver compiler has a known limitation: it cannot transpile predicates that directly use arithmetic comparison operators like `>`, `<`, or `=<`. This will cause compilation to fail. As a workaround, restructure your logic to avoid direct arithmetic comparisons in predicates you need to compile. Dependencies are handled automatically, but any predicate using these operators will block the compilation process.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "The base answer only documents what is NOT supported (arithmetic comparisons), but does not clarify what arithmetic operations ARE supported. The answer relies on negative specification rather than positive documentation of supported features."}
{"pair_id": "skill_unifyweaver_environment_001_q0", "cluster_id": "skill_unifyweaver_environment_001", "question": "I'm getting an error 'source_sink library(unifyweaver/...) does not exist' when running my script", "answer": "This error means the UnifyWeaver module path isn't set up. Use `swipl -f init.pl` from the project root directory to automatically configure all module search paths. The `init.pl` file sets up the `unifyweaver` file search path, allowing you to use `library(unifyweaver/...)` syntax. Alternatively, use relative paths like `'src/unifyweaver/sources'` instead of `library(unifyweaver/sources)`, but ensure you're running from the project root directory.", "question_type": "long", "topics": ["Compilation", "Environment Setup", "Troubleshooting"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["environment", "modules", "errors", "troubleshooting"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["init.pl", "scripts/testing/init_testing.sh"], "original_answer": "This error means the UnifyWeaver module path isn't in your search path. Run your script using `swipl -f init.pl` from the project root directory, which sets up all module paths automatically. Alternatively, use relative paths like `'src/unifyweaver/sources'` instead of `library(unifyweaver/sources)` and ensure you're running from the project root.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_001_q1", "cluster_id": "skill_unifyweaver_environment_001", "question": "How do I fix 'source_sink library does not exist' errors?", "answer": "This error occurs when UnifyWeaver modules can't be found in the search path. To fix it, run your script from the project root using `swipl -f init.pl -g \"goal, halt\"`. The `init.pl` file automatically sets up the correct module paths. If you can't use init.pl, use relative paths like `:- use_module('src/unifyweaver/sources')` instead of `library(unifyweaver/sources)`, and always run from the project root directory where `src/unifyweaver/` is located.", "question_type": "long", "topics": ["Compilation", "Environment Setup", "Troubleshooting"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["environment", "modules", "errors", "troubleshooting"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["init.pl", "scripts/testing/init_testing.sh"], "original_answer": "This error means the UnifyWeaver module path isn't in your search path. Run your script using `swipl -f init.pl` from the project root directory, which sets up all module paths automatically. Alternatively, use relative paths like `'src/unifyweaver/sources'` instead of `library(unifyweaver/sources)` and ensure you're running from the project root.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_001_q2", "cluster_id": "skill_unifyweaver_environment_001", "question": "Why can't Prolog find the UnifyWeaver modules?", "answer": "Prolog can't find UnifyWeaver modules because the module search path isn't configured. UnifyWeaver uses relative paths from the project root (like `'src/unifyweaver/sources'`), not the standard `library(...)` syntax, unless initialization is set up. To fix this: (1) Run from the project root directory, (2) Use `swipl -f init.pl -g \"your_goal, halt\"` which automatically configures the module search paths, or (3) Manually use relative paths like `use_module('src/unifyweaver/sources')` if running directly with `swipl -g`.", "question_type": "long", "topics": ["Compilation", "Environment Setup", "Troubleshooting"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["environment", "modules", "errors", "troubleshooting"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["init.pl", "scripts/testing/init_testing.sh"], "original_answer": "This error means the UnifyWeaver module path isn't in your search path. Run your script using `swipl -f init.pl` from the project root directory, which sets up all module paths automatically. Alternatively, use relative paths like `'src/unifyweaver/sources'` instead of `library(unifyweaver/sources)` and ensure you're running from the project root.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_001_q3", "cluster_id": "skill_unifyweaver_environment_001", "question": "Getting module not found errors in UnifyWeaver", "answer": "Module not found errors occur when UnifyWeaver modules can't be located in the search path. Fix this by running from the project root with `swipl -f init.pl -g \"your_goal, halt\"`, which automatically configures all module paths. If you can't use init.pl, ensure you're in the project root directory and use relative paths like `use_module('src/unifyweaver/sources')` instead of `library(unifyweaver/sources)`. Verify the module file exists at the expected path relative to your current working directory.", "question_type": "long", "topics": ["Compilation", "Environment Setup", "Troubleshooting"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["environment", "modules", "errors", "troubleshooting"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["init.pl", "scripts/testing/init_testing.sh"], "original_answer": "This error means the UnifyWeaver module path isn't in your search path. Run your script using `swipl -f init.pl` from the project root directory, which sets up all module paths automatically. Alternatively, use relative paths like `'src/unifyweaver/sources'` instead of `library(unifyweaver/sources)` and ensure you're running from the project root.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_002_q0", "cluster_id": "skill_unifyweaver_environment_002", "question": "How do I run UnifyWeaver playbooks correctly?", "answer": "Run UnifyWeaver playbooks from the project root directory. For playbooks, use inline initialization for reproducibility: `swipl -q -g \"asserta(file_search_path(unifyweaver, 'src/unifyweaver')), [your_playbook], halt\"`. Alternatively, use `swipl -f init.pl -g \"consult('playbooks/your_playbook.pl'), your_goal, halt\"` if init.pl is available. Both approaches ensure the Prolog environment is correctly configured with the right module search paths before executing playbook goals.", "question_type": "medium", "topics": ["Compilation", "Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["environment", "playbooks", "execution", "setup"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["init.pl", "playbooks/examples_library/", "templates/init_template.pl"], "original_answer": "Always run UnifyWeaver commands from the project root directory (which contains `src/unifyweaver/`, `playbooks/`, and `init.pl`). Use `swipl -f init.pl -g \"your_goal, halt\"` for scripts, or use inline initialization in playbooks: `swipl -q -g \"asserta(file_search_path(unifyweaver, 'src/unifyweaver')), [your_script], halt\"` for reproducibility.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "Base answer conflates script execution with playbook execution. The skill document indicates playbooks use 'inline initialization' as the recommended approach, but the base answer doesn't clearly distinguish between different playbook patterns. The confidence is reduced because the exact playbook invocation pattern isn't fully explicit in the source material."}
{"pair_id": "skill_unifyweaver_environment_002_q1", "cluster_id": "skill_unifyweaver_environment_002", "question": "What's the proper way to execute UnifyWeaver scripts?", "answer": "To execute UnifyWeaver scripts, always run from the project root directory. Use `swipl -f init.pl -g \"your_goal, halt\"` for the recommended approach\u2014init.pl automatically sets up paths and module loading. For playbooks or reproducibility, use inline initialization: `swipl -q -g \"asserta(file_search_path(unifyweaver, 'src/unifyweaver')), [your_script], halt\"`. Never use `library(unifyweaver/...)` syntax without proper initialization.", "question_type": "medium", "topics": ["Compilation", "Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["environment", "playbooks", "execution", "setup"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["init.pl", "playbooks/examples_library/", "templates/init_template.pl"], "original_answer": "Always run UnifyWeaver commands from the project root directory (which contains `src/unifyweaver/`, `playbooks/`, and `init.pl`). Use `swipl -f init.pl -g \"your_goal, halt\"` for scripts, or use inline initialization in playbooks: `swipl -q -g \"asserta(file_search_path(unifyweaver, 'src/unifyweaver')), [your_script], halt\"` for reproducibility.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_002_q2", "cluster_id": "skill_unifyweaver_environment_002", "question": "How do I set up the environment for running UnifyWeaver?", "answer": "To set up the environment for running UnifyWeaver, you must run commands from the project root directory (containing `src/unifyweaver/`, `playbooks/`, `templates/`, `scripts/`, and `init.pl`). For scripts, use `swipl -f init.pl -g \"your_goal, halt\"` which automatically sets up file search paths and module loading. For playbooks or inline scripts, use `swipl -q -g \"asserta(file_search_path(unifyweaver, 'src/unifyweaver')), [your_script], halt\"` for reproducibility. This ensures UnifyWeaver modules can be loaded correctly using `library(unifyweaver/...)` syntax.", "question_type": "medium", "topics": ["Compilation", "Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["environment", "playbooks", "execution", "setup"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["init.pl", "playbooks/examples_library/", "templates/init_template.pl"], "original_answer": "Always run UnifyWeaver commands from the project root directory (which contains `src/unifyweaver/`, `playbooks/`, and `init.pl`). Use `swipl -f init.pl -g \"your_goal, halt\"` for scripts, or use inline initialization in playbooks: `swipl -q -g \"asserta(file_search_path(unifyweaver, 'src/unifyweaver')), [your_script], halt\"` for reproducibility.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_002_q3", "cluster_id": "skill_unifyweaver_environment_002", "question": "What directory should I run UnifyWeaver commands from?", "answer": "Run UnifyWeaver commands from the project root directory, which contains `src/unifyweaver/`, `playbooks/`, `templates/`, `scripts/`, and `init.pl`. This is critical because UnifyWeaver modules use relative paths from the project root. Use `cd /path/to/UnifyWeaver` before executing any commands.", "question_type": "medium", "topics": ["Compilation", "Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["environment", "playbooks", "execution", "setup"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["init.pl", "playbooks/examples_library/", "templates/init_template.pl"], "original_answer": "Always run UnifyWeaver commands from the project root directory (which contains `src/unifyweaver/`, `playbooks/`, and `init.pl`). Use `swipl -f init.pl -g \"your_goal, halt\"` for scripts, or use inline initialization in playbooks: `swipl -q -g \"asserta(file_search_path(unifyweaver, 'src/unifyweaver')), [your_script], halt\"` for reproducibility.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_003_q0", "cluster_id": "skill_unifyweaver_environment_003", "question": "What's the difference between using init.pl and inline initialization?", "answer": "init.pl is a file-based initialization approach that automatically sets up all paths and module configurations when loaded with `swipl -f init.pl`. It's best for interactive sessions and regular scripts because the setup is handled centrally. Inline initialization embeds the path setup directly in your command using `asserta(file_search_path(...))`, making it ideal for playbooks where you want the entire setup self-contained and reproducible without external files. Both require running from the project root directory.", "question_type": "long", "topics": ["Compilation", "Environment Setup", "Initialization Methods"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["environment", "initialization", "init.pl", "best-practices"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["init.pl", "templates/init_template.pl"], "original_answer": "Use `swipl -f init.pl` for interactive sessions and regular scripts - it automatically sets up all paths. Use inline initialization (`asserta(file_search_path(unifyweaver, 'src/unifyweaver'))`) for playbooks where you want the setup embedded in the command for reproducibility. Both require running from the project root directory.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_003_q1", "cluster_id": "skill_unifyweaver_environment_003", "question": "Should I use init.pl or inline setup for my script?", "answer": "Use `swipl -f init.pl` for interactive sessions and regular scripts\u2014it automatically configures all module paths from the project root without manual setup. Use inline initialization (with `asserta(file_search_path(...))`) for playbooks where you want the environment setup embedded in the command itself for reproducibility and portability. Both approaches require running from the project root directory.", "question_type": "long", "topics": ["Compilation", "Environment Setup", "Initialization Methods"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["environment", "initialization", "init.pl", "best-practices"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["init.pl", "templates/init_template.pl"], "original_answer": "Use `swipl -f init.pl` for interactive sessions and regular scripts - it automatically sets up all paths. Use inline initialization (`asserta(file_search_path(unifyweaver, 'src/unifyweaver'))`) for playbooks where you want the setup embedded in the command for reproducibility. Both require running from the project root directory.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_003_q2", "cluster_id": "skill_unifyweaver_environment_003", "question": "When should I use swipl -f init.pl?", "answer": "Use `swipl -f init.pl` when running interactive sessions, standalone scripts, or any UnifyWeaver commands where you want automatic environment setup. The `-f init.pl` flag loads the initialization file from the project root, which automatically sets up file search paths and library directories. This is the recommended approach for most use cases. For playbooks, you may prefer inline initialization instead to keep the setup self-contained within the command itself.", "question_type": "long", "topics": ["Compilation", "Environment Setup", "Initialization Methods"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["environment", "initialization", "init.pl", "best-practices"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["init.pl", "templates/init_template.pl"], "original_answer": "Use `swipl -f init.pl` for interactive sessions and regular scripts - it automatically sets up all paths. Use inline initialization (`asserta(file_search_path(unifyweaver, 'src/unifyweaver'))`) for playbooks where you want the setup embedded in the command for reproducibility. Both require running from the project root directory.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_003_q3", "cluster_id": "skill_unifyweaver_environment_003", "question": "What's the best way to initialize the UnifyWeaver environment?", "answer": "The best way to initialize the UnifyWeaver environment is to use `swipl -f init.pl`, which automatically sets up all necessary paths and file search paths from the project root. For interactive sessions and scripts, this is the recommended approach. For playbooks requiring reproducibility, use inline initialization with `asserta(file_search_path(unifyweaver, 'src/unifyweaver'))` to embed the setup directly in the command. Regardless of method, always run from the project root directory where init.pl is located.", "question_type": "long", "topics": ["Compilation", "Environment Setup", "Initialization Methods"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["environment", "initialization", "init.pl", "best-practices"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["init.pl", "templates/init_template.pl"], "original_answer": "Use `swipl -f init.pl` for interactive sessions and regular scripts - it automatically sets up all paths. Use inline initialization (`asserta(file_search_path(unifyweaver, 'src/unifyweaver'))`) for playbooks where you want the setup embedded in the command for reproducibility. Both require running from the project root directory.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_004_q0", "cluster_id": "skill_unifyweaver_environment_004", "question": "How do I set up a test environment for UnifyWeaver?", "answer": "To set up a test environment for UnifyWeaver, run the initialization script from the project root: `cd /path/to/UnifyWeaver && bash scripts/testing/init_testing.sh`. By default, this creates a test_env directory in scripts/testing/ with all necessary modules, scripts, and configuration files. You can optionally specify a custom location using the -d flag for a parent directory or -p flag for a full custom path. After setup, navigate to the test environment and launch it with `./unifyweaver.sh`, which provides a self-contained Prolog environment for testing. Alternatively, you can manually source the SWI-Prolog environment initialization: `source ./scripts/init_swipl_env.sh` for quick access to the swipl command.", "question_type": "long", "topics": ["Compilation", "Environment Setup", "Testing"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["testing", "environment", "isolation", "test-setup"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["scripts/testing/init_testing.sh"], "original_answer": "Use the test environment initialization script: `cd /path/to/UnifyWeaver && bash scripts/testing/init_testing.sh && cd scripts/testing/test_env && ./unifyweaver.sh`. This creates a self-contained environment with all modules copied, allowing isolated testing without affecting your main project.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_004_q1", "cluster_id": "skill_unifyweaver_environment_004", "question": "Can I create an isolated UnifyWeaver environment for testing?", "answer": "Yes, you can create an isolated UnifyWeaver environment for testing. Run `bash scripts/testing/init_testing.sh` from the project root. Options include: `-d <dir>` to specify parent directory for test_env, `-p <path>` for custom full path, and `--force-windows` to test Windows wrapper logic. The script creates a self-contained environment with all dependencies.", "question_type": "long", "topics": ["Compilation", "Environment Setup", "Testing"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["testing", "environment", "isolation", "test-setup"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["scripts/testing/init_testing.sh"], "original_answer": "Use the test environment initialization script: `cd /path/to/UnifyWeaver && bash scripts/testing/init_testing.sh && cd scripts/testing/test_env && ./unifyweaver.sh`. This creates a self-contained environment with all modules copied, allowing isolated testing without affecting your main project.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_unifyweaver_environment_004_q2", "cluster_id": "skill_unifyweaver_environment_004", "question": "How do I test UnifyWeaver without affecting my main project?", "answer": "To test UnifyWeaver without affecting your main project, create an isolated testing environment using the provided setup script. From the project root, run: `bash scripts/testing/init_testing.sh` (or specify a custom location with `-d /path/to/parent` or `-p /path/to/custom/test`). This creates a self-contained test environment with copies of all core modules, templates, and configuration. Navigate to the test environment and launch the interactive Prolog session with `./unifyweaver.sh`. Once loaded, you can run tests (`test_basic.`, `load_stream.`, etc.) in complete isolation without affecting the main project. The test environment can be deleted or recreated at any time without impact.", "question_type": "long", "topics": ["Compilation", "Environment Setup", "Testing"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["testing", "environment", "isolation", "test-setup"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["scripts/testing/init_testing.sh"], "original_answer": "Use the test environment initialization script: `cd /path/to/UnifyWeaver && bash scripts/testing/init_testing.sh && cd scripts/testing/test_env && ./unifyweaver.sh`. This creates a self-contained environment with all modules copied, allowing isolated testing without affecting your main project.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": "The base answer's command path is slightly inaccurate (should emphasize running from project root). The actual launcher is in the created test_env, not immediately available. Also, the script requires SWI-Prolog to be installed and available via the `swipl` command."}
{"pair_id": "skill_unifyweaver_environment_004_q3", "cluster_id": "skill_unifyweaver_environment_004", "question": "What's the test environment initialization process?", "answer": "The test environment initialization process uses `scripts/testing/init_testing.sh`. Run it from the project root with options like `-d <dir>` for custom parent directory or `-p <path>` for full custom path. It configures SWI-Prolog paths, backs up existing configs, and creates an isolated test environment. Use `--help` to see all options.", "question_type": "long", "topics": ["Compilation", "Environment Setup", "Testing"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["testing", "environment", "isolation", "test-setup"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["scripts/testing/init_testing.sh"], "original_answer": "Use the test environment initialization script: `cd /path/to/UnifyWeaver && bash scripts/testing/init_testing.sh && cd scripts/testing/test_env && ./unifyweaver.sh`. This creates a self-contained environment with all modules copied, allowing isolated testing without affecting your main project.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_extract_records_001_q0", "cluster_id": "skill_extract_records_001", "question": "How do I extract code examples or data records from markdown files?", "answer": "Use the `scripts/utils/extract_records.pl` Perl script to extract code examples and data records from Markdown files conforming to the UnifyWeaver Example Record Format. Run it with options like `-f json` for structured output, `-f content` for raw code blocks, or `-q <pattern>` to filter records by name. This tool handles metadata parsing and multi-line blocks more reliably than grep and outputs in formats suitable for programmatic processing.", "question_type": "medium", "topics": ["Compilation", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["extraction", "parsing", "tools"], "related_skills": ["skill_extract_records.md"], "related_docs": ["docs/playbooks/parsing/README.md", "scripts/utils/extract_records.pl"], "original_answer": "Use the `scripts/utils/extract_records.pl` tool. It is designed to parse UnifyWeaver Example Record Format files, handling metadata and multi-line blocks more reliably than `grep`, and can output in JSON format.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_extract_records_001_q1", "cluster_id": "skill_extract_records_001", "question": "Is there a tool to parse structured data from the documentation?", "answer": "Yes, use the `scripts/utils/extract_records.pl` Perl script. It parses the UnifyWeaver Example Record Format from Markdown files, extracting structured data records with metadata. It handles multi-line content blocks reliably and outputs in multiple formats (full, content, or JSON), making it more robust than grep for programmatic processing of documentation records.", "question_type": "medium", "topics": ["Compilation", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["extraction", "parsing", "tools"], "related_skills": ["skill_extract_records.md"], "related_docs": ["docs/playbooks/parsing/README.md", "scripts/utils/extract_records.pl"], "original_answer": "Use the `scripts/utils/extract_records.pl` tool. It is designed to parse UnifyWeaver Example Record Format files, handling metadata and multi-line blocks more reliably than `grep`, and can output in JSON format.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_extract_records_001_q2", "cluster_id": "skill_extract_records_001", "question": "How can I get JSON output from markdown records instead of just using grep?", "answer": "Use the `scripts/utils/extract_records.pl` tool with the `-f json` flag to extract records as JSON objects. For example: `perl scripts/utils/extract_records.pl -f json path/to/file.md` outputs a stream of JSON objects, one per record. This is more robust than grep because it parses the UnifyWeaver Example Record Format structure, handles multi-line content blocks reliably, and extracts metadata like `id` and `name` fields.", "question_type": "medium", "topics": ["Compilation", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["extraction", "parsing", "tools"], "related_skills": ["skill_extract_records.md"], "related_docs": ["docs/playbooks/parsing/README.md", "scripts/utils/extract_records.pl"], "original_answer": "Use the `scripts/utils/extract_records.pl` tool. It is designed to parse UnifyWeaver Example Record Format files, handling metadata and multi-line blocks more reliably than `grep`, and can output in JSON format.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_extract_records_002_q0", "cluster_id": "skill_extract_records_002", "question": "How do I run a bash script found in a markdown record?", "answer": "To run a bash script from a markdown record: (1) Extract the content using `perl scripts/utils/extract_records.pl -f content -q \"record_name\" file.md > script.sh`, (2) Run it with `bash script.sh`. Do not use `swipl` to execute bash scripts.", "question_type": "long", "topics": ["Compilation", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["bash", "execution", "cli"], "related_skills": ["skill_extract_records.md"], "related_docs": ["scripts/utils/extract_records.pl"], "original_answer": "Extract the content using `perl scripts/utils/extract_records.pl -f content ... > script.sh`, then run it using `bash script.sh`. Do not attempt to run bash records using `swipl`.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_extract_records_002_q1", "cluster_id": "skill_extract_records_002", "question": "I want to execute a shell script record from the playbooks.", "answer": "To execute a shell script record from the playbooks: First, extract the script content using `perl scripts/utils/extract_records.pl -f content` with your query pattern and file path, redirecting output to a `.sh` file. Then execute it with `bash script.sh`. Ensure you use bash, not swipl, for shell script records.", "question_type": "long", "topics": ["Compilation", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["bash", "execution", "cli"], "related_skills": ["skill_extract_records.md"], "related_docs": ["scripts/utils/extract_records.pl"], "original_answer": "Extract the content using `perl scripts/utils/extract_records.pl -f content ... > script.sh`, then run it using `bash script.sh`. Do not attempt to run bash records using `swipl`.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_extract_records_002_q2", "cluster_id": "skill_extract_records_002", "question": "What is the correct way to extract and run a bash code block?", "answer": "To extract and run a bash code block: First, extract the content using `perl scripts/utils/extract_records.pl -f content -q <record_name> <path> > script.sh`. Then execute it with `bash script.sh`. Do not use `swipl` to run bash records, as that tool is for Prolog code, not shell scripts.", "question_type": "long", "topics": ["Compilation", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["bash", "execution", "cli"], "related_skills": ["skill_extract_records.md"], "related_docs": ["scripts/utils/extract_records.pl"], "original_answer": "Extract the content using `perl scripts/utils/extract_records.pl -f content ... > script.sh`, then run it using `bash script.sh`. Do not attempt to run bash records using `swipl`.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_extract_records_003_q0", "cluster_id": "skill_extract_records_003", "question": "How can I filter extracted records by their name?", "answer": "Use the `-q` or `--query` flag with `extract_records.pl` followed by a regex pattern to filter records by their `name` metadata. For example: `perl scripts/utils/extract_records.pl -q \"your_pattern\" path/to/file.md` will only extract records whose names match the regex pattern you provide.", "question_type": "long", "topics": ["Compilation", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["filtering", "querying", "metadata"], "related_skills": ["skill_extract_records.md"], "related_docs": ["scripts/utils/extract_records.pl"], "original_answer": "Use the `-q` or `--query` flag with the `extract_records.pl` script. This accepts a regex pattern to filter records based on their `name` metadata field.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_extract_records_003_q1", "cluster_id": "skill_extract_records_003", "question": "Can I search for a specific metadata ID within the markdown files?", "answer": "Yes, use the `-q` or `--query` flag with `extract_records.pl`. This flag accepts a regex pattern to filter records by their `name` metadata field. For example: `perl scripts/utils/extract_records.pl -q \"your_metadata_id\" path/to/file.md` will search for and extract records matching that ID pattern.", "question_type": "long", "topics": ["Compilation", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["filtering", "querying", "metadata"], "related_skills": ["skill_extract_records.md"], "related_docs": ["scripts/utils/extract_records.pl"], "original_answer": "Use the `-q` or `--query` flag with the `extract_records.pl` script. This accepts a regex pattern to filter records based on their `name` metadata field.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_extract_records_003_q2", "cluster_id": "skill_extract_records_003", "question": "How do I query records using a regex pattern?", "answer": "Use the `-q` or `--query` flag with `extract_records.pl` to query records by regex pattern. For example: `perl scripts/utils/extract_records.pl -q \"pattern_name\" path/to/file.md`. The pattern matches against the `name` metadata field of records in UnifyWeaver Example Record Format Markdown files.", "question_type": "long", "topics": ["Compilation", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["filtering", "querying", "metadata"], "related_skills": ["skill_extract_records.md"], "related_docs": ["scripts/utils/extract_records.pl"], "original_answer": "Use the `-q` or `--query` flag with the `extract_records.pl` script. This accepts a regex pattern to filter records based on their `name` metadata field.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_extract_records_004_q0", "cluster_id": "skill_extract_records_004", "question": "How do I extract and load Prolog code from documentation examples?", "answer": "Use `scripts/utils/extract_records.pl` with the `-f content` flag to extract Prolog code from documentation examples and save it to a `.pl` file. Then load it into SWI-Prolog using `swipl -f init.pl -g \"consult('file.pl')...\"` or by running `swipl` and executing `consult('file.pl').` at the prompt.", "question_type": "long", "topics": ["Compilation", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["prolog", "execution", "workflow"], "related_skills": ["skill_extract_records.md"], "related_docs": ["scripts/utils/extract_records.pl"], "original_answer": "Use `scripts/utils/extract_records.pl` with the `-f content` flag to save the code to a `.pl` file. You can then load it into the runtime using `swipl -f init.pl -g \"consult('file.pl')...\"`.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_extract_records_004_q1", "cluster_id": "skill_extract_records_004", "question": "How can I test the prolog snippets found in the guide?", "answer": "Extract Prolog code snippets using `scripts/utils/extract_records.pl` with the `-f content` flag to save the code to a `.pl` file. Then load it into SWI-Prolog using `swipl -f init.pl -g \"consult('file.pl')...\"` to test the snippets.", "question_type": "long", "topics": ["Compilation", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["prolog", "execution", "workflow"], "related_skills": ["skill_extract_records.md"], "related_docs": ["scripts/utils/extract_records.pl"], "original_answer": "Use `scripts/utils/extract_records.pl` with the `-f content` flag to save the code to a `.pl` file. You can then load it into the runtime using `swipl -f init.pl -g \"consult('file.pl')...\"`.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null}
{"pair_id": "skill_extract_records_004_q2", "cluster_id": "skill_extract_records_004", "question": "What is the workflow for consulting a prolog record?", "answer": "To consult a Prolog record: 1) Extract it using `perl scripts/utils/extract_records.pl -f content -q \"record_name\" file.md > file.pl`, 2) Load it into SWI-Prolog using `swipl -f init.pl -g \"consult('file.pl'), halt.\"` or interactively with `?- consult('file.pl').`", "question_type": "long", "topics": ["Compilation", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["prolog", "execution", "workflow"], "related_skills": ["skill_extract_records.md"], "related_docs": ["scripts/utils/extract_records.pl"], "original_answer": "Use `scripts/utils/extract_records.pl` with the `-f content` flag to save the code to a `.pl` file. You can then load it into the runtime using `swipl -f init.pl -g \"consult('file.pl')...\"`.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "Base answer lacks clarity on the complete workflow steps (extraction, file handling, loading). The confidence is moderate because the extracted answer infers procedural steps that aren't explicitly detailed in the base answer."}
{"pair_id": "skill_find_executable_001_q0", "cluster_id": "skill_find_executable_001", "question": "What should I do if a command like 'perl' is not found in my system path?", "answer": "To find an executable not in your PATH, use the Find Executable skill. It searches common installation directories per OS: Windows (C:\\Program Files, C:\\Strawberry), Linux (/usr/bin, /usr/local/bin, /snap/bin), macOS (/opt/homebrew/bin, /Applications). If found, it returns the absolute path you can use to run the command.", "question_type": "medium", "topics": ["Compilation", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["path", "troubleshooting", "executable"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "Use the 'Find Executable' skill to search common installation directories across Windows, Linux, and macOS. It returns the absolute path to the binary, allowing you to execute it directly even if it's missing from your PATH.", "answer_tailored": true, "confidence": 0.85, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_find_executable_001_q1", "cluster_id": "skill_find_executable_001", "question": "How do I locate an executable that is missing from my PATH?", "answer": "Use the 'Find Executable' skill to locate executables missing from your PATH. It searches common installation directories across Windows, Linux, and macOS (such as /usr/bin, /usr/local/bin on Linux; C:\\Program Files on Windows; /opt/homebrew/bin on macOS). The skill returns the absolute path to the executable if found, which you can then use to run the command directly.", "question_type": "medium", "topics": ["Compilation", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["path", "troubleshooting", "executable"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "Use the 'Find Executable' skill to search common installation directories across Windows, Linux, and macOS. It returns the absolute path to the binary, allowing you to execute it directly even if it's missing from your PATH.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_find_executable_001_q2", "cluster_id": "skill_find_executable_001", "question": "What happens if a tool like SWI-Prolog isn't recognized by the terminal?", "answer": "If a tool like SWI-Prolog isn't recognized by the terminal, use the 'Find Executable' skill to search common installation directories (C:\\Program Files\\swipl\\bin on Windows, /usr/local/bin on Linux, /opt/homebrew/bin on macOS). The skill returns the absolute path to the binary if found, which you can then use to execute the command directly\u2014for example, `& \"C:\\Program Files\\swipl\\bin\\swipl.exe\"` on Windows or `/usr/local/bin/swipl` on Linux/macOS\u2014bypassing the need for it to be in your PATH.", "question_type": "medium", "topics": ["Compilation", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["path", "troubleshooting", "executable"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "Use the 'Find Executable' skill to search common installation directories across Windows, Linux, and macOS. It returns the absolute path to the binary, allowing you to execute it directly even if it's missing from your PATH.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_find_executable_002_q0", "cluster_id": "skill_find_executable_002", "question": "How can I find the installation path for a specific tool on my computer?", "answer": "Use the 'Find Executable' skill by providing the executable name (e.g., 'swipl', 'perl'). It searches standard OS-specific installation directories\u2014such as /usr/local/bin on Linux, /opt/homebrew/bin on macOS, or Program Files on Windows\u2014and returns the full installation path if found.", "question_type": "medium", "topics": ["Compilation", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["installation", "search", "tools"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "By providing the executable name (e.g., 'swipl' or 'perl'), the 'Find Executable' skill searches standard OS-specific locations like /usr/local/bin or Program Files and returns the full path for execution.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_find_executable_002_q1", "cluster_id": "skill_find_executable_002", "question": "Can the agent help me locate where a program is installed?", "answer": "When an executable isn't in your system PATH, use the Find Executable skill which searches common installation directories. On Windows it checks C:\\Strawberry\\perl\\bin, C:\\Program Files\\swipl\\bin. On Linux: /usr/bin, /usr/local/bin, /snap/bin. On macOS: /usr/local/bin, /opt/homebrew/bin, /Applications/. The skill returns the absolute path if found, which you can use directly.", "question_type": "medium", "topics": ["Compilation", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["installation", "search", "tools"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "By providing the executable name (e.g., 'swipl' or 'perl'), the 'Find Executable' skill searches standard OS-specific locations like /usr/local/bin or Program Files and returns the full path for execution.", "answer_tailored": true, "confidence": 0.85, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_find_executable_002_q2", "cluster_id": "skill_find_executable_002", "question": "How do I find the full path to an executable file?", "answer": "When a program is installed but the agent can't execute it, use the Find Executable skill to locate it. The skill searches OS-specific directories: Windows (C:\\Program Files, C:\\Strawberry), Linux (/usr/bin, /usr/local/bin, /snap/bin), macOS (/opt/homebrew/bin, /Applications). Use the returned absolute path to execute the command directly.", "question_type": "medium", "topics": ["Compilation", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["installation", "search", "tools"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "By providing the executable name (e.g., 'swipl' or 'perl'), the 'Find Executable' skill searches standard OS-specific locations like /usr/local/bin or Program Files and returns the full path for execution.", "answer_tailored": true, "confidence": 0.85, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_find_executable_003_q0", "cluster_id": "skill_find_executable_003", "question": "Where does the agent look for software that isn't in the PATH?", "answer": "The 'Find Executable' skill searches predefined directories on the user's operating system. On Windows, it checks C:\\Strawberry\\perl\\bin and C:\\Program Files\\swipl\\bin. On Linux, it searches /usr/bin, /usr/local/bin, and /snap/bin. On macOS, it looks in /usr/bin, /usr/local/bin, /opt/homebrew/bin, and /Applications/SWI-Prolog.app/Contents/MacOS.", "question_type": "medium", "topics": ["Compilation", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["directories", "os-specific", "environment"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "The 'Find Executable' skill searches predefined directories based on your OS, such as C:\\Program Files on Windows, /usr/bin and /snap/bin on Linux, and /opt/homebrew/bin or Applications on macOS.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_find_executable_003_q1", "cluster_id": "skill_find_executable_003", "question": "What directories are searched when trying to find a missing tool?", "answer": "Common installation directories vary by OS. Windows: C:\\Program Files, C:\\Program Files (x86), C:\\Strawberry (Perl). Linux: /usr/bin, /usr/local/bin, /snap/bin, /opt. macOS: /usr/local/bin, /opt/homebrew/bin (Homebrew), /Applications. The Find Executable skill searches these locations automatically.", "question_type": "medium", "topics": ["Compilation", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["directories", "os-specific", "environment"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "The 'Find Executable' skill searches predefined directories based on your OS, such as C:\\Program Files on Windows, /usr/bin and /snap/bin on Linux, and /opt/homebrew/bin or Applications on macOS.", "answer_tailored": true, "confidence": 0.85, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_find_executable_003_q2", "cluster_id": "skill_find_executable_003", "question": "Which standard locations are checked for installed executables?", "answer": "The 'Find Executable' skill searches operating system-specific standard locations: On Windows, it checks C:\\Strawberry\\perl\\bin, C:\\Program Files\\swipl\\bin, and C:\\Program Files (x86)\\swipl\\bin. On Linux, it checks /usr/bin, /usr/local/bin, and /snap/bin. On macOS, it checks /usr/bin, /usr/local/bin, /opt/homebrew/bin, and /Applications/SWI-Prolog.app/Contents/MacOS.", "question_type": "medium", "topics": ["Compilation", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["directories", "os-specific", "environment"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "The 'Find Executable' skill searches predefined directories based on your OS, such as C:\\Program Files on Windows, /usr/bin and /snap/bin on Linux, and /opt/homebrew/bin or Applications on macOS.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_find_executable_004_q0", "cluster_id": "skill_find_executable_004", "question": "My terminal says 'command not found'. Is there a way to fix this automatically?", "answer": "Yes, you can use the 'Find Executable' skill to automatically fix 'command not found' errors. When this error occurs, the skill searches common installation directories for your operating system and returns the full path to the executable. You can then use that path to run the command directly (for example, on Windows: `& \"C:\\Strawberry\\perl\\bin\\perl.exe\" script.pl`). If the executable is found, you get the absolute path; if not found, the skill returns an empty string so you know the binary isn't installed.", "question_type": "medium", "topics": ["Compilation", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["errors", "automation", "fix"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "When a 'command not found' error occurs, trigger the 'Find Executable' skill. It attempts to locate the binary in common installation paths and returns the absolute path needed to run the command successfully.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_find_executable_004_q1", "cluster_id": "skill_find_executable_004", "question": "How do I resolve a 'command not found' error for a required tool?", "answer": "When you encounter a 'command not found' error for a required tool, use the 'Find Executable' skill to search common installation directories across your operating system. The skill checks Windows paths like C:\\Strawberry\\perl\\bin and C:\\Program Files\\swipl\\bin, Linux paths like /usr/bin, /usr/local/bin, and /snap/bin, and macOS paths including /usr/local/bin and /opt/homebrew/bin. If the executable is found, the skill returns its absolute path, which you can then use to run the command directly.", "question_type": "medium", "topics": ["Compilation", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["errors", "automation", "fix"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "When a 'command not found' error occurs, trigger the 'Find Executable' skill. It attempts to locate the binary in common installation paths and returns the absolute path needed to run the command successfully.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_find_executable_004_q2", "cluster_id": "skill_find_executable_004", "question": "Can the system automatically find a program if the shell can't?", "answer": "Yes. When a 'command not found' error occurs, the 'Find Executable' skill can automatically locate the program by searching common installation paths across the operating system (such as /usr/local/bin on Linux, /opt/homebrew/bin on macOS, or C:\\Program Files on Windows) and returns the absolute path needed to execute the command.", "question_type": "medium", "topics": ["Compilation", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["errors", "automation", "fix"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "When a 'command not found' error occurs, trigger the 'Find Executable' skill. It attempts to locate the binary in common installation paths and returns the absolute path needed to run the command successfully.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_001_q0", "cluster_id": "skill_json_sources_001", "question": "How do I read specific fields from a JSON file into a Prolog predicate?", "answer": "Use the `:- source(json, ...)` directive with `columns/1` to specify which fields to read. List field names using dot notation (e.g., `'order.customer.name'`) or JSONPath selectors (e.g., `jsonpath('$.items[0].total')`). The number of columns must match your predicate's arity. Example: `:- source(json, orders, [json_file('data/orders.json'), columns(['order.id', 'order.total'])])` creates a predicate `orders(Id, Total)` with 2 arguments.", "question_type": "medium", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["json", "source", "columns", "projection"], "related_skills": ["skill_json_sources.md"], "related_docs": [], "original_answer": "Use the `:- source(json, ...)` directive with the `columns/1` option. Provide a list of field names (dot notation) or `jsonpath(...)` selectors that match the arity of your predicate.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_001_q1", "cluster_id": "skill_json_sources_001", "question": "How to project JSON fields to Prolog arguments?", "answer": "To project JSON fields to Prolog arguments, use the `:- source(json, ...)` directive with `columns/1` containing a list of field selectors. Each selector maps to one Prolog argument in order: use dot notation (e.g., `'customer.name'`) for nested fields, array indices (e.g., `'items[0].total'`), or JSONPath expressions (e.g., `jsonpath('$.orders[*].id')`). The number of selectors in `columns/1` must match your predicate's arity.", "question_type": "medium", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["json", "source", "columns", "projection"], "related_skills": ["skill_json_sources.md"], "related_docs": [], "original_answer": "Use the `:- source(json, ...)` directive with the `columns/1` option. Provide a list of field names (dot notation) or `jsonpath(...)` selectors that match the arity of your predicate.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_json_sources_001_q2", "cluster_id": "skill_json_sources_001", "question": "Reading a JSON file with specific columns", "answer": "To read a JSON file with specific columns, use the `:- source(json, PredicateName, [json_file('path/to/file.json'), columns(['field1', 'field2', ...])])` directive. The `columns/1` parameter accepts field names using dot notation (e.g., 'customer.name') or JSONPath selectors (e.g., 'items[0].product'). The number of columns must match your predicate's arity. For complex selections, use `jsonpath('$.path[*].to.field')` syntax which supports root `$`, dotted properties, bracket notation, array indices, wildcards `[*]`, and recursive descent `..fieldname`.", "question_type": "medium", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["json", "source", "columns", "projection"], "related_skills": ["skill_json_sources.md"], "related_docs": [], "original_answer": "Use the `:- source(json, ...)` directive with the `columns/1` option. Provide a list of field names (dot notation) or `jsonpath(...)` selectors that match the arity of your predicate.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_json_sources_002_q0", "cluster_id": "skill_json_sources_002", "question": "How can I select nested data or arrays from a JSON source?", "answer": "To select nested data or arrays from a JSON source, use `jsonpath('$.selector')` within your `columns` or `schema` definition. JSONPath supports: root `$`, dotted properties, bracket properties (`['foo']`), array indices `[0]`, wildcards `[*]` for matching multiple values, and recursive descent `..name`. For example, `jsonpath('$.orders[*].total')` selects the total from all orders, or `jsonpath('$.items[0].product')` selects the first item's product. Alternatively, use dot notation with array indices in column names directly: `columns(['items[0].total', 'customer.name']). Strings beginning with `$` are automatically treated as JSONPath selectors.", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["json", "jsonpath", "nested-data"], "related_skills": ["skill_json_sources.md"], "related_docs": [], "original_answer": "Use `jsonpath('$.selector')` within your `columns` or `schema` definition. You can use standard JSONPath features like `[*]` for wildcards, `[0]` for indices, and `..` for recursive descent.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_002_q1", "cluster_id": "skill_json_sources_002", "question": "Using JSONPath in UnifyWeaver sources", "answer": "To use JSONPath in UnifyWeaver sources, include `jsonpath('$.selector')` within your `columns/1` or `schema/1` definition. Supported features include root selector `$`, dotted properties, bracket properties like `['foo']`, array indices `[0]`, wildcards `[*]` to match multiple elements, and recursive descent `..name`. Strings beginning with `$` are automatically treated as JSONPath selectors. For column projection, use `columns(['$.orders[0].id'])` to select specific data; for schema definitions, JSONPath works in both field paths and schema selectors. Note that wildcards currently return only the first matching value.", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["json", "jsonpath", "nested-data"], "related_skills": ["skill_json_sources.md"], "related_docs": [], "original_answer": "Use `jsonpath('$.selector')` within your `columns` or `schema` definition. You can use standard JSONPath features like `[*]` for wildcards, `[0]` for indices, and `..` for recursive descent.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_002_q2", "cluster_id": "skill_json_sources_002", "question": "Extracting values from JSON arrays using wildcards", "answer": "To extract values from JSON arrays using wildcards, use JSONPath selectors with the `[*]` wildcard syntax within your `columns/1` or `schema/1` definition. For example, `jsonpath('$.items[*].price')` selects the price field from all items in an array. You can combine wildcards with other JSONPath features like array indices `[0]`, dot notation for nested properties, and recursive descent `..fieldname`. Strings beginning with `$` are automatically treated as JSONPath selectors, so you can use either `columns(['$.items[*].id'])` or `jsonpath('$.items[*].id')`. Note that wildcards currently return the first matching value when used in column projections.", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["json", "jsonpath", "nested-data"], "related_skills": ["skill_json_sources.md"], "related_docs": [], "original_answer": "Use `jsonpath('$.selector')` within your `columns` or `schema` definition. You can use standard JSONPath features like `[*]` for wildcards, `[0]` for indices, and `..` for recursive descent.", "answer_tailored": true, "confidence": 0.75, "confidence_issues": "The base answer mentions wildcard support but lacks detail on the 'first matching value' limitation and doesn't clearly distinguish between column projection mode (returns first match) and other uses. The tailored answer adds this clarification but introduces some inference beyond the documented examples."}
{"pair_id": "skill_json_sources_003_q0", "cluster_id": "skill_json_sources_003", "question": "How do I map JSON data to strongly typed C# records?", "answer": "Use the `schema/1` option in your JSON source declaration to map JSON data to strongly typed C# records. Define a list of `field(Name, Path, Type)` terms specifying the field name, JSON path (supports dot notation and array indices), and .NET type. Set `record_type('YourRecordName')` to name the generated POCO. The predicate must have an arity of 1, and the C# backend will automatically generate the typed record class. For nested objects, use `record(TypeName, Fields)` or `record(Fields)` to create structured sub-objects within your schema.", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["json", "schema", "csharp", "types"], "related_skills": ["skill_json_sources.md"], "related_docs": [], "original_answer": "Use the `schema/1` option in your source declaration instead of `columns/1`. Define a list of `field(Name, Path, Type)` terms and set `record_type('TypeName')`. The predicate must have an arity of 1.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_003_q1", "cluster_id": "skill_json_sources_003", "question": "Generating POCOs from JSON sources", "answer": "To generate POCOs from JSON sources, use the `schema/1` option in your source declaration. Define a list of `field(Name, Path, Type)` terms to specify which JSON fields map to your POCO properties and their types. Set `record_type('TypeName')` to name the generated record class. The predicate must have an arity of 1. The C# backend will automatically generate a typed POCO class matching your schema definition. For nested objects, use `record(TypeName, Fields)` or `record(Fields)` within field definitions.", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["json", "schema", "csharp", "types"], "related_skills": ["skill_json_sources.md"], "related_docs": [], "original_answer": "Use the `schema/1` option in your source declaration instead of `columns/1`. Define a list of `field(Name, Path, Type)` terms and set `record_type('TypeName')`. The predicate must have an arity of 1.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_003_q2", "cluster_id": "skill_json_sources_003", "question": "Using schema definitions for JSON files", "answer": "To use schema definitions for JSON files, replace `columns/1` with `schema/1` in your source declaration. Define a list of `field(Name, Path, Type)` terms specifying the field name, JSONPath or dot notation selector, and data type. Set `record_type('TypeName')` to name the generated record type, and ensure the predicate has arity 1. The C# backend will automatically generate a typed POCO record from your schema definition. For nested objects, use `record(TypeName, Fields)` to create structured sub-objects within your schema.", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["json", "schema", "csharp", "types"], "related_skills": ["skill_json_sources.md"], "related_docs": [], "original_answer": "Use the `schema/1` option in your source declaration instead of `columns/1`. Define a list of `field(Name, Path, Type)` terms and set `record_type('TypeName')`. The predicate must have an arity of 1.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_004_q0", "cluster_id": "skill_json_sources_004", "question": "How do I process newline-delimited JSON (JSONL) files?", "answer": "To process newline-delimited JSON (JSONL) files, add `record_format(jsonl)` to your source options in the Prolog declaration. This tells the JSON source handler to parse each line as a separate JSON object. You can also configure `null_policy/1` to control how missing data is handled\u2014use `skip` to omit incomplete rows, `fail` to error on missing fields, or `default(Value)` to provide a fallback value.", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["json", "jsonl", "null-handling", "streaming"], "related_skills": ["skill_json_sources.md"], "related_docs": [], "original_answer": "Add `record_format(jsonl)` to your source options. You can also configure `null_policy/1` (set to `skip`, `fail`, or `default(Value)`) to manage how missing data impacts the stream.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_004_q1", "cluster_id": "skill_json_sources_004", "question": "Reading .jsonl files in UnifyWeaver", "answer": "To read .jsonl files in UnifyWeaver, add `record_format(jsonl)` to your source options in the Prolog declaration. You can also configure `null_policy/1` to control how missing data is handled\u2014set it to `skip` (omit records with null values), `fail` (halt on nulls), or `default(Value)` (substitute a default value). Example:\n\n```prolog\n:- source(json, my_data, [\n    json_file('data/records.jsonl'),\n    record_format(jsonl),\n    null_policy(skip),\n    columns(['id', 'name', 'value'])\n]).\n```", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["json", "jsonl", "null-handling", "streaming"], "related_skills": ["skill_json_sources.md"], "related_docs": [], "original_answer": "Add `record_format(jsonl)` to your source options. You can also configure `null_policy/1` (set to `skip`, `fail`, or `default(Value)`) to manage how missing data impacts the stream.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_004_q2", "cluster_id": "skill_json_sources_004", "question": "Handling null values in JSON sources", "answer": "To handle null values in JSON sources, add `null_policy/1` to your source options with one of three settings: `skip` (omit records with null values), `fail` (raise an error on null), or `default(Value)` (substitute a default value). You can also use `record_format(jsonl)` if working with JSONL data. For schema-based sources, null handling is applied consistently across all projected fields.", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["json", "jsonl", "null-handling", "streaming"], "related_skills": ["skill_json_sources.md"], "related_docs": [], "original_answer": "Add `record_format(jsonl)` to your source options. You can also configure `null_policy/1` (set to `skip`, `fail`, or `default(Value)`) to manage how missing data impacts the stream.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "The base answer conflates two separate features (`record_format(jsonl)` for format specification and `null_policy/1` for null handling), making it unclear which applies to the specific question. The base answer lacks examples and doesn't clarify whether null_policy applies to all source modes (column projection, return-object, schema-generated) or specific ones. Documentation reference would strengthen confidence."}
{"pair_id": "skill_unifyweaver_compile_001_q0", "cluster_id": "skill_unifyweaver_compile_001", "question": "How do I turn my Prolog file into an executable bash script?", "answer": "To turn your Prolog file into an executable bash script, use the UnifyWeaver compiler driver. Run: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('your_file.pl'), compile(predicate_name/arity, [output_dir('.')])\" -t halt`. Replace `your_file.pl` with your Prolog file path and `predicate_name/arity` with your main predicate (e.g., `my_rule/2`). This generates an executable `.sh` file in the current directory. Note: The compiler cannot handle predicates using arithmetic comparison operators like `>`, `<`, or `=<`.", "question_type": "medium", "topics": ["Compilation", "UnifyWeaver Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "bash", "prolog", "transpiler"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "docs/ADVANCED_RECURSION.md", "src/unifyweaver/core/compiler_driver.pl", "src/unifyweaver/targets/bash/"], "original_answer": "You can transpile Prolog logic to Bash using the UnifyWeaver compiler driver. Invoke it via `swipl` by loading the driver module and your source file, then calling the `compile/2` predicate. For example: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('my_rules.pl'), compile(my_pred/2, [output_dir('.')])\" -t halt`.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_001_q1", "cluster_id": "skill_unifyweaver_compile_001", "question": "Convert prolog logic to shell script", "answer": "To convert Prolog logic to a shell script, use the UnifyWeaver compiler driver. Execute: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<your_file>.pl'), compile(<predicate>/<arity>, [output_dir('.')])\" -t halt`. Replace `<your_file>.pl` with your Prolog source file and `<predicate>/<arity>` with the main predicate you want to compile (e.g., `my_pred/2`). This generates an executable `.sh` file in the current directory. Note: The compiler cannot handle arithmetic comparison operators (`>`, `<`, `=<`) directly in predicates.", "question_type": "medium", "topics": ["Compilation", "UnifyWeaver Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "bash", "prolog", "transpiler"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "docs/ADVANCED_RECURSION.md", "src/unifyweaver/core/compiler_driver.pl", "src/unifyweaver/targets/bash/"], "original_answer": "You can transpile Prolog logic to Bash using the UnifyWeaver compiler driver. Invoke it via `swipl` by loading the driver module and your source file, then calling the `compile/2` predicate. For example: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('my_rules.pl'), compile(my_pred/2, [output_dir('.')])\" -t halt`.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_001_q2", "cluster_id": "skill_unifyweaver_compile_001", "question": "How to compile prolog rules to bash", "answer": "To compile Prolog rules to Bash, use the UnifyWeaver compiler driver. Run the following command: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<prolog_file>'), compile(<predicate/arity>, [output_dir('.')])\" -t halt`. Replace `<prolog_file>` with your Prolog source file path and `<predicate/arity>` with your main predicate (e.g., `my_pred/2`). This generates an executable `.sh` file in the output directory. Note: predicates using direct arithmetic comparison operators (>, <, =<) are not currently supported.", "question_type": "medium", "topics": ["Compilation", "UnifyWeaver Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "bash", "prolog", "transpiler"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "docs/ADVANCED_RECURSION.md", "src/unifyweaver/core/compiler_driver.pl", "src/unifyweaver/targets/bash/"], "original_answer": "You can transpile Prolog logic to Bash using the UnifyWeaver compiler driver. Invoke it via `swipl` by loading the driver module and your source file, then calling the `compile/2` predicate. For example: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('my_rules.pl'), compile(my_pred/2, [output_dir('.')])\" -t halt`.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_001_q3", "cluster_id": "skill_unifyweaver_compile_001", "question": "Make prolog file executable in bash", "answer": "To make a Prolog file executable in Bash, use the UnifyWeaver compiler driver to transpile it. Run: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('your_file.pl'), compile(predicate_name/arity, [output_dir('.')])\" -t halt`. This generates an executable `.sh` file. Replace `your_file.pl` with your Prolog file, and `predicate_name/arity` with your main predicate (e.g., `main/0`). The output script can then be executed directly.", "question_type": "medium", "topics": ["Compilation", "UnifyWeaver Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "bash", "prolog", "transpiler"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "docs/ADVANCED_RECURSION.md", "src/unifyweaver/core/compiler_driver.pl", "src/unifyweaver/targets/bash/"], "original_answer": "You can transpile Prolog logic to Bash using the UnifyWeaver compiler driver. Invoke it via `swipl` by loading the driver module and your source file, then calling the `compile/2` predicate. For example: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('my_rules.pl'), compile(my_pred/2, [output_dir('.')])\" -t halt`.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_002_q0", "cluster_id": "skill_unifyweaver_compile_002", "question": "What is the command syntax to compile a specific predicate?", "answer": "To compile a specific predicate, use the command: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<prolog_file>'), compile(<predicate_indicator>, [<options>])\" -t halt`. Replace `<prolog_file>` with your .pl file path, `<predicate_indicator>` with the predicate name and arity (e.g., `choose_strategy/3`), and include `output_dir('.')` in the options list to specify the output directory for the compiled .sh file.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["command", "syntax", "compiler_driver", "swipl"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "src/unifyweaver/core/compiler_driver.pl"], "original_answer": "The standard command follows this template: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<prolog_file>'), compile(<predicate_indicator>, [<options>])\" -t halt`. Ensure you specify the `output_dir` option, usually `output_dir('.')`, to control where the resulting script is saved.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_002_q1", "cluster_id": "skill_unifyweaver_compile_002", "question": "Command to transpile a prolog predicate", "answer": "To transpile a Prolog predicate, use the swipl command with the compiler_driver module. The template is: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<prolog_file>'), compile(<predicate_indicator>, [<options>])\" -t halt`. Replace `<prolog_file>` with your `.pl` file path, `<predicate_indicator>` with the predicate in `functor/arity` format (e.g., `choose_strategy/3`), and include `output_dir('.')` in the options to specify the output directory for the generated bash script.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["command", "syntax", "compiler_driver", "swipl"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "src/unifyweaver/core/compiler_driver.pl"], "original_answer": "The standard command follows this template: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<prolog_file>'), compile(<predicate_indicator>, [<options>])\" -t halt`. Ensure you specify the `output_dir` option, usually `output_dir('.')`, to control where the resulting script is saved.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_002_q2", "cluster_id": "skill_unifyweaver_compile_002", "question": "How to run the unifyweaver compiler", "answer": "To run the unifyweaver compiler, use the command: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<prolog_file>'), compile(<predicate_indicator>, [<options>])\" -t halt`. Replace `<prolog_file>` with your Prolog source file path, `<predicate_indicator>` with the main predicate in `functor/arity` format, and include `output_dir('.')` in the options to specify where the compiled bash script should be saved. The compiler automatically handles predicate dependencies.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["command", "syntax", "compiler_driver", "swipl"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "src/unifyweaver/core/compiler_driver.pl"], "original_answer": "The standard command follows this template: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<prolog_file>'), compile(<predicate_indicator>, [<options>])\" -t halt`. Ensure you specify the `output_dir` option, usually `output_dir('.')`, to control where the resulting script is saved.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_002_q3", "cluster_id": "skill_unifyweaver_compile_002", "question": "Syntax for compiling functor/arity to bash", "answer": "To compile a Prolog functor/arity to bash, use: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<prolog_file>'), compile(<functor>/<arity>, [output_dir('.')])\" -t halt`. Replace `<prolog_file>` with your .pl file path and `<functor>/<arity>` with the predicate you want to compile (e.g., `choose_strategy/3`). The compiler automatically handles dependencies and outputs an executable .sh file.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["command", "syntax", "compiler_driver", "swipl"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "src/unifyweaver/core/compiler_driver.pl"], "original_answer": "The standard command follows this template: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<prolog_file>'), compile(<predicate_indicator>, [<options>])\" -t halt`. Ensure you specify the `output_dir` option, usually `output_dir('.')`, to control where the resulting script is saved.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_003_q0", "cluster_id": "skill_unifyweaver_compile_003", "question": "Does the compiler handle dependencies if my rule uses other rules?", "answer": "Yes, the compiler automatically handles dependencies. When you compile a predicate like `choose_strategy/3`, the `compiler_driver` analyzes the call graph and automatically compiles all user-defined predicates that your main predicate depends on into the final Bash script. You don't need to manually specify or compile dependencies separately.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["dependencies", "compilation", "automation"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "src/unifyweaver/core/compiler_driver.pl"], "original_answer": "Yes, the compiler automatically handles dependencies. When you target a specific predicate (e.g., `main/0`), the `compiler_driver` analyzes the call graph and compiles all user-defined predicates that your main predicate depends on into the final Bash script.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_003_q1", "cluster_id": "skill_unifyweaver_compile_003", "question": "Do I need to compile dependent predicates manually?", "answer": "No, you do not need to compile dependent predicates manually. The compiler automatically handles dependencies. When you target a specific predicate (e.g., `main/0`), the `compiler_driver` analyzes the call graph and compiles all user-defined predicates that your main predicate depends on into the final Bash script.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["dependencies", "compilation", "automation"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "src/unifyweaver/core/compiler_driver.pl"], "original_answer": "Yes, the compiler automatically handles dependencies. When you target a specific predicate (e.g., `main/0`), the `compiler_driver` analyzes the call graph and compiles all user-defined predicates that your main predicate depends on into the final Bash script.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_003_q2", "cluster_id": "skill_unifyweaver_compile_003", "question": "How does the compiler handle sub-goals?", "answer": "The compiler automatically analyzes the call graph of your targeted predicate and recursively compiles all user-defined sub-goals (predicates) that it depends on into the final Bash script. When you specify a predicate like `main/0`, the compiler_driver traces through all sub-goal calls and includes their implementations in the compiled output, handling the dependency chain automatically.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["dependencies", "compilation", "automation"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "src/unifyweaver/core/compiler_driver.pl"], "original_answer": "Yes, the compiler automatically handles dependencies. When you target a specific predicate (e.g., `main/0`), the `compiler_driver` analyzes the call graph and compiles all user-defined predicates that your main predicate depends on into the final Bash script.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer uses 'dependencies' which is slightly different from 'sub-goals' - sub-goals are the actual called predicates within a clause, while the answer describes dependency resolution. The answer correctly conveys the mechanism but could be more precise about the distinction between sub-goals and overall predicate dependencies."}
{"pair_id": "skill_unifyweaver_compile_003_q3", "cluster_id": "skill_unifyweaver_compile_003", "question": "Automatic dependency resolution in compilation", "answer": "Yes, the UnifyWeaver compiler automatically resolves dependencies. When you compile a predicate (e.g., `main/0`), the `compiler_driver` analyzes the call graph and automatically includes all user-defined predicates that your target predicate depends on in the final Bash script. You don't need to manually specify or import dependencies\u2014the compiler handles this automatically.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["dependencies", "compilation", "automation"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "src/unifyweaver/core/compiler_driver.pl"], "original_answer": "Yes, the compiler automatically handles dependencies. When you target a specific predicate (e.g., `main/0`), the `compiler_driver` analyzes the call graph and compiles all user-defined predicates that your main predicate depends on into the final Bash script.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_004_q0", "cluster_id": "skill_unifyweaver_compile_004", "question": "Why is my compilation failing when using arithmetic operators?", "answer": "The UnifyWeaver compiler_driver has a known limitation with arithmetic comparison operators like `>`, `<`, and `=<`. When you use these operators directly in your Prolog predicates, the compiler cannot transpile them to Bash. To resolve this, restructure your logic to avoid direct arithmetic comparisons in the source file. This may involve refactoring predicates that depend on arithmetic operations or using alternative logic patterns that don't rely on these operators.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["limitations", "arithmetic", "troubleshooting", "bash"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "src/unifyweaver/core/compiler_driver.pl"], "original_answer": "The current version of the UnifyWeaver `compiler_driver` has a limitation regarding arithmetic comparison operators. It cannot transpile predicates that directly use operators like `>`, `<`, or `=<`. You must restructure your logic to avoid direct arithmetic comparisons in the Prolog source intended for Bash compilation.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_004_q1", "cluster_id": "skill_unifyweaver_compile_004", "question": "Can I use greater than or less than signs in rules to be compiled?", "answer": "No, you cannot use greater than or less than signs (`>`, `<`, `=<`) directly in Prolog rules that you intend to compile with UnifyWeaver. The current version of the `compiler_driver` has a known limitation and cannot transpile predicates containing these arithmetic comparison operators. You'll need to restructure your logic to avoid direct arithmetic comparisons in the Prolog source before compilation to Bash.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["limitations", "arithmetic", "troubleshooting", "bash"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "src/unifyweaver/core/compiler_driver.pl"], "original_answer": "The current version of the UnifyWeaver `compiler_driver` has a limitation regarding arithmetic comparison operators. It cannot transpile predicates that directly use operators like `>`, `<`, or `=<`. You must restructure your logic to avoid direct arithmetic comparisons in the Prolog source intended for Bash compilation.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_004_q2", "cluster_id": "skill_unifyweaver_compile_004", "question": "Compilation error with arithmetic comparisons", "answer": "The UnifyWeaver compiler_driver has a known limitation with arithmetic comparison operators. If your Prolog predicates use `>`, `<`, `=<`, or similar arithmetic comparisons directly, compilation will fail. To resolve this, restructure your Prolog logic to avoid direct arithmetic comparisons in predicates intended for Bash transpilation. Consider using helper predicates or alternative logical constructs that don't rely on these operators.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["limitations", "arithmetic", "troubleshooting", "bash"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "src/unifyweaver/core/compiler_driver.pl"], "original_answer": "The current version of the UnifyWeaver `compiler_driver` has a limitation regarding arithmetic comparison operators. It cannot transpile predicates that directly use operators like `>`, `<`, or `=<`. You must restructure your logic to avoid direct arithmetic comparisons in the Prolog source intended for Bash compilation.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_004_q3", "cluster_id": "skill_unifyweaver_compile_004", "question": "Limitations of the bash transpiler", "answer": "Recursive predicates are handled through the compiler's dependency analysis, which tracks predicate calls and ensures proper code generation order. When compiling, dependencies are resolved recursively. The transpiler generates target-language code that preserves recursion semantics (e.g., proper tail-call handling where supported).", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["limitations", "arithmetic", "troubleshooting", "bash"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "src/unifyweaver/core/compiler_driver.pl"], "original_answer": "The current version of the UnifyWeaver `compiler_driver` has a limitation regarding arithmetic comparison operators. It cannot transpile predicates that directly use operators like `>`, `<`, or `=<`. You must restructure your logic to avoid direct arithmetic comparisons in the Prolog source intended for Bash compilation.", "answer_tailored": true, "confidence": 0.75, "confidence_issues": "Specific recursion optimizations depend on target language", "manually_reviewed": true}
{"pair_id": "skill_unifyweaver_environment_001_q0", "cluster_id": "skill_unifyweaver_environment_001", "question": "How do I run a UnifyWeaver Prolog script correctly?", "answer": "To run a UnifyWeaver Prolog script correctly, change to the project root directory and use `swipl -f init.pl` to automatically set up the environment. For example:\n\n```bash\ncd /path/to/UnifyWeaver\nswipl -f init.pl -g \"consult('your_script.pl'), run_goal, halt\"\n```\n\nThe `init.pl` file handles all necessary path configuration, including setting up `file_search_path(unifyweaver, 'src/unifyweaver')` and `library_directory('src')`. This allows your script to use `use_module(library(unifyweaver/...))` syntax without manual path setup. Always run from the project root\u2014`init.pl` must be located there for paths to resolve correctly.", "question_type": "medium", "topics": ["Compilation", "UnifyWeaver Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["environment", "init.pl", "execution"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["templates/init_template.pl"], "original_answer": "Run `swipl` from the project root using the `-f init.pl` flag to automatically set up paths. For example:\n```bash\ncd /path/to/UnifyWeaver\nswipl -f init.pl -g \"consult('your_script.pl'), run_goal, halt\"\n```", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_001_q1", "cluster_id": "skill_unifyweaver_environment_001", "question": "What is the standard command to execute a script using UnifyWeaver modules?", "answer": "The standard command to execute a script using UnifyWeaver modules is to run `swipl` from the project root with the `-f init.pl` flag, which automatically configures the environment. The general syntax is: `cd /path/to/UnifyWeaver && swipl -f init.pl -g \"consult('script.pl'), goal, halt\"`. This approach handles all necessary path configuration and module loading automatically, eliminating the need for manual environment setup.", "question_type": "medium", "topics": ["Compilation", "UnifyWeaver Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["environment", "init.pl", "execution"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["templates/init_template.pl"], "original_answer": "Run `swipl` from the project root using the `-f init.pl` flag to automatically set up paths. For example:\n```bash\ncd /path/to/UnifyWeaver\nswipl -f init.pl -g \"consult('your_script.pl'), run_goal, halt\"\n```", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_001_q2", "cluster_id": "skill_unifyweaver_environment_001", "question": "How do I use init.pl to run my script?", "answer": "To use init.pl to run your script, execute `swipl -f init.pl -g \"consult('your_script.pl'), run_goal, halt\"` from the project root directory. The `-f init.pl` flag automatically loads the initialization file which sets up the file search paths and module loading configuration. Replace 'your_script.pl' with your actual script path and 'run_goal' with the goal you want to execute. This approach eliminates the need for manual path setup since init.pl handles all environment configuration automatically.", "question_type": "medium", "topics": ["Compilation", "UnifyWeaver Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["environment", "init.pl", "execution"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["templates/init_template.pl"], "original_answer": "Run `swipl` from the project root using the `-f init.pl` flag to automatically set up paths. For example:\n```bash\ncd /path/to/UnifyWeaver\nswipl -f init.pl -g \"consult('your_script.pl'), run_goal, halt\"\n```", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_002_q0", "cluster_id": "skill_unifyweaver_environment_002", "question": "How do I fix 'source_sink library(unifyweaver/...) does not exist' errors?", "answer": "This error occurs when the module search path isn't configured. To fix it: (1) Ensure you're running from the project root directory where `init.pl` is located. (2) Use `swipl -f init.pl -g \"your_goal, halt\"` to load the initialization file, which automatically sets up the file search path for `library(unifyweaver/...)` syntax. (3) Alternatively, use relative paths directly: `use_module('src/unifyweaver/sources')` instead of `library(unifyweaver/sources)`. The `init.pl` approach is recommended as it handles all path configuration automatically.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["troubleshooting", "modules", "paths"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": [], "original_answer": "This error occurs when the module search path isn't configured. To fix it:\n1. Ensure you are running from the **project root directory**.\n2. Use the `init.pl` file: `swipl -f init.pl ...`\n3. Or use relative paths in your code (e.g., `'src/unifyweaver/sources'` instead of `library(...)`).", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_002_q1", "cluster_id": "skill_unifyweaver_environment_002", "question": "Why can't Prolog find the unifyweaver library modules?", "answer": "Prolog can't find unifyweaver library modules because the module search path isn't configured. This happens when: (1) you're not running from the project root directory where init.pl is located, (2) you're not using `swipl -f init.pl` to load the initialization file that sets up the search paths, or (3) you're using `library(unifyweaver/...)` syntax without proper initialization. Fix this by running from the project root and using `swipl -f init.pl -g \"your_goal, halt\"` to automatically configure the module paths, or use explicit relative paths like `'src/unifyweaver/sources'` instead of library syntax.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["troubleshooting", "modules", "paths"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": [], "original_answer": "This error occurs when the module search path isn't configured. To fix it:\n1. Ensure you are running from the **project root directory**.\n2. Use the `init.pl` file: `swipl -f init.pl ...`\n3. Or use relative paths in your code (e.g., `'src/unifyweaver/sources'` instead of `library(...)`).", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_002_q2", "cluster_id": "skill_unifyweaver_environment_002", "question": "I'm getting an error about missing source_sink library files when running a script.", "answer": "This error occurs when the module search path isn't configured properly. To fix it: (1) Ensure you're running from the project root directory where `init.pl` is located. (2) Use `swipl -f init.pl -g \"your_goal, halt\"` to load the initialization file, which automatically sets up `file_search_path(unifyweaver, 'src/unifyweaver')` and library paths. (3) Alternatively, use relative paths directly in your code (e.g., `consult('src/unifyweaver/sources')` instead of `library(unifyweaver/sources)` without init.pl). The most reliable solution is using init.pl, which handles all path configuration automatically.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["troubleshooting", "modules", "paths"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": [], "original_answer": "This error occurs when the module search path isn't configured. To fix it:\n1. Ensure you are running from the **project root directory**.\n2. Use the `init.pl` file: `swipl -f init.pl ...`\n3. Or use relative paths in your code (e.g., `'src/unifyweaver/sources'` instead of `library(...)`).", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_003_q0", "cluster_id": "skill_unifyweaver_environment_003", "question": "Where should I run UnifyWeaver commands from?", "answer": "Run all UnifyWeaver commands from the project root directory\u2014the directory containing `src/`, `playbooks/`, `templates/`, `scripts/`, and `init.pl`. This is critical because UnifyWeaver modules use relative paths from the project root for loading. When using `swipl`, change to the project root first with `cd /path/to/UnifyWeaver`, then run your commands. If you use `init.pl` with `swipl -f init.pl`, it will automatically set up the file search paths from the project root location.", "question_type": "medium", "topics": ["Compilation", "UnifyWeaver Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["environment", "directory", "setup"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": [], "original_answer": "CRITICAL: All UnifyWeaver commands and scripts must be run from the **project root directory**. This is the directory containing `src/`, `playbooks/`, and `init.pl`.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_003_q1", "cluster_id": "skill_unifyweaver_environment_003", "question": "What is the required working directory for UnifyWeaver?", "answer": "The required working directory for UnifyWeaver is the project root directory, which contains `src/`, `playbooks/`, `templates/`, `scripts/`, and `init.pl`. All UnifyWeaver commands and scripts must be run from this directory because modules use relative paths from the project root.", "question_type": "medium", "topics": ["Compilation", "UnifyWeaver Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["environment", "directory", "setup"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": [], "original_answer": "CRITICAL: All UnifyWeaver commands and scripts must be run from the **project root directory**. This is the directory containing `src/`, `playbooks/`, and `init.pl`.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_003_q2", "cluster_id": "skill_unifyweaver_environment_003", "question": "Do I need to be in a specific folder to run playbooks?", "answer": "Yes, you must run playbooks from the project root directory. This is the directory containing `src/`, `playbooks/`, `templates/`, and `init.pl`. UnifyWeaver uses relative paths from this location to load modules and resources, so running from any other directory will cause module loading failures.", "question_type": "medium", "topics": ["Compilation", "UnifyWeaver Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["environment", "directory", "setup"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": [], "original_answer": "CRITICAL: All UnifyWeaver commands and scripts must be run from the **project root directory**. This is the directory containing `src/`, `playbooks/`, and `init.pl`.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_004_q0", "cluster_id": "skill_unifyweaver_environment_004", "question": "How do I configure the UnifyWeaver environment in a standalone playbook?", "answer": "To configure the UnifyWeaver environment in a standalone playbook, use inline initialization to set the search path before loading modules:\n\n```bash\nswipl -g \"asserta(file_search_path(unifyweaver, 'src/unifyweaver')), [script], halt\"\n```\n\nAlternatively, invoke the playbook with `swipl -f init.pl -g \"consult('playbook.pl'), goal, halt\"` to leverage the pre-configured initialization file. Both approaches ensure modules are properly resolved from the project root directory.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["playbooks", "automation", "inline-init"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["playbooks/examples_library/"], "original_answer": "For reproducible playbooks, you can use inline initialization to set the search path before loading modules:\n```bash\nswipl -g \"asserta(file_search_path(unifyweaver, 'src/unifyweaver')), [script], halt\"\n```\nAlternatively, simply invoke with `swipl -f init.pl ...`.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_004_q1", "cluster_id": "skill_unifyweaver_environment_004", "question": "What is the best way to load paths in a bash playbook?", "answer": "Yes, you can create an isolated UnifyWeaver environment for testing. Run `bash scripts/testing/init_testing.sh` from the project root. Options include: `-d <dir>` to specify parent directory for test_env, `-p <path>` for custom full path, and `--force-windows` to test Windows wrapper logic. The script creates a self-contained environment with all dependencies.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["playbooks", "automation", "inline-init"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["playbooks/examples_library/"], "original_answer": "For reproducible playbooks, you can use inline initialization to set the search path before loading modules:\n```bash\nswipl -g \"asserta(file_search_path(unifyweaver, 'src/unifyweaver')), [script], halt\"\n```\nAlternatively, simply invoke with `swipl -f init.pl ...`.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_unifyweaver_environment_004_q2", "cluster_id": "skill_unifyweaver_environment_004", "question": "How do I use inline initialization for non-interactive scripts?", "answer": "For non-interactive scripts, use inline initialization to set the search path before loading modules. You can use `asserta(file_search_path(unifyweaver, 'src/unifyweaver'))` to dynamically add the search path, then load your script: `swipl -g \"asserta(file_search_path(unifyweaver, 'src/unifyweaver')), [script], halt\"`. Alternatively, the simpler approach is to use `swipl -f init.pl -g \"consult('script.pl'), goal, halt\"`, which automatically handles all path configuration and is the recommended method for reproducible scripts.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["playbooks", "automation", "inline-init"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["playbooks/examples_library/"], "original_answer": "For reproducible playbooks, you can use inline initialization to set the search path before loading modules:\n```bash\nswipl -g \"asserta(file_search_path(unifyweaver, 'src/unifyweaver')), [script], halt\"\n```\nAlternatively, simply invoke with `swipl -f init.pl ...`.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer mentions two approaches but doesn't clearly explain the tradeoff between them. The inline asserta approach works but requires manual path setup, while init.pl is simpler and more maintainable. The answer could better emphasize that init.pl is the preferred approach for reproducibility."}
{"pair_id": "skill_extract_records_001_q0", "cluster_id": "skill_extract_records_001", "question": "How do I extract structured data records from Markdown files?", "answer": "Use the `extract_records.pl` script located in `scripts/utils/` to parse structured data records from Markdown files that conform to the UnifyWeaver Example Record Format. This tool is more robust than grep for handling metadata and multi-line content blocks.\n\nBasic usage:\n```bash\nperl scripts/utils/extract_records.pl path/to/file.md\n```\n\nKey options:\n- `-f json` for JSON output\n- `-f content` to extract only the code block content\n- `-q <pattern>` to filter records by name\n- `-s <char>` to specify record separator (default is null character)\n\nFor example, to extract a specific record as JSON:\n```bash\nperl scripts/utils/extract_records.pl -f json -q \"record_name\" path/to/file.md\n```\n\nThe script automatically filters for files marked as `file_type=UnifyWeaver Example Library` in their YAML frontmatter. See the Extract Records skill documentation for complete details on record types and appropriate execution methods.", "question_type": "medium", "topics": ["Data Processing", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["data-extraction", "markdown", "parsing"], "related_skills": ["skill_extract_records.md", "skill_data_sources.md", "skill_json_sources.md"], "related_docs": ["docs/playbooks/parsing/README.md", "scripts/utils/extract_records.pl"], "original_answer": "Use the `extract_records.pl` script to parse structured data records from Markdown files. This is more robust than grep for handling metadata and multi-line content blocks.\n\nBasic command:\n```bash\nperl scripts/utils/extract_records.pl path/to/file.md\n```\n\nFor JSON output:\n```bash\nperl scripts/utils/extract_records.pl -f json path/to/file.md\n```\n\nSee skill_extract_records.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_extract_records_001_q1", "cluster_id": "skill_extract_records_001", "question": "How can I parse records from Markdown files?", "answer": "To parse records from Markdown files, use the `extract_records.pl` script located in `scripts/utils/`. This tool is specifically designed to handle the UnifyWeaver Example Record Format and is more robust than grep for extracting structured data with metadata and multi-line content blocks.\n\nBasic usage:\n```bash\nperl scripts/utils/extract_records.pl path/to/file.md\n```\n\nFor JSON output:\n```bash\nperl scripts/utils/extract_records.pl -f json path/to/file.md\n```\n\nYou can also filter records by name pattern using `-q` flag and specify different output formats: `full` (default, entire Markdown block), `content` (raw code block only), or `json` (structured JSON objects). For Bash script records, extract with `-f content` and run with bash. For other record types like Prolog, follow the appropriate execution method as documented in the skill guide.", "question_type": "medium", "topics": ["Data Processing", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["data-extraction", "markdown", "parsing"], "related_skills": ["skill_extract_records.md", "skill_data_sources.md", "skill_json_sources.md"], "related_docs": ["docs/playbooks/parsing/README.md", "scripts/utils/extract_records.pl"], "original_answer": "Use the `extract_records.pl` script to parse structured data records from Markdown files. This is more robust than grep for handling metadata and multi-line content blocks.\n\nBasic command:\n```bash\nperl scripts/utils/extract_records.pl path/to/file.md\n```\n\nFor JSON output:\n```bash\nperl scripts/utils/extract_records.pl -f json path/to/file.md\n```\n\nSee skill_extract_records.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_extract_records_001_q2", "cluster_id": "skill_extract_records_001", "question": "What's the best way to extract example data from Markdown?", "answer": "Use the `extract_records.pl` script located at `scripts/utils/extract_records.pl` to extract example data from Markdown files. This Perl-based tool is more robust than grep for handling structured records with metadata and multi-line content blocks.\n\nBasic usage:\n```bash\nperl scripts/utils/extract_records.pl path/to/file.md\n```\n\nFor JSON output:\n```bash\nperl scripts/utils/extract_records.pl -f json path/to/file.md\n```\n\nFor filtering by record name:\n```bash\nperl scripts/utils/extract_records.pl -q \"pattern\" path/to/file.md\n```\n\nKey output formats: `full` (entire record), `content` (code block only), or `json` (structured objects). The tool also supports file filtering via `--file-filter` to target specific file types like `UnifyWeaver Example Library`.", "question_type": "medium", "topics": ["Data Processing", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["data-extraction", "markdown", "parsing"], "related_skills": ["skill_extract_records.md", "skill_data_sources.md", "skill_json_sources.md"], "related_docs": ["docs/playbooks/parsing/README.md", "scripts/utils/extract_records.pl"], "original_answer": "Use the `extract_records.pl` script to parse structured data records from Markdown files. This is more robust than grep for handling metadata and multi-line content blocks.\n\nBasic command:\n```bash\nperl scripts/utils/extract_records.pl path/to/file.md\n```\n\nFor JSON output:\n```bash\nperl scripts/utils/extract_records.pl -f json path/to/file.md\n```\n\nSee skill_extract_records.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_extract_records_002_q0", "cluster_id": "skill_extract_records_002", "question": "How do I filter records by name when extracting from Markdown?", "answer": "To filter records by name when extracting from Markdown, use the `-q` (or `--query`) flag followed by a regex pattern that matches the record's `name` metadata. For example:\n\n```bash\nperl scripts/utils/extract_records.pl -q \"your_pattern\" path/to/file.md\n```\n\nThe pattern is matched against each record's name field. For instance, to extract records with names starting with \"unifyweaver.execution\":\n\n```bash\nperl scripts/utils/extract_records.pl -q \"unifyweaver.execution\" playbooks/examples_library/file.md\n```\n\nThis will only output records whose `name` metadata matches the provided regex pattern.", "question_type": "long", "topics": ["Data Processing", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["filtering", "regex", "metadata"], "related_skills": ["skill_extract_records.md"], "related_docs": ["docs/playbooks/parsing/README.md"], "original_answer": "Use the `-q` (query) flag with a regex pattern to filter records by their `name` metadata.\n\n```bash\nperl scripts/utils/extract_records.pl -q \"pattern_name\" path/to/file.md\n```\n\nExample filtering for specific record names:\n```bash\nperl scripts/utils/extract_records.pl -q \"unifyweaver.execution\" playbooks/examples_library/file.md\n```\n\nSee skill_extract_records.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_extract_records_002_q1", "cluster_id": "skill_extract_records_002", "question": "Can I search for specific records by name?", "answer": "Yes, you can search for specific records by name using the `-q` (query) flag with a regex pattern. For example:\n\n```bash\nperl scripts/utils/extract_records.pl -q \"pattern_name\" path/to/file.md\n```\n\nThis filters records by their `name` metadata. For instance, to find records named \"unifyweaver.execution\", use:\n\n```bash\nperl scripts/utils/extract_records.pl -q \"unifyweaver.execution\" playbooks/examples_library/file.md\n```", "question_type": "long", "topics": ["Data Processing", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["filtering", "regex", "metadata"], "related_skills": ["skill_extract_records.md"], "related_docs": ["docs/playbooks/parsing/README.md"], "original_answer": "Use the `-q` (query) flag with a regex pattern to filter records by their `name` metadata.\n\n```bash\nperl scripts/utils/extract_records.pl -q \"pattern_name\" path/to/file.md\n```\n\nExample filtering for specific record names:\n```bash\nperl scripts/utils/extract_records.pl -q \"unifyweaver.execution\" playbooks/examples_library/file.md\n```\n\nSee skill_extract_records.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_extract_records_002_q2", "cluster_id": "skill_extract_records_002", "question": "How do I extract only certain records from a file?", "answer": "Use the `-q` (query) flag with a regex pattern to filter records by their `name` metadata:\n\n```bash\nperl scripts/utils/extract_records.pl -q \"pattern_name\" path/to/file.md\n```\n\nFor example, to extract records with names matching \"unifyweaver.execution\":\n\n```bash\nperl scripts/utils/extract_records.pl -q \"unifyweaver.execution\" playbooks/examples_library/file.md\n```\n\nThe pattern is a regex, so you can use wildcards and other regex syntax to match multiple record names.", "question_type": "long", "topics": ["Data Processing", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["filtering", "regex", "metadata"], "related_skills": ["skill_extract_records.md"], "related_docs": ["docs/playbooks/parsing/README.md"], "original_answer": "Use the `-q` (query) flag with a regex pattern to filter records by their `name` metadata.\n\n```bash\nperl scripts/utils/extract_records.pl -q \"pattern_name\" path/to/file.md\n```\n\nExample filtering for specific record names:\n```bash\nperl scripts/utils/extract_records.pl -q \"unifyweaver.execution\" playbooks/examples_library/file.md\n```\n\nSee skill_extract_records.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_extract_records_003_q0", "cluster_id": "skill_extract_records_003", "question": "What output formats are available when extracting records?", "answer": "The `extract_records.pl` script provides three output formats via the `-f` flag:\n\n1. **full** (default): Outputs the entire original Markdown block for each matching record\n2. **content**: Outputs only the raw content of the record's code block, without metadata wrapper\n3. **json**: Outputs a stream of JSON objects, one for each record\n\nUsage example:\n```bash\nperl scripts/utils/extract_records.pl -f json path/to/file.md\nperl scripts/utils/extract_records.pl -f content path/to/file.md\n```", "question_type": "medium", "topics": ["Data Processing", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["output-formats", "json", "parsing"], "related_skills": ["skill_extract_records.md"], "related_docs": ["docs/playbooks/parsing/README.md"], "original_answer": "Three output formats are available via the `-f` flag:\n\n- **full**: Complete original Markdown block (default)\n- **content**: Raw content only (no metadata wrapper)\n- **json**: Stream of JSON objects with structured data\n\nExample:\n```bash\nperl scripts/utils/extract_records.pl -f json path/to/file.md\nperl scripts/utils/extract_records.pl -f content path/to/file.md\n```\n\nSee skill_extract_records.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_extract_records_003_q1", "cluster_id": "skill_extract_records_003", "question": "Can I get record output as JSON?", "answer": "Yes, you can get record output as JSON using the `-f json` flag with the `extract_records.pl` script. This outputs a stream of JSON objects, one for each matching record with structured data. Example: `perl scripts/utils/extract_records.pl -f json path/to/file.md`", "question_type": "medium", "topics": ["Data Processing", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["output-formats", "json", "parsing"], "related_skills": ["skill_extract_records.md"], "related_docs": ["docs/playbooks/parsing/README.md"], "original_answer": "Three output formats are available via the `-f` flag:\n\n- **full**: Complete original Markdown block (default)\n- **content**: Raw content only (no metadata wrapper)\n- **json**: Stream of JSON objects with structured data\n\nExample:\n```bash\nperl scripts/utils/extract_records.pl -f json path/to/file.md\nperl scripts/utils/extract_records.pl -f content path/to/file.md\n```\n\nSee skill_extract_records.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_extract_records_003_q2", "cluster_id": "skill_extract_records_003", "question": "How do I extract just the content without metadata?", "answer": "Use the `-f content` flag to extract just the content without metadata. This outputs only the raw content of the record's code block, stripped of the Markdown wrapper and YAML frontmatter. Example: `perl scripts/utils/extract_records.pl -f content path/to/file.md`. The other formats are `-f full` (default, includes metadata) and `-f json` (structured JSON output).", "question_type": "medium", "topics": ["Data Processing", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["output-formats", "json", "parsing"], "related_skills": ["skill_extract_records.md"], "related_docs": ["docs/playbooks/parsing/README.md"], "original_answer": "Three output formats are available via the `-f` flag:\n\n- **full**: Complete original Markdown block (default)\n- **content**: Raw content only (no metadata wrapper)\n- **json**: Stream of JSON objects with structured data\n\nExample:\n```bash\nperl scripts/utils/extract_records.pl -f json path/to/file.md\nperl scripts/utils/extract_records.pl -f content path/to/file.md\n```\n\nSee skill_extract_records.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_extract_records_004_q0", "cluster_id": "skill_extract_records_004", "question": "How do I run extracted bash scripts from records?", "answer": "To run extracted bash scripts from records, use the `-f content` flag to extract only the script content, save it to a `.sh` file, then execute with `bash`. For example: `perl scripts/utils/extract_records.pl -f content -q \"record_name\" file.md > script.sh && bash script.sh`. Always verify the code fence type in the original record (```bash vs ```prolog) and use the correct interpreter\u2014running bash scripts with `swipl` will fail.", "question_type": "long", "topics": ["Data Processing", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["bash", "execution", "scripts"], "related_skills": ["skill_extract_records.md"], "related_docs": ["docs/playbooks/parsing/README.md"], "original_answer": "Extract bash scripts with `-f content`, save to a `.sh` file, then run with `bash`:\n\n```bash\nperl scripts/utils/extract_records.pl -f content -q \"record_name\" file.md > script.sh\nbash script.sh\n```\n\nCritical: Always check the code fence type (```bash vs ```prolog) and use the appropriate interpreter. Running bash scripts with `swipl` will fail.\n\nSee skill_extract_records.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_extract_records_004_q1", "cluster_id": "skill_extract_records_004", "question": "I extracted a bash script - how do I execute it?", "answer": "To execute a bash script you extracted: (1) Extract it with `-f content` flag and save to a `.sh` file, (2) Run it with `bash script.sh`. Always verify the code fence type in the source file - bash scripts use ```bash, while Prolog uses ```prolog. Running bash scripts with the wrong interpreter (like `swipl`) will fail.", "question_type": "long", "topics": ["Data Processing", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["bash", "execution", "scripts"], "related_skills": ["skill_extract_records.md"], "related_docs": ["docs/playbooks/parsing/README.md"], "original_answer": "Extract bash scripts with `-f content`, save to a `.sh` file, then run with `bash`:\n\n```bash\nperl scripts/utils/extract_records.pl -f content -q \"record_name\" file.md > script.sh\nbash script.sh\n```\n\nCritical: Always check the code fence type (```bash vs ```prolog) and use the appropriate interpreter. Running bash scripts with `swipl` will fail.\n\nSee skill_extract_records.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_extract_records_004_q2", "cluster_id": "skill_extract_records_004", "question": "What's the right way to run bash code from extracted records?", "answer": "To run bash code from extracted records: (1) Extract the bash script using `-f content` flag with `extract_records.pl`, (2) Save the output to a `.sh` file, (3) Execute with `bash script.sh`. Always verify the code fence type in the record - bash scripts use ```bash while Prolog uses ```prolog. Running bash with the wrong interpreter (e.g., `swipl`) will fail.", "question_type": "long", "topics": ["Data Processing", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["bash", "execution", "scripts"], "related_skills": ["skill_extract_records.md"], "related_docs": ["docs/playbooks/parsing/README.md"], "original_answer": "Extract bash scripts with `-f content`, save to a `.sh` file, then run with `bash`:\n\n```bash\nperl scripts/utils/extract_records.pl -f content -q \"record_name\" file.md > script.sh\nbash script.sh\n```\n\nCritical: Always check the code fence type (```bash vs ```prolog) and use the appropriate interpreter. Running bash scripts with `swipl` will fail.\n\nSee skill_extract_records.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_extract_records_005_q0", "cluster_id": "skill_extract_records_005", "question": "How do I extract and load Prolog code from records?", "answer": "To extract and load Prolog code from records, use the `extract_records.pl` script with the `-f content` flag to extract only the code content, save it to a `.pl` file, then load it into SWI-Prolog with `swipl`. For example: `perl scripts/utils/extract_records.pl -f content -q \"record_name\" file.md > code.pl` followed by `swipl -f init.pl -g \"consult('code.pl'), goal, halt\"`. Always verify the code fence is marked with ```prolog (not ```bash) before loading with swipl, as bash scripts must be run with `bash` instead.", "question_type": "long", "topics": ["Data Processing", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["prolog", "swipl", "code-loading"], "related_skills": ["skill_extract_records.md"], "related_docs": ["docs/playbooks/parsing/README.md"], "original_answer": "Extract Prolog code with `-f content`, save to a `.pl` file, then load with `swipl`:\n\n```bash\nperl scripts/utils/extract_records.pl -f content -q \"record_name\" file.md > code.pl\nswipl -f init.pl -g \"consult('code.pl'), goal, halt\"\n```\n\nImportant: Code marked with ```prolog should be loaded with `swipl`, not `bash`. Verify the code fence language before choosing your interpreter.\n\nSee skill_extract_records.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_extract_records_005_q1", "cluster_id": "skill_extract_records_005", "question": "How do I use Prolog code from extracted records?", "answer": "To use Prolog code from extracted records, first extract the code with the `-f content` flag using the `extract_records.pl` script, specifying the record name with `-q`. Save the extracted content to a `.pl` file. Then load and execute it with `swipl` using the `-f` flag to specify an initialization file and `-g` to execute goals. For example: `perl scripts/utils/extract_records.pl -f content -q \"record_name\" file.md > code.pl` followed by `swipl -f init.pl -g \"consult('code.pl'), goal, halt\"`. Always verify the code fence is marked with ```prolog before using `swipl`, as bash-marked code should be run with `bash` instead.", "question_type": "long", "topics": ["Data Processing", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["prolog", "swipl", "code-loading"], "related_skills": ["skill_extract_records.md"], "related_docs": ["docs/playbooks/parsing/README.md"], "original_answer": "Extract Prolog code with `-f content`, save to a `.pl` file, then load with `swipl`:\n\n```bash\nperl scripts/utils/extract_records.pl -f content -q \"record_name\" file.md > code.pl\nswipl -f init.pl -g \"consult('code.pl'), goal, halt\"\n```\n\nImportant: Code marked with ```prolog should be loaded with `swipl`, not `bash`. Verify the code fence language before choosing your interpreter.\n\nSee skill_extract_records.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_extract_records_005_q2", "cluster_id": "skill_extract_records_005", "question": "How do I load extracted Prolog files with swipl?", "answer": "To load extracted Prolog files with swipl, first extract the Prolog code using the extract_records.pl script with the `-f content` flag, save it to a `.pl` file, then use swipl to load and execute it:\n\n```bash\nperl scripts/utils/extract_records.pl -f content -q \"record_name\" file.md > code.pl\nswipl -f init.pl -g \"consult('code.pl'), goal, halt\"\n```\n\nThe key points are: (1) Use `-f content` to extract only the code block content, (2) Save to a `.pl` file, (3) Load with `swipl` using the `consult/1` predicate within a goal directive. Make sure the code is marked with ```prolog in the source file, not ```bash.", "question_type": "long", "topics": ["Data Processing", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["prolog", "swipl", "code-loading"], "related_skills": ["skill_extract_records.md"], "related_docs": ["docs/playbooks/parsing/README.md"], "original_answer": "Extract Prolog code with `-f content`, save to a `.pl` file, then load with `swipl`:\n\n```bash\nperl scripts/utils/extract_records.pl -f content -q \"record_name\" file.md > code.pl\nswipl -f init.pl -g \"consult('code.pl'), goal, halt\"\n```\n\nImportant: Code marked with ```prolog should be loaded with `swipl`, not `bash`. Verify the code fence language before choosing your interpreter.\n\nSee skill_extract_records.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_extract_records_006_q0", "cluster_id": "skill_extract_records_006", "question": "When should I use extract_records instead of grep?", "answer": "Use `extract_records.pl` instead of `grep` when you need to parse metadata (like `id` or `name` fields), handle multi-line content blocks reliably, or get structured output like JSON from files following the UnifyWeaver Example Record Format. Use `grep` for simple pattern matching in plain text files.", "question_type": "medium", "topics": ["Data Processing", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["comparison", "tools", "best-practices"], "related_skills": ["skill_extract_records.md", "skill_data_sources.md"], "related_docs": ["docs/playbooks/parsing/README.md"], "original_answer": "Use `extract_records.pl` when you need to:\n\n- Parse metadata like `id` or `name` fields\n- Handle multi-line content blocks reliably\n- Get output in structured formats (JSON)\n- Process files that follow the UnifyWeaver Example Record Format\n\nUse `grep` for simple pattern matching in plain text. The `extract_records` tool is specifically designed for semantic parsing of structured records, making it more robust for complex data extraction tasks.\n\nSee skill_extract_records.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_extract_records_006_q1", "cluster_id": "skill_extract_records_006", "question": "Should I use grep or extract_records for parsing Markdown?", "answer": "Use `extract_records.pl` when you need to parse metadata (id, name fields), handle multi-line content blocks reliably, or get structured JSON output from UnifyWeaver Example Record Format files. Use `grep` for simple text pattern matching. The extract_records tool is purpose-built for semantic parsing of structured records in Markdown, making it more robust than grep for complex data extraction tasks.", "question_type": "medium", "topics": ["Data Processing", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["comparison", "tools", "best-practices"], "related_skills": ["skill_extract_records.md", "skill_data_sources.md"], "related_docs": ["docs/playbooks/parsing/README.md"], "original_answer": "Use `extract_records.pl` when you need to:\n\n- Parse metadata like `id` or `name` fields\n- Handle multi-line content blocks reliably\n- Get output in structured formats (JSON)\n- Process files that follow the UnifyWeaver Example Record Format\n\nUse `grep` for simple pattern matching in plain text. The `extract_records` tool is specifically designed for semantic parsing of structured records, making it more robust for complex data extraction tasks.\n\nSee skill_extract_records.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_extract_records_006_q2", "cluster_id": "skill_extract_records_006", "question": "What are the advantages of extract_records over grep?", "answer": "The extract_records.pl tool offers several advantages over grep for structured data extraction: it parses metadata fields like `id` and `name` from record headers, reliably handles multi-line content blocks that span multiple lines, and outputs data in structured formats like JSON for programmatic processing. While grep is suitable for simple pattern matching in plain text, extract_records is purpose-built for semantic parsing of files conforming to the UnifyWeaver Example Record Format, making it more robust and semantically aware for extracting and processing complex structured records.", "question_type": "medium", "topics": ["Data Processing", "Extract Records"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["comparison", "tools", "best-practices"], "related_skills": ["skill_extract_records.md", "skill_data_sources.md"], "related_docs": ["docs/playbooks/parsing/README.md"], "original_answer": "Use `extract_records.pl` when you need to:\n\n- Parse metadata like `id` or `name` fields\n- Handle multi-line content blocks reliably\n- Get output in structured formats (JSON)\n- Process files that follow the UnifyWeaver Example Record Format\n\nUse `grep` for simple pattern matching in plain text. The `extract_records` tool is specifically designed for semantic parsing of structured records, making it more robust for complex data extraction tasks.\n\nSee skill_extract_records.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_find_executable_001_q0", "cluster_id": "skill_find_executable_001", "question": "How do I find an executable that's not in my system PATH?", "answer": "To find an executable not in your PATH, use the Find Executable skill. It searches common installation directories per OS: Windows (C:\\Program Files, C:\\Strawberry), Linux (/usr/bin, /usr/local/bin, /snap/bin), macOS (/opt/homebrew/bin, /Applications). If found, it returns the absolute path you can use to run the command.", "question_type": "medium", "topics": ["System", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["executable", "path", "system", "command-not-found"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "Use the find executable skill to search common installation directories for the executable you need. Provide the executable name (e.g., 'perl', 'swipl'). The skill searches platform-specific directories and returns the absolute path if found, or an empty string if not. You can then use the returned path to run the command directly. See skill_find_executable.md for details.", "answer_tailored": true, "confidence": 0.85, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_find_executable_001_q1", "cluster_id": "skill_find_executable_001", "question": "Where can I locate a program if 'command not found' error occurs?", "answer": "When you encounter a 'command not found' error, use the find executable skill to locate the program. Provide the executable name (e.g., 'perl', 'swipl'), and the skill will search platform-specific directories: Windows (C:\\Strawberry\\perl\\bin, C:\\Program Files\\swipl\\bin), Linux (/usr/bin, /usr/local/bin, /snap/bin), or macOS (/usr/bin, /usr/local/bin, /opt/homebrew/bin, /Applications/SWI-Prolog.app/Contents/MacOS). The skill returns the absolute path to the executable if found, which you can then use to run the command directly (e.g., & \"C:\\Strawberry\\perl\\bin\\perl.exe\" script.pl on Windows).", "question_type": "medium", "topics": ["System", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["executable", "path", "system", "command-not-found"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "Use the find executable skill to search common installation directories for the executable you need. Provide the executable name (e.g., 'perl', 'swipl'). The skill searches platform-specific directories and returns the absolute path if found, or an empty string if not. You can then use the returned path to run the command directly. See skill_find_executable.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_find_executable_001_q2", "cluster_id": "skill_find_executable_001", "question": "How do I get the full path to an executable on my system?", "answer": "Use the find executable skill to locate an executable by searching common installation directories for your operating system. Provide the executable name (e.g., 'perl', 'swipl') and the skill will return the absolute path if found, or an empty string if not found. On Windows, it searches Strawberry Perl and SWI-Prolog directories; on Linux, it searches /usr/bin, /usr/local/bin, and /snap/bin; on macOS, it searches /usr/bin, /usr/local/bin, /opt/homebrew/bin, and SWI-Prolog.app. You can then use the returned path to execute the command directly.", "question_type": "medium", "topics": ["System", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["executable", "path", "system", "command-not-found"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "Use the find executable skill to search common installation directories for the executable you need. Provide the executable name (e.g., 'perl', 'swipl'). The skill searches platform-specific directories and returns the absolute path if found, or an empty string if not. You can then use the returned path to run the command directly. See skill_find_executable.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_find_executable_002_q0", "cluster_id": "skill_find_executable_002", "question": "What do I do when a command fails with 'command not found'?", "answer": "When a command fails with 'command not found', use the find executable skill to locate the program. Pass the executable name (e.g., 'perl', 'swipl') to the skill and it will search your system's common installation directories. If found, the skill returns the absolute path to the executable. Use this path to execute the command directly, for example: `& \"C:\\Strawberry\\perl\\bin\\perl.exe\" my_script.pl` on Windows or `/opt/homebrew/bin/perl` on macOS.", "question_type": "medium", "topics": ["System", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["command-not-found", "executable", "path", "error-handling"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "When you get a 'command not found' error, use the find executable skill to locate the program. Pass the executable name to the skill and it will search your system's common installation directories. If found, use the returned full path to execute the command, for example: `& \"C:\\Strawberry\\perl\\bin\\perl.exe\" my_script.pl` on Windows or `/opt/homebrew/bin/perl` on macOS. See skill_find_executable.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_find_executable_002_q1", "cluster_id": "skill_find_executable_002", "question": "How do I handle a 'command not found' error?", "answer": "When an executable isn't in your system PATH, use the Find Executable skill which searches common installation directories. On Windows it checks C:\\Strawberry\\perl\\bin, C:\\Program Files\\swipl\\bin. On Linux: /usr/bin, /usr/local/bin, /snap/bin. On macOS: /usr/local/bin, /opt/homebrew/bin, /Applications/. The skill returns the absolute path if found, which you can use directly.", "question_type": "medium", "topics": ["System", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["command-not-found", "executable", "path", "error-handling"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "When you get a 'command not found' error, use the find executable skill to locate the program. Pass the executable name to the skill and it will search your system's common installation directories. If found, use the returned full path to execute the command, for example: `& \"C:\\Strawberry\\perl\\bin\\perl.exe\" my_script.pl` on Windows or `/opt/homebrew/bin/perl` on macOS. See skill_find_executable.md for details.", "answer_tailored": true, "confidence": 0.85, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_find_executable_002_q2", "cluster_id": "skill_find_executable_002", "question": "What's the next step when a program can't be located?", "answer": "When a program is installed but the agent can't execute it, use the Find Executable skill to locate it. The skill searches OS-specific directories: Windows (C:\\Program Files, C:\\Strawberry), Linux (/usr/bin, /usr/local/bin, /snap/bin), macOS (/opt/homebrew/bin, /Applications). Use the returned absolute path to execute the command directly.", "question_type": "medium", "topics": ["System", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["command-not-found", "executable", "path", "error-handling"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "When you get a 'command not found' error, use the find executable skill to locate the program. Pass the executable name to the skill and it will search your system's common installation directories. If found, use the returned full path to execute the command, for example: `& \"C:\\Strawberry\\perl\\bin\\perl.exe\" my_script.pl` on Windows or `/opt/homebrew/bin/perl` on macOS. See skill_find_executable.md for details.", "answer_tailored": true, "confidence": 0.85, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_find_executable_003_q0", "cluster_id": "skill_find_executable_003", "question": "Which directories does the system check to find executables?", "answer": "The system checks different directories depending on the operating system. On Windows, it searches: `C:\\Strawberry\\perl\\bin`, `C:\\Program Files\\swipl\\bin`, and `C:\\Program Files (x86)\\swipl\\bin`. On Linux, it searches: `/usr/bin`, `/usr/local/bin`, and `/snap/bin`. On macOS, it searches: `/usr/bin`, `/usr/local/bin`, `/opt/homebrew/bin`, and `/Applications/SWI-Prolog.app/Contents/MacOS`.", "question_type": "long", "topics": ["System", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["directories", "paths", "windows", "linux", "macos", "installation"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "The search paths vary by operating system. On Windows: `C:\\Strawberry\\perl\\bin`, `C:\\Program Files\\swipl\\bin`, `C:\\Program Files (x86)\\swipl\\bin`. On Linux: `/usr/bin`, `/usr/local/bin`, `/snap/bin`. On macOS: `/usr/bin`, `/usr/local/bin`, `/opt/homebrew/bin`, `/Applications/SWI-Prolog.app/Contents/MacOS`. The skill automatically uses the correct paths for your platform. See skill_find_executable.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_find_executable_003_q1", "cluster_id": "skill_find_executable_003", "question": "What are the common installation directories for programs?", "answer": "Common installation directories vary by OS. Windows: C:\\Program Files, C:\\Program Files (x86), C:\\Strawberry (Perl). Linux: /usr/bin, /usr/local/bin, /snap/bin, /opt. macOS: /usr/local/bin, /opt/homebrew/bin (Homebrew), /Applications. The Find Executable skill searches these locations automatically.", "question_type": "long", "topics": ["System", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["directories", "paths", "windows", "linux", "macos", "installation"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "The search paths vary by operating system. On Windows: `C:\\Strawberry\\perl\\bin`, `C:\\Program Files\\swipl\\bin`, `C:\\Program Files (x86)\\swipl\\bin`. On Linux: `/usr/bin`, `/usr/local/bin`, `/snap/bin`. On macOS: `/usr/bin`, `/usr/local/bin`, `/opt/homebrew/bin`, `/Applications/SWI-Prolog.app/Contents/MacOS`. The skill automatically uses the correct paths for your platform. See skill_find_executable.md for details.", "answer_tailored": true, "confidence": 0.85, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_find_executable_003_q2", "cluster_id": "skill_find_executable_003", "question": "Where does the executable search look for programs?", "answer": "The executable search looks in operating system-specific directories. On Windows, it searches: C:\\Strawberry\\perl\\bin, C:\\Program Files\\swipl\\bin, C:\\Program Files (x86)\\swipl\\bin. On Linux: /usr/bin, /usr/local/bin, /snap/bin. On macOS: /usr/bin, /usr/local/bin, /opt/homebrew/bin, /Applications/SWI-Prolog.app/Contents/MacOS. The skill automatically selects the correct paths for your platform.", "question_type": "long", "topics": ["System", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["directories", "paths", "windows", "linux", "macos", "installation"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "The search paths vary by operating system. On Windows: `C:\\Strawberry\\perl\\bin`, `C:\\Program Files\\swipl\\bin`, `C:\\Program Files (x86)\\swipl\\bin`. On Linux: `/usr/bin`, `/usr/local/bin`, `/snap/bin`. On macOS: `/usr/bin`, `/usr/local/bin`, `/opt/homebrew/bin`, `/Applications/SWI-Prolog.app/Contents/MacOS`. The skill automatically uses the correct paths for your platform. See skill_find_executable.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_find_executable_004_q0", "cluster_id": "skill_find_executable_004", "question": "How do I use a found executable path to run a command?", "answer": "Once the find executable skill returns the full path, use it directly to run the command. On Windows, use the `&` operator with quotes: `& \"C:\\Strawberry\\perl\\bin\\perl.exe\" my_script.pl`. On Unix-like systems (Linux/macOS), use the path directly: `/usr/local/bin/perl my_script.pl` or `/opt/homebrew/bin/swipl`. This bypasses the need for the executable to be in PATH.", "question_type": "long", "topics": ["System", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["execution", "path", "command-execution", "full-path"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "Once the find executable skill returns the full path, use it directly to run the command. On Windows, use the `&` operator with quotes: `& \"C:\\Strawberry\\perl\\bin\\perl.exe\" my_script.pl`. On Unix-like systems, use the path directly: `/usr/local/bin/perl my_script.pl` or `/opt/homebrew/bin/swipl`. This bypasses the need for the executable to be in PATH. See skill_find_executable.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_find_executable_004_q1", "cluster_id": "skill_find_executable_004", "question": "What do I do with the returned executable path?", "answer": "Use the returned executable path directly to run the command. On Windows, use the `&` operator with quotes: `& \"C:\\Strawberry\\perl\\bin\\perl.exe\" my_script.pl`. On Unix-like systems (Linux/macOS), use the path directly: `/usr/local/bin/perl my_script.pl` or `/opt/homebrew/bin/swipl`. This allows you to execute the command without requiring the executable to be in your system's PATH.", "question_type": "long", "topics": ["System", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["execution", "path", "command-execution", "full-path"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "Once the find executable skill returns the full path, use it directly to run the command. On Windows, use the `&` operator with quotes: `& \"C:\\Strawberry\\perl\\bin\\perl.exe\" my_script.pl`. On Unix-like systems, use the path directly: `/usr/local/bin/perl my_script.pl` or `/opt/homebrew/bin/swipl`. This bypasses the need for the executable to be in PATH. See skill_find_executable.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_find_executable_004_q2", "cluster_id": "skill_find_executable_004", "question": "How do I execute a program using its full path?", "answer": "To execute a program using its full path: On Windows, use the `&` operator with quotes around the path: `& \"C:\\path\\to\\executable.exe\" arguments`. On Unix-like systems (Linux, macOS), use the path directly: `/path/to/executable arguments`. This allows you to run programs without requiring them to be in your system's PATH environment variable.", "question_type": "long", "topics": ["System", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["execution", "path", "command-execution", "full-path"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "Once the find executable skill returns the full path, use it directly to run the command. On Windows, use the `&` operator with quotes: `& \"C:\\Strawberry\\perl\\bin\\perl.exe\" my_script.pl`. On Unix-like systems, use the path directly: `/usr/local/bin/perl my_script.pl` or `/opt/homebrew/bin/swipl`. This bypasses the need for the executable to be in PATH. See skill_find_executable.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_find_executable_005_q0", "cluster_id": "skill_find_executable_005", "question": "What happens if an executable is not found?", "answer": "If the executable is not found in any of the searched directories, the skill returns an empty string. This indicates the program is not installed in the common installation locations on your system. You may need to install the executable or manually specify its installation path.", "question_type": "medium", "topics": ["System", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["not-found", "installation", "executable", "empty-result"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "If the executable cannot be found in any of the searched directories, the skill returns an empty string. This indicates the program is not installed in the common locations on your system. You may need to install the executable or manually specify its installation path. See skill_find_executable.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_find_executable_005_q1", "cluster_id": "skill_find_executable_005", "question": "What does the skill return if the program isn't installed?", "answer": "If the executable is not found in any of the searched directories, the skill returns an empty string. This indicates the program is not installed in the common locations on your system.", "question_type": "medium", "topics": ["System", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["not-found", "installation", "executable", "empty-result"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "If the executable cannot be found in any of the searched directories, the skill returns an empty string. This indicates the program is not installed in the common locations on your system. You may need to install the executable or manually specify its installation path. See skill_find_executable.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_find_executable_005_q2", "cluster_id": "skill_find_executable_005", "question": "How do I know if an executable couldn't be located?", "answer": "If the executable cannot be found, the skill returns an empty string. This indicates the program is not installed in any of the common directories searched by the skill (such as /usr/bin, /usr/local/bin, /snap/bin on Linux). When you receive an empty string result, it means the executable is either not installed on your system or located in a directory outside the predefined search paths. You can then install the executable or manually specify its installation path.", "question_type": "medium", "topics": ["System", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["not-found", "installation", "executable", "empty-result"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "If the executable cannot be found in any of the searched directories, the skill returns an empty string. This indicates the program is not installed in the common locations on your system. You may need to install the executable or manually specify its installation path. See skill_find_executable.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_find_executable_006_q0", "cluster_id": "skill_find_executable_006", "question": "Can I use this skill to find perl, Python, or SWI-Prolog?", "answer": "Yes, this skill can find perl, Python, and SWI-Prolog. It searches platform-specific directories for these executables: on Windows it checks `C:\\Strawberry\\perl\\bin` for Perl and `C:\\Program Files\\swipl\\bin` for SWI-Prolog; on Linux it searches `/usr/bin`, `/usr/local/bin`, and `/snap/bin`; on macOS it checks `/usr/bin`, `/usr/local/bin`, `/opt/homebrew/bin`, and `/Applications/SWI-Prolog.app/Contents/MacOS`. Provide the executable name ('perl', 'python', or 'swipl') and the skill will return the full path if found.", "question_type": "long", "topics": ["System", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["perl", "swipl", "prolog", "python", "programming-languages"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "Yes, the skill is designed to find commonly used executables including perl, swipl (SWI-Prolog), and other programs. It searches dedicated installation directories for these tools on each platform. For example, on Windows it checks `C:\\Strawberry\\perl\\bin` for Perl. Provide the executable name (e.g., 'perl', 'swipl', 'python') and the skill will search the platform-specific directories. See skill_find_executable.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_find_executable_006_q1", "cluster_id": "skill_find_executable_006", "question": "What programs can this skill find?", "answer": "This skill can find any executable by searching platform-specific directories. On Windows, it searches Strawberry Perl and SWI-Prolog installation directories. On Linux, it searches /usr/bin, /usr/local/bin, and /snap/bin. On macOS, it searches /usr/bin, /usr/local/bin, /opt/homebrew/bin, and the SWI-Prolog application directory. Common examples include perl, swipl (SWI-Prolog), and python, but the skill works with any executable name provided as input.", "question_type": "long", "topics": ["System", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["perl", "swipl", "prolog", "python", "programming-languages"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "Yes, the skill is designed to find commonly used executables including perl, swipl (SWI-Prolog), and other programs. It searches dedicated installation directories for these tools on each platform. For example, on Windows it checks `C:\\Strawberry\\perl\\bin` for Perl. Provide the executable name (e.g., 'perl', 'swipl', 'python') and the skill will search the platform-specific directories. See skill_find_executable.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_find_executable_006_q2", "cluster_id": "skill_find_executable_006", "question": "Does the skill work with specific programming languages?", "answer": "Yes, the skill works with specific programming languages. It's designed to locate executables for commonly used languages and tools including Perl, SWI-Prolog (swipl), and Python. The skill searches language-specific installation directories on each platform\u2014for example, on Windows it checks `C:\\Strawberry\\perl\\bin` for Perl installations. You provide the executable name (e.g., 'perl', 'swipl', 'python') and the skill searches the appropriate platform-specific directories to find it.", "question_type": "long", "topics": ["System", "Find Executable"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["perl", "swipl", "prolog", "python", "programming-languages"], "related_skills": ["skill_find_executable.md"], "related_docs": [], "original_answer": "Yes, the skill is designed to find commonly used executables including perl, swipl (SWI-Prolog), and other programs. It searches dedicated installation directories for these tools on each platform. For example, on Windows it checks `C:\\Strawberry\\perl\\bin` for Perl. Provide the executable name (e.g., 'perl', 'swipl', 'python') and the skill will search the platform-specific directories. See skill_find_executable.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_001_q0", "cluster_id": "skill_json_sources_001", "question": "How do I read specific columns from a JSON file in my playbook?", "answer": "To read specific columns from a JSON file in your playbook, use the `source(json, ...)` directive with `json_file()` to specify the file path and `columns()` to list the fields you want to extract. Provide column names using dot notation for nested properties (e.g., `'order.customer.name'`) or array indices for items (e.g., `'items[0].product'`, `'items[0].total'`). The number of columns must match your predicate's arity. For example:\n\n```prolog\n:- source(json, order_totals, [\n    json_file('data/orders.json'),\n    columns(['order.customer.name', 'items[0].product', 'items[0].total'])\n]).\n```\n\nFor more complex selectors, use JSONPath syntax (e.g., `'$.orders[*].total'`) in the columns list.", "question_type": "medium", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["json", "columns", "projection", "dot-notation"], "related_skills": ["skill_json_sources.md"], "related_docs": ["src/unifyweaver/sources/json_source.pl"], "original_answer": "Use the `source(json, ...)` directive with `json_file()` and `columns()`. Provide column names using dot notation (e.g., `'order.customer.name'`) or array indices (e.g., `'items[0].total'`). The `columns/1` arity must match your predicate arity. Example:\n```prolog\n:- source(json, order_totals, [\n    json_file('data/orders.json'),\n    columns(['order.customer.name', 'items[0].product', 'items[0].total'])\n]).\n```\nSee skill_json_sources.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_json_sources_001_q1", "cluster_id": "skill_json_sources_001", "question": "How do I project columns from JSON data?", "answer": "To project columns from JSON data, use the `source(json, ...)` directive with `json_file()` and `columns()`. Specify column names using dot notation for nested fields (e.g., `'order.customer.name'`) or array indices for items (e.g., `'items[0].total'`). The number of columns must match your predicate's arity. Example:\n```prolog\n:- source(json, order_totals, [\n    json_file('data/orders.json'),\n    columns(['order.customer.name', 'items[0].product', 'items[0].total'])\n]).\n```\nFor complex queries where dot notation is insufficient, use JSONPath selectors like `jsonpath('$.orders[*].total')` in the columns list.", "question_type": "medium", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["json", "columns", "projection", "dot-notation"], "related_skills": ["skill_json_sources.md"], "related_docs": ["src/unifyweaver/sources/json_source.pl"], "original_answer": "Use the `source(json, ...)` directive with `json_file()` and `columns()`. Provide column names using dot notation (e.g., `'order.customer.name'`) or array indices (e.g., `'items[0].total'`). The `columns/1` arity must match your predicate arity. Example:\n```prolog\n:- source(json, order_totals, [\n    json_file('data/orders.json'),\n    columns(['order.customer.name', 'items[0].product', 'items[0].total'])\n]).\n```\nSee skill_json_sources.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_001_q2", "cluster_id": "skill_json_sources_001", "question": "What's the syntax for selecting fields from JSON with dot notation?", "answer": "Use dot notation in the `columns/1` list within a `source(json, ...)` directive. For example, `'order.customer.name'` accesses nested fields, and `'items[0].total'` accesses array elements. The column names are passed as a list to `columns([...])`, and the number of columns must match your predicate's arity.\n\nExample:\n```prolog\n:- source(json, order_totals, [\n    json_file('data/orders.json'),\n    columns(['order.customer.name', 'items[0].product', 'items[0].total'])\n]).\n```", "question_type": "medium", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["json", "columns", "projection", "dot-notation"], "related_skills": ["skill_json_sources.md"], "related_docs": ["src/unifyweaver/sources/json_source.pl"], "original_answer": "Use the `source(json, ...)` directive with `json_file()` and `columns()`. Provide column names using dot notation (e.g., `'order.customer.name'`) or array indices (e.g., `'items[0].total'`). The `columns/1` arity must match your predicate arity. Example:\n```prolog\n:- source(json, order_totals, [\n    json_file('data/orders.json'),\n    columns(['order.customer.name', 'items[0].product', 'items[0].total'])\n]).\n```\nSee skill_json_sources.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_json_sources_002_q0", "cluster_id": "skill_json_sources_002", "question": "When should I use JSONPath selectors instead of dot notation?", "answer": "Use JSONPath selectors instead of dot notation when you need advanced selection features that dot notation cannot handle. JSONPath is necessary for: wildcards ([*]) to select multiple array elements, recursive descent (..name) to find properties at any depth, bracket notation (['foo']) for property names with special characters, and complex filtering. Dot notation handles simple cases like 'order.customer.name' and 'items[0].product', but JSONPath becomes essential when you need to select all items in an array ($.orders[*].total) or search across nested structures. Strings beginning with '$' are automatically treated as JSONPath selectors in both columns/1 and schema/1.", "question_type": "medium", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["jsonpath", "selectors", "complex-queries", "recursive-descent"], "related_skills": ["skill_json_sources.md"], "related_docs": ["src/unifyweaver/sources/json_source.pl"], "original_answer": "Use `jsonpath()` for complex selections that dot notation can't handle. JSONPath supports root `$`, dotted properties, bracket properties, array indices `[0]`, wildcards `[*]`, and recursive descent `..name`. Strings starting with `$` are automatically treated as JSONPath. Example:\n```prolog\njsonpath('$.orders[*].total')\n```\nUse JSONPath in both `columns/1` and `schema/1` when you need advanced filtering or recursive selection. See skill_json_sources.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_002_q1", "cluster_id": "skill_json_sources_002", "question": "How do I use JSONPath expressions to query JSON data?", "answer": "Use the `jsonpath()` function to query JSON data with expressions like `jsonpath('$.orders[*].total')`. JSONPath supports: root selector `$`, dotted properties (e.g., `$.order.customer`), bracket notation (e.g., `$['key']`), array indices (e.g., `[0]`), wildcards (e.g., `[*]` to select all array elements), and recursive descent (e.g., `..name` to find all `name` fields at any depth). You can use JSONPath in both `columns/1` for column projection and `schema/1` for typed record definitions. Strings that already begin with `$` are automatically treated as JSONPath selectors, so explicit `jsonpath()` wrapping is optional in those cases.", "question_type": "medium", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["jsonpath", "selectors", "complex-queries", "recursive-descent"], "related_skills": ["skill_json_sources.md"], "related_docs": ["src/unifyweaver/sources/json_source.pl"], "original_answer": "Use `jsonpath()` for complex selections that dot notation can't handle. JSONPath supports root `$`, dotted properties, bracket properties, array indices `[0]`, wildcards `[*]`, and recursive descent `..name`. Strings starting with `$` are automatically treated as JSONPath. Example:\n```prolog\njsonpath('$.orders[*].total')\n```\nUse JSONPath in both `columns/1` and `schema/1` when you need advanced filtering or recursive selection. See skill_json_sources.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_002_q2", "cluster_id": "skill_json_sources_002", "question": "What complex JSON queries can I perform with JSONPath?", "answer": "JSONPath enables complex JSON queries beyond simple dot notation. Supported features include: root selector `$`, dotted properties (e.g., `$.order.total`), bracket notation (e.g., `$['order']['total']`), array indices (e.g., `$.items[0]`), wildcards (e.g., `$.orders[*].total` to select all order totals), and recursive descent (e.g., `$..name` to find all 'name' properties at any depth). Use JSONPath in `columns/1` for column projection or in `schema/1` for typed record extraction. Strings beginning with `$` are automatically treated as JSONPath selectors. Example: `jsonpath('$.orders[*].total')` selects the total field from all items in an orders array. Note: wildcards currently return the first matching value.", "question_type": "medium", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["jsonpath", "selectors", "complex-queries", "recursive-descent"], "related_skills": ["skill_json_sources.md"], "related_docs": ["src/unifyweaver/sources/json_source.pl"], "original_answer": "Use `jsonpath()` for complex selections that dot notation can't handle. JSONPath supports root `$`, dotted properties, bracket properties, array indices `[0]`, wildcards `[*]`, and recursive descent `..name`. Strings starting with `$` are automatically treated as JSONPath. Example:\n```prolog\njsonpath('$.orders[*].total')\n```\nUse JSONPath in both `columns/1` and `schema/1` when you need advanced filtering or recursive selection. See skill_json_sources.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_003_q0", "cluster_id": "skill_json_sources_003", "question": "How do I return full JSON objects as rows instead of projecting columns?", "answer": "Use return-object mode by setting `arity(1)`, `return_object(true)`, and providing a `type_hint` with a .NET type. Example:\n```prolog\n:- source(json, raw_products, [\n    json_file('test_data/test_products.json'),\n    arity(1),\n    return_object(true),\n    type_hint('System.Text.Json.Nodes.JsonObject, System.Text.Json')\n]).\n```\nThis returns each JSON object as a row instead of extracting individual columns.", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["return-object", "raw-json", "type-hint"], "related_skills": ["skill_json_sources.md"], "related_docs": ["src/unifyweaver/sources/json_source.pl"], "original_answer": "Use return-object mode by setting `arity(1)`, `return_object(true)`, and providing a `type_hint` with a .NET type. Example:\n```prolog\n:- source(json, raw_products, [\n    json_file('test_data/test_products.json'),\n    arity(1),\n    return_object(true),\n    type_hint('System.Text.Json.Nodes.JsonObject, System.Text.Json')\n]).\n```\nThis returns each JSON object as a row instead of extracting individual columns. See skill_json_sources.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_json_sources_003_q1", "cluster_id": "skill_json_sources_003", "question": "How do I work with raw JSON objects in my playbook?", "answer": "To work with raw JSON objects in your playbook, use return-object mode by setting three parameters: `arity(1)` to specify single-column output, `return_object(true)` to return full JSON objects instead of extracted fields, and `type_hint('System.Text.Json.Nodes.JsonObject, System.Text.Json')` to specify the .NET type. Example:\n```prolog\n:- source(json, raw_products, [\n    json_file('test_data/test_products.json'),\n    arity(1),\n    return_object(true),\n    type_hint('System.Text.Json.Nodes.JsonObject, System.Text.Json')\n]).\n```\nEach row will contain a complete JSON object rather than individual extracted columns.", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["return-object", "raw-json", "type-hint"], "related_skills": ["skill_json_sources.md"], "related_docs": ["src/unifyweaver/sources/json_source.pl"], "original_answer": "Use return-object mode by setting `arity(1)`, `return_object(true)`, and providing a `type_hint` with a .NET type. Example:\n```prolog\n:- source(json, raw_products, [\n    json_file('test_data/test_products.json'),\n    arity(1),\n    return_object(true),\n    type_hint('System.Text.Json.Nodes.JsonObject, System.Text.Json')\n]).\n```\nThis returns each JSON object as a row instead of extracting individual columns. See skill_json_sources.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_json_sources_003_q2", "cluster_id": "skill_json_sources_003", "question": "When would I use return_object mode?", "answer": "Use return-object mode when you want full JSON objects returned as rows rather than extracting individual columns. Set `arity(1)`, `return_object(true)`, and provide a `type_hint` with a .NET type like `'System.Text.Json.Nodes.JsonObject, System.Text.Json'`. This is useful when you need the complete JSON structure preserved rather than projecting specific fields.", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["return-object", "raw-json", "type-hint"], "related_skills": ["skill_json_sources.md"], "related_docs": ["src/unifyweaver/sources/json_source.pl"], "original_answer": "Use return-object mode by setting `arity(1)`, `return_object(true)`, and providing a `type_hint` with a .NET type. Example:\n```prolog\n:- source(json, raw_products, [\n    json_file('test_data/test_products.json'),\n    arity(1),\n    return_object(true),\n    type_hint('System.Text.Json.Nodes.JsonObject, System.Text.Json')\n]).\n```\nThis returns each JSON object as a row instead of extracting individual columns. See skill_json_sources.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_004_q0", "cluster_id": "skill_json_sources_004", "question": "How do I define a typed record structure from JSON data?", "answer": "To define a typed record structure from JSON data, use the `schema([field(Name, Path, Type), ...])` directive. This tells the C# backend to generate a POCO (Plain Old CLR Object) automatically. Example:\n\n```prolog\n:- source(json, product_rows, [\n    json_file('test_data/test_products.json'),\n    schema([\n        field(id, 'id', string),\n        field(name, 'name', string),\n        field(price, 'price', double)\n    ]),\n    record_type('ProductRecord')\n]).\n```\n\nKey requirements:\n- Predicate arity must be `1`\n- Use `record_type('YourRecordName')` to name the generated record\n- Paths support dot notation and array indices (e.g., `'customer.name'` or `'items[0].total'`)\n- `return_object(true)` is automatically implied when using `schema/1`", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["schema", "typed-records", "poco", "field-mapping"], "related_skills": ["skill_json_sources.md"], "related_docs": ["src/unifyweaver/sources/json_source.pl"], "original_answer": "Use `schema([field(Name, Path, Type), ...])` to declare typed records. The C# backend generates a POCO automatically. Example:\n```prolog\n:- source(json, product_rows, [\n    json_file('test_data/test_products.json'),\n    schema([\n        field(id, 'id', string),\n        field(name, 'name', string),\n        field(price, 'price', double)\n    ]),\n    record_type('ProductRecord')\n]).\n```\nPredicate arity must be `1` and `return_object(true)` is implied. Use `record_type()` to name the generated record. See skill_json_sources.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_json_sources_004_q1", "cluster_id": "skill_json_sources_004", "question": "How do I create a POCO from JSON using schema?", "answer": "To create a POCO from JSON using schema, use the `schema([field(Name, Path, Type), ...])` declaration in your source directive. The C# backend automatically generates a Plain Old CLR Object (POCO) class. Example:\n\n```prolog\n:- source(json, product_rows, [\n    json_file('test_data/test_products.json'),\n    schema([\n        field(id, 'id', string),\n        field(name, 'name', string),\n        field(price, 'price', double)\n    ]),\n    record_type('ProductRecord')\n]).\n```\n\nKey requirements: set predicate arity to `1`, use `record_type('YourRecordName')` to name the generated POCO, and specify field names, JSON paths (supporting dot notation and array indices), and C# types. The `return_object(true)` setting is automatically applied when using schema mode.", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["schema", "typed-records", "poco", "field-mapping"], "related_skills": ["skill_json_sources.md"], "related_docs": ["src/unifyweaver/sources/json_source.pl"], "original_answer": "Use `schema([field(Name, Path, Type), ...])` to declare typed records. The C# backend generates a POCO automatically. Example:\n```prolog\n:- source(json, product_rows, [\n    json_file('test_data/test_products.json'),\n    schema([\n        field(id, 'id', string),\n        field(name, 'name', string),\n        field(price, 'price', double)\n    ]),\n    record_type('ProductRecord')\n]).\n```\nPredicate arity must be `1` and `return_object(true)` is implied. Use `record_type()` to name the generated record. See skill_json_sources.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_004_q2", "cluster_id": "skill_json_sources_004", "question": "How do I specify field types when reading JSON?", "answer": "To specify field types when reading JSON, use the `schema([field(Name, Path, Type), ...])` option in your JSON source declaration. Each `field()` tuple specifies the field name, JSONPath or dot-notation path to the data, and the type (e.g., `string`, `double`, `int`). The C# backend automatically generates a POCO record. Example:\n\n```prolog\n:- source(json, product_rows, [\n    json_file('test_data/test_products.json'),\n    schema([\n        field(id, 'id', string),\n        field(name, 'name', string),\n        field(price, 'price', double)\n    ]),\n    record_type('ProductRecord')\n]).\n```\n\nRequirements: predicate arity must be `1` (arity is implied by schema mode), and `return_object(true)` is automatically enabled. Optionally use `record_type()` to name the generated record class.", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["schema", "typed-records", "poco", "field-mapping"], "related_skills": ["skill_json_sources.md"], "related_docs": ["src/unifyweaver/sources/json_source.pl"], "original_answer": "Use `schema([field(Name, Path, Type), ...])` to declare typed records. The C# backend generates a POCO automatically. Example:\n```prolog\n:- source(json, product_rows, [\n    json_file('test_data/test_products.json'),\n    schema([\n        field(id, 'id', string),\n        field(name, 'name', string),\n        field(price, 'price', double)\n    ]),\n    record_type('ProductRecord')\n]).\n```\nPredicate arity must be `1` and `return_object(true)` is implied. Use `record_type()` to name the generated record. See skill_json_sources.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_005_q0", "cluster_id": "skill_json_sources_005", "question": "How do I create nested record structures from JSON?", "answer": "To create nested record structures from JSON, use `record(TypeName, Fields)` or `record(Fields)` within your `schema/1` declaration. Nested selectors are evaluated relative to their sub-object using dot notation or JSONPath. Example:\n\n```prolog\n:- source(json, order_rows, [\n    json_file('test_data/test_orders.json'),\n    schema([\n        field(order, 'order', record('OrderRecord', [\n            field(id, 'id', string),\n            field(customer, 'customer.name', string)\n        ])),\n        field(first_item, 'items[0]', record('LineItemRecord', [\n            field(product, 'product', string),\n            field(total, 'total', double)\n        ]))\n    ]),\n    record_type('OrderSummaryRecord')\n]).\n```\n\nThe C# backend generates all nested POCOs (OrderRecord, LineItemRecord, OrderSummaryRecord) automatically. Use dot notation for nested properties (e.g., 'customer.name') and array indices (e.g., 'items[0]') within field paths.", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["nested-records", "nested-schema", "sub-objects", "structured-data"], "related_skills": ["skill_json_sources.md"], "related_docs": ["src/unifyweaver/sources/json_source.pl"], "original_answer": "Use `record(TypeName, Fields)` or `record(Fields)` within your schema to create nested structures. Nested selectors are evaluated relative to their sub-object. Example:\n```prolog\n:- source(json, order_rows, [\n    json_file('test_data/test_orders.json'),\n    schema([\n        field(order, 'order', record('OrderRecord', [\n            field(id, 'id', string),\n            field(customer, 'customer.name', string)\n        ])),\n        field(first_item, 'items[0]', record('LineItemRecord', [\n            field(product, 'product', string),\n            field(total, 'total', double)\n        ]))\n    ]),\n    record_type('OrderSummaryRecord')\n]).\n```\nThe runtime instantiates all nested POCOs automatically. See skill_json_sources.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_005_q1", "cluster_id": "skill_json_sources_005", "question": "How do I handle nested objects in schema definitions?", "answer": "To handle nested objects in schema definitions, use `record(TypeName, Fields)` or `record(Fields)` within your `schema/1` declaration. Nested selectors are evaluated relative to their sub-object context.\n\nExample with nested records:\n```prolog\n:- source(json, order_rows, [\n    json_file('test_data/test_orders.json'),\n    schema([\n        field(order, 'order', record('OrderRecord', [\n            field(id, 'id', string),\n            field(customer, 'customer.name', string)\n        ])),\n        field(first_item, 'items[0]', record('LineItemRecord', [\n            field(product, 'product', string),\n            field(total, 'total', double)\n        ]))\n    ]),\n    record_type('OrderSummaryRecord')\n]).\n```\n\nThe system automatically generates all nested POCOs (Plain Old CLR Objects) at runtime. Selectors within nested records use dot notation or JSONPath, evaluated relative to the parent field's data path.", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["nested-records", "nested-schema", "sub-objects", "structured-data"], "related_skills": ["skill_json_sources.md"], "related_docs": ["src/unifyweaver/sources/json_source.pl"], "original_answer": "Use `record(TypeName, Fields)` or `record(Fields)` within your schema to create nested structures. Nested selectors are evaluated relative to their sub-object. Example:\n```prolog\n:- source(json, order_rows, [\n    json_file('test_data/test_orders.json'),\n    schema([\n        field(order, 'order', record('OrderRecord', [\n            field(id, 'id', string),\n            field(customer, 'customer.name', string)\n        ])),\n        field(first_item, 'items[0]', record('LineItemRecord', [\n            field(product, 'product', string),\n            field(total, 'total', double)\n        ]))\n    ]),\n    record_type('OrderSummaryRecord')\n]).\n```\nThe runtime instantiates all nested POCOs automatically. See skill_json_sources.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_json_sources_005_q2", "cluster_id": "skill_json_sources_005", "question": "How do I map sub-objects from JSON to nested records?", "answer": "To map sub-objects from JSON to nested records, use `record(TypeName, Fields)` or `record(Fields)` within your schema definition. Place the record specification as the Type parameter of a field. Nested selectors (using dot notation or JSONPath) are evaluated relative to their sub-object's context. For example:\n\n```prolog\n:- source(json, order_rows, [\n    json_file('test_data/test_orders.json'),\n    schema([\n        field(order, 'order', record('OrderRecord', [\n            field(id, 'id', string),\n            field(customer, 'customer.name', string)\n        ])),\n        field(first_item, 'items[0]', record('LineItemRecord', [\n            field(product, 'product', string),\n            field(total, 'total', double)\n        ]))\n    ]),\n    record_type('OrderSummaryRecord')\n]).\n```\n\nThe C# backend automatically generates all nested POCOs and instantiates them at runtime.", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["nested-records", "nested-schema", "sub-objects", "structured-data"], "related_skills": ["skill_json_sources.md"], "related_docs": ["src/unifyweaver/sources/json_source.pl"], "original_answer": "Use `record(TypeName, Fields)` or `record(Fields)` within your schema to create nested structures. Nested selectors are evaluated relative to their sub-object. Example:\n```prolog\n:- source(json, order_rows, [\n    json_file('test_data/test_orders.json'),\n    schema([\n        field(order, 'order', record('OrderRecord', [\n            field(id, 'id', string),\n            field(customer, 'customer.name', string)\n        ])),\n        field(first_item, 'items[0]', record('LineItemRecord', [\n            field(product, 'product', string),\n            field(total, 'total', double)\n        ]))\n    ]),\n    record_type('OrderSummaryRecord')\n]).\n```\nThe runtime instantiates all nested POCOs automatically. See skill_json_sources.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_json_sources_006_q0", "cluster_id": "skill_json_sources_006", "question": "How do I handle missing or null values when reading JSON Lines files?", "answer": "When reading JSON Lines files with `record_format(jsonl)`, use `null_policy()` to control null handling. Choose from: `null_policy(fail)` to throw an error on null values, `null_policy(skip)` to skip rows containing nulls, or `null_policy(default(Value))` to substitute a placeholder value. Example:\n\n```prolog\n:- source(json, order_items, [\n    json_file('test_data/test_orders.jsonl'),\n    record_format(jsonl),\n    columns([jsonpath('$.order.customer.name'), jsonpath('$.items[1].product')]),\n    null_policy(default('N/A'))\n]).\n```\n\nEach line in the JSONL file is treated as an independent JSON object, and the null policy applies to all projected columns.", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["jsonl", "null-policy", "missing-data", "default-values"], "related_skills": ["skill_json_sources.md"], "related_docs": ["src/unifyweaver/sources/json_source.pl"], "original_answer": "Use `record_format(jsonl)` for newline-delimited JSON and `null_policy()` to control null behavior. Options: `null_policy(fail)` throws on null, `null_policy(skip)` skips rows with nulls, `null_policy(default(Value))` substitutes a placeholder. Example:\n```prolog\n:- source(json, order_items, [\n    json_file('test_data/test_orders.jsonl'),\n    record_format(jsonl),\n    columns([jsonpath('$.order.customer.name'), jsonpath('$.items[1].product')]),\n    null_policy(default('N/A'))\n]).\n```\nEach line is treated as an independent object. See skill_json_sources.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_006_q1", "cluster_id": "skill_json_sources_006", "question": "How do I configure null handling for JSONL streams?", "answer": "Configure null handling for JSONL streams using the `null_policy()` option. For newline-delimited JSON files, combine `record_format(jsonl)` with one of three null policies: `null_policy(fail)` to throw an error when nulls are encountered, `null_policy(skip)` to skip entire rows containing null values, or `null_policy(default(Value))` to substitute a placeholder value for nulls. Example:\n```prolog\n:- source(json, order_items, [\n    json_file('test_data/test_orders.jsonl'),\n    record_format(jsonl),\n    null_policy(default('N/A'))\n]).\n```\nEach line in the JSONL file is treated as an independent JSON object, and the null policy applies across all fields.", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["jsonl", "null-policy", "missing-data", "default-values"], "related_skills": ["skill_json_sources.md"], "related_docs": ["src/unifyweaver/sources/json_source.pl"], "original_answer": "Use `record_format(jsonl)` for newline-delimited JSON and `null_policy()` to control null behavior. Options: `null_policy(fail)` throws on null, `null_policy(skip)` skips rows with nulls, `null_policy(default(Value))` substitutes a placeholder. Example:\n```prolog\n:- source(json, order_items, [\n    json_file('test_data/test_orders.jsonl'),\n    record_format(jsonl),\n    columns([jsonpath('$.order.customer.name'), jsonpath('$.items[1].product')]),\n    null_policy(default('N/A'))\n]).\n```\nEach line is treated as an independent object. See skill_json_sources.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_006_q2", "cluster_id": "skill_json_sources_006", "question": "What options do I have for missing JSON fields?", "answer": "For missing JSON fields, use the `null_policy()` option to control how they're handled. Available options: `null_policy(fail)` throws an error when a field is null/missing, `null_policy(skip)` skips rows with missing fields, and `null_policy(default(Value))` substitutes a placeholder value (e.g., 'N/A') for missing fields. Example: `null_policy(default('N/A'))` will replace any null or missing field with the string 'N/A'. This works with both column projection mode and schema-based declarations.", "question_type": "long", "topics": ["Compilation", "Declaring JSON Dynamic Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["jsonl", "null-policy", "missing-data", "default-values"], "related_skills": ["skill_json_sources.md"], "related_docs": ["src/unifyweaver/sources/json_source.pl"], "original_answer": "Use `record_format(jsonl)` for newline-delimited JSON and `null_policy()` to control null behavior. Options: `null_policy(fail)` throws on null, `null_policy(skip)` skips rows with nulls, `null_policy(default(Value))` substitutes a placeholder. Example:\n```prolog\n:- source(json, order_items, [\n    json_file('test_data/test_orders.jsonl'),\n    record_format(jsonl),\n    columns([jsonpath('$.order.customer.name'), jsonpath('$.items[1].product')]),\n    null_policy(default('N/A'))\n]).\n```\nEach line is treated as an independent object. See skill_json_sources.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "The base answer conflates two separate concerns: `record_format(jsonl)` is for file format (newline-delimited), not for handling missing fields. The example mixes this with `null_policy()`. The question asks specifically about missing fields, so the answer focuses on `null_policy()` which is the correct mechanism, but the base answer's inclusion of `record_format()` adds unnecessary context that could confuse the distinction between file format and field handling strategy."}
{"pair_id": "skill_unifyweaver_compile_001_q0", "cluster_id": "skill_unifyweaver_compile_001", "question": "How do I convert Prolog rules into an executable bash script?", "answer": "To convert Prolog rules into an executable bash script, use the UnifyWeaver compilation engine with swipl. Run: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<prolog_file>'), compile(<predicate_indicator>, [output_dir('.')])\" -t halt` where `<prolog_file>` is your .pl file containing the Prolog rules and `<predicate_indicator>` is the main predicate in `functor/arity` format (e.g., `choose_strategy/3`). The compiler will automatically handle dependencies and output an executable .sh file to your specified directory. Note: The compiler cannot transpile predicates using arithmetic comparison operators (`>`, `<`, `=<`).", "question_type": "medium", "topics": ["Compilation", "UnifyWeaver Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "transpiler", "prolog", "bash"], "related_skills": ["skill_unifyweaver_compile.md", "skill_unifyweaver_environment.md"], "related_docs": ["docs/EXTENDED_README.md", "src/unifyweaver/core/compiler_driver.pl", "src/unifyweaver/targets/bash/"], "original_answer": "Use the UnifyWeaver compilation engine with swipl. Run: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<prolog_file>'), compile(<predicate_indicator>, [<options>])\" -t halt` where `<prolog_file>` is your .pl file and `<predicate_indicator>` is the main predicate (e.g., `choose_strategy/3`). Always include `output_dir('.')` in options to save the compiled .sh file to the current directory. See skill_unifyweaver_compile.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_001_q1", "cluster_id": "skill_unifyweaver_compile_001", "question": "How do I transpile Prolog predicates to bash?", "answer": "To transpile Prolog predicates to bash, use the UnifyWeaver compilation engine with swipl. Run the command: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<prolog_file>'), compile(<predicate_indicator>, [<options>])\" -t halt` where `<prolog_file>` is your .pl file containing Prolog rules and `<predicate_indicator>` is the main predicate in `functor/arity` format (e.g., `choose_strategy/3`). Always include `output_dir('.')` in the options list to save the compiled .sh file to the current directory. The compiler automatically handles dependencies of your main predicate. Note that arithmetic comparison operators (>, <, =<) in predicates will cause compilation to fail.", "question_type": "medium", "topics": ["Compilation", "UnifyWeaver Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "transpiler", "prolog", "bash"], "related_skills": ["skill_unifyweaver_compile.md", "skill_unifyweaver_environment.md"], "related_docs": ["docs/EXTENDED_README.md", "src/unifyweaver/core/compiler_driver.pl", "src/unifyweaver/targets/bash/"], "original_answer": "Use the UnifyWeaver compilation engine with swipl. Run: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<prolog_file>'), compile(<predicate_indicator>, [<options>])\" -t halt` where `<prolog_file>` is your .pl file and `<predicate_indicator>` is the main predicate (e.g., `choose_strategy/3`). Always include `output_dir('.')` in options to save the compiled .sh file to the current directory. See skill_unifyweaver_compile.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_001_q2", "cluster_id": "skill_unifyweaver_compile_001", "question": "What's the process for turning Prolog code into a runnable script?", "answer": "To turn Prolog code into a runnable script, use the UnifyWeaver compilation engine. First, ensure your Prolog predicates are in a .pl file. Then run the SWI-Prolog compiler with: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<prolog_file>'), compile(<predicate_indicator>, [output_dir('.')])\" -t halt`. Replace `<prolog_file>` with your file path (e.g., `my_rules.pl`) and `<predicate_indicator>` with your main predicate in functor/arity format (e.g., `choose_strategy/3`). The compiler will analyze dependencies and output an executable .sh file in your specified directory. Note: arithmetic comparison operators (>, <, =<) are not currently supported in predicates being compiled.", "question_type": "medium", "topics": ["Compilation", "UnifyWeaver Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "transpiler", "prolog", "bash"], "related_skills": ["skill_unifyweaver_compile.md", "skill_unifyweaver_environment.md"], "related_docs": ["docs/EXTENDED_README.md", "src/unifyweaver/core/compiler_driver.pl", "src/unifyweaver/targets/bash/"], "original_answer": "Use the UnifyWeaver compilation engine with swipl. Run: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<prolog_file>'), compile(<predicate_indicator>, [<options>])\" -t halt` where `<prolog_file>` is your .pl file and `<predicate_indicator>` is the main predicate (e.g., `choose_strategy/3`). Always include `output_dir('.')` in options to save the compiled .sh file to the current directory. See skill_unifyweaver_compile.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_001_q3", "cluster_id": "skill_unifyweaver_compile_001", "question": "How do I compile my Prolog rules to bash?", "answer": "To compile your Prolog rules to bash, use the UnifyWeaver compilation engine with swipl. Run: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<prolog_file>'), compile(<predicate_indicator>, [output_dir('.')])\" -t halt` where `<prolog_file>` is your .pl file path and `<predicate_indicator>` is your main predicate in functor/arity format (e.g., `choose_strategy/3`). This generates an executable .sh file in your current directory. Note: the compiler cannot transpile predicates using direct arithmetic operators like `>`, `<`, or `=<`.", "question_type": "medium", "topics": ["Compilation", "UnifyWeaver Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "transpiler", "prolog", "bash"], "related_skills": ["skill_unifyweaver_compile.md", "skill_unifyweaver_environment.md"], "related_docs": ["docs/EXTENDED_README.md", "src/unifyweaver/core/compiler_driver.pl", "src/unifyweaver/targets/bash/"], "original_answer": "Use the UnifyWeaver compilation engine with swipl. Run: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<prolog_file>'), compile(<predicate_indicator>, [<options>])\" -t halt` where `<prolog_file>` is your .pl file and `<predicate_indicator>` is the main predicate (e.g., `choose_strategy/3`). Always include `output_dir('.')` in options to save the compiled .sh file to the current directory. See skill_unifyweaver_compile.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_002_q0", "cluster_id": "skill_unifyweaver_compile_002", "question": "Where does the compiled bash script get saved after compilation?", "answer": "The compiled .sh file is saved to the directory specified by the `output_dir()` option in the compile command. For example, `output_dir('.')` saves to the current directory, while `output_dir('/path/to/output')` saves to that specific path. The filename is automatically derived from the predicate name\u2014for instance, compiling `choose_strategy/3` produces `choose_strategy.sh`. It's recommended to always explicitly set `output_dir` to a known location to avoid unexpected output paths.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "output", "configuration"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "src/unifyweaver/core/compiler_driver.pl"], "original_answer": "The compiled .sh file is saved to the directory specified by the `output_dir()` option. Include `output_dir('.')` to save to the current directory, or specify another path like `output_dir('/path/to/output')`. The filename is automatically derived from the predicate name (e.g., `choose_strategy/3` becomes `choose_strategy.sh`). It's highly recommended to always set `output_dir` to a known location. See skill_unifyweaver_compile.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_002_q1", "cluster_id": "skill_unifyweaver_compile_002", "question": "What's the output location for compiled scripts?", "answer": "The compiled .sh file is saved to the directory specified by the `output_dir()` option in the compile command. Use `output_dir('.')` to save to the current directory, or specify another path like `output_dir('/path/to/output')`. The filename is automatically derived from the predicate name (e.g., `choose_strategy/3` becomes `choose_strategy.sh`). It's recommended to always explicitly set `output_dir` to a known location to avoid unexpected output paths.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "output", "configuration"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "src/unifyweaver/core/compiler_driver.pl"], "original_answer": "The compiled .sh file is saved to the directory specified by the `output_dir()` option. Include `output_dir('.')` to save to the current directory, or specify another path like `output_dir('/path/to/output')`. The filename is automatically derived from the predicate name (e.g., `choose_strategy/3` becomes `choose_strategy.sh`). It's highly recommended to always set `output_dir` to a known location. See skill_unifyweaver_compile.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_002_q2", "cluster_id": "skill_unifyweaver_compile_002", "question": "How do I control where the .sh file is created?", "answer": "Use the `output_dir()` option in the compile command to control where the .sh file is created. Set `output_dir('.')` to save to the current directory, or specify any other path like `output_dir('/path/to/output')`. The filename is automatically derived from the predicate name (e.g., `choose_strategy/3` becomes `choose_strategy.sh`). Always explicitly set `output_dir` to avoid unexpected output locations.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "output", "configuration"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "src/unifyweaver/core/compiler_driver.pl"], "original_answer": "The compiled .sh file is saved to the directory specified by the `output_dir()` option. Include `output_dir('.')` to save to the current directory, or specify another path like `output_dir('/path/to/output')`. The filename is automatically derived from the predicate name (e.g., `choose_strategy/3` becomes `choose_strategy.sh`). It's highly recommended to always set `output_dir` to a known location. See skill_unifyweaver_compile.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_002_q3", "cluster_id": "skill_unifyweaver_compile_002", "question": "Can I specify the output directory for my compiled script?", "answer": "Yes, you can specify the output directory using the `output_dir()` option in the compile command. Use `output_dir('.')` to save to the current directory, or `output_dir('/path/to/output')` for a specific path. The filename is automatically derived from the predicate name (e.g., `choose_strategy/3` becomes `choose_strategy.sh`). It's highly recommended to always explicitly set `output_dir` to avoid unexpected output locations.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "output", "configuration"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "src/unifyweaver/core/compiler_driver.pl"], "original_answer": "The compiled .sh file is saved to the directory specified by the `output_dir()` option. Include `output_dir('.')` to save to the current directory, or specify another path like `output_dir('/path/to/output')`. The filename is automatically derived from the predicate name (e.g., `choose_strategy/3` becomes `choose_strategy.sh`). It's highly recommended to always set `output_dir` to a known location. See skill_unifyweaver_compile.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_003_q0", "cluster_id": "skill_unifyweaver_compile_003", "question": "What happens if my Prolog predicates use arithmetic comparison operators like > or <?", "answer": "The current version of the UnifyWeaver compiler driver has a known limitation: it cannot transpile Prolog predicates that directly use arithmetic comparison operators such as `>`, `<`, `=<`, `>=`, `=:=`, or `=\\=`. If you attempt to compile predicates containing these operators, the compilation will fail. To work around this limitation, you'll need to refactor your Prolog rules to avoid direct arithmetic comparisons or implement alternative logic patterns that don't rely on these operators.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "limitations", "arithmetic", "operators"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "docs/ADVANCED_RECURSION.md"], "original_answer": "The current version of the compiler driver has a known limitation: it cannot transpile predicates that directly use arithmetic comparison operators (`>`, `<`, `=<`, etc.). Attempting to compile such predicates will cause the compilation to fail. You'll need to refactor your Prolog rules to avoid direct arithmetic comparisons or use alternative logic patterns. See skill_unifyweaver_compile.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_003_q1", "cluster_id": "skill_unifyweaver_compile_003", "question": "Can I compile Prolog rules with arithmetic comparisons?", "answer": "No, the current version of the UnifyWeaver compiler driver cannot compile Prolog rules that directly use arithmetic comparison operators like `>`, `<`, and `=<`. Attempting to do so will cause compilation to fail. You'll need to refactor your Prolog rules to avoid direct arithmetic comparisons or use alternative logic patterns instead.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "limitations", "arithmetic", "operators"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "docs/ADVANCED_RECURSION.md"], "original_answer": "The current version of the compiler driver has a known limitation: it cannot transpile predicates that directly use arithmetic comparison operators (`>`, `<`, `=<`, etc.). Attempting to compile such predicates will cause the compilation to fail. You'll need to refactor your Prolog rules to avoid direct arithmetic comparisons or use alternative logic patterns. See skill_unifyweaver_compile.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_003_q2", "cluster_id": "skill_unifyweaver_compile_003", "question": "Why is my compilation failing with arithmetic operators?", "answer": "Your compilation is failing because the UnifyWeaver compiler driver has a known limitation: it cannot transpile predicates that directly use arithmetic comparison operators like `>`, `<`, `=<`, `>=`, `=:=`, and `=\\=`. When you try to compile a predicate containing these operators, the compilation will fail. To resolve this, you need to refactor your Prolog rules to avoid direct arithmetic comparisons. You may need to use alternative logic patterns or helper predicates that don't rely on these operators. Check the skill documentation for examples of workarounds.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "limitations", "arithmetic", "operators"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "docs/ADVANCED_RECURSION.md"], "original_answer": "The current version of the compiler driver has a known limitation: it cannot transpile predicates that directly use arithmetic comparison operators (`>`, `<`, `=<`, etc.). Attempting to compile such predicates will cause the compilation to fail. You'll need to refactor your Prolog rules to avoid direct arithmetic comparisons or use alternative logic patterns. See skill_unifyweaver_compile.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_003_q3", "cluster_id": "skill_unifyweaver_compile_003", "question": "Are there limitations with math operators in Prolog compilation?", "answer": "Yes, the current version of the UnifyWeaver compiler driver has a known limitation with arithmetic operators. It cannot transpile predicates that directly use arithmetic comparison operators such as `>`, `<`, `=<`, etc. Attempting to compile predicates containing these operators will cause compilation to fail. To work around this, you'll need to refactor your Prolog rules to avoid direct arithmetic comparisons or use alternative logic patterns.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "limitations", "arithmetic", "operators"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/EXTENDED_README.md", "docs/ADVANCED_RECURSION.md"], "original_answer": "The current version of the compiler driver has a known limitation: it cannot transpile predicates that directly use arithmetic comparison operators (`>`, `<`, `=<`, etc.). Attempting to compile such predicates will cause the compilation to fail. You'll need to refactor your Prolog rules to avoid direct arithmetic comparisons or use alternative logic patterns. See skill_unifyweaver_compile.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_004_q0", "cluster_id": "skill_unifyweaver_compile_004", "question": "Do I need to manually handle all the dependencies when compiling a predicate?", "answer": "No, you don't need to manually handle dependencies. The UnifyWeaver compiler automatically analyzes your main predicate and includes all user-defined predicates it depends on. You only need to specify the main predicate indicator (e.g., `choose_strategy/3`) in the compile command, and the compiler resolves and compiles all dependencies into the output bash script.", "question_type": "medium", "topics": ["Compilation", "UnifyWeaver Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "dependencies", "automation"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["src/unifyweaver/core/compiler_driver.pl", "docs/ADVANCED_RECURSION.md"], "original_answer": "No, you don't need to manually handle dependencies. The compiler automatically analyzes and compiles any user-defined predicates that your main predicate depends on. You only need to specify the main predicate indicator (e.g., `choose_strategy/3`) in the compile command, and the compiler will take care of resolving and including all dependencies in the output bash script. See skill_unifyweaver_compile.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_004_q1", "cluster_id": "skill_unifyweaver_compile_004", "question": "How are dependencies handled during compilation?", "answer": "The UnifyWeaver compiler automatically handles dependencies during compilation. When you specify a main predicate indicator (e.g., `choose_strategy/3`) in the compile command, the compiler automatically analyzes the predicate and identifies all user-defined predicates it depends on. These dependencies are then compiled and included in the output bash script without requiring manual intervention. You only need to provide the main predicate; the compiler resolves and includes all necessary dependencies automatically.", "question_type": "medium", "topics": ["Compilation", "UnifyWeaver Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "dependencies", "automation"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["src/unifyweaver/core/compiler_driver.pl", "docs/ADVANCED_RECURSION.md"], "original_answer": "No, you don't need to manually handle dependencies. The compiler automatically analyzes and compiles any user-defined predicates that your main predicate depends on. You only need to specify the main predicate indicator (e.g., `choose_strategy/3`) in the compile command, and the compiler will take care of resolving and including all dependencies in the output bash script. See skill_unifyweaver_compile.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_004_q2", "cluster_id": "skill_unifyweaver_compile_004", "question": "Will the compiler automatically compile predicates that my main predicate depends on?", "answer": "Yes, the compiler automatically analyzes and compiles any user-defined predicates that your main predicate depends on. You only need to specify the main predicate indicator (e.g., `choose_strategy/3`) in the compile command, and the compiler will take care of resolving and including all dependencies in the output bash script.", "question_type": "medium", "topics": ["Compilation", "UnifyWeaver Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "dependencies", "automation"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["src/unifyweaver/core/compiler_driver.pl", "docs/ADVANCED_RECURSION.md"], "original_answer": "No, you don't need to manually handle dependencies. The compiler automatically analyzes and compiles any user-defined predicates that your main predicate depends on. You only need to specify the main predicate indicator (e.g., `choose_strategy/3`) in the compile command, and the compiler will take care of resolving and including all dependencies in the output bash script. See skill_unifyweaver_compile.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_004_q3", "cluster_id": "skill_unifyweaver_compile_004", "question": "What happens with helper predicates during compilation?", "answer": "Recursive predicates are handled through the compiler's dependency analysis, which tracks predicate calls and ensures proper code generation order. When compiling, dependencies are resolved recursively. The transpiler generates target-language code that preserves recursion semantics (e.g., proper tail-call handling where supported).", "question_type": "medium", "topics": ["Compilation", "UnifyWeaver Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "dependencies", "automation"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["src/unifyweaver/core/compiler_driver.pl", "docs/ADVANCED_RECURSION.md"], "original_answer": "No, you don't need to manually handle dependencies. The compiler automatically analyzes and compiles any user-defined predicates that your main predicate depends on. You only need to specify the main predicate indicator (e.g., `choose_strategy/3`) in the compile command, and the compiler will take care of resolving and including all dependencies in the output bash script. See skill_unifyweaver_compile.md for details.", "answer_tailored": true, "confidence": 0.75, "confidence_issues": "Specific recursion optimizations depend on target language", "manually_reviewed": true}
{"pair_id": "skill_unifyweaver_compile_005_q0", "cluster_id": "skill_unifyweaver_compile_005", "question": "What format should I use to specify which predicate to compile?", "answer": "Use the predicate indicator format `functor/arity`, where functor is the predicate name and arity is the number of arguments. For example, `choose_strategy/3` specifies the predicate named `choose_strategy` with 3 arguments. In the compile command, include it as: `compile(choose_strategy/3, [output_dir('.')])`. This format tells the compiler exactly which predicate to transpile from your .pl file.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "predicate", "syntax", "indicators"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["src/unifyweaver/core/compiler_driver.pl"], "original_answer": "Use the predicate indicator format `functor/arity`, where functor is the predicate name and arity is the number of arguments. For example, `choose_strategy/3` means compile the predicate named `choose_strategy` that takes 3 arguments. This format tells the compiler exactly which predicate to transpile from your .pl file. Include it in the compile command as: `compile(choose_strategy/3, [output_dir('.')])`. See skill_unifyweaver_compile.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_005_q1", "cluster_id": "skill_unifyweaver_compile_005", "question": "How do I identify the main predicate to compile?", "answer": "Use the predicate indicator format `functor/arity`, where functor is the predicate name and arity is the number of arguments. For example, `choose_strategy/3` means the predicate named `choose_strategy` that takes 3 arguments. This format identifies which predicate to transpile from your .pl file. Include it in the compile command as: `compile(choose_strategy/3, [output_dir('.')])`. The main predicate is typically the one you want to execute, and the compiler will automatically handle its dependencies.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "predicate", "syntax", "indicators"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["src/unifyweaver/core/compiler_driver.pl"], "original_answer": "Use the predicate indicator format `functor/arity`, where functor is the predicate name and arity is the number of arguments. For example, `choose_strategy/3` means compile the predicate named `choose_strategy` that takes 3 arguments. This format tells the compiler exactly which predicate to transpile from your .pl file. Include it in the compile command as: `compile(choose_strategy/3, [output_dir('.')])`. See skill_unifyweaver_compile.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_005_q2", "cluster_id": "skill_unifyweaver_compile_005", "question": "What's the correct syntax for the predicate indicator?", "answer": "The predicate indicator uses the format `functor/arity`, where `functor` is the predicate name and `arity` is the number of arguments. For example, `choose_strategy/3` specifies the predicate named `choose_strategy` with 3 arguments. Use this format directly in the compile command: `compile(choose_strategy/3, [output_dir('.')])`. The compiler uses this to identify which predicate to transpile from your .pl file.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "predicate", "syntax", "indicators"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["src/unifyweaver/core/compiler_driver.pl"], "original_answer": "Use the predicate indicator format `functor/arity`, where functor is the predicate name and arity is the number of arguments. For example, `choose_strategy/3` means compile the predicate named `choose_strategy` that takes 3 arguments. This format tells the compiler exactly which predicate to transpile from your .pl file. Include it in the compile command as: `compile(choose_strategy/3, [output_dir('.')])`. See skill_unifyweaver_compile.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_005_q3", "cluster_id": "skill_unifyweaver_compile_005", "question": "How do predicates work with their arity in compilation?", "answer": "Predicates in UnifyWeaver compilation are identified using the predicate indicator format `functor/arity`, where `functor` is the predicate name and `arity` specifies the exact number of arguments the predicate accepts. For example, `choose_strategy/3` refers to a predicate named `choose_strategy` that takes exactly 3 arguments. This format is required when invoking the compiler\u2014you specify it as the first argument to the `compile/2` function, like `compile(choose_strategy/3, [output_dir('.')])`. The compiler uses the arity to distinguish between predicates with the same name but different argument counts, ensuring it transpiles the correct version into your executable bash script.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "predicate", "syntax", "indicators"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["src/unifyweaver/core/compiler_driver.pl"], "original_answer": "Use the predicate indicator format `functor/arity`, where functor is the predicate name and arity is the number of arguments. For example, `choose_strategy/3` means compile the predicate named `choose_strategy` that takes 3 arguments. This format tells the compiler exactly which predicate to transpile from your .pl file. Include it in the compile command as: `compile(choose_strategy/3, [output_dir('.')])`. See skill_unifyweaver_compile.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_006_q0", "cluster_id": "skill_unifyweaver_compile_006", "question": "What basic command structure should I use when compiling Prolog to bash?", "answer": "Use this command structure: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<prolog_file>'), compile(<predicate_indicator>, [<options>])\" -t halt`. Replace `<prolog_file>` with your .pl file path and `<predicate_indicator>` with your predicate (e.g., `choose_strategy/3`). Always include `output_dir('.')` in the options list to specify the output directory. The compiler will generate an executable .sh file with the predicate name.", "question_type": "medium", "topics": ["Compilation", "UnifyWeaver Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "command", "template", "swipl"], "related_skills": ["skill_unifyweaver_compile.md", "skill_unifyweaver_environment.md"], "related_docs": ["docs/EXTENDED_README.md"], "original_answer": "The basic command structure is: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<prolog_file>'), compile(<predicate_indicator>, [<options>])\" -t halt`. Replace `<prolog_file>` with your .pl file path, `<predicate_indicator>` with the predicate you want to compile (e.g., `choose_strategy/3`), and include at least `output_dir('.')` in the options. The result is an executable .sh file in your specified output directory. See skill_unifyweaver_compile.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_006_q1", "cluster_id": "skill_unifyweaver_compile_006", "question": "What's the general command format for compilation?", "answer": "The general command format for UnifyWeaver compilation is: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<prolog_file>'), compile(<predicate_indicator>, [<options>])\" -t halt`. You need to provide the path to your Prolog file, the predicate indicator (functor/arity), and options like `output_dir('.')` to specify where the compiled bash script should be saved.", "question_type": "medium", "topics": ["Compilation", "UnifyWeaver Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "command", "template", "swipl"], "related_skills": ["skill_unifyweaver_compile.md", "skill_unifyweaver_environment.md"], "related_docs": ["docs/EXTENDED_README.md"], "original_answer": "The basic command structure is: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<prolog_file>'), compile(<predicate_indicator>, [<options>])\" -t halt`. Replace `<prolog_file>` with your .pl file path, `<predicate_indicator>` with the predicate you want to compile (e.g., `choose_strategy/3`), and include at least `output_dir('.')` in the options. The result is an executable .sh file in your specified output directory. See skill_unifyweaver_compile.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_006_q2", "cluster_id": "skill_unifyweaver_compile_006", "question": "Can you show me the basic template for a compilation command?", "answer": "The basic template for a UnifyWeaver compilation command is:\n\n```bash\nswipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<prolog_file>'), compile(<predicate_indicator>, [<options>])\" -t halt\n```\n\nReplace:\n- `<prolog_file>` with your .pl file path\n- `<predicate_indicator>` with the predicate to compile (format: `functor/arity`, e.g., `choose_strategy/3`)\n- `<options>` with at least `output_dir('.')` to specify where the resulting .sh file should be saved\n\nThe compiler automatically handles predicate dependencies and generates an executable bash script.", "question_type": "medium", "topics": ["Compilation", "UnifyWeaver Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "command", "template", "swipl"], "related_skills": ["skill_unifyweaver_compile.md", "skill_unifyweaver_environment.md"], "related_docs": ["docs/EXTENDED_README.md"], "original_answer": "The basic command structure is: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<prolog_file>'), compile(<predicate_indicator>, [<options>])\" -t halt`. Replace `<prolog_file>` with your .pl file path, `<predicate_indicator>` with the predicate you want to compile (e.g., `choose_strategy/3`), and include at least `output_dir('.')` in the options. The result is an executable .sh file in your specified output directory. See skill_unifyweaver_compile.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_006_q3", "cluster_id": "skill_unifyweaver_compile_006", "question": "How do I structure the swipl command for compilation?", "answer": "To structure the swipl command for compilation, use this format: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<prolog_file>'), compile(<predicate_indicator>, [<options>])\" -t halt`. The key components are: (1) `<prolog_file>` - path to your .pl file, (2) `<predicate_indicator>` - your target predicate in functor/arity format (e.g., `choose_strategy/3`), and (3) `[<options>]` - at minimum include `output_dir('.')` to specify where the compiled .sh file is saved. The compiler automatically handles dependencies of your main predicate.", "question_type": "medium", "topics": ["Compilation", "UnifyWeaver Prolog-to-Bash Transpiler"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compilation", "command", "template", "swipl"], "related_skills": ["skill_unifyweaver_compile.md", "skill_unifyweaver_environment.md"], "related_docs": ["docs/EXTENDED_README.md"], "original_answer": "The basic command structure is: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('<prolog_file>'), compile(<predicate_indicator>, [<options>])\" -t halt`. Replace `<prolog_file>` with your .pl file path, `<predicate_indicator>` with the predicate you want to compile (e.g., `choose_strategy/3`), and include at least `output_dir('.')` in the options. The result is an executable .sh file in your specified output directory. See skill_unifyweaver_compile.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_001_q0", "cluster_id": "skill_unifyweaver_environment_001", "question": "I'm getting an error that says 'source_sink library(...) does not exist' when trying to run a Prolog script. How do I fix this?", "answer": "This error occurs because the module search path isn't configured for UnifyWeaver modules. To fix it: (1) Ensure you're running from the project root directory, (2) Use `swipl -f init.pl -g \"consult('your_script.pl'), halt\"` to load the initialization file that sets up the search paths, or (3) If not using init.pl, use relative paths in your script: `:- use_module('src/unifyweaver/sources').` The init.pl approach is recommended as it automatically configures `file_search_path(unifyweaver, 'src/unifyweaver')` and `library_directory('src')` for you.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["module-loading", "error-handling", "prolog"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["init.pl", "scripts/testing/init_testing.sh", "templates/init_template.pl"], "original_answer": "This error means the module path isn't in your search path. Run from the project root and use `swipl -f init.pl -g \"use_module(library(unifyweaver/sources)), halt\"`. If that doesn't work, use relative paths instead: `:- use_module('src/unifyweaver/sources').` See skill_unifyweaver_environment.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_001_q1", "cluster_id": "skill_unifyweaver_environment_001", "question": "Why can't Prolog find my UnifyWeaver modules?", "answer": "Prolog can't find UnifyWeaver modules because the module search path isn't configured. This typically happens when: (1) You're not running from the project root directory, (2) The `init.pl` initialization file isn't being loaded, or (3) You're using incorrect module path syntax. To fix this: First, ensure you're in the UnifyWeaver project root directory. Then use `swipl -f init.pl -g \"use_module(library(unifyweaver/sources)), halt\"` to load modules with proper initialization. Alternatively, use relative paths directly: `:- use_module('src/unifyweaver/sources').` The `init.pl` file automatically sets up the file search path and library directories, so using `-f init.pl` when launching SWI-Prolog is the recommended approach for all UnifyWeaver scripts and playbooks.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["module-loading", "error-handling", "prolog"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["init.pl", "scripts/testing/init_testing.sh", "templates/init_template.pl"], "original_answer": "This error means the module path isn't in your search path. Run from the project root and use `swipl -f init.pl -g \"use_module(library(unifyweaver/sources)), halt\"`. If that doesn't work, use relative paths instead: `:- use_module('src/unifyweaver/sources').` See skill_unifyweaver_environment.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_001_q2", "cluster_id": "skill_unifyweaver_environment_001", "question": "How do I fix module loading errors in Prolog scripts?", "answer": "Module loading errors occur when Prolog can't find the modules in its search path. To fix this: (1) Always run from the project root directory, (2) Use `swipl -f init.pl -g \"use_module(library(unifyweaver/sources)), halt\"` which automatically configures all paths, or (3) If init.pl isn't available, use relative paths in your script: `:- use_module('src/unifyweaver/sources').` The init.pl approach is recommended because it handles all path configuration automatically without manual setup.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["module-loading", "error-handling", "prolog"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["init.pl", "scripts/testing/init_testing.sh", "templates/init_template.pl"], "original_answer": "This error means the module path isn't in your search path. Run from the project root and use `swipl -f init.pl -g \"use_module(library(unifyweaver/sources)), halt\"`. If that doesn't work, use relative paths instead: `:- use_module('src/unifyweaver/sources').` See skill_unifyweaver_environment.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_001_q3", "cluster_id": "skill_unifyweaver_environment_001", "question": "What does 'library(...) does not exist' mean and how do I resolve it?", "answer": "The error 'library(...) does not exist' means the Prolog module search path isn't configured to find your UnifyWeaver modules. To resolve it: (1) Run commands from the project root directory, (2) Use `swipl -f init.pl` to automatically set up the file search paths, or (3) Use relative paths in your code like `:- use_module('src/unifyweaver/sources').` instead of the `library(...)` syntax. The init.pl file handles all path configuration automatically, so `-f init.pl` is the recommended approach.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["module-loading", "error-handling", "prolog"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["init.pl", "scripts/testing/init_testing.sh", "templates/init_template.pl"], "original_answer": "This error means the module path isn't in your search path. Run from the project root and use `swipl -f init.pl -g \"use_module(library(unifyweaver/sources)), halt\"`. If that doesn't work, use relative paths instead: `:- use_module('src/unifyweaver/sources').` See skill_unifyweaver_environment.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_002_q0", "cluster_id": "skill_unifyweaver_environment_002", "question": "What's the correct way to run UnifyWeaver Prolog scripts?", "answer": "The correct way to run UnifyWeaver Prolog scripts depends on your use case. For standalone scripts, use `init.pl` initialization: first `cd` to the project root, then run `swipl -f init.pl -g \"goal, halt\"`. This automatically sets up module paths and allows using `library(unifyweaver/...)` syntax. For playbooks or when you need reproducibility, use inline initialization: `swipl -q -g \"asserta(file_search_path(unifyweaver, 'src/unifyweaver')), [script.pl], goal, halt\"`. The critical requirement is always running from the project root directory, since UnifyWeaver modules use relative paths from there.", "question_type": "medium", "topics": ["Compilation", "UnifyWeaver Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["script-execution", "playbooks", "prolog"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["init.pl", "playbooks/README.md", "templates/init_template.pl"], "original_answer": "Use `init.pl` for scripts: First `cd /path/to/UnifyWeaver`, then run `swipl -f init.pl -g \"goal, halt\"`. For playbooks, use inline initialization with `swipl -q -g \"asserta(file_search_path(unifyweaver, 'src/unifyweaver')), [script.pl], goal, halt\"`. Always run from the project root directory. See skill_unifyweaver_environment.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_002_q1", "cluster_id": "skill_unifyweaver_environment_002", "question": "How do I execute Prolog scripts with UnifyWeaver modules?", "answer": "To execute Prolog scripts with UnifyWeaver modules, use `init.pl` from the project root: `cd /path/to/UnifyWeaver` then run `swipl -f init.pl -g \"consult('script.pl'), goal, halt\"`. The `init.pl` file automatically sets up module paths and search paths, allowing you to use `library(unifyweaver/...)` syntax. For inline initialization without init.pl, use `swipl -q -g \"asserta(file_search_path(unifyweaver, 'src/unifyweaver')), consult('script.pl'), goal, halt\"`. Always execute from the project root directory.", "question_type": "medium", "topics": ["Compilation", "UnifyWeaver Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["script-execution", "playbooks", "prolog"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["init.pl", "playbooks/README.md", "templates/init_template.pl"], "original_answer": "Use `init.pl` for scripts: First `cd /path/to/UnifyWeaver`, then run `swipl -f init.pl -g \"goal, halt\"`. For playbooks, use inline initialization with `swipl -q -g \"asserta(file_search_path(unifyweaver, 'src/unifyweaver')), [script.pl], goal, halt\"`. Always run from the project root directory. See skill_unifyweaver_environment.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_002_q2", "cluster_id": "skill_unifyweaver_environment_002", "question": "Should I use init.pl or inline initialization for running scripts?", "answer": "Use `init.pl` for running scripts. Change to the project root directory, then execute `swipl -f init.pl -g \"goal, halt\"`. This automatically sets up the module search paths and allows you to use `library(unifyweaver/...)` syntax. For playbooks, use inline initialization instead with `swipl -q -g \"asserta(file_search_path(unifyweaver, 'src/unifyweaver')), [script.pl], goal, halt\"`. The key difference: `init.pl` is the recommended approach for standalone scripts, while inline initialization is preferred for playbooks to ensure reproducibility.", "question_type": "medium", "topics": ["Compilation", "UnifyWeaver Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["script-execution", "playbooks", "prolog"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["init.pl", "playbooks/README.md", "templates/init_template.pl"], "original_answer": "Use `init.pl` for scripts: First `cd /path/to/UnifyWeaver`, then run `swipl -f init.pl -g \"goal, halt\"`. For playbooks, use inline initialization with `swipl -q -g \"asserta(file_search_path(unifyweaver, 'src/unifyweaver')), [script.pl], goal, halt\"`. Always run from the project root directory. See skill_unifyweaver_environment.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_002_q3", "cluster_id": "skill_unifyweaver_environment_002", "question": "What's the recommended approach for running UnifyWeaver playbooks?", "answer": "For UnifyWeaver playbooks, use inline initialization with `swipl -q -g \"asserta(file_search_path(unifyweaver, 'src/unifyweaver')), [script.pl], goal, halt\"`. This approach is recommended for reproducibility and eliminates the need for separate initialization files. Always run from the project root directory to ensure relative paths resolve correctly.", "question_type": "medium", "topics": ["Compilation", "UnifyWeaver Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["script-execution", "playbooks", "prolog"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["init.pl", "playbooks/README.md", "templates/init_template.pl"], "original_answer": "Use `init.pl` for scripts: First `cd /path/to/UnifyWeaver`, then run `swipl -f init.pl -g \"goal, halt\"`. For playbooks, use inline initialization with `swipl -q -g \"asserta(file_search_path(unifyweaver, 'src/unifyweaver')), [script.pl], goal, halt\"`. Always run from the project root directory. See skill_unifyweaver_environment.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_003_q0", "cluster_id": "skill_unifyweaver_environment_003", "question": "I'm getting an 'Unknown procedure' error when running a Prolog script. How do I fix it?", "answer": "An 'Unknown procedure' error means a required module wasn't loaded. To fix it: (1) Add `:- use_module('src/unifyweaver/...')` directives to your script for each module you need. (2) Verify the module file exists at the specified path and exports the predicate you're using. (3) Ensure you're running from the project root directory, as UnifyWeaver uses relative paths. (4) If using init.pl, run with `swipl -f init.pl -g \"consult('your_script.pl'), goal, halt\"` to automatically set up the module search paths. Check skill_unifyweaver_environment.md for detailed setup instructions.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["module-loading", "error-handling", "debugging"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["src/unifyweaver/", "init.pl"], "original_answer": "This means a required module wasn't loaded. Add `:- use_module('src/unifyweaver/...')` directives to your script. Make sure the module file exists and exports the predicate you're using. Also verify you're running from the project root directory. See skill_unifyweaver_environment.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_003_q1", "cluster_id": "skill_unifyweaver_environment_003", "question": "Why is Prolog saying my predicates don't exist?", "answer": "This error occurs when a required module isn't loaded in your Prolog script. To fix it: (1) Add `:- use_module('src/unifyweaver/...')` directives at the top of your script to load the modules containing those predicates; (2) Verify the module file exists at the path you're referencing; (3) Check that the module actually exports the predicate you're trying to use; (4) Ensure you're running your script from the UnifyWeaver project root directory, since module paths are relative to the current working directory. If using init.pl, run with `swipl -f init.pl -g \"consult('your_script.pl'), halt\"` to automatically set up the environment.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["module-loading", "error-handling", "debugging"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["src/unifyweaver/", "init.pl"], "original_answer": "This means a required module wasn't loaded. Add `:- use_module('src/unifyweaver/...')` directives to your script. Make sure the module file exists and exports the predicate you're using. Also verify you're running from the project root directory. See skill_unifyweaver_environment.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_003_q2", "cluster_id": "skill_unifyweaver_environment_003", "question": "How do I load modules to fix 'Unknown procedure' errors?", "answer": "To fix 'Unknown procedure' errors, you need to load the required module using `:- use_module('src/unifyweaver/...')` directives at the top of your script. First, verify that the module file exists in the `src/unifyweaver/` directory and exports the predicate you're trying to use. Ensure you're running from the project root directory, as UnifyWeaver modules use relative paths. If you're using init.pl (recommended), run `swipl -f init.pl -g \"goal, halt\"` from the project root, which automatically sets up module paths. Without init.pl, manually add the use_module directives and ensure your working directory is correct.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["module-loading", "error-handling", "debugging"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["src/unifyweaver/", "init.pl"], "original_answer": "This means a required module wasn't loaded. Add `:- use_module('src/unifyweaver/...')` directives to your script. Make sure the module file exists and exports the predicate you're using. Also verify you're running from the project root directory. See skill_unifyweaver_environment.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_003_q3", "cluster_id": "skill_unifyweaver_environment_003", "question": "What causes 'Unknown procedure' errors in UnifyWeaver scripts?", "answer": "'Unknown procedure' errors occur when a required module containing the predicate hasn't been loaded. To fix this: (1) Add `:- use_module('src/unifyweaver/...')` directives for the modules you need, (2) Verify the module file exists at the specified path, (3) Confirm the predicate is exported by that module, (4) Ensure you're running from the project root directory where relative paths are resolved correctly. For scripts using UnifyWeaver, use `swipl -f init.pl -g \"consult('script.pl'), goal, halt\"` to automatically set up the module search paths.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["module-loading", "error-handling", "debugging"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["src/unifyweaver/", "init.pl"], "original_answer": "This means a required module wasn't loaded. Add `:- use_module('src/unifyweaver/...')` directives to your script. Make sure the module file exists and exports the predicate you're using. Also verify you're running from the project root directory. See skill_unifyweaver_environment.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_004_q0", "cluster_id": "skill_unifyweaver_environment_004", "question": "Where should I run UnifyWeaver Prolog commands from?", "answer": "Always run UnifyWeaver Prolog commands from the project root directory. This is where `src/unifyweaver/`, `playbooks/`, `templates/`, and `scripts/` are located. Module paths are relative to this root, and `init.pl` uses its own location to determine the project root. Running from elsewhere will cause module loading to fail with errors like \"source_sink 'library(...)' does not exist\".", "question_type": "medium", "topics": ["Compilation", "UnifyWeaver Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["working-directory", "setup", "best-practices"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["init.pl"], "original_answer": "Always run from the project root directory. UnifyWeaver expects to find `src/unifyweaver/`, `playbooks/`, `templates/`, and `scripts/` subdirectories. Module paths are relative to this root, and `init.pl` uses its own location to determine the project root. Running from elsewhere will cause module loading to fail. See skill_unifyweaver_environment.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_004_q1", "cluster_id": "skill_unifyweaver_environment_004", "question": "Does working directory matter when running UnifyWeaver scripts?", "answer": "Yes, you can create an isolated UnifyWeaver environment for testing. Run `bash scripts/testing/init_testing.sh` from the project root. Options include: `-d <dir>` to specify parent directory for test_env, `-p <path>` for custom full path, and `--force-windows` to test Windows wrapper logic. The script creates a self-contained environment with all dependencies.", "question_type": "medium", "topics": ["Compilation", "UnifyWeaver Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["working-directory", "setup", "best-practices"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["init.pl"], "original_answer": "Always run from the project root directory. UnifyWeaver expects to find `src/unifyweaver/`, `playbooks/`, `templates/`, and `scripts/` subdirectories. Module paths are relative to this root, and `init.pl` uses its own location to determine the project root. Running from elsewhere will cause module loading to fail. See skill_unifyweaver_environment.md for details.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_unifyweaver_environment_004_q2", "cluster_id": "skill_unifyweaver_environment_004", "question": "Why should I run commands from the project root?", "answer": "You should run commands from the project root because UnifyWeaver modules use relative paths from that location to find `src/unifyweaver/`, `playbooks/`, `templates/`, and `scripts/` subdirectories. The `init.pl` initialization file determines the project root from its own location, so running from elsewhere will cause module loading to fail with errors like \"source_sink 'library(...)' does not exist\".", "question_type": "medium", "topics": ["Compilation", "UnifyWeaver Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["working-directory", "setup", "best-practices"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["init.pl"], "original_answer": "Always run from the project root directory. UnifyWeaver expects to find `src/unifyweaver/`, `playbooks/`, `templates/`, and `scripts/` subdirectories. Module paths are relative to this root, and `init.pl` uses its own location to determine the project root. Running from elsewhere will cause module loading to fail. See skill_unifyweaver_environment.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_004_q3", "cluster_id": "skill_unifyweaver_environment_004", "question": "What directory structure does UnifyWeaver expect?", "answer": "The test environment initialization process uses `scripts/testing/init_testing.sh`. Run it from the project root with options like `-d <dir>` for custom parent directory or `-p <path>` for full custom path. It configures SWI-Prolog paths, backs up existing configs, and creates an isolated test environment. Use `--help` to see all options.", "question_type": "medium", "topics": ["Compilation", "UnifyWeaver Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["working-directory", "setup", "best-practices"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["init.pl"], "original_answer": "Always run from the project root directory. UnifyWeaver expects to find `src/unifyweaver/`, `playbooks/`, `templates/`, and `scripts/` subdirectories. Module paths are relative to this root, and `init.pl` uses its own location to determine the project root. Running from elsewhere will cause module loading to fail. See skill_unifyweaver_environment.md for details.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_unifyweaver_environment_005_q0", "cluster_id": "skill_unifyweaver_environment_005", "question": "How do I set up an isolated testing environment for UnifyWeaver?", "answer": "To set up an isolated testing environment for UnifyWeaver, run `bash scripts/testing/init_testing.sh` from the project root. This creates a self-contained test environment. Use `-d /tmp` to create it in /tmp, or `-p /path/to/custom_env` for a custom location. The script handles SWI-Prolog configuration and path setup automatically.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["testing", "isolated-environment", "setup"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["scripts/testing/init_testing.sh"], "original_answer": "Run `bash scripts/testing/init_testing.sh` from the project root. This creates a self-contained test environment at `scripts/testing/test_env` with all modules copied. Then `cd scripts/testing/test_env` and run `./unifyweaver.sh`. This approach isolates your tests from the main environment. See skill_unifyweaver_environment.md for details.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_unifyweaver_environment_005_q1", "cluster_id": "skill_unifyweaver_environment_005", "question": "Can I test UnifyWeaver scripts in isolation?", "answer": "Yes. Run `bash scripts/testing/init_testing.sh` from the project root to create a self-contained test environment at `scripts/testing/test_env` with all necessary modules copied. Then `cd scripts/testing/test_env` and run `./unifyweaver.sh` to execute tests in isolation from the main environment.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["testing", "isolated-environment", "setup"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["scripts/testing/init_testing.sh"], "original_answer": "Run `bash scripts/testing/init_testing.sh` from the project root. This creates a self-contained test environment at `scripts/testing/test_env` with all modules copied. Then `cd scripts/testing/test_env` and run `./unifyweaver.sh`. This approach isolates your tests from the main environment. See skill_unifyweaver_environment.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "The base answer references 'skill_unifyweaver_environment.md' which doesn't appear in the provided skill document. The answer assumes the testing script and structure exist but provides no details on what tests can be run or how to write them. Confidence is moderate because the isolation approach is clear, but the practical testing workflow is incomplete."}
{"pair_id": "skill_unifyweaver_environment_005_q2", "cluster_id": "skill_unifyweaver_environment_005", "question": "What's the test environment initialization script?", "answer": "The test environment initialization script is `scripts/testing/init_testing.sh`. Run it with `bash scripts/testing/init_testing.sh` from the project root. It accepts options: `-d <dir>` for parent directory, `-p <path>` for full custom path, `--force-windows` for Windows testing, and `--help` for usage info.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["testing", "isolated-environment", "setup"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["scripts/testing/init_testing.sh"], "original_answer": "Run `bash scripts/testing/init_testing.sh` from the project root. This creates a self-contained test environment at `scripts/testing/test_env` with all modules copied. Then `cd scripts/testing/test_env` and run `./unifyweaver.sh`. This approach isolates your tests from the main environment. See skill_unifyweaver_environment.md for details.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_unifyweaver_environment_005_q3", "cluster_id": "skill_unifyweaver_environment_005", "question": "How do I use scripts/testing/init_testing.sh?", "answer": "From the project root, run `bash scripts/testing/init_testing.sh` to create a self-contained test environment at `scripts/testing/test_env`. Optionally use `-d <dir>` to specify a custom parent directory or `-p <path>` for a custom full path. The script copies all core modules, templates, scripts, and configs to the test environment. Then navigate to the test environment directory and run `./unifyweaver.sh` to launch the Prolog interactive session with UnifyWeaver modules initialized.", "question_type": "long", "topics": ["Compilation", "UnifyWeaver Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["testing", "isolated-environment", "setup"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["scripts/testing/init_testing.sh"], "original_answer": "Run `bash scripts/testing/init_testing.sh` from the project root. This creates a self-contained test environment at `scripts/testing/test_env` with all modules copied. Then `cd scripts/testing/test_env` and run `./unifyweaver.sh`. This approach isolates your tests from the main environment. See skill_unifyweaver_environment.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": "The base answer was mostly accurate but omitted the command-line options (-d, -p) that the script actually supports, and didn't mention that the script prompts for configuration settings at the end. The confidence is high because the core information is correct, but the omitted details represent incomplete coverage."}
{"pair_id": "skill_unifyweaver_environment_006_q0", "cluster_id": "skill_unifyweaver_environment_006", "question": "Can I run UnifyWeaver scripts interactively and what module syntax should I use?", "answer": "Yes, you can run UnifyWeaver scripts interactively. From the project root, use `swipl -f init.pl` to start an interactive session. This loads `init.pl` which automatically sets up the file search paths, allowing you to use `library(unifyweaver/...)` syntax for modules like `use_module(library(unifyweaver/sources))`. Without `init.pl`, you must use relative paths instead: `:- use_module('src/unifyweaver/sources').` Always ensure you're running from the project root directory where `init.pl` is located.", "question_type": "medium", "topics": ["Compilation", "UnifyWeaver Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["interactive-session", "module-paths", "prolog-syntax"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["init.pl", "templates/init_template.pl"], "original_answer": "Yes, use `swipl -f init.pl` from the project root to start an interactive session. Once loaded, `init.pl` sets up the paths so you can use `library(unifyweaver/...)` syntax. Without `init.pl`, use relative paths like `:- use_module('src/unifyweaver/sources').` instead. Always run from project root. See skill_unifyweaver_environment.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_006_q1", "cluster_id": "skill_unifyweaver_environment_006", "question": "How do I start an interactive Prolog session with UnifyWeaver?", "answer": "To start an interactive Prolog session with UnifyWeaver, run `swipl -f init.pl` from the project root directory. This loads the initialization file which automatically sets up the module search paths. Once loaded, you can use the `library(unifyweaver/...)` syntax to load modules. For example: `use_module(library(unifyweaver/sources)).`", "question_type": "medium", "topics": ["Compilation", "UnifyWeaver Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["interactive-session", "module-paths", "prolog-syntax"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["init.pl", "templates/init_template.pl"], "original_answer": "Yes, use `swipl -f init.pl` from the project root to start an interactive session. Once loaded, `init.pl` sets up the paths so you can use `library(unifyweaver/...)` syntax. Without `init.pl`, use relative paths like `:- use_module('src/unifyweaver/sources').` instead. Always run from project root. See skill_unifyweaver_environment.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_006_q2", "cluster_id": "skill_unifyweaver_environment_006", "question": "Should I use library(...) or relative paths for module loading?", "answer": "Use `library(unifyweaver/...)` syntax when running with `swipl -f init.pl` from the project root, as init.pl sets up the necessary file search paths. Without init.pl, use relative paths like `:- use_module('src/unifyweaver/sources').` instead. The choice depends on your execution method: init.pl enables library syntax, direct execution requires relative paths.", "question_type": "medium", "topics": ["Compilation", "UnifyWeaver Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["interactive-session", "module-paths", "prolog-syntax"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["init.pl", "templates/init_template.pl"], "original_answer": "Yes, use `swipl -f init.pl` from the project root to start an interactive session. Once loaded, `init.pl` sets up the paths so you can use `library(unifyweaver/...)` syntax. Without `init.pl`, use relative paths like `:- use_module('src/unifyweaver/sources').` instead. Always run from project root. See skill_unifyweaver_environment.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_environment_006_q3", "cluster_id": "skill_unifyweaver_environment_006", "question": "What's the difference between library(unifyweaver/...) and 'src/unifyweaver/...'?", "answer": "library(unifyweaver/...) is used after init.pl sets up the file search path, mapping 'unifyweaver' to 'src/unifyweaver'. The 'src/unifyweaver/...' syntax uses relative paths directly from the project root without needing init.pl. Use library() with init.pl for cleaner code; use relative paths when init.pl isn't available or for standalone scripts.", "question_type": "medium", "topics": ["Compilation", "UnifyWeaver Environment Setup"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["interactive-session", "module-paths", "prolog-syntax"], "related_skills": ["skill_unifyweaver_environment.md"], "related_docs": ["init.pl", "templates/init_template.pl"], "original_answer": "Yes, use `swipl -f init.pl` from the project root to start an interactive session. Once loaded, `init.pl` sets up the paths so you can use `library(unifyweaver/...)` syntax. Without `init.pl`, use relative paths like `:- use_module('src/unifyweaver/sources').` instead. Always run from project root. See skill_unifyweaver_environment.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_001_q0", "cluster_id": "skill_unifyweaver_compile_001", "question": "How do I compile Prolog to Bash with UnifyWeaver?", "answer": "To compile Prolog to Bash with UnifyWeaver, use the compiler_driver via SWI-Prolog: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('my_rules.pl'), compile(my_predicate/2, [output_dir('.')])\" -t halt`. Replace 'my_rules.pl' with your Prolog file path and 'my_predicate/2' with your target predicate indicator (functor/arity). This generates an executable .sh file in the specified output directory. Always set output_dir to a known location to avoid unexpected file placement. Known limitation: arithmetic comparison operators (>, <, =<) are not currently supported.", "question_type": "medium", "topics": ["Compilation", "Prolog to Bash"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compile", "prolog", "bash", "transpile"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["src/unifyweaver/core/compiler_driver.pl", "docs/EXTENDED_README.md"], "original_answer": "Use the compiler_driver: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('my_rules.pl'), compile(my_predicate/2, [output_dir('.')])\" -t halt`. This generates an executable .sh file. Always set output_dir to a known location. Note: arithmetic operators (>, <, =<) are not currently supported.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_001_q1", "cluster_id": "skill_unifyweaver_compile_001", "question": "How do I transpile Prolog to shell scripts?", "answer": "To transpile Prolog to shell scripts, use the UnifyWeaver compiler_driver with the command: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('my_rules.pl'), compile(my_predicate/2, [output_dir('.')])\" -t halt`. Replace 'my_rules.pl' with your Prolog file path and 'my_predicate/2' with your target predicate in functor/arity format. This generates an executable .sh file in the specified output directory. Always set output_dir to a known location like '.'. Note that arithmetic operators (>, <, =<) are not currently supported and will cause compilation to fail.", "question_type": "medium", "topics": ["Compilation", "Prolog to Bash"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compile", "prolog", "bash", "transpile"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["src/unifyweaver/core/compiler_driver.pl", "docs/EXTENDED_README.md"], "original_answer": "Use the compiler_driver: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('my_rules.pl'), compile(my_predicate/2, [output_dir('.')])\" -t halt`. This generates an executable .sh file. Always set output_dir to a known location. Note: arithmetic operators (>, <, =<) are not currently supported.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_001_q2", "cluster_id": "skill_unifyweaver_compile_001", "question": "Can UnifyWeaver generate executable bash?", "answer": "Yes, UnifyWeaver can generate executable bash scripts. Use the compiler_driver with the command: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('my_rules.pl'), compile(my_predicate/2, [output_dir('.')])\" -t halt`. This generates an executable .sh file from Prolog source code. Always specify output_dir to a known location. Note that arithmetic operators (>, <, =<) are not currently supported.", "question_type": "medium", "topics": ["Compilation", "Prolog to Bash"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compile", "prolog", "bash", "transpile"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["src/unifyweaver/core/compiler_driver.pl", "docs/EXTENDED_README.md"], "original_answer": "Use the compiler_driver: `swipl -g \"use_module('src/unifyweaver/core/compiler_driver'), consult('my_rules.pl'), compile(my_predicate/2, [output_dir('.')])\" -t halt`. This generates an executable .sh file. Always set output_dir to a known location. Note: arithmetic operators (>, <, =<) are not currently supported.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_002_q0", "cluster_id": "skill_unifyweaver_compile_002", "question": "What are the limitations of the UnifyWeaver compiler?", "answer": "The UnifyWeaver compiler has a known limitation: the current version of the compiler_driver cannot transpile predicates that directly use arithmetic comparison operators such as >, <, =<, and >=. These operators will cause compilation to fail. To work around this limitation, you can use helper predicates or restructure your logic to avoid direct arithmetic comparisons. The compiler does automatically handle user-defined predicate dependencies, though it may encounter issues with complex nested structures.", "question_type": "long", "topics": ["Compilation", "Limitations"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compile", "limitations", "arithmetic"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/ADVANCED_RECURSION.md"], "original_answer": "The current compiler_driver cannot transpile predicates with direct arithmetic comparison operators (>, <, =<, >=). These cause compilation to fail. Work around by using helper predicates or restructuring logic. The compiler automatically handles user-defined predicate dependencies but may have issues with complex nested structures.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_002_q1", "cluster_id": "skill_unifyweaver_compile_002", "question": "What can't UnifyWeaver compile?", "answer": "UnifyWeaver's compiler_driver has a known limitation: it cannot transpile predicates that directly use arithmetic comparison operators (>, <, =<, >=). These operators will cause compilation to fail. To work around this limitation, you can use helper predicates or restructure your logic to avoid direct arithmetic comparisons.", "question_type": "long", "topics": ["Compilation", "Limitations"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compile", "limitations", "arithmetic"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/ADVANCED_RECURSION.md"], "original_answer": "The current compiler_driver cannot transpile predicates with direct arithmetic comparison operators (>, <, =<, >=). These cause compilation to fail. Work around by using helper predicates or restructuring logic. The compiler automatically handles user-defined predicate dependencies but may have issues with complex nested structures.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_unifyweaver_compile_002_q2", "cluster_id": "skill_unifyweaver_compile_002", "question": "Are there any known compiler issues?", "answer": "Yes, the current compiler_driver has a known limitation: it cannot transpile predicates that directly use arithmetic comparison operators (>, <, =<, >=). When these operators are used, compilation will fail. To work around this limitation, you can use helper predicates or restructure your logic to avoid direct arithmetic comparisons. The compiler successfully handles user-defined predicate dependencies automatically, but may encounter issues with complex nested structures.", "question_type": "long", "topics": ["Compilation", "Limitations"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["compile", "limitations", "arithmetic"], "related_skills": ["skill_unifyweaver_compile.md"], "related_docs": ["docs/ADVANCED_RECURSION.md"], "original_answer": "The current compiler_driver cannot transpile predicates with direct arithmetic comparison operators (>, <, =<, >=). These cause compilation to fail. Work around by using helper predicates or restructuring logic. The compiler automatically handles user-defined predicate dependencies but may have issues with complex nested structures.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_transpiler_extension_001_q0", "cluster_id": "skill_transpiler_extension_001", "question": "How do I add a new data source to UnifyWeaver?", "answer": "To add a new data source to UnifyWeaver, use the `source(TYPE, NAME, [OPTIONS])` directive. For built-in types (json, csv, xml, yaml, sqlite, http, python, semantic), specify the type and configuration options. For custom sources, create a plugin module implementing source_info/1 (metadata), validate_config/1 (validation), and compile_source/4 (code generation), then register it with `register_source_type(my_format, my_module)` during module initialization.", "question_type": "medium", "topics": ["Compilation", "Extension", "Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["source", "extension", "plugin", "data"], "related_skills": ["skill_transpiler_extension.md", "skill_json_sources.md"], "related_docs": ["src/unifyweaver/sources/", "src/unifyweaver/core/dynamic_source_compiler.pl"], "original_answer": "Declare a source with `source(TYPE, NAME, [OPTIONS])`. Built-in types: json, csv, xml, yaml, sqlite, http, python, semantic. For custom sources, create a plugin module with source_info/1, validate_config/1, and compile_source/4, then register with `register_source_type(my_format, my_module)`.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_transpiler_extension_001_q1", "cluster_id": "skill_transpiler_extension_001", "question": "Can I read from custom file formats?", "answer": "Yes. Declare a custom source using `source(TYPE, NAME, [OPTIONS])`. For custom file formats, create a plugin module implementing source_info/1, validate_config/1, and compile_source/4, then register it with `register_source_type(my_format, my_module)`. Built-in types (json, csv, xml, yaml, sqlite, http, python, semantic) are available immediately; custom types require plugin registration.", "question_type": "medium", "topics": ["Compilation", "Extension", "Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["source", "extension", "plugin", "data"], "related_skills": ["skill_transpiler_extension.md", "skill_json_sources.md"], "related_docs": ["src/unifyweaver/sources/", "src/unifyweaver/core/dynamic_source_compiler.pl"], "original_answer": "Declare a source with `source(TYPE, NAME, [OPTIONS])`. Built-in types: json, csv, xml, yaml, sqlite, http, python, semantic. For custom sources, create a plugin module with source_info/1, validate_config/1, and compile_source/4, then register with `register_source_type(my_format, my_module)`.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_transpiler_extension_001_q2", "cluster_id": "skill_transpiler_extension_001", "question": "How do I create a source plugin?", "answer": "To create a source plugin, create a Prolog module with three required predicates: source_info/1 (metadata), validate_config/1 (configuration validation), and compile_source/4 (generates target code). Register your plugin using register_source_type(format_name, module_name). See the custom source example in the skill document for the complete structure including module declaration and initialization.", "question_type": "medium", "topics": ["Compilation", "Extension", "Sources"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["source", "extension", "plugin", "data"], "related_skills": ["skill_transpiler_extension.md", "skill_json_sources.md"], "related_docs": ["src/unifyweaver/sources/", "src/unifyweaver/core/dynamic_source_compiler.pl"], "original_answer": "Declare a source with `source(TYPE, NAME, [OPTIONS])`. Built-in types: json, csv, xml, yaml, sqlite, http, python, semantic. For custom sources, create a plugin module with source_info/1, validate_config/1, and compile_source/4, then register with `register_source_type(my_format, my_module)`.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_transpiler_extension_002_q0", "cluster_id": "skill_transpiler_extension_002", "question": "How do I map Prolog predicates to Python functions?", "answer": "Use bindings to map Prolog predicates to Python functions with the `binding/6` directive. For example: `binding(python, string_length/2, 'len', [string], [int], [pure])` maps the Prolog predicate `string_length/2` to Python's `len()` function. The directive specifies the target language (python), the Prolog predicate and arity (string_length/2), the target function name ('len'), input types ([string]), output types ([int]), and properties ([pure] for side-effect-free functions). Additional properties include `effect(io)` for I/O operations, `effect(state)` for state mutations, `import(Module)` to specify the Python module, and `deterministic` for functions with single solutions. Initialize bindings with `:- init_python_bindings.` to activate Python binding support.", "question_type": "medium", "topics": ["Compilation", "Extension", "Bindings"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["bindings", "python", "ffi", "mapping"], "related_skills": ["skill_transpiler_extension.md"], "related_docs": ["src/unifyweaver/bindings/python_bindings.pl", "docs/BINDING_MATRIX.md"], "original_answer": "Use bindings: `binding(python, string_length/2, 'len', [string], [int], [pure])`. This maps the Prolog predicate to Python's len(). Options include pure, effect(io), effect(state), import(Module), and deterministic. Initialize with `:- init_python_bindings.` Available binding modules exist for Python, Go, Rust, Bash, C#, PowerShell, and 20+ targets.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_transpiler_extension_002_q1", "cluster_id": "skill_transpiler_extension_002", "question": "Can I call Python stdlib from Prolog?", "answer": "Yes, use bindings to call Python stdlib functions from Prolog. Define a binding like `binding(python, string_length/2, 'len', [string], [int], [pure])` to map a Prolog predicate to Python's `len()` function. The binding specifies the predicate name/arity, target function, input types, output types, and properties (pure, io effects, state effects, etc.). Initialize with `:- init_python_bindings.` The transpiler generates target code that calls the Python stdlib function. Binding modules are available for Python and 20+ other languages.", "question_type": "medium", "topics": ["Compilation", "Extension", "Bindings"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["bindings", "python", "ffi", "mapping"], "related_skills": ["skill_transpiler_extension.md"], "related_docs": ["src/unifyweaver/bindings/python_bindings.pl", "docs/BINDING_MATRIX.md"], "original_answer": "Use bindings: `binding(python, string_length/2, 'len', [string], [int], [pure])`. This maps the Prolog predicate to Python's len(). Options include pure, effect(io), effect(state), import(Module), and deterministic. Initialize with `:- init_python_bindings.` Available binding modules exist for Python, Go, Rust, Bash, C#, PowerShell, and 20+ targets.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_transpiler_extension_002_q2", "cluster_id": "skill_transpiler_extension_002", "question": "How do bindings work?", "answer": "Bindings map Prolog predicates to target language functions. Use the syntax `binding(TargetLanguage, PrologPredicate/Arity, 'FunctionName', [InputTypes], [OutputTypes], [Options])`. For example, `binding(python, string_length/2, 'len', [string], [int], [pure])` maps the Prolog predicate `string_length/2` to Python's `len()` function. Options specify behavior: `pure` for side-effect-free functions, `effect(io)` for I/O operations, `effect(state)` for stateful operations, `import(Module)` to specify the source module, and `deterministic` for functions with single outputs. Initialize bindings with `:- init_bindings.` Bindings are available for Python, Go, Rust, Bash, C#, PowerShell, and 20+ other target languages.", "question_type": "medium", "topics": ["Compilation", "Extension", "Bindings"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["bindings", "python", "ffi", "mapping"], "related_skills": ["skill_transpiler_extension.md"], "related_docs": ["src/unifyweaver/bindings/python_bindings.pl", "docs/BINDING_MATRIX.md"], "original_answer": "Use bindings: `binding(python, string_length/2, 'len', [string], [int], [pure])`. This maps the Prolog predicate to Python's len(). Options include pure, effect(io), effect(state), import(Module), and deterministic. Initialize with `:- init_python_bindings.` Available binding modules exist for Python, Go, Rust, Bash, C#, PowerShell, and 20+ targets.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_transpiler_extension_003_q0", "cluster_id": "skill_transpiler_extension_003", "question": "How do I add a new target language to UnifyWeaver?", "answer": "To add a new target language to UnifyWeaver, create a target module that implements compile_to_mylang/3 and register it using `register_target(mylang, mylang_target, [extension('.ml'), comment_style('...'), supports([recursion])])`. The compile_to_mylang/3 predicate should handle the core transpilation logic. Add language-specific bindings in a separate module using `declare_binding/6` to map Prolog predicates to your target language's standard library functions. Optionally, define mylang_template/3 predicates to provide reusable code generation patterns for common constructs.", "question_type": "long", "topics": ["Compilation", "Extension", "New Target"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["target", "language", "extension", "compile"], "related_skills": ["skill_transpiler_extension.md"], "related_docs": ["src/unifyweaver/core/target_registry.pl"], "original_answer": "Create a target module with compile_to_mylang/3 and register it: `register_target(mylang, mylang_target, [extension('.ml'), comment_style('...'), supports([recursion])])`. Add bindings in a separate module with `declare_binding/6`. Optionally add templates with mylang_template/3 for code generation patterns.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer lacks implementation details about what compile_to_mylang/3 should actually do internally, the structure of the target module file, where files should be located in the codebase, and how to test the new target. The answer assumes familiarity with the registration API but doesn't explain the workflow."}
{"pair_id": "skill_transpiler_extension_003_q1", "cluster_id": "skill_transpiler_extension_003", "question": "Can I compile to a custom language?", "answer": "Yes. Create a target module implementing compile_to_mylang/3, then register it with `register_target(mylang, mylang_target, [extension('.ml'), comment_style('...'), supports([recursion])])`. Add language-specific bindings in a separate module using `declare_binding/6` to map Prolog predicates to your target language's functions. Optionally define mylang_template/3 for code generation patterns.", "question_type": "long", "topics": ["Compilation", "Extension", "New Target"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["target", "language", "extension", "compile"], "related_skills": ["skill_transpiler_extension.md"], "related_docs": ["src/unifyweaver/core/target_registry.pl"], "original_answer": "Create a target module with compile_to_mylang/3 and register it: `register_target(mylang, mylang_target, [extension('.ml'), comment_style('...'), supports([recursion])])`. Add bindings in a separate module with `declare_binding/6`. Optionally add templates with mylang_template/3 for code generation patterns.", "answer_tailored": true, "confidence": 0.75, "confidence_issues": "The base answer assumes familiarity with the registration API and doesn't explain what compile_to_mylang/3 should implement or provide a concrete example. The answer is accurate but could benefit from showing the signature/structure of these functions."}
{"pair_id": "skill_transpiler_extension_003_q2", "cluster_id": "skill_transpiler_extension_003", "question": "How do I create a new compilation target?", "answer": "To create a new compilation target, you need to: (1) Create a target module implementing compile_to_mylang/3 that generates code for your target language, (2) Register it using `register_target(mylang, mylang_target, [extension('.ml'), comment_style('...'), supports([recursion])])`, (3) Add language-specific bindings in a separate module using `declare_binding/6` to map Prolog predicates to target language functions, and (4) Optionally define code generation patterns with mylang_template/3 for reusable templates.", "question_type": "long", "topics": ["Compilation", "Extension", "New Target"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["target", "language", "extension", "compile"], "related_skills": ["skill_transpiler_extension.md"], "related_docs": ["src/unifyweaver/core/target_registry.pl"], "original_answer": "Create a target module with compile_to_mylang/3 and register it: `register_target(mylang, mylang_target, [extension('.ml'), comment_style('...'), supports([recursion])])`. Add bindings in a separate module with `declare_binding/6`. Optionally add templates with mylang_template/3 for code generation patterns.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "Base answer assumes familiarity with the UnifyWeaver architecture and doesn't explain where to place these modules, how compile_to_mylang/3 should be structured, or provide concrete examples of what the generated code should look like. Answer lacks guidance on testing or debugging the new target."}
{"pair_id": "skill_transpiler_extension_004_q0", "cluster_id": "skill_transpiler_extension_004", "question": "What is the component registry?", "answer": "The component registry is a system that manages reusable units organized into categories (runtime, source, binding). It works through four main operations: define categories with `define_category/3` to establish component types, register component types with `register_component_type/4` to specify how they're structured, declare component instances with `declare_component/4` to create specific implementations, and invoke them with `invoke_component/4` to use them in your code.", "question_type": "long", "topics": ["Compilation", "Extension", "Components"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["component", "registry", "reusable", "plugin"], "related_skills": ["skill_transpiler_extension.md"], "related_docs": ["src/unifyweaver/core/component_registry.pl", "docs/proposals/COMPONENT_REGISTRY.md"], "original_answer": "The component registry manages reusable units across categories (runtime, source, binding). Define a category with `define_category(validator, 'Data validation', [...])`, register a type with `register_component_type(validator, json_schema, module, [...])`, declare instances with `declare_component(validator, my_validator, json_schema, [...])`, and invoke with `invoke_component/4`.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_transpiler_extension_004_q1", "cluster_id": "skill_transpiler_extension_004", "question": "How do I create reusable components?", "answer": "To create reusable components, use the component registry system: (1) Define a category with `define_category(Name, Description, Attributes)` to establish the component type; (2) Register a component type within that category using `register_component_type(Category, TypeName, Implementation, Options)`; (3) Declare component instances with `declare_component(Category, ComponentName, TypeName, Config)`; (4) Invoke components in your code with `invoke_component(Category, ComponentName, Input, Output)`. Components can be registered as modules or plugins and are reusable across your transpilation pipeline.", "question_type": "long", "topics": ["Compilation", "Extension", "Components"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["component", "registry", "reusable", "plugin"], "related_skills": ["skill_transpiler_extension.md"], "related_docs": ["src/unifyweaver/core/component_registry.pl", "docs/proposals/COMPONENT_REGISTRY.md"], "original_answer": "The component registry manages reusable units across categories (runtime, source, binding). Define a category with `define_category(validator, 'Data validation', [...])`, register a type with `register_component_type(validator, json_schema, module, [...])`, declare instances with `declare_component(validator, my_validator, json_schema, [...])`, and invoke with `invoke_component/4`.", "answer_tailored": true, "confidence": 0.75, "confidence_issues": "Base answer lacks concrete examples and doesn't explain where/how to organize component files or which categories are pre-defined vs custom. The invoke syntax may not be fully accurate without seeing actual codebase implementation details."}
{"pair_id": "skill_transpiler_extension_004_q2", "cluster_id": "skill_transpiler_extension_004", "question": "What's the component system for?", "answer": "The component system provides a registry for managing reusable units across categories like runtime, source, and binding. You define a category with `define_category/3`, register a component type with `register_component_type/5`, declare component instances with `declare_component/4`, and invoke them with `invoke_component/4`. This lets you create plugins and reusable registered units that can be integrated into the transpilation pipeline.", "question_type": "long", "topics": ["Compilation", "Extension", "Components"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["component", "registry", "reusable", "plugin"], "related_skills": ["skill_transpiler_extension.md"], "related_docs": ["src/unifyweaver/core/component_registry.pl", "docs/proposals/COMPONENT_REGISTRY.md"], "original_answer": "The component registry manages reusable units across categories (runtime, source, binding). Define a category with `define_category(validator, 'Data validation', [...])`, register a type with `register_component_type(validator, json_schema, module, [...])`, declare instances with `declare_component(validator, my_validator, json_schema, [...])`, and invoke with `invoke_component/4`.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer focuses heavily on the mechanics (how to use it) rather than the purpose (what it's for). The tailored answer adds clarification about 'plugins and reusable registered units' from the skill document's 'When to Use' section, but the underlying purpose of the component system could be more explicit\u2014it appears designed for modularity and extensibility in the transpilation system."}
{"pair_id": "skill_webassembly_001_q0", "cluster_id": "skill_webassembly_001", "question": "How do I compile Prolog to WebAssembly?", "answer": "To compile Prolog to WebAssembly: First, use `compile_tail_recursion_llvm(factorial/2, [export(true)], LLVMCode)` to generate LLVM IR code. Then write it to a file using `write_llvm_program/2`. Finally, compile to WASM with `build_wasm_module('file.ll', 'output', Commands)`, which generates clang commands with `--target=wasm32`. The `musttail` annotation ensures O(1) stack space. Alternatively, use `compile_wasm_module([function_list], Options, WASMCode)` directly for a more streamlined approach.", "question_type": "medium", "topics": ["Compilation", "WebAssembly"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["webassembly", "wasm", "llvm", "browser"], "related_skills": ["skill_webassembly.md"], "related_docs": ["src/unifyweaver/targets/llvm_target.pl"], "original_answer": "Use the LLVM target: `compile_tail_recursion_llvm(factorial/2, [export(true)], LLVMCode)`. Write to file with `write_llvm_program/2`, then build WASM with `build_wasm_module('file.ll', 'output', Commands)`. The generated commands use clang with --target=wasm32. Use musttail for guaranteed O(1) stack space.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_webassembly_001_q1", "cluster_id": "skill_webassembly_001", "question": "Can UnifyWeaver generate WASM?", "answer": "Yes, UnifyWeaver can generate WASM. Use the LLVM target to compile Prolog to LLVM IR, then build it as WebAssembly. Call `compile_tail_recursion_llvm(factorial/2, [export(true)], LLVMCode)` to generate LLVM IR with tail-call optimization, then use `build_wasm_module('file.ll', 'output', Commands)` to compile to WASM with clang targeting wasm32. Alternatively, use `compile_wasm_module(Functions, Options, Code)` directly to generate a WebAssembly module. The musttail annotation ensures O(1) stack space.", "question_type": "medium", "topics": ["Compilation", "WebAssembly"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["webassembly", "wasm", "llvm", "browser"], "related_skills": ["skill_webassembly.md"], "related_docs": ["src/unifyweaver/targets/llvm_target.pl"], "original_answer": "Use the LLVM target: `compile_tail_recursion_llvm(factorial/2, [export(true)], LLVMCode)`. Write to file with `write_llvm_program/2`, then build WASM with `build_wasm_module('file.ll', 'output', Commands)`. The generated commands use clang with --target=wasm32. Use musttail for guaranteed O(1) stack space.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_webassembly_001_q2", "cluster_id": "skill_webassembly_001", "question": "How do I run Prolog in the browser?", "answer": "To run Prolog in the browser, compile your code to WebAssembly using the LLVM target. Use `compile_tail_recursion_llvm(factorial/2, [export(true)], LLVMCode)` to generate LLVM IR, then `build_wasm_module('file.ll', 'output', Commands)` to compile to WASM with clang's wasm32 target. The musttail annotation guarantees O(1) stack space. Finally, use `generate_ts_bindings([factorial], TSCode)` or `generate_js_bindings([factorial], JSCode)` to create browser bindings for your compiled Prolog functions.", "question_type": "medium", "topics": ["Compilation", "WebAssembly"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["webassembly", "wasm", "llvm", "browser"], "related_skills": ["skill_webassembly.md"], "related_docs": ["src/unifyweaver/targets/llvm_target.pl"], "original_answer": "Use the LLVM target: `compile_tail_recursion_llvm(factorial/2, [export(true)], LLVMCode)`. Write to file with `write_llvm_program/2`, then build WASM with `build_wasm_module('file.ll', 'output', Commands)`. The generated commands use clang with --target=wasm32. Use musttail for guaranteed O(1) stack space.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_webassembly_002_q0", "cluster_id": "skill_webassembly_002", "question": "How do I generate TypeScript bindings for WASM?", "answer": "To generate TypeScript bindings for WASM, use `generate_ts_bindings([factorial, fibonacci], TSCode)` which creates a WasmModule class with async init() and typed methods. For functions with string arguments, use `generate_ts_string_bindings/2` which includes encoder/decoder support.", "question_type": "long", "topics": ["Compilation", "WebAssembly", "TypeScript"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["typescript", "wasm", "bindings", "browser"], "related_skills": ["skill_webassembly.md"], "related_docs": ["src/unifyweaver/targets/llvm_target.pl"], "original_answer": "After compiling to WASM, generate bindings: `generate_ts_bindings([factorial, fibonacci], TSCode)`. This creates a WasmModule class with async init() and typed methods. For functions with string arguments, use `generate_ts_string_bindings/2` which includes encoder/decoder support.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_webassembly_002_q1", "cluster_id": "skill_webassembly_002", "question": "Can I call WASM from TypeScript?", "answer": "Yes, you can call WASM from TypeScript. After compiling to WASM using `compile_wasm_module([factorial], [], WASMCode)`, generate TypeScript bindings with `generate_ts_bindings([factorial], TSCode)`. This creates a WasmModule class with an async init() method and typed function wrappers that let you call compiled functions directly from TypeScript. For functions with string arguments, use `generate_ts_string_bindings/2` instead, which includes encoder/decoder support for string marshalling across the WASM boundary.", "question_type": "long", "topics": ["Compilation", "WebAssembly", "TypeScript"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["typescript", "wasm", "bindings", "browser"], "related_skills": ["skill_webassembly.md"], "related_docs": ["src/unifyweaver/targets/llvm_target.pl"], "original_answer": "After compiling to WASM, generate bindings: `generate_ts_bindings([factorial, fibonacci], TSCode)`. This creates a WasmModule class with async init() and typed methods. For functions with string arguments, use `generate_ts_string_bindings/2` which includes encoder/decoder support.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_webassembly_002_q2", "cluster_id": "skill_webassembly_002", "question": "How do I use compiled WASM in my app?", "answer": "After compiling to WASM, generate bindings using `generate_ts_bindings([factorial, fibonacci], TSCode)` to create a WasmModule class with async init() and typed methods matching your compiled functions. Import the WasmModule, await initialization, then call your functions directly. For functions with string arguments, use `generate_ts_string_bindings/2` instead, which includes built-in encoder/decoder support for seamless string handling.", "question_type": "long", "topics": ["Compilation", "WebAssembly", "TypeScript"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["typescript", "wasm", "bindings", "browser"], "related_skills": ["skill_webassembly.md"], "related_docs": ["src/unifyweaver/targets/llvm_target.pl"], "original_answer": "After compiling to WASM, generate bindings: `generate_ts_bindings([factorial, fibonacci], TSCode)`. This creates a WasmModule class with async init() and typed methods. For functions with string arguments, use `generate_ts_string_bindings/2` which includes encoder/decoder support.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "Answer could be more specific about integration steps (importing module, instantiation, calling methods), but captures the core workflow of generating bindings and using the resulting class."}
{"pair_id": "skill_webassembly_003_q0", "cluster_id": "skill_webassembly_003", "question": "How do I create a native library for Go from Prolog?", "answer": "To create a native library for Go from Prolog: (1) Compile to shared library using `compile_shared_library_llvm([factorial, fibonacci], [], LLVMCode)`. (2) Generate a C header with `generate_c_header/2` so Go can call the functions. (3) Generate Go bindings with `generate_cgo_bindings/2`. (4) Build the shared library using `build_shared_library('math.ll', 'math', Commands)` which produces libmath.so. The resulting .so library can be imported into Go projects via cgo, allowing Go code to call your Prolog-compiled functions with native speed.", "question_type": "long", "topics": ["Compilation", "WebAssembly", "FFI"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["go", "cgo", "ffi", "native"], "related_skills": ["skill_webassembly.md"], "related_docs": ["src/unifyweaver/targets/llvm_target.pl"], "original_answer": "Compile to shared library: `compile_shared_library_llvm([factorial, fibonacci], [], LLVMCode)`. Generate C header with `generate_c_header/2` and Go bindings with `generate_cgo_bindings/2`. Build with `build_shared_library('math.ll', 'math', Commands)` which produces libmodule.so. Similar FFI generators exist for Rust (`generate_rust_ffi/2`).", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "Base answer references functions like generate_cgo_bindings/2 and generate_c_header/2 without showing their signatures or outputs. Unclear if generate_cgo_bindings is the actual function name or if it requires additional parameters. No example of how the Go code would actually use the compiled library shown. Skill document doesn't provide complete documentation for Go FFI workflow."}
{"pair_id": "skill_webassembly_003_q1", "cluster_id": "skill_webassembly_003", "question": "Can I call UnifyWeaver code from Go?", "answer": "Yes. Compile your Prolog code to a shared library using `compile_shared_library_llvm([factorial, fibonacci], [], LLVMCode)`. Generate Go bindings with `generate_cgo_bindings/2`, and a C header with `generate_c_header/2`. Build the shared library with `build_shared_library('math.ll', 'math', Commands)`, which produces libmath.so. Go can then call your compiled functions via cgo.", "question_type": "long", "topics": ["Compilation", "WebAssembly", "FFI"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["go", "cgo", "ffi", "native"], "related_skills": ["skill_webassembly.md"], "related_docs": ["src/unifyweaver/targets/llvm_target.pl"], "original_answer": "Compile to shared library: `compile_shared_library_llvm([factorial, fibonacci], [], LLVMCode)`. Generate C header with `generate_c_header/2` and Go bindings with `generate_cgo_bindings/2`. Build with `build_shared_library('math.ll', 'math', Commands)` which produces libmodule.so. Similar FFI generators exist for Rust (`generate_rust_ffi/2`).", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer references specific predicates for Go FFI support, but the skill document doesn't show complete examples of `generate_cgo_bindings/2` or confirm it exists as a public API. The answer assumes these functions are available and properly documented."}
{"pair_id": "skill_webassembly_003_q2", "cluster_id": "skill_webassembly_003", "question": "How do I generate cgo bindings?", "answer": "To generate cgo bindings: First compile to a shared library using `compile_shared_library_llvm([factorial, fibonacci], [], LLVMCode)`. Then generate the C header with `generate_c_header/2` and Go bindings with `generate_cgo_bindings/2`. Finally, build the shared library with `build_shared_library('math.ll', 'math', Commands)` which produces libmath.so. This shared library can then be imported into Go via cgo.", "question_type": "long", "topics": ["Compilation", "WebAssembly", "FFI"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["go", "cgo", "ffi", "native"], "related_skills": ["skill_webassembly.md"], "related_docs": ["src/unifyweaver/targets/llvm_target.pl"], "original_answer": "Compile to shared library: `compile_shared_library_llvm([factorial, fibonacci], [], LLVMCode)`. Generate C header with `generate_c_header/2` and Go bindings with `generate_cgo_bindings/2`. Build with `build_shared_library('math.ll', 'math', Commands)` which produces libmodule.so. Similar FFI generators exist for Rust (`generate_rust_ffi/2`).", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "The base answer references `generate_cgo_bindings/2` but provides no details about its parameters, expected output format, or how it integrates with the rest of the workflow. The skill document doesn't contain explicit cgo examples, only general FFI mentions. The answer assumes the reader knows how to use the generated bindings in actual Go code."}
{"pair_id": "skill_webassembly_004_q0", "cluster_id": "skill_webassembly_004", "question": "What recursion patterns does the LLVM target support?", "answer": "The LLVM target supports four recursion patterns: (1) Tail recursion via `compile_tail_recursion_llvm/3`, which uses the `musttail` annotation to guarantee O(1) stack space; (2) Linear recursion via `compile_linear_recursion_llvm/3` for Fibonacci-style recursion with memoization; (3) Transitive closure via `compile_transitive_closure_llvm/3` for graph traversal algorithms; and (4) Mutual recursion via `compile_mutual_recursion_llvm/3` for mutually recursive predicates.", "question_type": "long", "topics": ["Compilation", "WebAssembly", "Recursion"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["recursion", "tail-call", "llvm", "optimization"], "related_skills": ["skill_webassembly.md"], "related_docs": ["src/unifyweaver/targets/llvm_target.pl"], "original_answer": "The LLVM target supports: tail recursion with `compile_tail_recursion_llvm/3` (uses musttail for O(1) stack), linear recursion with `compile_linear_recursion_llvm/3` (Fibonacci-style with memoization), transitive closure with `compile_transitive_closure_llvm/3` (graph traversal), and mutual recursion with `compile_mutual_recursion_llvm/3`.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_webassembly_004_q1", "cluster_id": "skill_webassembly_004", "question": "Can I compile recursive Prolog to WASM?", "answer": "Yes, you can compile recursive Prolog to WASM. The LLVM target supports multiple recursion patterns: tail recursion via `compile_tail_recursion_llvm/3` (uses musttail for O(1) stack guarantees), linear recursion via `compile_linear_recursion_llvm/3` (Fibonacci-style with memoization), transitive closure via `compile_transitive_closure_llvm/3` (for graph traversal), and mutual recursion via `compile_mutual_recursion_llvm/3`. You then generate WebAssembly from the LLVM IR using `compile_wasm_module/3` with functions like factorial or fibonacci.", "question_type": "long", "topics": ["Compilation", "WebAssembly", "Recursion"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["recursion", "tail-call", "llvm", "optimization"], "related_skills": ["skill_webassembly.md"], "related_docs": ["src/unifyweaver/targets/llvm_target.pl"], "original_answer": "The LLVM target supports: tail recursion with `compile_tail_recursion_llvm/3` (uses musttail for O(1) stack), linear recursion with `compile_linear_recursion_llvm/3` (Fibonacci-style with memoization), transitive closure with `compile_transitive_closure_llvm/3` (graph traversal), and mutual recursion with `compile_mutual_recursion_llvm/3`.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_webassembly_004_q2", "cluster_id": "skill_webassembly_004", "question": "How does tail-call optimization work?", "answer": "Tail-call optimization in the LLVM target is implemented using the `musttail` annotation, which guarantees O(1) stack space by ensuring the compiler performs tail-call optimization. When you compile a tail-recursive function with `compile_tail_recursion_llvm/3`, the generated LLVM IR uses `musttail call` instead of regular function calls, allowing the runtime to reuse the current stack frame for recursive calls instead of creating new frames. This is enforced at the LLVM level, meaning the compiler must guarantee the optimization or raise an error\u2014you don't get a fallback to regular recursion.", "question_type": "long", "topics": ["Compilation", "WebAssembly", "Recursion"], "source_file": "by-topic/compilation/skills-generated.jsonl", "tags": ["recursion", "tail-call", "llvm", "optimization"], "related_skills": ["skill_webassembly.md"], "related_docs": ["src/unifyweaver/targets/llvm_target.pl"], "original_answer": "The LLVM target supports: tail recursion with `compile_tail_recursion_llvm/3` (uses musttail for O(1) stack), linear recursion with `compile_linear_recursion_llvm/3` (Fibonacci-style with memoization), transitive closure with `compile_transitive_closure_llvm/3` (graph traversal), and mutual recursion with `compile_mutual_recursion_llvm/3`.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_infrastructure_001_q0", "cluster_id": "skill_infrastructure_001", "question": "How do I deploy my UnifyWeaver service?", "answer": "To deploy your UnifyWeaver service, first declare your service configuration using `declare_service/2` with parameters like host, port, target language, and lifecycle. Then generate deployment artifacts based on your platform: use `generate_dockerfile/3` for Docker, `generate_k8s_deployment/3` for Kubernetes, `generate_lambda_function/3` for AWS Lambda, or `generate_deploy_script/3` for SSH deployment. Each function takes your service spec and generates the necessary configuration files or scripts for deployment.", "question_type": "medium", "topics": ["Infrastructure", "Deployment"], "source_file": "by-topic/infrastructure/skills-generated.jsonl", "tags": ["deployment", "docker", "kubernetes", "cloud"], "related_skills": ["skill_infrastructure.md", "skill_deployment.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "UnifyWeaver supports multiple deployment options: SSH deployment with `generate_deploy_script/3`, Docker with `generate_dockerfile/3`, Kubernetes with `generate_k8s_deployment/3`, and cloud functions (AWS Lambda, GCP, Azure). Use `declare_service/2` to define your service configuration first, then generate the appropriate deployment artifacts.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_infrastructure_001_q1", "cluster_id": "skill_infrastructure_001", "question": "How can I deploy a service built with UnifyWeaver?", "answer": "To deploy a service built with UnifyWeaver, first declare your service configuration using `declare_service/2` with deployment parameters like host, port, and target language. Then generate deployment artifacts based on your deployment method: use `generate_dockerfile/3` for Docker, `generate_k8s_deployment/3` for Kubernetes, `generate_lambda_function/3` for AWS Lambda, or `generate_deploy_script/3` for SSH deployment. UnifyWeaver also supports GCP Cloud Functions and Azure Functions, as well as secrets management through Vault or cloud-native secret services.", "question_type": "medium", "topics": ["Infrastructure", "Deployment"], "source_file": "by-topic/infrastructure/skills-generated.jsonl", "tags": ["deployment", "docker", "kubernetes", "cloud"], "related_skills": ["skill_infrastructure.md", "skill_deployment.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "UnifyWeaver supports multiple deployment options: SSH deployment with `generate_deploy_script/3`, Docker with `generate_dockerfile/3`, Kubernetes with `generate_k8s_deployment/3`, and cloud functions (AWS Lambda, GCP, Azure). Use `declare_service/2` to define your service configuration first, then generate the appropriate deployment artifacts.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer references `generate_deploy_script/3` for SSH deployment, but this specific function signature is not shown in the skill document examples. The answer makes reasonable inferences about SSH deployment based on the capability table, but the exact API is not verified."}
{"pair_id": "skill_infrastructure_001_q2", "cluster_id": "skill_infrastructure_001", "question": "What deployment options does UnifyWeaver support?", "answer": "UnifyWeaver supports SSH deployment, Docker containerization, Kubernetes orchestration, and cloud functions (AWS Lambda, Google Cloud Functions, Azure Functions). Define your service using `declare_service/2` with configuration options like host, port, target language, and lifecycle. Then generate deployment artifacts: use `generate_deploy_script/3` for SSH, `generate_dockerfile/3` for Docker, `generate_k8s_deployment/3` for Kubernetes, or `generate_lambda_function/3` for AWS Lambda.", "question_type": "medium", "topics": ["Infrastructure", "Deployment"], "source_file": "by-topic/infrastructure/skills-generated.jsonl", "tags": ["deployment", "docker", "kubernetes", "cloud"], "related_skills": ["skill_infrastructure.md", "skill_deployment.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "UnifyWeaver supports multiple deployment options: SSH deployment with `generate_deploy_script/3`, Docker with `generate_dockerfile/3`, Kubernetes with `generate_k8s_deployment/3`, and cloud functions (AWS Lambda, GCP, Azure). Use `declare_service/2` to define your service configuration first, then generate the appropriate deployment artifacts.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_infrastructure_002_q0", "cluster_id": "skill_infrastructure_002", "question": "How do I add authentication to my UnifyWeaver app?", "answer": "To add authentication to your UnifyWeaver app, use the auth_backends module to declare your app with authentication configuration: `app(my_app, [auth([backend(text_file), password_hash(bcrypt), token_type(jwt), session_duration(86400)])])`. UnifyWeaver supports multiple backends including mock (for development), text_file, sqlite, postgresql, mongodb, ldap, and oauth2. After configuring your app spec, generate the authentication server with `generate_auth_server(AppSpec, node, Files)` to produce the necessary authentication code and files.", "question_type": "medium", "topics": ["Infrastructure", "Authentication"], "source_file": "by-topic/infrastructure/skills-generated.jsonl", "tags": ["authentication", "jwt", "security", "login"], "related_skills": ["skill_infrastructure.md", "skill_authentication.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "Use the auth_backends module: `app(my_app, [auth([backend(text_file), password_hash(bcrypt), token_type(jwt)])])`. Available backends include mock (development), text_file, sqlite, postgresql, mongodb, ldap, and oauth2. Generate the auth server with `generate_auth_server(AppSpec, node, Files)`.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_infrastructure_002_q1", "cluster_id": "skill_infrastructure_002", "question": "How can I secure my app with login?", "answer": "To secure your app with login, use the auth_backends module to configure authentication. Define your app with an auth specification like: `app(my_app, [auth([backend(text_file), password_hash(bcrypt), token_type(jwt), session_duration(86400)])])`. Choose your backend based on needs: use 'mock' for development, 'text_file' for simple file-based storage, or 'postgresql'/'mongodb' for production databases. You can also integrate OAuth2 or LDAP for existing identity systems. Generate the authentication server using `generate_auth_server(AppSpec, node, Files)` to create the necessary code files for your chosen platform.", "question_type": "medium", "topics": ["Infrastructure", "Authentication"], "source_file": "by-topic/infrastructure/skills-generated.jsonl", "tags": ["authentication", "jwt", "security", "login"], "related_skills": ["skill_infrastructure.md", "skill_authentication.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "Use the auth_backends module: `app(my_app, [auth([backend(text_file), password_hash(bcrypt), token_type(jwt)])])`. Available backends include mock (development), text_file, sqlite, postgresql, mongodb, ldap, and oauth2. Generate the auth server with `generate_auth_server(AppSpec, node, Files)`.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_infrastructure_002_q2", "cluster_id": "skill_infrastructure_002", "question": "What authentication backends are available?", "answer": "Available authentication backends in UnifyWeaver include: mock (for development), text_file (simple file storage), sqlite, postgresql, mongodb, ldap, and oauth2. Use the auth_backends module to configure: `app(my_app, [auth([backend(text_file), password_hash(bcrypt), token_type(jwt)])])`. Text_file and mock are currently implemented; the others are proposed. Generate the auth server with `generate_auth_server(AppSpec, node, Files)`.", "question_type": "medium", "topics": ["Infrastructure", "Authentication"], "source_file": "by-topic/infrastructure/skills-generated.jsonl", "tags": ["authentication", "jwt", "security", "login"], "related_skills": ["skill_infrastructure.md", "skill_authentication.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "Use the auth_backends module: `app(my_app, [auth([backend(text_file), password_hash(bcrypt), token_type(jwt)])])`. Available backends include mock (development), text_file, sqlite, postgresql, mongodb, ldap, and oauth2. Generate the auth server with `generate_auth_server(AppSpec, node, Files)`.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_infrastructure_003_q0", "cluster_id": "skill_infrastructure_003", "question": "How do I generate HTTP servers and clients?", "answer": "Use the `network_glue` module to generate HTTP servers and clients. For HTTP servers, call `generate_http_server(Language, Endpoints, Options, Code)` where Language is python, go, rust, or bash, and Options include port and cors settings. For HTTP clients, call `generate_http_client(Language, Services, Options, Code)` with similar language support and options like timeout. Python uses Flask/requests, Go uses net/http, Rust uses Actix-web/reqwest, and Bash uses curl.", "question_type": "medium", "topics": ["Infrastructure", "Networking"], "source_file": "by-topic/infrastructure/skills-generated.jsonl", "tags": ["http", "server", "client", "networking"], "related_skills": ["skill_infrastructure.md", "skill_networking.md"], "related_docs": ["src/unifyweaver/glue/network_glue.pl"], "original_answer": "Use the network_glue module. For servers: `generate_http_server(python, Endpoints, [port(8080), cors(true)], Code)`. For clients: `generate_http_client(go, Services, [timeout(30)], Code)`. Supported targets include Python (Flask/requests), Go (net/http), Rust (Actix-web/reqwest), and Bash (curl).", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_infrastructure_003_q1", "cluster_id": "skill_infrastructure_003", "question": "Can UnifyWeaver create web servers?", "answer": "Yes, UnifyWeaver can create web servers using the network_glue module. Use `generate_http_server(language, Endpoints, Options, Code)` to generate server code. Supported languages include Python (Flask), Go (net/http), and Rust (Actix-web). You can configure options like port, CORS, and other parameters.", "question_type": "medium", "topics": ["Infrastructure", "Networking"], "source_file": "by-topic/infrastructure/skills-generated.jsonl", "tags": ["http", "server", "client", "networking"], "related_skills": ["skill_infrastructure.md", "skill_networking.md"], "related_docs": ["src/unifyweaver/glue/network_glue.pl"], "original_answer": "Use the network_glue module. For servers: `generate_http_server(python, Endpoints, [port(8080), cors(true)], Code)`. For clients: `generate_http_client(go, Services, [timeout(30)], Code)`. Supported targets include Python (Flask/requests), Go (net/http), Rust (Actix-web/reqwest), and Bash (curl).", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_infrastructure_003_q2", "cluster_id": "skill_infrastructure_003", "question": "How do I make API calls from generated code?", "answer": "To make API calls from generated code, use the `generate_http_client()` function from the network_glue module. Specify your target language, services to call, and options like timeout: `generate_http_client(python, Services, [timeout(30)], Code)`. Supported languages include Python (requests library), Go (net/http), Rust (reqwest), and Bash (curl). For the server side, use `generate_http_server()` to create endpoints that can receive these calls.", "question_type": "medium", "topics": ["Infrastructure", "Networking"], "source_file": "by-topic/infrastructure/skills-generated.jsonl", "tags": ["http", "server", "client", "networking"], "related_skills": ["skill_infrastructure.md", "skill_networking.md"], "related_docs": ["src/unifyweaver/glue/network_glue.pl"], "original_answer": "Use the network_glue module. For servers: `generate_http_server(python, Endpoints, [port(8080), cors(true)], Code)`. For clients: `generate_http_client(go, Services, [timeout(30)], Code)`. Supported targets include Python (Flask/requests), Go (net/http), Rust (Actix-web/reqwest), and Bash (curl).", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "Base answer conflates client and server generation; unclear if question asks about outbound API calls (client) or receiving them (server). Answer assumes client-side API calls based on question wording, but base answer structure suggests both are equally relevant."}
{"pair_id": "skill_deployment_001_q0", "cluster_id": "skill_deployment_001", "question": "How do I generate a Dockerfile for my service?", "answer": "To generate a Dockerfile for your service, first declare your service using `declare_service(my_api, [host('server.example.com'), port(8080), target(python), entry_point('main.py')])`. Then call `generate_dockerfile(my_api, [], Dockerfile)` to generate the Dockerfile. The `target(Target)` option specifies the compilation target (python, go, rust) which determines the base image and build process.", "question_type": "long", "topics": ["Infrastructure", "Deployment", "Docker"], "source_file": "by-topic/infrastructure/skills-generated.jsonl", "tags": ["docker", "dockerfile", "container", "deployment"], "related_skills": ["skill_deployment.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "First declare your service: `declare_service(my_api, [host('server.example.com'), port(8080), target(python), entry_point('main.py')])`. Then generate the Dockerfile: `generate_dockerfile(my_api, [], Dockerfile)`. You can also generate docker-compose with `generate_docker_compose/3` for multi-service deployments.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_deployment_001_q1", "cluster_id": "skill_deployment_001", "question": "Can UnifyWeaver create Docker containers?", "answer": "Yes, UnifyWeaver can create Docker containers. Declare your service using `declare_service(my_api, [host('server.example.com'), port(8080), target(python), entry_point('main.py')])`, then generate a Dockerfile with `generate_dockerfile(my_api, [], Dockerfile)`. For multi-service setups, use `generate_docker_compose/3` to create docker-compose configurations.", "question_type": "long", "topics": ["Infrastructure", "Deployment", "Docker"], "source_file": "by-topic/infrastructure/skills-generated.jsonl", "tags": ["docker", "dockerfile", "container", "deployment"], "related_skills": ["skill_deployment.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "First declare your service: `declare_service(my_api, [host('server.example.com'), port(8080), target(python), entry_point('main.py')])`. Then generate the Dockerfile: `generate_dockerfile(my_api, [], Dockerfile)`. You can also generate docker-compose with `generate_docker_compose/3` for multi-service deployments.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_deployment_001_q2", "cluster_id": "skill_deployment_001", "question": "How do I containerize my UnifyWeaver app?", "answer": "To containerize your UnifyWeaver app, first declare your service with `declare_service(my_api, [host('server.example.com'), port(8080), target(python), entry_point('main.py')])`. Then generate the Dockerfile using `generate_dockerfile(my_api, [], Dockerfile)`. For multi-service setups, use `generate_docker_compose(my_project, [], ComposeYaml)` to generate a docker-compose configuration that manages all services together.", "question_type": "long", "topics": ["Infrastructure", "Deployment", "Docker"], "source_file": "by-topic/infrastructure/skills-generated.jsonl", "tags": ["docker", "dockerfile", "container", "deployment"], "related_skills": ["skill_deployment.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "First declare your service: `declare_service(my_api, [host('server.example.com'), port(8080), target(python), entry_point('main.py')])`. Then generate the Dockerfile: `generate_dockerfile(my_api, [], Dockerfile)`. You can also generate docker-compose with `generate_docker_compose/3` for multi-service deployments.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer assumes a specific host and port without knowing UnifyWeaver's actual configuration. The confidence is moderate because containerization typically requires understanding the app's structure, dependencies, and port mappings specific to UnifyWeaver, which aren't detailed in the skill document."}
{"pair_id": "skill_deployment_002_q0", "cluster_id": "skill_deployment_002", "question": "How do I deploy to Kubernetes?", "answer": "To deploy to Kubernetes, first declare your K8s configuration using `declare_k8s_config(my_api, [replicas(3), namespace(production), image('myregistry/myapi:latest'), resources([requests([cpu('100m'), memory('128Mi')])])])`. Then generate the necessary manifests: use `generate_k8s_deployment/3` for the deployment manifest, `generate_k8s_service/3` for the service manifest, and `generate_k8s_configmap/3` for configuration. For a complete setup, you can generate a Helm chart with `generate_helm_chart/3` to manage all resources together.", "question_type": "long", "topics": ["Infrastructure", "Deployment", "Kubernetes"], "source_file": "by-topic/infrastructure/skills-generated.jsonl", "tags": ["kubernetes", "k8s", "helm", "deployment"], "related_skills": ["skill_deployment.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "Declare K8s config: `declare_k8s_config(my_api, [replicas(3), namespace(production), image('myregistry/myapi:latest'), resources([requests([cpu('100m'), memory('128Mi')])])])`. Generate manifests with `generate_k8s_deployment/3`, `generate_k8s_service/3`, `generate_k8s_configmap/3`, or a complete Helm chart with `generate_helm_chart/3`.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_deployment_002_q1", "cluster_id": "skill_deployment_002", "question": "Can I generate K8s manifests?", "answer": "Yes, you can generate K8s manifests. Declare your service configuration with `declare_k8s_config(my_api, [replicas(3), namespace(production), image('myregistry/myapi:latest'), resources([requests([cpu('100m'), memory('128Mi')])])])`, then use `generate_k8s_deployment/3` for deployments, `generate_k8s_service/3` for services, `generate_k8s_configmap/3` for config maps, or `generate_helm_chart/3` for a complete Helm chart.", "question_type": "long", "topics": ["Infrastructure", "Deployment", "Kubernetes"], "source_file": "by-topic/infrastructure/skills-generated.jsonl", "tags": ["kubernetes", "k8s", "helm", "deployment"], "related_skills": ["skill_deployment.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "Declare K8s config: `declare_k8s_config(my_api, [replicas(3), namespace(production), image('myregistry/myapi:latest'), resources([requests([cpu('100m'), memory('128Mi')])])])`. Generate manifests with `generate_k8s_deployment/3`, `generate_k8s_service/3`, `generate_k8s_configmap/3`, or a complete Helm chart with `generate_helm_chart/3`.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_deployment_002_q2", "cluster_id": "skill_deployment_002", "question": "How do I set up Kubernetes deployment?", "answer": "To set up Kubernetes deployment, first declare your K8s config using `declare_k8s_config(my_api, [replicas(3), namespace(production), image('myregistry/myapi:latest'), ports([8080]), resources([requests([cpu('100m'), memory('128Mi')]), limits([cpu('500m'), memory('512Mi')])])])`. Then generate the required manifests: use `generate_k8s_deployment/3` for the Deployment, `generate_k8s_service/3` for the Service, and `generate_k8s_configmap/3` for ConfigMaps. For a complete setup, use `generate_helm_chart/3` to generate a full Helm chart.", "question_type": "long", "topics": ["Infrastructure", "Deployment", "Kubernetes"], "source_file": "by-topic/infrastructure/skills-generated.jsonl", "tags": ["kubernetes", "k8s", "helm", "deployment"], "related_skills": ["skill_deployment.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "Declare K8s config: `declare_k8s_config(my_api, [replicas(3), namespace(production), image('myregistry/myapi:latest'), resources([requests([cpu('100m'), memory('128Mi')])])])`. Generate manifests with `generate_k8s_deployment/3`, `generate_k8s_service/3`, `generate_k8s_configmap/3`, or a complete Helm chart with `generate_helm_chart/3`.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_deployment_003_q0", "cluster_id": "skill_deployment_003", "question": "How do I deploy to AWS Lambda?", "answer": "To deploy to AWS Lambda, use `declare_lambda_config(my_func, [runtime(python39), handler('main.handler'), memory(256), timeout(30)])` to declare your Lambda function configuration. Then generate the deployment package with `generate_lambda_function(my_func, [], Package)` or use `generate_sam_template(my_func, [], Template)` for AWS SAM template generation. The runtime, handler, memory, and timeout are key parameters you can customize for your Lambda function.", "question_type": "long", "topics": ["Infrastructure", "Deployment", "Cloud Functions"], "source_file": "by-topic/infrastructure/skills-generated.jsonl", "tags": ["lambda", "serverless", "aws", "cloud"], "related_skills": ["skill_deployment.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "Declare Lambda config: `declare_lambda_config(my_func, [runtime(python39), handler('main.handler'), memory(256), timeout(30)])`. Generate with `generate_lambda_function/3` for the package or `generate_sam_template/3` for AWS SAM. Similar predicates exist for Google Cloud Functions (`generate_gcf_deploy/3`) and Azure Functions (`generate_azure_func_deploy/3`).", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_deployment_003_q1", "cluster_id": "skill_deployment_003", "question": "Can UnifyWeaver generate serverless functions?", "answer": "Yes, UnifyWeaver can generate serverless functions for multiple cloud platforms. For AWS Lambda, declare the configuration with `declare_lambda_config(my_func, [runtime(python39), handler('main.handler'), memory(256), timeout(30)])` and generate using `generate_lambda_function/3` for a deployable package or `generate_sam_template/3` for AWS SAM templates. Similar functionality is available for Google Cloud Functions via `generate_gcf_deploy/3` and Azure Functions via `generate_azure_func_deploy/3`.", "question_type": "long", "topics": ["Infrastructure", "Deployment", "Cloud Functions"], "source_file": "by-topic/infrastructure/skills-generated.jsonl", "tags": ["lambda", "serverless", "aws", "cloud"], "related_skills": ["skill_deployment.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "Declare Lambda config: `declare_lambda_config(my_func, [runtime(python39), handler('main.handler'), memory(256), timeout(30)])`. Generate with `generate_lambda_function/3` for the package or `generate_sam_template/3` for AWS SAM. Similar predicates exist for Google Cloud Functions (`generate_gcf_deploy/3`) and Azure Functions (`generate_azure_func_deploy/3`).", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_deployment_003_q2", "cluster_id": "skill_deployment_003", "question": "How do I create cloud functions?", "answer": "To create cloud functions, declare configuration using `declare_lambda_config(my_func, [runtime(python39), handler('main.handler'), memory(256), timeout(30)])` for AWS Lambda. Generate the function package with `generate_lambda_function/3` or use `generate_sam_template/3` for AWS SAM template. For Google Cloud Functions, use `generate_gcf_deploy/3`. For Azure Functions, use `generate_azure_func_deploy/3`. Each predicate takes the function name, options list, and output variable.", "question_type": "long", "topics": ["Infrastructure", "Deployment", "Cloud Functions"], "source_file": "by-topic/infrastructure/skills-generated.jsonl", "tags": ["lambda", "serverless", "aws", "cloud"], "related_skills": ["skill_deployment.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "Declare Lambda config: `declare_lambda_config(my_func, [runtime(python39), handler('main.handler'), memory(256), timeout(30)])`. Generate with `generate_lambda_function/3` for the package or `generate_sam_template/3` for AWS SAM. Similar predicates exist for Google Cloud Functions (`generate_gcf_deploy/3`) and Azure Functions (`generate_azure_func_deploy/3`).", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_deployment_004_q0", "cluster_id": "skill_deployment_004", "question": "How do I manage secrets in my deployment?", "answer": "UnifyWeaver supports multiple secrets management systems: HashiCorp Vault, AWS Secrets Manager, Azure Key Vault, and GCP Secret Manager. To manage secrets in your deployment, declare service secrets using `declare_service_secrets(my_api, [secret(db_password, vault, 'secret/data/db'), secret(api_key, aws, 'prod/api-key')])`. Then generate the appropriate configuration with `generate_secret_env_script/3` for direct environment variable injection or `generate_k8s_external_secret/3` if deploying to Kubernetes.", "question_type": "long", "topics": ["Infrastructure", "Deployment", "Secrets"], "source_file": "by-topic/infrastructure/skills-generated.jsonl", "tags": ["secrets", "vault", "security", "deployment"], "related_skills": ["skill_deployment.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "UnifyWeaver supports HashiCorp Vault, AWS Secrets Manager, Azure Key Vault, and GCP Secret Manager. Declare bindings: `declare_service_secrets(my_api, [secret(db_password, vault, 'secret/data/db'), secret(api_key, aws, 'prod/api-key')])`. Generate with `generate_secret_env_script/3` or `generate_k8s_external_secret/3` for Kubernetes.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_deployment_004_q1", "cluster_id": "skill_deployment_004", "question": "How do I handle API keys securely?", "answer": "UnifyWeaver supports multiple secret management systems for handling API keys securely: HashiCorp Vault, AWS Secrets Manager, Azure Key Vault, and GCP Secret Manager. Declare secret bindings using `declare_service_secrets(my_api, [secret(api_key, aws, 'prod/api-key')])` to associate your API keys with the appropriate backend. Generate environment scripts with `generate_secret_env_script/3` for local deployments or `generate_k8s_external_secret/3` for Kubernetes. This keeps sensitive credentials out of your codebase and allows secure runtime injection.", "question_type": "long", "topics": ["Infrastructure", "Deployment", "Secrets"], "source_file": "by-topic/infrastructure/skills-generated.jsonl", "tags": ["secrets", "vault", "security", "deployment"], "related_skills": ["skill_deployment.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "UnifyWeaver supports HashiCorp Vault, AWS Secrets Manager, Azure Key Vault, and GCP Secret Manager. Declare bindings: `declare_service_secrets(my_api, [secret(db_password, vault, 'secret/data/db'), secret(api_key, aws, 'prod/api-key')])`. Generate with `generate_secret_env_script/3` or `generate_k8s_external_secret/3` for Kubernetes.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_deployment_004_q2", "cluster_id": "skill_deployment_004", "question": "Can I use HashiCorp Vault with UnifyWeaver?", "answer": "Yes, UnifyWeaver supports HashiCorp Vault for secrets management. Declare secret bindings using `declare_service_secrets(my_api, [secret(db_password, vault, 'secret/data/db')])` to specify which secrets to retrieve from Vault. Generate environment scripts with `generate_secret_env_script/3` or use `generate_k8s_external_secret/3` for Kubernetes deployments.", "question_type": "long", "topics": ["Infrastructure", "Deployment", "Secrets"], "source_file": "by-topic/infrastructure/skills-generated.jsonl", "tags": ["secrets", "vault", "security", "deployment"], "related_skills": ["skill_deployment.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "UnifyWeaver supports HashiCorp Vault, AWS Secrets Manager, Azure Key Vault, and GCP Secret Manager. Declare bindings: `declare_service_secrets(my_api, [secret(db_password, vault, 'secret/data/db'), secret(api_key, aws, 'prod/api-key')])`. Generate with `generate_secret_env_script/3` or `generate_k8s_external_secret/3` for Kubernetes.", "answer_tailored": true, "confidence": 0.85, "confidence_issues": null}
{"pair_id": "skill_authentication_001_q0", "cluster_id": "skill_authentication_001", "question": "What password hashing algorithms does UnifyWeaver support?", "answer": "UnifyWeaver supports five password hashing algorithms: plain (development only, no security), sha256 (medium security), bcrypt (high security, recommended for production), argon2 (very high security, proposed), and scrypt (high security, proposed). For production use, configure bcrypt with: `app(my_app, [auth([password_hash(bcrypt)])])`. Check algorithm availability using `hash_available(bcrypt)`.", "question_type": "long", "topics": ["Infrastructure", "Authentication", "Password Hashing"], "source_file": "by-topic/infrastructure/skills-generated.jsonl", "tags": ["password", "hashing", "bcrypt", "security"], "related_skills": ["skill_authentication.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "UnifyWeaver supports: plain (dev only), sha256 (medium security), bcrypt (high, recommended), argon2 (very high, proposed), and scrypt (high, proposed). Use bcrypt for production: `app(my_app, [auth([password_hash(bcrypt)])])`. Query availability with `hash_available(bcrypt)`.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_authentication_001_q1", "cluster_id": "skill_authentication_001", "question": "How do I hash passwords securely?", "answer": "UnifyWeaver supports several password hashing algorithms: plain (development only), sha256 (medium security), bcrypt (high security, recommended for production), argon2 (very high security, proposed), and scrypt (high security, proposed). For secure password hashing in production, use bcrypt by configuring it in your authentication settings: `app(my_app, [auth([password_hash(bcrypt)])])`. You can check if an algorithm is available using `hash_available(bcrypt)` and retrieve algorithm properties with `hash_algorithm(argon2, Props)`.", "question_type": "long", "topics": ["Infrastructure", "Authentication", "Password Hashing"], "source_file": "by-topic/infrastructure/skills-generated.jsonl", "tags": ["password", "hashing", "bcrypt", "security"], "related_skills": ["skill_authentication.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "UnifyWeaver supports: plain (dev only), sha256 (medium security), bcrypt (high, recommended), argon2 (very high, proposed), and scrypt (high, proposed). Use bcrypt for production: `app(my_app, [auth([password_hash(bcrypt)])])`. Query availability with `hash_available(bcrypt)`.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_authentication_001_q2", "cluster_id": "skill_authentication_001", "question": "What's the recommended password hash?", "answer": "For production use, bcrypt is the recommended password hashing algorithm in UnifyWeaver. It provides high security and is fully implemented. Use it in your auth configuration with `password_hash(bcrypt)`. If you need even higher security, argon2 (very high security) is proposed but not yet implemented. Plain text hashing is only for development, and sha256 provides medium security.", "question_type": "long", "topics": ["Infrastructure", "Authentication", "Password Hashing"], "source_file": "by-topic/infrastructure/skills-generated.jsonl", "tags": ["password", "hashing", "bcrypt", "security"], "related_skills": ["skill_authentication.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "UnifyWeaver supports: plain (dev only), sha256 (medium security), bcrypt (high, recommended), argon2 (very high, proposed), and scrypt (high, proposed). Use bcrypt for production: `app(my_app, [auth([password_hash(bcrypt)])])`. Query availability with `hash_available(bcrypt)`.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_authentication_002_q0", "cluster_id": "skill_authentication_002", "question": "How do I set up JWT authentication?", "answer": "To set up JWT authentication, configure your app with `app(my_app, [auth([backend(text_file), password_hash(bcrypt), token_type(jwt), session_duration(86400)])])`. Then generate the auth server using `generate_auth_server(AppSpec, node, Files)`. The generated server provides authenticate/2 for validating credentials, register/4 for user creation, and automatic JWT token generation for authenticated requests.", "question_type": "long", "topics": ["Infrastructure", "Authentication", "JWT"], "source_file": "by-topic/infrastructure/skills-generated.jsonl", "tags": ["jwt", "token", "authentication", "stateless"], "related_skills": ["skill_authentication.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "Configure JWT in your app: `app(my_app, [auth([backend(text_file), password_hash(bcrypt), token_type(jwt), session_duration(86400)])])`. Generate the auth server with `generate_auth_server(AppSpec, node, Files)`. The generated server includes authenticate/2, register/4, and JWT token generation.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_authentication_002_q1", "cluster_id": "skill_authentication_002", "question": "Can UnifyWeaver generate JWT tokens?", "answer": "Yes, UnifyWeaver can generate JWT tokens. Configure JWT as the token type in your app specification: `app(my_app, [auth([backend(text_file), password_hash(bcrypt), token_type(jwt), session_duration(86400)])])`. Then generate the auth server using `generate_auth_server(AppSpec, node, Files)`. The generated server includes JWT token generation functionality along with authenticate/2 and register/4 endpoints.", "question_type": "long", "topics": ["Infrastructure", "Authentication", "JWT"], "source_file": "by-topic/infrastructure/skills-generated.jsonl", "tags": ["jwt", "token", "authentication", "stateless"], "related_skills": ["skill_authentication.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "Configure JWT in your app: `app(my_app, [auth([backend(text_file), password_hash(bcrypt), token_type(jwt), session_duration(86400)])])`. Generate the auth server with `generate_auth_server(AppSpec, node, Files)`. The generated server includes authenticate/2, register/4, and JWT token generation.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_authentication_002_q2", "cluster_id": "skill_authentication_002", "question": "How do I use stateless auth?", "answer": "To use stateless auth, configure JWT tokens in your app specification: `app(my_app, [auth([backend(text_file), password_hash(bcrypt), token_type(jwt), session_duration(86400)])])`. Generate the auth server using `generate_auth_server(AppSpec, node, Files)`. JWT is stateless\u2014tokens are self-contained and don't require server-side session storage. The generated server provides authenticate/2 for login (returns JWT), register/4 for user creation, and automatic token validation on subsequent requests. Each request includes the JWT in the Authorization header, and the server verifies it without querying a session database.", "question_type": "long", "topics": ["Infrastructure", "Authentication", "JWT"], "source_file": "by-topic/infrastructure/skills-generated.jsonl", "tags": ["jwt", "token", "authentication", "stateless"], "related_skills": ["skill_authentication.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "Configure JWT in your app: `app(my_app, [auth([backend(text_file), password_hash(bcrypt), token_type(jwt), session_duration(86400)])])`. Generate the auth server with `generate_auth_server(AppSpec, node, Files)`. The generated server includes authenticate/2, register/4, and JWT token generation.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_authentication_003_q0", "cluster_id": "skill_authentication_003", "question": "How do I configure OAuth2 authentication?", "answer": "To configure OAuth2 authentication, use the oauth2 backend with your desired providers: `app(my_app, [auth([backend(oauth2), providers([google, github]), token_type(jwt)])])`. This enables delegated authentication through external OAuth2 providers like Google and GitHub. Note that OAuth2 support is currently in proposed status and not yet fully implemented. For production deployments, consider using the text_file or database backends (sqlite, postgresql) until OAuth2 becomes stable.", "question_type": "long", "topics": ["Infrastructure", "Authentication", "OAuth2"], "source_file": "by-topic/infrastructure/skills-generated.jsonl", "tags": ["oauth2", "google", "github", "social"], "related_skills": ["skill_authentication.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "Configure OAuth2 backend: `app(social_app, [auth([backend(oauth2), providers([google, github]), token_type(jwt)])])`. This enables delegated authentication via external providers. OAuth2 support is currently proposed/experimental. For production, consider text_file or database backends until OAuth2 is fully implemented.", "answer_tailored": true, "confidence": 0.75, "confidence_issues": "OAuth2 is marked as 'Proposed' status rather than 'Implemented', so the answer appropriately cautions against production use. The skill document provides the configuration syntax but limited implementation details about setup steps, required credentials, or callback configuration."}
{"pair_id": "skill_authentication_003_q1", "cluster_id": "skill_authentication_003", "question": "Can I add Google or GitHub login?", "answer": "Yes, you can add Google or GitHub login using the OAuth2 backend. Configure it with: `app(social_app, [auth([backend(oauth2), providers([google, github]), token_type(jwt)])])`. This enables delegated authentication via external providers. Note that OAuth2 support is currently proposed/experimental, so for production use consider the implemented backends like text_file or database backends until OAuth2 is fully implemented.", "question_type": "long", "topics": ["Infrastructure", "Authentication", "OAuth2"], "source_file": "by-topic/infrastructure/skills-generated.jsonl", "tags": ["oauth2", "google", "github", "social"], "related_skills": ["skill_authentication.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "Configure OAuth2 backend: `app(social_app, [auth([backend(oauth2), providers([google, github]), token_type(jwt)])])`. This enables delegated authentication via external providers. OAuth2 support is currently proposed/experimental. For production, consider text_file or database backends until OAuth2 is fully implemented.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_authentication_003_q2", "cluster_id": "skill_authentication_003", "question": "How do I set up social login?", "answer": "To set up social login, configure the OAuth2 backend in your authentication settings: `app(my_app, [auth([backend(oauth2), providers([google, github]), token_type(jwt)])])`. This enables delegated authentication through external providers like Google and GitHub. Note that OAuth2 support is currently in proposed/experimental status. For production use, consider using text_file or database backends until OAuth2 is fully implemented and stable.", "question_type": "long", "topics": ["Infrastructure", "Authentication", "OAuth2"], "source_file": "by-topic/infrastructure/skills-generated.jsonl", "tags": ["oauth2", "google", "github", "social"], "related_skills": ["skill_authentication.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "Configure OAuth2 backend: `app(social_app, [auth([backend(oauth2), providers([google, github]), token_type(jwt)])])`. This enables delegated authentication via external providers. OAuth2 support is currently proposed/experimental. For production, consider text_file or database backends until OAuth2 is fully implemented.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_001_q0", "cluster_id": "skill_folder_suggestion_001", "question": "How do I know where a mindmap should be organized?", "answer": "Use the folder suggestion skill to determine where a mindmap should be organized. Run `python3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"` to get folder suggestions ranked by semantic similarity. The output shows probability scores for each suggested folder: >50% indicates a strong match for where the mindmap belongs, 25-50% suggests a good match with some ambiguity, and <25% means multiple folders could work equally well. You can also search by title using `--title \"MINDMAP_TITLE\"` if you don't have the tree ID.", "question_type": "medium", "topics": ["Mindmap", "Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["organization", "mindmap", "folder-management"], "related_skills": ["skill_folder_suggestion.md", "skill_mst_folder_grouping.md", "skill_mindmap_linking.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/suggest_folder.py"], "original_answer": "Use the folder suggestion skill to find the best folder for a mindmap using semantic similarity. Run: `python3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"` to get suggestions with confidence scores. Folders with >50% probability are strong matches, 25-50% are good matches with some ambiguity, and <25% suggest multiple valid options.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_001_q1", "cluster_id": "skill_folder_suggestion_001", "question": "Where should this mindmap go?", "answer": "Use the folder suggestion skill to find the best folder for a mindmap. Run `python3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"` to get folder suggestions ranked by semantic similarity. The output shows probability scores: >50% indicates a strong match for that folder, 25-50% shows good matches with some ambiguity about placement, and <25% means multiple folders are equally valid. You can also search by title using `--title \"MINDMAP_TITLE\"` instead of tree ID.", "question_type": "medium", "topics": ["Mindmap", "Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["organization", "mindmap", "folder-management"], "related_skills": ["skill_folder_suggestion.md", "skill_mst_folder_grouping.md", "skill_mindmap_linking.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/suggest_folder.py"], "original_answer": "Use the folder suggestion skill to find the best folder for a mindmap using semantic similarity. Run: `python3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"` to get suggestions with confidence scores. Folders with >50% probability are strong matches, 25-50% are good matches with some ambiguity, and <25% suggest multiple valid options.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_001_q2", "cluster_id": "skill_folder_suggestion_001", "question": "Can I get folder suggestions for my mindmap?", "answer": "Yes, you can get folder suggestions for your mindmap using the folder suggestion skill. Run `python3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"` to get suggestions with confidence scores. Folders with >50% probability are strong matches, 25-50% are good matches with some ambiguity, and <25% suggest multiple valid options. You can also suggest by title using `--title \"MINDMAP_TITLE\"` or check an entire folder for misplacements with `--check-folder \"FOLDER_PATH\" --threshold 0.5`.", "question_type": "medium", "topics": ["Mindmap", "Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["organization", "mindmap", "folder-management"], "related_skills": ["skill_folder_suggestion.md", "skill_mst_folder_grouping.md", "skill_mindmap_linking.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/suggest_folder.py"], "original_answer": "Use the folder suggestion skill to find the best folder for a mindmap using semantic similarity. Run: `python3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"` to get suggestions with confidence scores. Folders with >50% probability are strong matches, 25-50% are good matches with some ambiguity, and <25% suggest multiple valid options.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_001_q3", "cluster_id": "skill_folder_suggestion_001", "question": "How do I find the best folder for a mindmap?", "answer": "Use the folder suggestion skill to find the best folder for a mindmap using semantic similarity and Procrustes projection. Run `python3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"` to get folder suggestions with confidence scores. Interpret results: >50% probability indicates a strong match, 25-50% indicates a good match with minor ambiguity, and <25% suggests multiple valid options. You can also search by title with `--title \"MINDMAP_TITLE\"` or check an entire folder for misplacements with `--check-folder \"FOLDER_PATH\" --threshold 0.5`. First ensure folder projections are built using `scripts/mindmap/build_folder_projections.py`.", "question_type": "medium", "topics": ["Mindmap", "Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["organization", "mindmap", "folder-management"], "related_skills": ["skill_folder_suggestion.md", "skill_mst_folder_grouping.md", "skill_mindmap_linking.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/suggest_folder.py"], "original_answer": "Use the folder suggestion skill to find the best folder for a mindmap using semantic similarity. Run: `python3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"` to get suggestions with confidence scores. Folders with >50% probability are strong matches, 25-50% are good matches with some ambiguity, and <25% suggest multiple valid options.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_002_q0", "cluster_id": "skill_folder_suggestion_002", "question": "How can I check if mindmaps in a folder are organized correctly?", "answer": "Use the folder suggestion skill to audit an entire folder for misplaced mindmaps. Run: `python3 scripts/mindmap/suggest_folder.py --check-folder \"FOLDER_PATH\" --threshold 0.5` to identify mindmaps that may belong in a different folder based on semantic similarity. The threshold parameter controls sensitivity\u2014lower values apply stricter checking to catch more potential misplacements. This command analyzes each mindmap's semantic content against folder projections to find organization inconsistencies.", "question_type": "medium", "topics": ["Mindmap", "Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["organization", "mindmap", "validation", "folder-management"], "related_skills": ["skill_folder_suggestion.md", "skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/suggest_folder.py", "docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "Use the folder suggestion skill to audit an entire folder for misplaced mindmaps. Run: `python3 scripts/mindmap/suggest_folder.py --check-folder \"FOLDER_PATH\" --threshold 0.5` to identify mindmaps that may belong in a different folder based on semantic similarity. The threshold parameter controls sensitivity (lower = stricter checking).", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_002_q1", "cluster_id": "skill_folder_suggestion_002", "question": "Are my mindmaps in the right folders?", "answer": "To check if your mindmaps are in the right folders, use the folder suggestion skill's audit feature. Run: `python3 scripts/mindmap/suggest_folder.py --check-folder \"FOLDER_PATH\" --threshold 0.5` to identify mindmaps that may belong in a different folder based on semantic similarity. The threshold parameter controls sensitivity\u2014lower values perform stricter checking to catch more potential misplacements. This will compare each mindmap's semantic content against all available folders and flag items with weak semantic alignment to their current location.", "question_type": "medium", "topics": ["Mindmap", "Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["organization", "mindmap", "validation", "folder-management"], "related_skills": ["skill_folder_suggestion.md", "skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/suggest_folder.py", "docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "Use the folder suggestion skill to audit an entire folder for misplaced mindmaps. Run: `python3 scripts/mindmap/suggest_folder.py --check-folder \"FOLDER_PATH\" --threshold 0.5` to identify mindmaps that may belong in a different folder based on semantic similarity. The threshold parameter controls sensitivity (lower = stricter checking).", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_002_q2", "cluster_id": "skill_folder_suggestion_002", "question": "How do I find misplaced mindmaps?", "answer": "To find misplaced mindmaps, use the folder suggestion script with the `--check-folder` flag: `python3 scripts/mindmap/suggest_folder.py --check-folder \"FOLDER_PATH\" --threshold 0.5`. This audits an entire folder and identifies mindmaps that semantically belong in different folders based on semantic similarity analysis. Adjust the threshold lower for stricter checking or higher to be more lenient.", "question_type": "medium", "topics": ["Mindmap", "Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["organization", "mindmap", "validation", "folder-management"], "related_skills": ["skill_folder_suggestion.md", "skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/suggest_folder.py", "docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "Use the folder suggestion skill to audit an entire folder for misplaced mindmaps. Run: `python3 scripts/mindmap/suggest_folder.py --check-folder \"FOLDER_PATH\" --threshold 0.5` to identify mindmaps that may belong in a different folder based on semantic similarity. The threshold parameter controls sensitivity (lower = stricter checking).", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_002_q3", "cluster_id": "skill_folder_suggestion_002", "question": "Can I scan a folder for organization issues?", "answer": "Yes, you can scan a folder for organization issues using the folder suggestion skill. Run `python3 scripts/mindmap/suggest_folder.py --check-folder \"FOLDER_PATH\" --threshold 0.5` to audit an entire folder and identify mindmaps that may be misplaced based on semantic similarity. The threshold parameter controls sensitivity\u2014lower values perform stricter checking to find more potential misplacements.", "question_type": "medium", "topics": ["Mindmap", "Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["organization", "mindmap", "validation", "folder-management"], "related_skills": ["skill_folder_suggestion.md", "skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/suggest_folder.py", "docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "Use the folder suggestion skill to audit an entire folder for misplaced mindmaps. Run: `python3 scripts/mindmap/suggest_folder.py --check-folder \"FOLDER_PATH\" --threshold 0.5` to identify mindmaps that may belong in a different folder based on semantic similarity. The threshold parameter controls sensitivity (lower = stricter checking).", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_003_q0", "cluster_id": "skill_folder_suggestion_003", "question": "Can I search for a folder suggestion by mindmap title instead of ID?", "answer": "Yes, you can suggest a folder by mindmap title instead of tree ID. Use the command: `python3 scripts/mindmap/suggest_folder.py --title \"MINDMAP_TITLE\"` to get folder suggestions based on the mindmap's title and semantic content.", "question_type": "long", "topics": ["Mindmap", "Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["organization", "mindmap", "search"], "related_skills": ["skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/suggest_folder.py", "scripts/mindmap/README.md"], "original_answer": "Yes, you can suggest a folder by mindmap title instead of tree ID. Run: `python3 scripts/mindmap/suggest_folder.py --title \"MINDMAP_TITLE\"` to get folder suggestions based on the mindmap's title and semantic content.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_003_q1", "cluster_id": "skill_folder_suggestion_003", "question": "How do I suggest a folder for a mindmap by name?", "answer": "You can suggest a folder for a mindmap by name using the `--title` flag. Run: `python3 scripts/mindmap/suggest_folder.py --title \"MINDMAP_TITLE\"` to get folder suggestions based on the mindmap's title and semantic content.", "question_type": "long", "topics": ["Mindmap", "Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["organization", "mindmap", "search"], "related_skills": ["skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/suggest_folder.py", "scripts/mindmap/README.md"], "original_answer": "Yes, you can suggest a folder by mindmap title instead of tree ID. Run: `python3 scripts/mindmap/suggest_folder.py --title \"MINDMAP_TITLE\"` to get folder suggestions based on the mindmap's title and semantic content.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_003_q2", "cluster_id": "skill_folder_suggestion_003", "question": "Can I use the mindmap title to find a folder?", "answer": "Yes, you can suggest a folder by mindmap title using the `--title` parameter. Run: `python3 scripts/mindmap/suggest_folder.py --title \"MINDMAP_TITLE\"` to get folder suggestions based on the mindmap's semantic content.", "question_type": "long", "topics": ["Mindmap", "Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["organization", "mindmap", "search"], "related_skills": ["skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/suggest_folder.py", "scripts/mindmap/README.md"], "original_answer": "Yes, you can suggest a folder by mindmap title instead of tree ID. Run: `python3 scripts/mindmap/suggest_folder.py --title \"MINDMAP_TITLE\"` to get folder suggestions based on the mindmap's title and semantic content.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_004_q0", "cluster_id": "skill_folder_suggestion_004", "question": "What do I need to set up before using folder suggestions?", "answer": "Before using folder suggestions, you need to build folder projections first. Run `python3 scripts/mindmap/build_folder_projections.py --embeddings \"EMBEDDINGS_FILE\" --index \"INDEX_FILE\" --output \"PROJECTIONS_DB\"` to create the W matrices that map mindmaps to their optimal folders using Procrustes projection and semantic embeddings.", "question_type": "medium", "topics": ["Mindmap", "Setup"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["setup", "preparation", "projections"], "related_skills": ["skill_folder_suggestion.md", "skill_train_model.md"], "related_docs": ["scripts/mindmap/build_folder_projections.py", "docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "Before using folder suggestions, build folder projections using semantic embeddings. Run: `python3 scripts/mindmap/build_folder_projections.py --embeddings \"EMBEDDINGS_FILE\" --index \"INDEX_FILE\" --output \"PROJECTIONS_DB\"` to create the necessary projection models. This uses Procrustes projection to map mindmaps to their optimal folders semantically.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_004_q1", "cluster_id": "skill_folder_suggestion_004", "question": "How do I prepare folder projections?", "answer": "To prepare folder projections, run: `python3 scripts/mindmap/build_folder_projections.py --embeddings \"EMBEDDINGS_FILE\" --index \"INDEX_FILE\" --output \"PROJECTIONS_DB\"`. This builds the necessary projection models using semantic embeddings and Procrustes projection, which enables the folder suggestion system to semantically match mindmaps to their optimal folders.", "question_type": "medium", "topics": ["Mindmap", "Setup"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["setup", "preparation", "projections"], "related_skills": ["skill_folder_suggestion.md", "skill_train_model.md"], "related_docs": ["scripts/mindmap/build_folder_projections.py", "docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "Before using folder suggestions, build folder projections using semantic embeddings. Run: `python3 scripts/mindmap/build_folder_projections.py --embeddings \"EMBEDDINGS_FILE\" --index \"INDEX_FILE\" --output \"PROJECTIONS_DB\"` to create the necessary projection models. This uses Procrustes projection to map mindmaps to their optimal folders semantically.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_004_q2", "cluster_id": "skill_folder_suggestion_004", "question": "What's required to use the folder suggestion tool?", "answer": "To use the folder suggestion tool, you must first build folder projections by running: `python3 scripts/mindmap/build_folder_projections.py --embeddings \"EMBEDDINGS_FILE\" --index \"INDEX_FILE\" --output \"PROJECTIONS_DB\"`. This creates the semantic projection models needed for the suggestion script to work. Once projections are built, you can suggest folders using commands like `python3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"`.", "question_type": "medium", "topics": ["Mindmap", "Setup"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["setup", "preparation", "projections"], "related_skills": ["skill_folder_suggestion.md", "skill_train_model.md"], "related_docs": ["scripts/mindmap/build_folder_projections.py", "docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "Before using folder suggestions, build folder projections using semantic embeddings. Run: `python3 scripts/mindmap/build_folder_projections.py --embeddings \"EMBEDDINGS_FILE\" --index \"INDEX_FILE\" --output \"PROJECTIONS_DB\"` to create the necessary projection models. This uses Procrustes projection to map mindmaps to their optimal folders semantically.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_004_q3", "cluster_id": "skill_folder_suggestion_004", "question": "Do I need to build projections first?", "answer": "Yes, you need to build projections first. Run `python3 scripts/mindmap/build_folder_projections.py --embeddings \"EMBEDDINGS_FILE\" --index \"INDEX_FILE\" --output \"PROJECTIONS_DB\"` before using folder suggestions. This creates the Procrustes projection models that map mindmaps to their optimal folders semantically.", "question_type": "medium", "topics": ["Mindmap", "Setup"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["setup", "preparation", "projections"], "related_skills": ["skill_folder_suggestion.md", "skill_train_model.md"], "related_docs": ["scripts/mindmap/build_folder_projections.py", "docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "Before using folder suggestions, build folder projections using semantic embeddings. Run: `python3 scripts/mindmap/build_folder_projections.py --embeddings \"EMBEDDINGS_FILE\" --index \"INDEX_FILE\" --output \"PROJECTIONS_DB\"` to create the necessary projection models. This uses Procrustes projection to map mindmaps to their optimal folders semantically.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_001_q0", "cluster_id": "skill_mindmap_cross_links_001", "question": "How do I link multiple mindmaps together?", "answer": "Use cloudmapref links to connect mindmaps for local navigation. First build an index with `python3 scripts/mindmap/build_index.py output/mindmaps/ -o output/mindmaps/index.json` to catalog all your mindmaps, then add cross-links with `python3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx --index output/mindmaps/index.json`. This creates local navigation links between the mindmaps without requiring external URLs, allowing you to reference and navigate between multiple linked mindmaps.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["linking", "cross-reference", "navigation"], "related_skills": ["skill_mindmap_linking.md", "skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/build_index.py", "scripts/mindmap/add_relative_links.py"], "original_answer": "Use cloudmapref links to connect mindmaps for local navigation. First build an index with `python3 scripts/mindmap/build_index.py output/mindmaps/ -o output/mindmaps/index.json`, then add cross-links with `python3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx --index output/mindmaps/index.json`. This creates local navigation links between mindmaps without requiring external URLs.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer addresses linking mindmaps together but doesn't clarify the difference between linking mindmaps to Pearltrees (the primary skill) versus linking mindmaps to each other (which is a separate technical concern). The answer is technically accurate for the mindmap-to-mindmap use case, but the question could be ambiguous about whether the user wants to link mindmaps together or link them to Pearltrees content."}
{"pair_id": "skill_mindmap_cross_links_001_q1", "cluster_id": "skill_mindmap_cross_links_001", "question": "How can I connect mindmaps to each other?", "answer": "To connect mindmaps to each other, use cloudmapref links for local navigation. First build an index of your mindmaps with `python3 scripts/mindmap/build_index.py output/mindmaps/ -o output/mindmaps/index.json`, then add cross-links between them using `python3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx --index output/mindmaps/index.json`. This creates navigable links between mindmaps without requiring external URLs.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["linking", "cross-reference", "navigation"], "related_skills": ["skill_mindmap_linking.md", "skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/build_index.py", "scripts/mindmap/add_relative_links.py"], "original_answer": "Use cloudmapref links to connect mindmaps for local navigation. First build an index with `python3 scripts/mindmap/build_index.py output/mindmaps/ -o output/mindmaps/index.json`, then add cross-links with `python3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx --index output/mindmaps/index.json`. This creates local navigation links between mindmaps without requiring external URLs.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_001_q2", "cluster_id": "skill_mindmap_cross_links_001", "question": "How do I cross-reference mindmaps?", "answer": "To cross-reference mindmaps, build an index first with `python3 scripts/mindmap/build_index.py output/mindmaps/ -o output/mindmaps/index.json`, then add cross-links using `python3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx --index output/mindmaps/index.json`. This creates cloudmapref links that enable local navigation between mindmaps without requiring external URLs.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["linking", "cross-reference", "navigation"], "related_skills": ["skill_mindmap_linking.md", "skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/build_index.py", "scripts/mindmap/add_relative_links.py"], "original_answer": "Use cloudmapref links to connect mindmaps for local navigation. First build an index with `python3 scripts/mindmap/build_index.py output/mindmaps/ -o output/mindmaps/index.json`, then add cross-links with `python3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx --index output/mindmaps/index.json`. This creates local navigation links between mindmaps without requiring external URLs.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_001_q3", "cluster_id": "skill_mindmap_cross_links_001", "question": "Can I make mindmaps link to each other?", "answer": "Yes, you can link mindmaps to each other using cloudmapref links for local navigation. First, build an index of your mindmaps with `python3 scripts/mindmap/build_index.py output/mindmaps/ -o output/mindmaps/index.json`. Then add cross-links between mindmaps with `python3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx --index output/mindmaps/index.json`. This creates local navigation links between mindmaps without requiring external URLs.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["linking", "cross-reference", "navigation"], "related_skills": ["skill_mindmap_linking.md", "skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/build_index.py", "scripts/mindmap/add_relative_links.py"], "original_answer": "Use cloudmapref links to connect mindmaps for local navigation. First build an index with `python3 scripts/mindmap/build_index.py output/mindmaps/ -o output/mindmaps/index.json`, then add cross-links with `python3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx --index output/mindmaps/index.json`. This creates local navigation links between mindmaps without requiring external URLs.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_002_q0", "cluster_id": "skill_mindmap_cross_links_002", "question": "How do I rename mindmaps without breaking links?", "answer": "Use `rename_mindmap.py` to safely rename mindmaps while automatically updating all cross-link references. For auto-generated names based on the root topic, run: `python3 scripts/mindmap/rename_mindmap.py --mindmap \"MINDMAP_PATH\" --titled`. For explicit names, use: `python3 scripts/mindmap/rename_mindmap.py --mindmap \"MINDMAP_PATH\" --new-name \"New_Name.smmx\"`. To batch rename multiple mindmaps, use: `python3 scripts/mindmap/rename_mindmap.py --batch \"MINDMAP_DIR\" --titled --dry-run`. The tool handles updating all references automatically, so links won't break.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["rename", "refactoring", "preservation"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py"], "original_answer": "Use `rename_mindmap.py` to safely rename mindmaps and update all cross-link references. For auto-generated names based on root topic: `python3 scripts/mindmap/rename_mindmap.py --mindmap \"MINDMAP_PATH\" --titled`. For explicit names: `python3 scripts/mindmap/rename_mindmap.py --mindmap \"MINDMAP_PATH\" --new-name \"New_Name.smmx\"`. For batch renaming: `python3 scripts/mindmap/rename_mindmap.py --batch \"MINDMAP_DIR\" --titled --dry-run`", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_002_q1", "cluster_id": "skill_mindmap_cross_links_002", "question": "Can I safely rename a mindmap?", "answer": "Yes, you can safely rename a mindmap using `rename_mindmap.py`. This tool updates all cross-link references automatically, so existing cloudmapref links won't break. Use `--titled` to auto-generate the name from the root topic, or `--new-name` to specify an explicit name. For batch renaming, use `--batch` with `--dry-run` to preview changes first.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["rename", "refactoring", "preservation"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py"], "original_answer": "Use `rename_mindmap.py` to safely rename mindmaps and update all cross-link references. For auto-generated names based on root topic: `python3 scripts/mindmap/rename_mindmap.py --mindmap \"MINDMAP_PATH\" --titled`. For explicit names: `python3 scripts/mindmap/rename_mindmap.py --mindmap \"MINDMAP_PATH\" --new-name \"New_Name.smmx\"`. For batch renaming: `python3 scripts/mindmap/rename_mindmap.py --batch \"MINDMAP_DIR\" --titled --dry-run`", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_002_q2", "cluster_id": "skill_mindmap_cross_links_002", "question": "How do I rename mindmaps and update their references?", "answer": "Use `rename_mindmap.py` to safely rename mindmaps while updating all cross-link references. For auto-generated names based on the root topic: `python3 scripts/mindmap/rename_mindmap.py --mindmap \"MINDMAP_PATH\" --titled`. For explicit names: `python3 scripts/mindmap/rename_mindmap.py --mindmap \"MINDMAP_PATH\" --new-name \"New_Name.smmx\"`. For batch renaming multiple mindmaps: `python3 scripts/mindmap/rename_mindmap.py --batch \"MINDMAP_DIR\" --titled --dry-run` to preview changes before applying.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["rename", "refactoring", "preservation"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py"], "original_answer": "Use `rename_mindmap.py` to safely rename mindmaps and update all cross-link references. For auto-generated names based on root topic: `python3 scripts/mindmap/rename_mindmap.py --mindmap \"MINDMAP_PATH\" --titled`. For explicit names: `python3 scripts/mindmap/rename_mindmap.py --mindmap \"MINDMAP_PATH\" --new-name \"New_Name.smmx\"`. For batch renaming: `python3 scripts/mindmap/rename_mindmap.py --batch \"MINDMAP_DIR\" --titled --dry-run`", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_002_q3", "cluster_id": "skill_mindmap_cross_links_002", "question": "What happens to links when I rename a mindmap?", "answer": "When you rename a mindmap, use `rename_mindmap.py` to automatically update all cross-link references that point to it. The script preserves `cloudmapref` links by updating the target paths. For auto-generated names from the root topic: `python3 scripts/mindmap/rename_mindmap.py --mindmap \"MINDMAP_PATH\" --titled`. For explicit names: `python3 scripts/mindmap/rename_mindmap.py --mindmap \"MINDMAP_PATH\" --new-name \"New_Name.smmx\"`. Use `--dry-run` first to preview changes before applying them.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["rename", "refactoring", "preservation"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py"], "original_answer": "Use `rename_mindmap.py` to safely rename mindmaps and update all cross-link references. For auto-generated names based on root topic: `python3 scripts/mindmap/rename_mindmap.py --mindmap \"MINDMAP_PATH\" --titled`. For explicit names: `python3 scripts/mindmap/rename_mindmap.py --mindmap \"MINDMAP_PATH\" --new-name \"New_Name.smmx\"`. For batch renaming: `python3 scripts/mindmap/rename_mindmap.py --batch \"MINDMAP_DIR\" --titled --dry-run`", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_003_q0", "cluster_id": "skill_mindmap_cross_links_003", "question": "How do I preview what links will be added before applying them?", "answer": "Use the `--dry-run` and `--verbose` flags with the `add_relative_links.py` script to preview changes without modifying files: `python3 scripts/mindmap/add_relative_links.py \"MINDMAP_FILES\" --index \"INDEX_FILE\" --dry-run --verbose`. This displays exactly which links will be added to which mindmaps before applying them.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["preview", "dry-run", "testing"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/add_relative_links.py"], "original_answer": "Use the dry-run mode to preview changes without modifying files: `python3 scripts/mindmap/add_relative_links.py \"MINDMAP_FILES\" --index \"INDEX_FILE\" --dry-run --verbose`. This shows exactly which links will be added to which mindmaps before you commit to the changes.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_003_q1", "cluster_id": "skill_mindmap_cross_links_003", "question": "Can I see what cross-links will be created?", "answer": "Yes, use dry-run mode to preview cross-links before applying them: `python3 scripts/mindmap/add_relative_links.py \"MINDMAP_FILES\" --index \"INDEX_FILE\" --dry-run --verbose`. This command shows exactly which `cloudmapref` links will be added to which mindmaps without modifying any files.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["preview", "dry-run", "testing"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/add_relative_links.py"], "original_answer": "Use the dry-run mode to preview changes without modifying files: `python3 scripts/mindmap/add_relative_links.py \"MINDMAP_FILES\" --index \"INDEX_FILE\" --dry-run --verbose`. This shows exactly which links will be added to which mindmaps before you commit to the changes.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_003_q2", "cluster_id": "skill_mindmap_cross_links_003", "question": "How do I do a dry run of link creation?", "answer": "To preview link creation without modifying files, run: `python3 scripts/mindmap/add_relative_links.py \"MINDMAP_FILES\" --index \"INDEX_FILE\" --dry-run --verbose`. The `--dry-run` flag shows which links would be added to which mindmaps, and `--verbose` provides detailed output of the changes before they're committed.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["preview", "dry-run", "testing"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/add_relative_links.py"], "original_answer": "Use the dry-run mode to preview changes without modifying files: `python3 scripts/mindmap/add_relative_links.py \"MINDMAP_FILES\" --index \"INDEX_FILE\" --dry-run --verbose`. This shows exactly which links will be added to which mindmaps before you commit to the changes.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_003_q3", "cluster_id": "skill_mindmap_cross_links_003", "question": "How do I test mindmap linking safely?", "answer": "Use the `--dry-run` and `--verbose` flags to preview mindmap link changes safely without modifying files: `python3 scripts/mindmap/add_relative_links.py \"MINDMAP_FILES\" --index \"INDEX_FILE\" --dry-run --verbose`. This shows exactly which cloudmapref links will be added to which mindmaps before committing to the changes. You can also do a batch dry-run rename with `python3 scripts/mindmap/rename_mindmap.py --batch \"MINDMAP_DIR\" --titled --dry-run` to preview name-based updates.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["preview", "dry-run", "testing"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/add_relative_links.py"], "original_answer": "Use the dry-run mode to preview changes without modifying files: `python3 scripts/mindmap/add_relative_links.py \"MINDMAP_FILES\" --index \"INDEX_FILE\" --dry-run --verbose`. This shows exactly which links will be added to which mindmaps before you commit to the changes.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_004_q0", "cluster_id": "skill_mindmap_cross_links_004", "question": "How do I find all mindmaps that reference a specific mindmap?", "answer": "Use the reverse index builder to find all mindmaps that reference a specific mindmap: `python3 scripts/mindmap/build_reverse_index.py \"MINDMAP_DIR\" -o \"REVERSE_INDEX_FILE\"`. This creates a backlinks index that shows which mindmaps contain references to any given mindmap, allowing you to quickly identify all incoming cross-links.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["backlinks", "references", "dependencies"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/build_reverse_index.py"], "original_answer": "Build a reverse index to track which mindmaps reference others: `python3 scripts/mindmap/build_reverse_index.py \"MINDMAP_DIR\" -o \"REVERSE_INDEX_FILE\"`. This creates a backlinks index showing all incoming references to each mindmap, helping you understand dependency relationships in your mindmap collection.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_004_q1", "cluster_id": "skill_mindmap_cross_links_004", "question": "How do I see which mindmaps link to this one?", "answer": "Build a reverse index using `python3 scripts/mindmap/build_reverse_index.py \"MINDMAP_DIR\" -o \"REVERSE_INDEX_FILE\"`. This creates a backlinks index showing which mindmaps link to your specific mindmap, allowing you to see all incoming references and understand the dependency relationships.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["backlinks", "references", "dependencies"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/build_reverse_index.py"], "original_answer": "Build a reverse index to track which mindmaps reference others: `python3 scripts/mindmap/build_reverse_index.py \"MINDMAP_DIR\" -o \"REVERSE_INDEX_FILE\"`. This creates a backlinks index showing all incoming references to each mindmap, helping you understand dependency relationships in your mindmap collection.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_004_q2", "cluster_id": "skill_mindmap_cross_links_004", "question": "Can I build a backlinks index?", "answer": "Yes, you can build a backlinks index using `python3 scripts/mindmap/build_reverse_index.py \"MINDMAP_DIR\" -o \"REVERSE_INDEX_FILE\"`. This creates a reverse index that tracks which mindmaps reference others, showing all incoming references to each mindmap and helping you understand dependency relationships in your collection.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["backlinks", "references", "dependencies"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/build_reverse_index.py"], "original_answer": "Build a reverse index to track which mindmaps reference others: `python3 scripts/mindmap/build_reverse_index.py \"MINDMAP_DIR\" -o \"REVERSE_INDEX_FILE\"`. This creates a backlinks index showing all incoming references to each mindmap, helping you understand dependency relationships in your mindmap collection.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_004_q3", "cluster_id": "skill_mindmap_cross_links_004", "question": "How do I create a reverse index of mindmap references?", "answer": "Build a reverse index to track which mindmaps reference others using: `python3 scripts/mindmap/build_reverse_index.py \"MINDMAP_DIR\" -o \"REVERSE_INDEX_FILE\"`. This creates a backlinks index showing all incoming references to each mindmap, helping you understand dependency relationships in your mindmap collection.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["backlinks", "references", "dependencies"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/build_reverse_index.py"], "original_answer": "Build a reverse index to track which mindmaps reference others: `python3 scripts/mindmap/build_reverse_index.py \"MINDMAP_DIR\" -o \"REVERSE_INDEX_FILE\"`. This creates a backlinks index showing all incoming references to each mindmap, helping you understand dependency relationships in your mindmap collection.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_001_q0", "cluster_id": "skill_mindmap_linking_001", "question": "How do I connect my SimpleMind mindmap to Pearltrees?", "answer": "To connect your SimpleMind mindmap to Pearltrees, use the mindmap linking skill. Run: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --output \"OUTPUT_PATH\"`. For best results with hierarchical semantic matching, add embeddings and projection model: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --embeddings datasets/pearltrees_combined_embeddings.npz --projection-model models/pearltrees_federated_nomic.pkl --output \"OUTPUT_PATH\"`. The tool enriches your mindmap by matching nodes to Pearltrees content using title matching, URL matching, and semantic similarity.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "pearltrees", "linking", "enrichment"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/README.md"], "original_answer": "Use the mindmap linking skill to automatically connect your SimpleMind mindmap to Pearltrees content. The basic command is: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --output \"OUTPUT_PATH\"`. For best results, include hierarchical projection: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --embeddings datasets/pearltrees_combined_embeddings.npz --projection-model models/pearltrees_federated_nomic.pkl --output \"OUTPUT_PATH\"`.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_001_q1", "cluster_id": "skill_mindmap_linking_001", "question": "How do I link a mindmap to Pearltrees?", "answer": "To link a mindmap to Pearltrees, use the mindmap linking skill with: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --output \"OUTPUT_PATH\"`. For best results with semantic matching, add hierarchical projection: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --embeddings datasets/pearltrees_combined_embeddings.npz --projection-model models/pearltrees_federated_nomic.pkl --output \"OUTPUT_PATH\"`. The tool automatically adds child nodes with labels (PP for PagePearls, PT for exact title matches, PT? for fuzzy semantic matches).", "question_type": "medium", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "pearltrees", "linking", "enrichment"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/README.md"], "original_answer": "Use the mindmap linking skill to automatically connect your SimpleMind mindmap to Pearltrees content. The basic command is: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --output \"OUTPUT_PATH\"`. For best results, include hierarchical projection: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --embeddings datasets/pearltrees_combined_embeddings.npz --projection-model models/pearltrees_federated_nomic.pkl --output \"OUTPUT_PATH\"`.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_001_q2", "cluster_id": "skill_mindmap_linking_001", "question": "How do I enrich my mindmap with Pearltrees connections?", "answer": "To enrich your mindmap with Pearltrees connections, use the mindmap linking skill which automatically matches mindmap nodes to Pearltrees content. Start with the basic command: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --output \"OUTPUT_PATH\"`. For better matching quality, use the recommended approach with hierarchical projection: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --embeddings datasets/pearltrees_combined_embeddings.npz --projection-model models/pearltrees_federated_nomic.pkl --output \"OUTPUT_PATH\"`. This will add linked child nodes labeled PT (exact match), PT? (fuzzy match), or PP (URL match) to your mindmap.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "pearltrees", "linking", "enrichment"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/README.md"], "original_answer": "Use the mindmap linking skill to automatically connect your SimpleMind mindmap to Pearltrees content. The basic command is: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --output \"OUTPUT_PATH\"`. For best results, include hierarchical projection: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --embeddings datasets/pearltrees_combined_embeddings.npz --projection-model models/pearltrees_federated_nomic.pkl --output \"OUTPUT_PATH\"`.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_001_q3", "cluster_id": "skill_mindmap_linking_001", "question": "Can I connect my exported mindmap to my Pearltrees collection?", "answer": "Yes, you can connect your exported SimpleMind mindmap to your Pearltrees collection using the mindmap linking skill. Run: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --output \"OUTPUT_PATH\"`. For optimal results with hierarchical semantic matching, add embeddings and projection model: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --embeddings datasets/pearltrees_combined_embeddings.npz --projection-model models/pearltrees_federated_nomic.pkl --output \"OUTPUT_PATH\"`. The tool will automatically match mindmap nodes to Pearltrees using title matching and semantic similarity.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "pearltrees", "linking", "enrichment"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/README.md"], "original_answer": "Use the mindmap linking skill to automatically connect your SimpleMind mindmap to Pearltrees content. The basic command is: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --output \"OUTPUT_PATH\"`. For best results, include hierarchical projection: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --embeddings datasets/pearltrees_combined_embeddings.npz --projection-model models/pearltrees_federated_nomic.pkl --output \"OUTPUT_PATH\"`.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_002_q0", "cluster_id": "skill_mindmap_linking_002", "question": "What matching methods does mindmap linking use?", "answer": "Mindmap linking uses three matching methods: PP (PearlPage) for URL matching with Pearltrees pages, PT (Pearltree) for exact title matches, and PT? (fuzzy Pearltree) for semantic similarity matches above a configurable threshold. The linking process leverages hierarchical semantic matching with projection models to identify connections at different levels of abstraction.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["matching", "semantic", "pearltrees", "linking"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "Mindmap linking uses three types of matching indicated by labels on linked nodes: PP (PearlPage) for URL matches with Pearltrees pages, PT (Pearltree) for exact title matches, and PT? (fuzzy Pearltree) for semantic similarity matches above the threshold. The script uses hierarchical semantic matching with projection models to find connections at different levels of abstraction.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_002_q1", "cluster_id": "skill_mindmap_linking_002", "question": "How does the script match mindmap nodes to Pearltrees?", "answer": "The script matches mindmap nodes to Pearltrees using three matching strategies: (1) PP (PearlPage) matches node URLs against PagePearl external URLs in the database, (2) PT (Pearltree) matches node titles exactly against Pearltree titles (including disambiguated variants), and (3) PT? (fuzzy Pearltree) uses semantic similarity matching with hierarchical projection models to find matches above a configurable threshold. The matching process leverages embeddings and projection models to compare nodes at different levels of abstraction across the Pearltrees hierarchy.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["matching", "semantic", "pearltrees", "linking"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "Mindmap linking uses three types of matching indicated by labels on linked nodes: PP (PearlPage) for URL matches with Pearltrees pages, PT (Pearltree) for exact title matches, and PT? (fuzzy Pearltree) for semantic similarity matches above the threshold. The script uses hierarchical semantic matching with projection models to find connections at different levels of abstraction.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_002_q2", "cluster_id": "skill_mindmap_linking_002", "question": "What are the different linking labels mean?", "answer": "The different linking labels indicate the type of match found between mindmap nodes and Pearltrees:\n\n- **PP (PearlPage)**: The node's URL matches a PagePearl's external URL\n- **PT (Pearltree)**: Exact title match with a Pearltree node (including disambiguated titles)\n- **PT? (Pearltree fuzzy)**: Semantic similarity match above the configured threshold, using hierarchical projection models\n\nThese labels are automatically added as child nodes during the linking process to show how each connection was established.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["matching", "semantic", "pearltrees", "linking"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "Mindmap linking uses three types of matching indicated by labels on linked nodes: PP (PearlPage) for URL matches with Pearltrees pages, PT (Pearltree) for exact title matches, and PT? (fuzzy Pearltree) for semantic similarity matches above the threshold. The script uses hierarchical semantic matching with projection models to find connections at different levels of abstraction.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_002_q3", "cluster_id": "skill_mindmap_linking_002", "question": "What types of matches can mindmap linking find?", "answer": "Mindmap linking can find three types of matches, each indicated by a specific label: PP (PearlPage) when a node's URL matches a PagePearl's external URL, PT (Pearltree) for exact title matches including disambiguated titles, and PT? (fuzzy Pearltree) for semantic similarity matches above the configured threshold. The matching uses hierarchical semantic matching with projection models to find connections at different levels of abstraction.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["matching", "semantic", "pearltrees", "linking"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "Mindmap linking uses three types of matching indicated by labels on linked nodes: PP (PearlPage) for URL matches with Pearltrees pages, PT (Pearltree) for exact title matches, and PT? (fuzzy Pearltree) for semantic similarity matches above the threshold. The script uses hierarchical semantic matching with projection models to find connections at different levels of abstraction.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_003_q0", "cluster_id": "skill_mindmap_linking_003", "question": "What data do I need to prepare before linking a mindmap?", "answer": "To link a mindmap, you need: (1) your exported SimpleMind mindmap file, and (2) the Pearltrees targets file (reports/pearltrees_targets_s243a.jsonl). This minimum setup enables title-based matching. For better matching quality, optionally add: embeddings file (datasets/pearltrees_combined_embeddings.npz), projection model (models/pearltrees_federated_nomic.pkl), and URL database (data/databases/children_index.db) for semantic and URL matching. You can start with just the mindmap and trees file, then add optional components as needed.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "pearltrees", "data-preparation", "setup"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/README.md"], "original_answer": "Minimum requirement: export your SimpleMind mindmap and have the Pearltrees targets file (reports/pearltrees_targets_s243a.jsonl). For better results, also prepare: embeddings file (datasets/pearltrees_combined_embeddings.npz), projection model (models/pearltrees_federated_nomic.pkl), and optionally a URL database (data/databases/children_index.db). You can start with just the mindmap and trees file, then add more options for improved matching quality.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_003_q1", "cluster_id": "skill_mindmap_linking_003", "question": "What files are required for mindmap linking?", "answer": "For mindmap linking, you need at minimum: your exported SimpleMind mindmap file and the Pearltrees targets file (reports/pearltrees_targets_s243a.jsonl). For enhanced matching, also prepare: embeddings file (datasets/pearltrees_combined_embeddings.npz), projection model (models/pearltrees_federated_nomic.pkl), and optionally a URL database (data/databases/children_index.db). The basic command requires only the mindmap and trees file; additional files enable semantic similarity matching and URL-based matching for better accuracy.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "pearltrees", "data-preparation", "setup"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/README.md"], "original_answer": "Minimum requirement: export your SimpleMind mindmap and have the Pearltrees targets file (reports/pearltrees_targets_s243a.jsonl). For better results, also prepare: embeddings file (datasets/pearltrees_combined_embeddings.npz), projection model (models/pearltrees_federated_nomic.pkl), and optionally a URL database (data/databases/children_index.db). You can start with just the mindmap and trees file, then add more options for improved matching quality.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_003_q2", "cluster_id": "skill_mindmap_linking_003", "question": "Do I need a projection model to link my mindmap?", "answer": "No, a projection model is optional. You can link your mindmap with just the basic requirements: your SimpleMind mindmap file and the Pearltrees targets file (reports/pearltrees_targets_s243a.jsonl). This enables title-based matching. However, adding a projection model (models/pearltrees_federated_nomic.pkl) with embeddings (datasets/pearltrees_combined_embeddings.npz) significantly improves matching quality by enabling semantic similarity search. Start without the model if you want quick results, then add it for better accuracy.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "pearltrees", "data-preparation", "setup"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/README.md"], "original_answer": "Minimum requirement: export your SimpleMind mindmap and have the Pearltrees targets file (reports/pearltrees_targets_s243a.jsonl). For better results, also prepare: embeddings file (datasets/pearltrees_combined_embeddings.npz), projection model (models/pearltrees_federated_nomic.pkl), and optionally a URL database (data/databases/children_index.db). You can start with just the mindmap and trees file, then add more options for improved matching quality.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_003_q3", "cluster_id": "skill_mindmap_linking_003", "question": "What's the minimum setup to link a mindmap to Pearltrees?", "answer": "The minimum setup to link a mindmap to Pearltrees requires: (1) an exported SimpleMind mindmap file, and (2) the Pearltrees targets file (reports/pearltrees_targets_s243a.jsonl). Run: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --output \"OUTPUT_PATH\"`. This performs title-based matching only. For semantic matching and URL-based linking, optionally add the embeddings file, projection model, and URL database as shown in the \"With Hierarchical Projection\" command.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "pearltrees", "data-preparation", "setup"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/README.md"], "original_answer": "Minimum requirement: export your SimpleMind mindmap and have the Pearltrees targets file (reports/pearltrees_targets_s243a.jsonl). For better results, also prepare: embeddings file (datasets/pearltrees_combined_embeddings.npz), projection model (models/pearltrees_federated_nomic.pkl), and optionally a URL database (data/databases/children_index.db). You can start with just the mindmap and trees file, then add more options for improved matching quality.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_004_q0", "cluster_id": "skill_mindmap_linking_004", "question": "How do I preview mindmap linking changes before applying them?", "answer": "Use the `--dry-run` flag with `--verbose` to preview all changes without modifying your mindmap. Run: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --dry-run --verbose`. This will display all the matches and labels (PP, PT, PT?) that would be added to your mindmap nodes before you apply them.", "question_type": "long", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "preview", "dry-run", "testing"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/README.md"], "original_answer": "Use the `--dry-run` flag with `--verbose` to preview all changes without modifying your mindmap. Run: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --dry-run --verbose`. This will show all the matches and labels that would be added to your mindmap nodes.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_004_q1", "cluster_id": "skill_mindmap_linking_004", "question": "Can I do a dry run of mindmap linking?", "answer": "Yes, you can preview mindmap linking changes with a dry run. Use the `--dry-run` flag with `--verbose`: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --dry-run --verbose`. This shows all matches and labels that would be added without modifying your mindmap.", "question_type": "long", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "preview", "dry-run", "testing"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/README.md"], "original_answer": "Use the `--dry-run` flag with `--verbose` to preview all changes without modifying your mindmap. Run: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --dry-run --verbose`. This will show all the matches and labels that would be added to your mindmap nodes.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_004_q2", "cluster_id": "skill_mindmap_linking_004", "question": "How do I see what connections will be made?", "answer": "Use the `--dry-run` flag with `--verbose` to preview all connections before applying them. Run: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --dry-run --verbose`. This will display all the Pearltree matches and labels (PP, PT, PT?) that would be added to your mindmap nodes without making any actual changes.", "question_type": "long", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "preview", "dry-run", "testing"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/README.md"], "original_answer": "Use the `--dry-run` flag with `--verbose` to preview all changes without modifying your mindmap. Run: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --dry-run --verbose`. This will show all the matches and labels that would be added to your mindmap nodes.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_004_q3", "cluster_id": "skill_mindmap_linking_004", "question": "Can I test mindmap linking without modifying my file?", "answer": "Yes. Use the `--dry-run` flag with `--verbose` to preview all matching results without modifying your mindmap file. Run: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --dry-run --verbose`. This will display all the Pearltree matches and labels that would be added to your nodes, letting you review the results before applying any changes.", "question_type": "long", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "preview", "dry-run", "testing"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/README.md"], "original_answer": "Use the `--dry-run` flag with `--verbose` to preview all changes without modifying your mindmap. Run: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --dry-run --verbose`. This will show all the matches and labels that would be added to your mindmap nodes.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_001_q0", "cluster_id": "skill_mst_folder_grouping_001", "question": "How do I organize mindmaps by semantic similarity?", "answer": "Use the MST Folder Grouping skill to organize mindmaps by semantic similarity. Run `python3 scripts/mindmap/mst_folder_grouping.py --trees-only --target-size 10 --max-depth 5 -o output/mst_folder_structure.json` to generate a semantically coherent folder hierarchy. Adjust `--target-size` (target items per folder) and `--max-depth` (maximum folder depth) as needed. For curated hierarchies, use `--tree-source curated` instead of the default `mst`. After generating the structure, use `python3 scripts/mindmap/generate_mst_mindmaps.py` to create mindmaps from the folder structure.", "question_type": "medium", "topics": ["Mindmap", "Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["clustering", "organization", "mindmap", "semantic"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md", "docs/design/FEDERATED_MODEL_FORMAT.md", "education/book-13-semantic-search/07_density_scoring.md"], "original_answer": "Use the MST Folder Grouping skill to organize mindmaps into semantically coherent folder hierarchies. Run `python3 scripts/mindmap/mst_folder_grouping.py --trees-only --target-size 10 --max-depth 5 -o output/mst_folder_structure.json` to generate a folder structure based on semantic similarity.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_001_q1", "cluster_id": "skill_mst_folder_grouping_001", "question": "How can I cluster mindmaps into folders?", "answer": "Use the MST Folder Grouping skill to organize mindmaps into semantically coherent folder hierarchies. Run `python3 scripts/mindmap/mst_folder_grouping.py --trees-only --target-size 10 --max-depth 5 -o output/mst_folder_structure.json` to cluster mindmaps based on semantic similarity. You can adjust `--target-size` to control items per folder and `--max-depth` to limit folder depth. After generating the structure, use `python3 scripts/mindmap/generate_mst_mindmaps.py --mst-structure output/mst_folder_structure.json --output output/mst_mindmaps/` to create mindmaps from the folder structure.", "question_type": "medium", "topics": ["Mindmap", "Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["clustering", "organization", "mindmap", "semantic"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md", "docs/design/FEDERATED_MODEL_FORMAT.md", "education/book-13-semantic-search/07_density_scoring.md"], "original_answer": "Use the MST Folder Grouping skill to organize mindmaps into semantically coherent folder hierarchies. Run `python3 scripts/mindmap/mst_folder_grouping.py --trees-only --target-size 10 --max-depth 5 -o output/mst_folder_structure.json` to generate a folder structure based on semantic similarity.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_001_q2", "cluster_id": "skill_mst_folder_grouping_001", "question": "I want to group related mindmaps together - how do I do that?", "answer": "Use the MST Folder Grouping skill to organize mindmaps by semantic similarity. Run `python3 scripts/mindmap/mst_folder_grouping.py --trees-only --target-size 10 --max-depth 5 -o output/mst_folder_structure.json` to generate a folder hierarchy. Adjust `--target-size` to control items per folder and `--max-depth` to control folder depth. After generating the structure, use `python3 scripts/mindmap/generate_mst_mindmaps.py --mst-structure output/mst_folder_structure.json --output output/mst_mindmaps/` to create the actual mindmaps.", "question_type": "medium", "topics": ["Mindmap", "Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["clustering", "organization", "mindmap", "semantic"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md", "docs/design/FEDERATED_MODEL_FORMAT.md", "education/book-13-semantic-search/07_density_scoring.md"], "original_answer": "Use the MST Folder Grouping skill to organize mindmaps into semantically coherent folder hierarchies. Run `python3 scripts/mindmap/mst_folder_grouping.py --trees-only --target-size 10 --max-depth 5 -o output/mst_folder_structure.json` to generate a folder structure based on semantic similarity.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_001_q3", "cluster_id": "skill_mst_folder_grouping_001", "question": "Can I automatically organize mindmaps by content?", "answer": "Yes, you can automatically organize mindmaps by content using the MST Folder Grouping skill. This feature uses Minimum Spanning Tree partitioning to create semantically coherent folder hierarchies based on content similarity. To get started, run: `python3 scripts/mindmap/mst_folder_grouping.py --trees-only --target-size 10 --max-depth 5 -o output/mst_folder_structure.json`. This command generates a folder structure automatically organized by semantic similarity. You can customize the organization with options like `--target-size` (items per folder) and `--max-depth` (folder depth). After generating the structure, use `generate_mst_mindmaps.py` to create mindmaps from the resulting hierarchy.", "question_type": "medium", "topics": ["Mindmap", "Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["clustering", "organization", "mindmap", "semantic"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md", "docs/design/FEDERATED_MODEL_FORMAT.md", "education/book-13-semantic-search/07_density_scoring.md"], "original_answer": "Use the MST Folder Grouping skill to organize mindmaps into semantically coherent folder hierarchies. Run `python3 scripts/mindmap/mst_folder_grouping.py --trees-only --target-size 10 --max-depth 5 -o output/mst_folder_structure.json` to generate a folder structure based on semantic similarity.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_002_q0", "cluster_id": "skill_mst_folder_grouping_002", "question": "How do I test MST folder grouping on a specific subject?", "answer": "Use the `--subset` flag to test on a specific subject. For example: `python3 scripts/mindmap/mst_folder_grouping.py --subset physics --target-size 8 --max-depth 3 --verbose` will run MST folder grouping on physics mindmaps only, with a target of 8 items per folder, maximum depth of 3 levels, and verbose output to see the grouping process.", "question_type": "long", "topics": ["Mindmap", "Organization", "Advanced"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["testing", "subset", "mst", "clustering"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md"], "original_answer": "Use the `--subset` flag to test on a specific subject. For example: `python3 scripts/mindmap/mst_folder_grouping.py --subset physics --target-size 8 --max-depth 3 --verbose` will test the MST grouping on physics mindmaps only.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_002_q1", "cluster_id": "skill_mst_folder_grouping_002", "question": "Can I try the grouping on just physics mindmaps?", "answer": "Yes, use the `--subset` flag to test on physics mindmaps only: `python3 scripts/mindmap/mst_folder_grouping.py --subset physics --target-size 8 --max-depth 3 --verbose`. This runs the MST grouping algorithm on just the physics subset without processing the full dataset.", "question_type": "long", "topics": ["Mindmap", "Organization", "Advanced"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["testing", "subset", "mst", "clustering"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md"], "original_answer": "Use the `--subset` flag to test on a specific subject. For example: `python3 scripts/mindmap/mst_folder_grouping.py --subset physics --target-size 8 --max-depth 3 --verbose` will test the MST grouping on physics mindmaps only.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_002_q2", "cluster_id": "skill_mst_folder_grouping_002", "question": "How do I test the folder organization on a subset of data?", "answer": "Use the `--subset` flag to test on a specific subject. For example: `python3 scripts/mindmap/mst_folder_grouping.py --subset physics --target-size 8 --max-depth 3 --verbose` will run the MST folder grouping algorithm on only the physics mindmaps, allowing you to validate the organization approach before running on your full dataset.", "question_type": "long", "topics": ["Mindmap", "Organization", "Advanced"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["testing", "subset", "mst", "clustering"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md"], "original_answer": "Use the `--subset` flag to test on a specific subject. For example: `python3 scripts/mindmap/mst_folder_grouping.py --subset physics --target-size 8 --max-depth 3 --verbose` will test the MST grouping on physics mindmaps only.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_003_q0", "cluster_id": "skill_mst_folder_grouping_003", "question": "What options can I customize when grouping mindmaps?", "answer": "When grouping mindmaps, you can customize: `--target-size` (default 8) to control how many items go in each folder, `--max-depth` (default 4) to limit folder depth, `--tree-source` (choose mst, curated, or hybrid) to select the grouping strategy, and `--cluster-method` (multilevel or bisection) to pick the partitioning algorithm. Use `--help` to see all available options.", "question_type": "long", "topics": ["Mindmap", "Organization", "Configuration"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["configuration", "parameters", "options", "mst"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md"], "original_answer": "Key customizable options include: `--target-size` (default 8, controls items per folder), `--max-depth` (default 4, controls folder depth), `--tree-source` (mst, curated, or hybrid), and `--cluster-method` (multilevel or bisection). See all options with `--help` flag.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_003_q1", "cluster_id": "skill_mst_folder_grouping_003", "question": "How do I adjust the folder size or depth?", "answer": "To adjust folder size, use `--target-size` (default 8 items per folder). To adjust depth, use `--max-depth` (default 4 levels). For example: `python3 scripts/mindmap/mst_folder_grouping.py --target-size 10 --max-depth 5 -o output.json`. View all available options with `--help`.", "question_type": "long", "topics": ["Mindmap", "Organization", "Configuration"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["configuration", "parameters", "options", "mst"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md"], "original_answer": "Key customizable options include: `--target-size` (default 8, controls items per folder), `--max-depth` (default 4, controls folder depth), `--tree-source` (mst, curated, or hybrid), and `--cluster-method` (multilevel or bisection). See all options with `--help` flag.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_003_q2", "cluster_id": "skill_mst_folder_grouping_003", "question": "What are the parameters for semantic grouping?", "answer": "The main parameters for semantic grouping are: `--target-size` (default 8, sets the target number of items per folder), `--max-depth` (default 4, limits folder hierarchy depth), `--tree-source` (choose from 'mst', 'curated', or 'hybrid' to select the clustering strategy), and `--cluster-method` (either 'multilevel' or 'bisection' for the partitioning algorithm). Additional options like `--embed-blend` control weighting in hybrid mode. Use `--help` to see all available parameters.", "question_type": "long", "topics": ["Mindmap", "Organization", "Configuration"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["configuration", "parameters", "options", "mst"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md"], "original_answer": "Key customizable options include: `--target-size` (default 8, controls items per folder), `--max-depth` (default 4, controls folder depth), `--tree-source` (mst, curated, or hybrid), and `--cluster-method` (multilevel or bisection). See all options with `--help` flag.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_003_q3", "cluster_id": "skill_mst_folder_grouping_003", "question": "Can I change how mindmaps are clustered into folders?", "answer": "Yes, you can customize mindmap clustering through several options: `--target-size` controls how many items go in each folder (default 8), `--max-depth` controls folder nesting depth (default 4), `--tree-source` lets you choose the clustering algorithm (`mst`, `curated`, or `hybrid`), and `--cluster-method` lets you pick between `multilevel` or `bisection` partitioning. Run with `--help` to see all available options.", "question_type": "long", "topics": ["Mindmap", "Organization", "Configuration"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["configuration", "parameters", "options", "mst"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md"], "original_answer": "Key customizable options include: `--target-size` (default 8, controls items per folder), `--max-depth` (default 4, controls folder depth), `--tree-source` (mst, curated, or hybrid), and `--cluster-method` (multilevel or bisection). See all options with `--help` flag.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_004_q0", "cluster_id": "skill_mst_folder_grouping_004", "question": "How do I generate mindmaps from a folder structure?", "answer": "To generate mindmaps from a folder structure, use the generate_mst_mindmaps.py script. Run: `python3 scripts/mindmap/generate_mst_mindmaps.py --mst-structure output/mst_folder_structure.json --output output/mst_mindmaps/ --root-name \"My_Collection\"`. This creates mindmaps from the hierarchical folder structure previously generated by mst_folder_grouping.py.", "question_type": "long", "topics": ["Mindmap", "Organization", "Generation"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["generation", "visualization", "mindmap", "mst"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/hierarchy_objective.py"], "original_answer": "After generating a folder structure with MST Folder Grouping, use: `python3 scripts/mindmap/generate_mst_mindmaps.py --mst-structure output/mst_folder_structure.json --output output/mst_mindmaps/ --root-name \"My_Collection\"` to create mindmaps from the hierarchical structure.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_004_q1", "cluster_id": "skill_mst_folder_grouping_004", "question": "After organizing folders, how do I create mindmaps from the structure?", "answer": "After organizing folders with MST Folder Grouping, use the generate_mst_mindmaps.py script to create mindmaps from the structure. Run: `python3 scripts/mindmap/generate_mst_mindmaps.py --mst-structure output/mst_folder_structure.json --output output/mst_mindmaps/ --root-name \"My_Collection\"`. This converts your hierarchical folder structure into visual mindmap files in the specified output directory.", "question_type": "long", "topics": ["Mindmap", "Organization", "Generation"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["generation", "visualization", "mindmap", "mst"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/hierarchy_objective.py"], "original_answer": "After generating a folder structure with MST Folder Grouping, use: `python3 scripts/mindmap/generate_mst_mindmaps.py --mst-structure output/mst_folder_structure.json --output output/mst_mindmaps/ --root-name \"My_Collection\"` to create mindmaps from the hierarchical structure.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_004_q2", "cluster_id": "skill_mst_folder_grouping_004", "question": "Can I visualize the MST folder organization as mindmaps?", "answer": "Yes. After generating a folder structure with MST Folder Grouping, use `python3 scripts/mindmap/generate_mst_mindmaps.py --mst-structure output/mst_folder_structure.json --output output/mst_mindmaps/ --root-name \"My_Collection\"` to visualize the hierarchical folder organization as mindmaps.", "question_type": "long", "topics": ["Mindmap", "Organization", "Generation"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["generation", "visualization", "mindmap", "mst"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/hierarchy_objective.py"], "original_answer": "After generating a folder structure with MST Folder Grouping, use: `python3 scripts/mindmap/generate_mst_mindmaps.py --mst-structure output/mst_folder_structure.json --output output/mst_mindmaps/ --root-name \"My_Collection\"` to create mindmaps from the hierarchical structure.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_001_q0", "cluster_id": "skill_folder_suggestion_001", "question": "Where should I put this mindmap?", "answer": "Use the folder suggestion tool to find the best location for your mindmap based on semantic similarity. Run `python3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"` to get suggestions by tree ID, or `python3 scripts/mindmap/suggest_folder.py --title \"MINDMAP_TITLE\"` to search by title. The tool will show probability scores for each folder\u2014anything above 50% indicates a strong match, 25-50% suggests a good match with minor ambiguity, and below 25% means multiple options are equally valid. See `skill_folder_suggestion.md` for more details.", "question_type": "medium", "topics": ["Mindmap", "Folder Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "folder-organization", "semantic-search", "procrustes"], "related_skills": ["skill_folder_suggestion.md", "skill_mst_folder_grouping.md", "skill_mindmap_linking.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/suggest_folder.py", "scripts/mindmap/build_folder_projections.py", "education/book-13-semantic-search/05_semantic_playbook.md", "education/book-13-semantic-search/15_zero_shot_path_mapping.md"], "original_answer": "Use the folder suggestion tool to find the best location based on semantic similarity:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"\n```\n\nOr search by title:\n```bash\npython3 scripts/mindmap/suggest_folder.py --title \"MINDMAP_TITLE\"\n```\n\nThe tool shows probability scores for each folder. >50% means strong match, 25-50% is good with minor ambiguity.\n\nSee `skill_folder_suggestion.md` for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_001_q1", "cluster_id": "skill_folder_suggestion_001", "question": "How do I find the right folder for a mindmap?", "answer": "To find the right folder for a mindmap, use the folder suggestion tool with semantic similarity analysis:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"\n```\n\nOr search by mindmap title:\n```bash\npython3 scripts/mindmap/suggest_folder.py --title \"MINDMAP_TITLE\"\n```\n\nThe tool returns probability scores for each suggested folder. Scores above 50% indicate a strong match, 25-50% means good match with minor ambiguity, and below 25% suggests the mindmap could fit in multiple folders.\n\nFor checking if existing mindmaps are in the right folders:\n```bash\npython3 scripts/mindmap/suggest_folder.py --check-folder \"FOLDER_PATH\" --threshold 0.5\n```\n\nNote: You'll need to build folder projections first using `build_folder_projections.py` if they don't exist.", "question_type": "medium", "topics": ["Mindmap", "Folder Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "folder-organization", "semantic-search", "procrustes"], "related_skills": ["skill_folder_suggestion.md", "skill_mst_folder_grouping.md", "skill_mindmap_linking.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/suggest_folder.py", "scripts/mindmap/build_folder_projections.py", "education/book-13-semantic-search/05_semantic_playbook.md", "education/book-13-semantic-search/15_zero_shot_path_mapping.md"], "original_answer": "Use the folder suggestion tool to find the best location based on semantic similarity:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"\n```\n\nOr search by title:\n```bash\npython3 scripts/mindmap/suggest_folder.py --title \"MINDMAP_TITLE\"\n```\n\nThe tool shows probability scores for each folder. >50% means strong match, 25-50% is good with minor ambiguity.\n\nSee `skill_folder_suggestion.md` for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_001_q2", "cluster_id": "skill_folder_suggestion_001", "question": "Which folder should this mindmap go in?", "answer": "Use the folder suggestion tool to find the best location for your mindmap based on semantic similarity. Run `python3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"` to get folder recommendations with probability scores, or use `--title \"MINDMAP_TITLE\"` to search by title instead. Scores above 50% indicate a strong match, 25-50% shows good matches with some ambiguity, and below 25% means multiple valid options exist. For detailed information, see `skill_folder_suggestion.md`.", "question_type": "medium", "topics": ["Mindmap", "Folder Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "folder-organization", "semantic-search", "procrustes"], "related_skills": ["skill_folder_suggestion.md", "skill_mst_folder_grouping.md", "skill_mindmap_linking.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/suggest_folder.py", "scripts/mindmap/build_folder_projections.py", "education/book-13-semantic-search/05_semantic_playbook.md", "education/book-13-semantic-search/15_zero_shot_path_mapping.md"], "original_answer": "Use the folder suggestion tool to find the best location based on semantic similarity:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"\n```\n\nOr search by title:\n```bash\npython3 scripts/mindmap/suggest_folder.py --title \"MINDMAP_TITLE\"\n```\n\nThe tool shows probability scores for each folder. >50% means strong match, 25-50% is good with minor ambiguity.\n\nSee `skill_folder_suggestion.md` for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_001_q3", "cluster_id": "skill_folder_suggestion_001", "question": "How do I organize my mindmaps into folders?", "answer": "To organize your mindmaps into folders, use the folder suggestion tool which recommends the best folder based on semantic similarity of your mindmap content.\n\nFor a specific mindmap, run:\n```bash\npython3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"\n```\n\nOr search by title:\n```bash\npython3 scripts/mindmap/suggest_folder.py --title \"MINDMAP_TITLE\"\n```\n\nTo check an entire folder for misplacements:\n```bash\npython3 scripts/mindmap/suggest_folder.py --check-folder \"FOLDER_PATH\" --threshold 0.5\n```\n\nThe tool returns probability scores for each suggested folder: >50% indicates a strong match, 25-50% is a good match with minor ambiguity, and <25% means multiple valid options exist.\n\nNote: You'll need to build folder projections first using `scripts/mindmap/build_folder_projections.py` if you haven't already.", "question_type": "medium", "topics": ["Mindmap", "Folder Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "folder-organization", "semantic-search", "procrustes"], "related_skills": ["skill_folder_suggestion.md", "skill_mst_folder_grouping.md", "skill_mindmap_linking.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/suggest_folder.py", "scripts/mindmap/build_folder_projections.py", "education/book-13-semantic-search/05_semantic_playbook.md", "education/book-13-semantic-search/15_zero_shot_path_mapping.md"], "original_answer": "Use the folder suggestion tool to find the best location based on semantic similarity:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"\n```\n\nOr search by title:\n```bash\npython3 scripts/mindmap/suggest_folder.py --title \"MINDMAP_TITLE\"\n```\n\nThe tool shows probability scores for each folder. >50% means strong match, 25-50% is good with minor ambiguity.\n\nSee `skill_folder_suggestion.md` for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_002_q0", "cluster_id": "skill_folder_suggestion_002", "question": "How do I check if my mindmaps are in the wrong folders?", "answer": "Check an entire folder for misplaced mindmaps using the folder suggestion tool:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py \\\n  --check-folder \"FOLDER_PATH\" \\\n  --threshold 0.5\n```\n\nThis identifies mindmaps that would fit better in other folders. The `--threshold` parameter controls sensitivity:\n- 0.5 (default): Flags items with <50% probability in their current folder\n- Lower threshold: More lenient, catches only obvious misplacements\n- Higher threshold: Stricter, flags items that only partially match their folder\n\nThe output shows each mindmap's current folder and suggested alternatives with confidence scores. A strong match is >50% probability.", "question_type": "long", "topics": ["Mindmap", "Folder Organization", "Validation"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "folder-validation", "audit", "threshold"], "related_skills": ["skill_folder_suggestion.md", "skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/suggest_folder.py", "education/book-13-semantic-search/07_density_scoring.md"], "original_answer": "Check an entire folder for misplaced mindmaps using the folder suggestion tool:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py \\\n  --check-folder \"FOLDER_PATH\" \\\n  --threshold 0.5\n```\n\nThis identifies mindmaps that would fit better elsewhere. Adjust `--threshold` to control sensitivity (default 0.5 means it flags items with <50% probability in current folder).\n\nSee `skill_folder_suggestion.md` for probability interpretation.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_002_q1", "cluster_id": "skill_folder_suggestion_002", "question": "How can I find misplaced mindmaps?", "answer": "Check an entire folder for misplaced mindmaps using the folder suggestion tool:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py \\\n  --check-folder \"FOLDER_PATH\" \\\n  --threshold 0.5\n```\n\nThis identifies mindmaps that would fit better elsewhere by comparing their embeddings against folder projections. Mindmaps with probability below the threshold in their current folder are flagged as potential misplacements. Adjust `--threshold` to control sensitivity (lower values flag more items, higher values only flag obvious misplacements).", "question_type": "long", "topics": ["Mindmap", "Folder Organization", "Validation"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "folder-validation", "audit", "threshold"], "related_skills": ["skill_folder_suggestion.md", "skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/suggest_folder.py", "education/book-13-semantic-search/07_density_scoring.md"], "original_answer": "Check an entire folder for misplaced mindmaps using the folder suggestion tool:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py \\\n  --check-folder \"FOLDER_PATH\" \\\n  --threshold 0.5\n```\n\nThis identifies mindmaps that would fit better elsewhere. Adjust `--threshold` to control sensitivity (default 0.5 means it flags items with <50% probability in current folder).\n\nSee `skill_folder_suggestion.md` for probability interpretation.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_002_q2", "cluster_id": "skill_folder_suggestion_002", "question": "Are my mindmaps organized correctly?", "answer": "Check if your mindmaps are organized correctly by scanning a folder for misplaced items:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py \\\n  --check-folder \"FOLDER_PATH\" \\\n  --threshold 0.5\n```\n\nThis identifies mindmaps that would fit better in other folders based on semantic similarity. The threshold controls sensitivity\u20140.5 flags items with less than 50% probability in their current folder. Items with >50% probability are well-placed, 25-50% are acceptable but ambiguous, and <25% should be reconsidered.", "question_type": "long", "topics": ["Mindmap", "Folder Organization", "Validation"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "folder-validation", "audit", "threshold"], "related_skills": ["skill_folder_suggestion.md", "skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/suggest_folder.py", "education/book-13-semantic-search/07_density_scoring.md"], "original_answer": "Check an entire folder for misplaced mindmaps using the folder suggestion tool:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py \\\n  --check-folder \"FOLDER_PATH\" \\\n  --threshold 0.5\n```\n\nThis identifies mindmaps that would fit better elsewhere. Adjust `--threshold` to control sensitivity (default 0.5 means it flags items with <50% probability in current folder).\n\nSee `skill_folder_suggestion.md` for probability interpretation.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_002_q3", "cluster_id": "skill_folder_suggestion_002", "question": "How do I audit mindmap folder placement?", "answer": "To audit mindmap folder placement, use the folder suggestion tool to check an entire folder for misplacements:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py \\\n  --check-folder \"FOLDER_PATH\" \\\n  --threshold 0.5\n```\n\nThis scans all mindmaps in the specified folder and identifies ones that would fit better elsewhere. Items with placement probability below the threshold are flagged as potentially misplaced. Adjust `--threshold` (default 0.5) to control sensitivity\u2014lower values flag more items, higher values only flag clear misplacements. The output shows current folder probability and better-matching alternatives, helping you reorganize mindmaps to their optimal locations.", "question_type": "long", "topics": ["Mindmap", "Folder Organization", "Validation"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "folder-validation", "audit", "threshold"], "related_skills": ["skill_folder_suggestion.md", "skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/suggest_folder.py", "education/book-13-semantic-search/07_density_scoring.md"], "original_answer": "Check an entire folder for misplaced mindmaps using the folder suggestion tool:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py \\\n  --check-folder \"FOLDER_PATH\" \\\n  --threshold 0.5\n```\n\nThis identifies mindmaps that would fit better elsewhere. Adjust `--threshold` to control sensitivity (default 0.5 means it flags items with <50% probability in current folder).\n\nSee `skill_folder_suggestion.md` for probability interpretation.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_003_q0", "cluster_id": "skill_folder_suggestion_003", "question": "What do the probability scores mean when suggesting folders?", "answer": "Folder suggestion probability scores indicate the confidence level that a mindmap belongs in a particular folder:\n\n- **>50%**: Strong match with clear best folder\n- **25-50%**: Good match but minor ambiguity between folder options\n- **<25%**: Highly ambiguous with multiple valid folder candidates\n\nThe tool also provides a `fit` score (0-1) from Procrustes analysis, showing geometric alignment between the mindmap's embedding and the folder's semantic space. Higher fit scores indicate better semantic coherence with the folder's contents.", "question_type": "medium", "topics": ["Mindmap", "Folder Organization", "Interpretation"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "probability", "interpretation", "procrustes", "fit-score"], "related_skills": ["skill_folder_suggestion.md", "skill_semantic_inference.md"], "related_docs": ["scripts/mindmap/README.md", "education/book-13-semantic-search/07_density_scoring.md", "education/book-14-ai-training/03_lda_projection.md"], "original_answer": "Folder suggestion probabilities indicate fit confidence:\n\n- **>50%**: Strong match, clear best folder\n- **25-50%**: Good match, minor ambiguity between options\n- **<25%**: Highly ambiguous, multiple valid folders\n\nThe tool also shows a `fit` score (0-1) measuring geometric alignment via Procrustes analysis. Higher fit means better semantic coherence with folder contents.\n\nExample output:\n```\nSuggested folders:\n  1. Hacktivism: 51.2% (fit=0.9667) <-- current\n  2. eyes-symbols: 20.3%\n```\n\nSee `skill_folder_suggestion.md` for more details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_003_q1", "cluster_id": "skill_folder_suggestion_003", "question": "How do I interpret folder suggestion probabilities?", "answer": "Folder suggestion probabilities indicate how confident the system is that a mindmap belongs in each suggested folder:\n\n- **>50%**: Strong match - clear best folder for the mindmap\n- **25-50%**: Good match - suitable folder but with minor ambiguity between options\n- **<25%**: Highly ambiguous - multiple folders are equally valid\n\nThe output also includes a `fit` score (0-1) from Procrustes analysis, which measures how well the mindmap's semantic content aligns geometrically with the folder's embedding space. Higher fit scores indicate stronger semantic coherence with existing folder contents.\n\nExample: A mindmap with 51.2% probability and fit=0.9667 for \"Hacktivism\" indicates it's a strong match with excellent geometric alignment to that folder's semantic space.", "question_type": "medium", "topics": ["Mindmap", "Folder Organization", "Interpretation"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "probability", "interpretation", "procrustes", "fit-score"], "related_skills": ["skill_folder_suggestion.md", "skill_semantic_inference.md"], "related_docs": ["scripts/mindmap/README.md", "education/book-13-semantic-search/07_density_scoring.md", "education/book-14-ai-training/03_lda_projection.md"], "original_answer": "Folder suggestion probabilities indicate fit confidence:\n\n- **>50%**: Strong match, clear best folder\n- **25-50%**: Good match, minor ambiguity between options\n- **<25%**: Highly ambiguous, multiple valid folders\n\nThe tool also shows a `fit` score (0-1) measuring geometric alignment via Procrustes analysis. Higher fit means better semantic coherence with folder contents.\n\nExample output:\n```\nSuggested folders:\n  1. Hacktivism: 51.2% (fit=0.9667) <-- current\n  2. eyes-symbols: 20.3%\n```\n\nSee `skill_folder_suggestion.md` for more details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_003_q2", "cluster_id": "skill_folder_suggestion_003", "question": "What's a good probability score for folder placement?", "answer": "A good probability score for folder placement depends on your use case:\n\n- **>50%**: Strong match - the mindmap clearly belongs in this folder\n- **25-50%**: Good match - acceptable placement with minor ambiguity about alternatives\n- **<25%**: Ambiguous - multiple folders are equally valid, consider manual review\n\nThe tool also provides a `fit` score (0-1) from Procrustes analysis showing geometric alignment with folder contents. A fit score near 1.0 indicates strong semantic coherence.\n\nFor most cases, aim for >50% probability as a reliable placement threshold. Use the fit score to validate confidence in the recommendation.", "question_type": "medium", "topics": ["Mindmap", "Folder Organization", "Interpretation"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "probability", "interpretation", "procrustes", "fit-score"], "related_skills": ["skill_folder_suggestion.md", "skill_semantic_inference.md"], "related_docs": ["scripts/mindmap/README.md", "education/book-13-semantic-search/07_density_scoring.md", "education/book-14-ai-training/03_lda_projection.md"], "original_answer": "Folder suggestion probabilities indicate fit confidence:\n\n- **>50%**: Strong match, clear best folder\n- **25-50%**: Good match, minor ambiguity between options\n- **<25%**: Highly ambiguous, multiple valid folders\n\nThe tool also shows a `fit` score (0-1) measuring geometric alignment via Procrustes analysis. Higher fit means better semantic coherence with folder contents.\n\nExample output:\n```\nSuggested folders:\n  1. Hacktivism: 51.2% (fit=0.9667) <-- current\n  2. eyes-symbols: 20.3%\n```\n\nSee `skill_folder_suggestion.md` for more details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_003_q3", "cluster_id": "skill_folder_suggestion_003", "question": "When should I trust the folder suggestion?", "answer": "Trust folder suggestions based on their probability score and fit metric:\n\n**Probability Score Interpretation:**\n- **>50%**: Strong match - the suggested folder is clearly the best fit\n- **25-50%**: Good match - reasonable choice but some ambiguity exists with other options\n- **<25%**: Low confidence - multiple folders could work equally well, consider manual review\n\n**Fit Score:** Values closer to 1.0 indicate stronger semantic alignment with the folder's content structure. A high fit score combined with a >50% probability gives you the most confidence.\n\n**Decision Guide:**\nUse the suggestion when probability is >50% and fit >0.9. Below 50% probability, you may want to review the top alternatives before moving the mindmap. Below 25%, treat suggestions as starting points rather than definitive answers.", "question_type": "medium", "topics": ["Mindmap", "Folder Organization", "Interpretation"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "probability", "interpretation", "procrustes", "fit-score"], "related_skills": ["skill_folder_suggestion.md", "skill_semantic_inference.md"], "related_docs": ["scripts/mindmap/README.md", "education/book-13-semantic-search/07_density_scoring.md", "education/book-14-ai-training/03_lda_projection.md"], "original_answer": "Folder suggestion probabilities indicate fit confidence:\n\n- **>50%**: Strong match, clear best folder\n- **25-50%**: Good match, minor ambiguity between options\n- **<25%**: Highly ambiguous, multiple valid folders\n\nThe tool also shows a `fit` score (0-1) measuring geometric alignment via Procrustes analysis. Higher fit means better semantic coherence with folder contents.\n\nExample output:\n```\nSuggested folders:\n  1. Hacktivism: 51.2% (fit=0.9667) <-- current\n  2. eyes-symbols: 20.3%\n```\n\nSee `skill_folder_suggestion.md` for more details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_004_q0", "cluster_id": "skill_folder_suggestion_004", "question": "How do I set up folder suggestions for my mindmaps?", "answer": "To set up folder suggestions for your mindmaps, follow these two steps:\n\n1. **Build folder projections** using:\n```bash\npython3 scripts/mindmap/build_folder_projections.py \\\n  --embeddings \"EMBEDDINGS_FILE\" \\\n  --index \"INDEX_FILE\" \\\n  --output \"PROJECTIONS_DB\"\n```\nThis creates Procrustes projection matrices for each folder based on your mindmap embeddings and index.\n\n2. **Start suggesting folders** using:\n```bash\npython3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"\n```\n\nYou can also suggest by title, check a folder for misplacements, or get JSON output for automation. Run `python3 scripts/mindmap/suggest_folder.py --help` for all options.", "question_type": "long", "topics": ["Mindmap", "Folder Organization", "Setup"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "setup", "prerequisites", "projections", "embeddings"], "related_skills": ["skill_folder_suggestion.md", "skill_train_model.md", "skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/build_folder_projections.py", "scripts/mindmap/suggest_folder.py", "docs/design/FEDERATED_MODEL_FORMAT.md", "education/book-13-semantic-search/08_advanced_federation.md", "education/book-14-ai-training/03_lda_projection.md"], "original_answer": "Build folder projections first using this command:\n\n```bash\npython3 scripts/mindmap/build_folder_projections.py \\\n  --embeddings \"EMBEDDINGS_FILE\" \\\n  --index \"INDEX_FILE\" \\\n  --output \"PROJECTIONS_DB\"\n```\n\nThis creates Procrustes projection matrices for each folder. Then use:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"\n```\n\nFor JSON output (useful for automation):\n```bash\npython3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\" --json\n```\n\nSee `skill_folder_suggestion.md` for complete setup.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_004_q1", "cluster_id": "skill_folder_suggestion_004", "question": "What are the prerequisites for folder suggestion?", "answer": "The prerequisites for folder suggestion are:\n\n1. **Build folder projections first** using:\n```bash\npython3 scripts/mindmap/build_folder_projections.py \\\n  --embeddings \"EMBEDDINGS_FILE\" \\\n  --index \"INDEX_FILE\" \\\n  --output \"PROJECTIONS_DB\"\n```\n\nThis creates Procrustes projection matrices for each folder, which are required before you can suggest folders.\n\n2. **Then use the suggestion script**:\n```bash\npython3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"\n```\n\nWithout building the folder projections first, the suggestion script will not function correctly.", "question_type": "long", "topics": ["Mindmap", "Folder Organization", "Setup"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "setup", "prerequisites", "projections", "embeddings"], "related_skills": ["skill_folder_suggestion.md", "skill_train_model.md", "skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/build_folder_projections.py", "scripts/mindmap/suggest_folder.py", "docs/design/FEDERATED_MODEL_FORMAT.md", "education/book-13-semantic-search/08_advanced_federation.md", "education/book-14-ai-training/03_lda_projection.md"], "original_answer": "Build folder projections first using this command:\n\n```bash\npython3 scripts/mindmap/build_folder_projections.py \\\n  --embeddings \"EMBEDDINGS_FILE\" \\\n  --index \"INDEX_FILE\" \\\n  --output \"PROJECTIONS_DB\"\n```\n\nThis creates Procrustes projection matrices for each folder. Then use:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"\n```\n\nFor JSON output (useful for automation):\n```bash\npython3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\" --json\n```\n\nSee `skill_folder_suggestion.md` for complete setup.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_004_q2", "cluster_id": "skill_folder_suggestion_004", "question": "How do I prepare for mindmap folder organization?", "answer": "To prepare for mindmap folder organization, build folder projections first using:\n\n```bash\npython3 scripts/mindmap/build_folder_projections.py \\\n  --embeddings \"EMBEDDINGS_FILE\" \\\n  --index \"INDEX_FILE\" \\\n  --output \"PROJECTIONS_DB\"\n```\n\nThis creates Procrustes projection matrices for each folder, which enable semantic similarity matching. Once built, you can suggest folders for mindmaps using:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"\n```\n\nFor batch operations or automation, use the `--json` flag for structured output.", "question_type": "long", "topics": ["Mindmap", "Folder Organization", "Setup"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "setup", "prerequisites", "projections", "embeddings"], "related_skills": ["skill_folder_suggestion.md", "skill_train_model.md", "skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/build_folder_projections.py", "scripts/mindmap/suggest_folder.py", "docs/design/FEDERATED_MODEL_FORMAT.md", "education/book-13-semantic-search/08_advanced_federation.md", "education/book-14-ai-training/03_lda_projection.md"], "original_answer": "Build folder projections first using this command:\n\n```bash\npython3 scripts/mindmap/build_folder_projections.py \\\n  --embeddings \"EMBEDDINGS_FILE\" \\\n  --index \"INDEX_FILE\" \\\n  --output \"PROJECTIONS_DB\"\n```\n\nThis creates Procrustes projection matrices for each folder. Then use:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"\n```\n\nFor JSON output (useful for automation):\n```bash\npython3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\" --json\n```\n\nSee `skill_folder_suggestion.md` for complete setup.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_004_q3", "cluster_id": "skill_folder_suggestion_004", "question": "What do I need before using folder suggestions?", "answer": "Before using folder suggestions, you need to build folder projections first. Run this command to create Procrustes projection matrices for each folder:\n\n```bash\npython3 scripts/mindmap/build_folder_projections.py \\\n  --embeddings \"EMBEDDINGS_FILE\" \\\n  --index \"INDEX_FILE\" \\\n  --output \"PROJECTIONS_DB\"\n```\n\nOnce the projections are built, you can use the folder suggestion tool:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"\n```", "question_type": "long", "topics": ["Mindmap", "Folder Organization", "Setup"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "setup", "prerequisites", "projections", "embeddings"], "related_skills": ["skill_folder_suggestion.md", "skill_train_model.md", "skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/build_folder_projections.py", "scripts/mindmap/suggest_folder.py", "docs/design/FEDERATED_MODEL_FORMAT.md", "education/book-13-semantic-search/08_advanced_federation.md", "education/book-14-ai-training/03_lda_projection.md"], "original_answer": "Build folder projections first using this command:\n\n```bash\npython3 scripts/mindmap/build_folder_projections.py \\\n  --embeddings \"EMBEDDINGS_FILE\" \\\n  --index \"INDEX_FILE\" \\\n  --output \"PROJECTIONS_DB\"\n```\n\nThis creates Procrustes projection matrices for each folder. Then use:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"\n```\n\nFor JSON output (useful for automation):\n```bash\npython3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\" --json\n```\n\nSee `skill_folder_suggestion.md` for complete setup.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_001_q0", "cluster_id": "skill_mindmap_cross_links_001", "question": "How do I link my mindmaps together so they can reference each other?", "answer": "To link your mindmaps together for mutual referencing, use a two-step process:\n\n1. Build an index of your mindmaps:\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o output/mindmaps/index.json\n```\n\n2. Add cross-reference links between them:\n```bash\npython3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx --index output/mindmaps/index.json\n```\n\nThis adds `cloudmapref` attributes to create local navigation links between mindmaps without requiring external URLs. You can preview changes first with the `--dry-run --verbose` flags.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "cross-linking", "navigation", "cloudmapref"], "related_skills": ["skill_mindmap_cross_links.md", "skill_mindmap_linking.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/build_index.py", "scripts/mindmap/add_relative_links.py"], "original_answer": "Use `build_index.py` to create an index of your mindmaps, then `add_relative_links.py` to add cloudmapref links between them:\n\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o output/mindmaps/index.json\npython3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx --index output/mindmaps/index.json\n```\n\nThis enables local navigation between mindmaps without external URLs.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_001_q1", "cluster_id": "skill_mindmap_cross_links_001", "question": "Can I cross-reference mindmaps locally?", "answer": "Yes, you can cross-reference mindmaps locally using cloudmapref links. Build an index of your mindmaps with `python3 scripts/mindmap/build_index.py output/mindmaps/ -o output/mindmaps/index.json`, then add cross-links with `python3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx --index output/mindmaps/index.json`. This creates local navigation between mindmaps without requiring external URLs.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "cross-linking", "navigation", "cloudmapref"], "related_skills": ["skill_mindmap_cross_links.md", "skill_mindmap_linking.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/build_index.py", "scripts/mindmap/add_relative_links.py"], "original_answer": "Use `build_index.py` to create an index of your mindmaps, then `add_relative_links.py` to add cloudmapref links between them:\n\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o output/mindmaps/index.json\npython3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx --index output/mindmaps/index.json\n```\n\nThis enables local navigation between mindmaps without external URLs.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_001_q2", "cluster_id": "skill_mindmap_cross_links_001", "question": "How do I connect multiple mindmaps without external URLs?", "answer": "Use `build_index.py` to create an index of your mindmaps, then `add_relative_links.py` to add cloudmapref links between them:\n\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o output/mindmaps/index.json\npython3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx --index output/mindmaps/index.json\n```\n\nThis creates local navigation links (cloudmapref) between mindmaps without requiring external URLs.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "cross-linking", "navigation", "cloudmapref"], "related_skills": ["skill_mindmap_cross_links.md", "skill_mindmap_linking.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/build_index.py", "scripts/mindmap/add_relative_links.py"], "original_answer": "Use `build_index.py` to create an index of your mindmaps, then `add_relative_links.py` to add cloudmapref links between them:\n\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o output/mindmaps/index.json\npython3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx --index output/mindmaps/index.json\n```\n\nThis enables local navigation between mindmaps without external URLs.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_001_q3", "cluster_id": "skill_mindmap_cross_links_001", "question": "How do I make mindmaps link to each other?", "answer": "Use `build_index.py` to create an index of your mindmaps, then `add_relative_links.py` to add cloudmapref links between them:\n\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o output/mindmaps/index.json\npython3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx --index output/mindmaps/index.json\n```\n\nThis enables local navigation between mindmaps without external URLs. You can preview changes first with the `--dry-run` flag to see what links will be added before applying them.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "cross-linking", "navigation", "cloudmapref"], "related_skills": ["skill_mindmap_cross_links.md", "skill_mindmap_linking.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/build_index.py", "scripts/mindmap/add_relative_links.py"], "original_answer": "Use `build_index.py` to create an index of your mindmaps, then `add_relative_links.py` to add cloudmapref links between them:\n\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o output/mindmaps/index.json\npython3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx --index output/mindmaps/index.json\n```\n\nThis enables local navigation between mindmaps without external URLs.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_002_q0", "cluster_id": "skill_mindmap_cross_links_002", "question": "How do I rename a mindmap file without breaking its links?", "answer": "Use `rename_mindmap.py` to rename mindmaps while automatically updating all references. For auto-generated names based on the root topic, run:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py --mindmap \"MINDMAP_PATH\" --titled\n```\n\nFor explicit naming, use:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py --mindmap \"MINDMAP_PATH\" --new-name \"New_Name.smmx\"\n```\n\nThis tool automatically updates all cloudmapref links in other mindmaps that reference the renamed file, preserving cross-references without manual intervention.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links", "Rename"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "rename", "links", "references"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/rename_mindmap.py"], "original_answer": "Use `rename_mindmap.py` to rename mindmaps while automatically updating all references:\n\n```bash\n# Auto-generate name from root topic\npython3 scripts/mindmap/rename_mindmap.py --mindmap \"MINDMAP_PATH\" --titled\n\n# Explicit new name\npython3 scripts/mindmap/rename_mindmap.py --mindmap \"MINDMAP_PATH\" --new-name \"New_Name.smmx\"\n```\n\nThis updates all cloudmapref links in other mindmaps that reference the renamed file.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_002_q1", "cluster_id": "skill_mindmap_cross_links_002", "question": "What happens to links when I rename a mindmap?", "answer": "When you rename a mindmap, links are automatically updated if you use the `rename_mindmap.py` script. This script updates all `cloudmapref` links in other mindmaps that reference the renamed file, preserving the cross-link connections. If you rename a file without using this script, the links will break. To safely rename, use either `python3 scripts/mindmap/rename_mindmap.py --mindmap \"MINDMAP_PATH\" --titled` to auto-generate the name from the root topic, or `python3 scripts/mindmap/rename_mindmap.py --mindmap \"MINDMAP_PATH\" --new-name \"New_Name.smmx\"` for an explicit name.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links", "Rename"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "rename", "links", "references"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/rename_mindmap.py"], "original_answer": "Use `rename_mindmap.py` to rename mindmaps while automatically updating all references:\n\n```bash\n# Auto-generate name from root topic\npython3 scripts/mindmap/rename_mindmap.py --mindmap \"MINDMAP_PATH\" --titled\n\n# Explicit new name\npython3 scripts/mindmap/rename_mindmap.py --mindmap \"MINDMAP_PATH\" --new-name \"New_Name.smmx\"\n```\n\nThis updates all cloudmapref links in other mindmaps that reference the renamed file.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_002_q2", "cluster_id": "skill_mindmap_cross_links_002", "question": "How do I update references after renaming mindmaps?", "answer": "Use `rename_mindmap.py` to rename mindmaps while automatically updating all references. For a single mindmap, use `python3 scripts/mindmap/rename_mindmap.py --mindmap \"MINDMAP_PATH\" --titled` to auto-generate the name from the root topic, or `python3 scripts/mindmap/rename_mindmap.py --mindmap \"MINDMAP_PATH\" --new-name \"New_Name.smmx\"` for an explicit name. For batch renaming, use `python3 scripts/mindmap/rename_mindmap.py --batch \"MINDMAP_DIR\" --titled --dry-run` to preview changes. This automatically updates all cloudmapref links in other mindmaps that reference the renamed file.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links", "Rename"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "rename", "links", "references"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/rename_mindmap.py"], "original_answer": "Use `rename_mindmap.py` to rename mindmaps while automatically updating all references:\n\n```bash\n# Auto-generate name from root topic\npython3 scripts/mindmap/rename_mindmap.py --mindmap \"MINDMAP_PATH\" --titled\n\n# Explicit new name\npython3 scripts/mindmap/rename_mindmap.py --mindmap \"MINDMAP_PATH\" --new-name \"New_Name.smmx\"\n```\n\nThis updates all cloudmapref links in other mindmaps that reference the renamed file.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_002_q3", "cluster_id": "skill_mindmap_cross_links_002", "question": "Can I safely rename mindmaps that are linked together?", "answer": "Yes, you can safely rename mindmaps that are linked together. Use `rename_mindmap.py` to rename while automatically updating all `cloudmapref` references in other mindmaps:\n\n```bash\n# Auto-generate name from root topic\npython3 scripts/mindmap/rename_mindmap.py --mindmap \"MINDMAP_PATH\" --titled\n\n# Or specify explicit new name\npython3 scripts/mindmap/rename_mindmap.py --mindmap \"MINDMAP_PATH\" --new-name \"New_Name.smmx\"\n```\n\nThis ensures all cross-links to the renamed mindmap are automatically updated, so the links remain valid.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links", "Rename"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "rename", "links", "references"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/rename_mindmap.py"], "original_answer": "Use `rename_mindmap.py` to rename mindmaps while automatically updating all references:\n\n```bash\n# Auto-generate name from root topic\npython3 scripts/mindmap/rename_mindmap.py --mindmap \"MINDMAP_PATH\" --titled\n\n# Explicit new name\npython3 scripts/mindmap/rename_mindmap.py --mindmap \"MINDMAP_PATH\" --new-name \"New_Name.smmx\"\n```\n\nThis updates all cloudmapref links in other mindmaps that reference the renamed file.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_003_q0", "cluster_id": "skill_mindmap_cross_links_003", "question": "How do I preview what links will be added before making changes?", "answer": "Use the `--dry-run` flag with `add_relative_links.py` to preview changes without modifying files:\n\n```bash\npython3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx \\\n  --index output/mindmaps/index.json \\\n  --dry-run --verbose\n```\n\nThe `--verbose` flag shows detailed output of what links would be added, and `--dry-run` prevents any file modifications.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links", "Preview"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "preview", "dry-run", "testing"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/add_relative_links.py"], "original_answer": "Use the `--dry-run` flag with `add_relative_links.py` to preview changes:\n\n```bash\npython3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx \\\n  --index output/mindmaps/index.json \\\n  --dry-run --verbose\n```\n\nThis shows what links would be added without modifying any files.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_003_q1", "cluster_id": "skill_mindmap_cross_links_003", "question": "Can I test mindmap linking without modifying files?", "answer": "Yes, you can test mindmap linking without modifying files using the `--dry-run` flag with `add_relative_links.py`. This flag previews all changes that would be made without writing to disk. For detailed output, combine it with `--verbose`:\n\n```bash\npython3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx \\\n  --index output/mindmaps/index.json \\\n  --dry-run --verbose\n```\n\nThis shows exactly which cloudmapref links would be added to each mindmap, allowing you to verify the linking behavior before applying changes.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links", "Preview"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "preview", "dry-run", "testing"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/add_relative_links.py"], "original_answer": "Use the `--dry-run` flag with `add_relative_links.py` to preview changes:\n\n```bash\npython3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx \\\n  --index output/mindmaps/index.json \\\n  --dry-run --verbose\n```\n\nThis shows what links would be added without modifying any files.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_003_q2", "cluster_id": "skill_mindmap_cross_links_003", "question": "How do I see what cross-links will be created?", "answer": "Use the `--dry-run` flag with `add_relative_links.py` to preview cross-links before applying them:\n\n```bash\npython3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx \\\n  --index output/mindmaps/index.json \\\n  --dry-run --verbose\n```\n\nAdd `--verbose` to see detailed output of which mindmaps will be linked together and where the `cloudmapref` attributes will be added. The `--dry-run` flag ensures no files are modified.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links", "Preview"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "preview", "dry-run", "testing"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/add_relative_links.py"], "original_answer": "Use the `--dry-run` flag with `add_relative_links.py` to preview changes:\n\n```bash\npython3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx \\\n  --index output/mindmaps/index.json \\\n  --dry-run --verbose\n```\n\nThis shows what links would be added without modifying any files.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_003_q3", "cluster_id": "skill_mindmap_cross_links_003", "question": "Is there a dry-run mode for adding mindmap links?", "answer": "Yes. Use the `--dry-run` flag with `add_relative_links.py` to preview changes without modifying files:\n\n```bash\npython3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx \\\n  --index output/mindmaps/index.json \\\n  --dry-run --verbose\n```\n\nAdd `--verbose` to see detailed output of what links would be added.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links", "Preview"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "preview", "dry-run", "testing"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/add_relative_links.py"], "original_answer": "Use the `--dry-run` flag with `add_relative_links.py` to preview changes:\n\n```bash\npython3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx \\\n  --index output/mindmaps/index.json \\\n  --dry-run --verbose\n```\n\nThis shows what links would be added without modifying any files.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_004_q0", "cluster_id": "skill_mindmap_cross_links_004", "question": "How do I find all mindmaps that link to a specific mindmap?", "answer": "Use `build_reverse_index.py` to create a backlinks index that shows all incoming links to each mindmap:\n\n```bash\npython3 scripts/mindmap/build_reverse_index.py output/mindmaps/ \\\n  -o output/mindmaps/reverse_index.json\n```\n\nThis generates a reverse index file where you can look up a specific mindmap to see all other mindmaps that link to it. The index is useful for understanding which mindmaps reference a particular mindmap.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links", "Backlinks"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "backlinks", "reverse-index", "references"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/build_reverse_index.py"], "original_answer": "Use `build_reverse_index.py` to create a backlinks index:\n\n```bash\npython3 scripts/mindmap/build_reverse_index.py output/mindmaps/ \\\n  -o output/mindmaps/reverse_index.json\n```\n\nThis builds an index showing all incoming links to each mindmap, useful for understanding mindmap relationships.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_004_q1", "cluster_id": "skill_mindmap_cross_links_004", "question": "Can I see backlinks between mindmaps?", "answer": "Yes, use `build_reverse_index.py` to see backlinks between mindmaps:\n\n```bash\npython3 scripts/mindmap/build_reverse_index.py output/mindmaps/ \\\n  -o output/mindmaps/reverse_index.json\n```\n\nThis creates an index showing which mindmaps link to each other, so you can see all incoming links for each mindmap and understand their relationships.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links", "Backlinks"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "backlinks", "reverse-index", "references"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/build_reverse_index.py"], "original_answer": "Use `build_reverse_index.py` to create a backlinks index:\n\n```bash\npython3 scripts/mindmap/build_reverse_index.py output/mindmaps/ \\\n  -o output/mindmaps/reverse_index.json\n```\n\nThis builds an index showing all incoming links to each mindmap, useful for understanding mindmap relationships.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_004_q2", "cluster_id": "skill_mindmap_cross_links_004", "question": "How do I build a reverse index of mindmap references?", "answer": "Use `build_reverse_index.py` to create a backlinks index:\n\n```bash\npython3 scripts/mindmap/build_reverse_index.py output/mindmaps/ \\\n  -o output/mindmaps/reverse_index.json\n```\n\nThis builds an index showing all incoming links to each mindmap, useful for understanding mindmap relationships and identifying which mindmaps reference a given target.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links", "Backlinks"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "backlinks", "reverse-index", "references"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/build_reverse_index.py"], "original_answer": "Use `build_reverse_index.py` to create a backlinks index:\n\n```bash\npython3 scripts/mindmap/build_reverse_index.py output/mindmaps/ \\\n  -o output/mindmaps/reverse_index.json\n```\n\nThis builds an index showing all incoming links to each mindmap, useful for understanding mindmap relationships.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_004_q3", "cluster_id": "skill_mindmap_cross_links_004", "question": "Which mindmaps reference a particular mindmap?", "answer": "Use `build_reverse_index.py` to create a backlinks index that shows which mindmaps reference a particular mindmap:\n\n```bash\npython3 scripts/mindmap/build_reverse_index.py output/mindmaps/ \\\n  -o output/mindmaps/reverse_index.json\n```\n\nThis generates a reverse index where you can look up any mindmap and see all other mindmaps that link to it via `cloudmapref` attributes. The output file maps each mindmap to its incoming references.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links", "Backlinks"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "backlinks", "reverse-index", "references"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/build_reverse_index.py"], "original_answer": "Use `build_reverse_index.py` to create a backlinks index:\n\n```bash\npython3 scripts/mindmap/build_reverse_index.py output/mindmaps/ \\\n  -o output/mindmaps/reverse_index.json\n```\n\nThis builds an index showing all incoming links to each mindmap, useful for understanding mindmap relationships.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_001_q0", "cluster_id": "skill_mindmap_linking_001", "question": "How do I connect my SimpleMind mindmap to my Pearltrees bookmarks?", "answer": "To connect your SimpleMind mindmap to your Pearltrees bookmarks, use the `link_pearltrees.py` script. The simplest approach is:\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"YOUR_MINDMAP_PATH\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --output \"OUTPUT_PATH\"\n```\n\nFor better matching results, include the hierarchical projection model:\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"YOUR_MINDMAP_PATH\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --projection-model models/pearltrees_federated_nomic.pkl \\\n  --output \"OUTPUT_PATH\"\n```\n\nThe script will add linked child nodes to your mindmap, labeled as:\n- **PP**: Direct URL match to a PagePearl\n- **PT**: Exact Pearltree title match\n- **PT?**: Semantic similarity match\n\nFor more options and detailed guidance, run `python3 scripts/mindmap/link_pearltrees.py --help` or see the full documentation.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "pearltrees", "linking", "semantic-search"], "related_skills": ["skill_mindmap_linking.md", "skill_bookmark_filing.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/README.md", "scripts/mindmap/link_pearltrees.py", "education/book-13-semantic-search/01_introduction.md", "education/book-13-semantic-search/05_semantic_playbook.md"], "original_answer": "Use the `link_pearltrees.py` script to enrich your SimpleMind mindmap with Pearltrees links. For best results with hierarchical semantic matching:\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"MINDMAP_PATH\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --projection-model models/pearltrees_federated_nomic.pkl \\\n  --output \"OUTPUT_PATH\"\n```\n\nThis adds child nodes labeled PP (PearlPage for URL matches), PT (exact Pearltree title matches), or PT? (semantic similarity matches). See `skill_mindmap_linking.md` for full options and `docs/QUICKSTART_MINDMAP_LINKING.md` for detailed guidance.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_001_q1", "cluster_id": "skill_mindmap_linking_001", "question": "Can I link my mindmap to Pearltrees?", "answer": "Yes, you can link your mindmap to Pearltrees using the `link_pearltrees.py` script. This enriches your SimpleMind mindmap with Pearltrees connections through hierarchical semantic matching. Run: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --projection-model models/pearltrees_federated_nomic.pkl --output \"OUTPUT_PATH\"`. This adds child nodes labeled PP (PearlPage URL matches), PT (exact Pearltree titles), or PT? (semantic similarity matches). For basic title matching only, omit the `--projection-model` flag. See the skill documentation for additional options like URL matching and custom thresholds.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "pearltrees", "linking", "semantic-search"], "related_skills": ["skill_mindmap_linking.md", "skill_bookmark_filing.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/README.md", "scripts/mindmap/link_pearltrees.py", "education/book-13-semantic-search/01_introduction.md", "education/book-13-semantic-search/05_semantic_playbook.md"], "original_answer": "Use the `link_pearltrees.py` script to enrich your SimpleMind mindmap with Pearltrees links. For best results with hierarchical semantic matching:\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"MINDMAP_PATH\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --projection-model models/pearltrees_federated_nomic.pkl \\\n  --output \"OUTPUT_PATH\"\n```\n\nThis adds child nodes labeled PP (PearlPage for URL matches), PT (exact Pearltree title matches), or PT? (semantic similarity matches). See `skill_mindmap_linking.md` for full options and `docs/QUICKSTART_MINDMAP_LINKING.md` for detailed guidance.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_001_q2", "cluster_id": "skill_mindmap_linking_001", "question": "How do I enrich my mindmap with Pearltrees links?", "answer": "Use the `link_pearltrees.py` script to enrich your SimpleMind mindmap with Pearltrees links. The basic command is:\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"MINDMAP_PATH\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --output \"OUTPUT_PATH\"\n```\n\nFor best results with hierarchical semantic matching, add the projection model:\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"MINDMAP_PATH\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --projection-model models/pearltrees_federated_nomic.pkl \\\n  --output \"OUTPUT_PATH\"\n```\n\nThis adds child nodes with labels:\n- **PP**: PearlPage (URL matches)\n- **PT**: Exact Pearltree title match\n- **PT?**: Semantic similarity match\n\nFor advanced options like URL matching, additional pearls data, or custom thresholds, use `--help` to see all flags.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "pearltrees", "linking", "semantic-search"], "related_skills": ["skill_mindmap_linking.md", "skill_bookmark_filing.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/README.md", "scripts/mindmap/link_pearltrees.py", "education/book-13-semantic-search/01_introduction.md", "education/book-13-semantic-search/05_semantic_playbook.md"], "original_answer": "Use the `link_pearltrees.py` script to enrich your SimpleMind mindmap with Pearltrees links. For best results with hierarchical semantic matching:\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"MINDMAP_PATH\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --projection-model models/pearltrees_federated_nomic.pkl \\\n  --output \"OUTPUT_PATH\"\n```\n\nThis adds child nodes labeled PP (PearlPage for URL matches), PT (exact Pearltree title matches), or PT? (semantic similarity matches). See `skill_mindmap_linking.md` for full options and `docs/QUICKSTART_MINDMAP_LINKING.md` for detailed guidance.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_001_q3", "cluster_id": "skill_mindmap_linking_001", "question": "I want to add Pearltrees references to my mindmap", "answer": "Use the `link_pearltrees.py` script to enrich your SimpleMind mindmap with Pearltrees references. Run:\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"YOUR_MINDMAP_PATH\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --projection-model models/pearltrees_federated_nomic.pkl \\\n  --output \"OUTPUT_PATH\"\n```\n\nThis adds child nodes with labels: PP (URL matches), PT (exact title matches), or PT? (semantic similarity matches). For simpler title-only matching, omit the `--projection-model` flag. See the Mindmap Linking skill documentation for additional options like URL database matching and custom thresholds.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "pearltrees", "linking", "semantic-search"], "related_skills": ["skill_mindmap_linking.md", "skill_bookmark_filing.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/README.md", "scripts/mindmap/link_pearltrees.py", "education/book-13-semantic-search/01_introduction.md", "education/book-13-semantic-search/05_semantic_playbook.md"], "original_answer": "Use the `link_pearltrees.py` script to enrich your SimpleMind mindmap with Pearltrees links. For best results with hierarchical semantic matching:\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"MINDMAP_PATH\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --projection-model models/pearltrees_federated_nomic.pkl \\\n  --output \"OUTPUT_PATH\"\n```\n\nThis adds child nodes labeled PP (PearlPage for URL matches), PT (exact Pearltree title matches), or PT? (semantic similarity matches). See `skill_mindmap_linking.md` for full options and `docs/QUICKSTART_MINDMAP_LINKING.md` for detailed guidance.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_002_q0", "cluster_id": "skill_mindmap_linking_002", "question": "What do the PP, PT, and PT? labels mean in my mindmap?", "answer": "The PP, PT, and PT? labels indicate what type of match was found when linking your mindmap to Pearltrees:\n\n- **PP** (PearlPage): Your node's URL exactly matches a PagePearl's external URL\n- **PT** (Pearltree): Your node title exactly matches a Pearltree name (including disambiguated variants)\n- **PT?** (Pearltree fuzzy): Your node has semantic similarity to a Pearltree above the confidence threshold, but isn't an exact title match\n\nThese labels are automatically added by the mindmap linking tool to show you how each connection was made.", "question_type": "long", "topics": ["Mindmap", "Mindmap Linking", "Output Labels"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "labels", "output"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/link_pearltrees.py"], "original_answer": "These labels indicate the match quality when linking to Pearltrees:\n\n- **PP** (PearlPage): The node's URL exactly matches a PagePearl's external URL\n- **PT** (Pearltree): Exact title match with a Pearltree (including disambiguated names)\n- **PT?** (Pearltree fuzzy): Semantic similarity match above threshold (not exact)\n\nLabels are added automatically by `link_pearltrees.py` based on matching strategy. See `skill_mindmap_linking.md` for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_002_q1", "cluster_id": "skill_mindmap_linking_002", "question": "What are these PT labels on my mindmap nodes?", "answer": "PT labels on your mindmap nodes indicate a Pearltree match. **PT** means the node title exactly matches a Pearltree in your linked collection. **PT?** means the match was based on semantic similarity above your threshold, not an exact match. **PP** labels indicate the node's URL matches a PagePearl's external URL. These labels are added automatically by the `link_pearltrees.py` script during the linking process.", "question_type": "long", "topics": ["Mindmap", "Mindmap Linking", "Output Labels"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "labels", "output"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/link_pearltrees.py"], "original_answer": "These labels indicate the match quality when linking to Pearltrees:\n\n- **PP** (PearlPage): The node's URL exactly matches a PagePearl's external URL\n- **PT** (Pearltree): Exact title match with a Pearltree (including disambiguated names)\n- **PT?** (Pearltree fuzzy): Semantic similarity match above threshold (not exact)\n\nLabels are added automatically by `link_pearltrees.py` based on matching strategy. See `skill_mindmap_linking.md` for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_002_q2", "cluster_id": "skill_mindmap_linking_002", "question": "Why are some nodes marked PT? instead of PT?", "answer": "Nodes are marked as PT? (Pearltree fuzzy) instead of PT (Pearltree exact) when the match is based on semantic similarity rather than an exact title match. PT? indicates the node was matched using the hierarchical projection model, which compares embeddings and returns results above the similarity threshold (default 0.7). This fuzzy matching is useful when Pearltree titles don't match exactly but are semantically related to your mindmap node. Use the `--threshold` flag to adjust sensitivity\u2014lower values accept more fuzzy matches, higher values require closer semantic similarity.", "question_type": "long", "topics": ["Mindmap", "Mindmap Linking", "Output Labels"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "labels", "output"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/link_pearltrees.py"], "original_answer": "These labels indicate the match quality when linking to Pearltrees:\n\n- **PP** (PearlPage): The node's URL exactly matches a PagePearl's external URL\n- **PT** (Pearltree): Exact title match with a Pearltree (including disambiguated names)\n- **PT?** (Pearltree fuzzy): Semantic similarity match above threshold (not exact)\n\nLabels are added automatically by `link_pearltrees.py` based on matching strategy. See `skill_mindmap_linking.md` for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_002_q3", "cluster_id": "skill_mindmap_linking_002", "question": "What's the difference between PP and PT labels?", "answer": "PP (PearlPage) and PT (Pearltree) labels indicate different types of matches when linking mindmaps to Pearltrees:\n\n- **PP (PearlPage)**: The mindmap node's URL exactly matches a PagePearl's external URL\n- **PT (Pearltree)**: Exact title match with a Pearltree node (including disambiguated names)\n- **PT? (Pearltree fuzzy)**: Semantic similarity match above the confidence threshold (not an exact match)\n\nThese labels are automatically assigned by the `link_pearltrees.py` script based on which matching strategy successfully identifies a link.", "question_type": "long", "topics": ["Mindmap", "Mindmap Linking", "Output Labels"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "labels", "output"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/link_pearltrees.py"], "original_answer": "These labels indicate the match quality when linking to Pearltrees:\n\n- **PP** (PearlPage): The node's URL exactly matches a PagePearl's external URL\n- **PT** (Pearltree): Exact title match with a Pearltree (including disambiguated names)\n- **PT?** (Pearltree fuzzy): Semantic similarity match above threshold (not exact)\n\nLabels are added automatically by `link_pearltrees.py` based on matching strategy. See `skill_mindmap_linking.md` for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_003_q0", "cluster_id": "skill_mindmap_linking_003", "question": "How can I preview what links will be added to my mindmap before changing it?", "answer": "Use the `--dry-run` flag with `--verbose` to preview all proposed links without modifying your mindmap:\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"MINDMAP_PATH\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --dry-run --verbose\n```\n\nThis will display all matches found (with their match types: PP for PearlPage, PT for exact title match, PT? for fuzzy semantic matches) and show what links would be added, without creating any output file or modifying your original mindmap.", "question_type": "long", "topics": ["Mindmap", "Mindmap Linking", "Preview"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "dry-run", "preview", "testing"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["scripts/mindmap/link_pearltrees.py", "docs/QUICKSTART_MINDMAP_LINKING.md"], "original_answer": "Use the `--dry-run` flag with `--verbose` to preview changes without modifying your mindmap:\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"MINDMAP_PATH\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --dry-run --verbose\n```\n\nThis shows all matches and proposed links without writing to the output file. See `skill_mindmap_linking.md` for more options.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_003_q1", "cluster_id": "skill_mindmap_linking_003", "question": "Can I do a dry run of mindmap linking?", "answer": "Yes, use the `--dry-run` flag with `--verbose` to preview all proposed links without modifying your mindmap:\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"MINDMAP_PATH\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --dry-run --verbose\n```\n\nThis displays all matches and proposed links (PP, PT, PT? labels) without writing changes to the output file. Add other flags like `--embeddings` and `--projection-model` if you want to test those features during the dry run.", "question_type": "long", "topics": ["Mindmap", "Mindmap Linking", "Preview"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "dry-run", "preview", "testing"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["scripts/mindmap/link_pearltrees.py", "docs/QUICKSTART_MINDMAP_LINKING.md"], "original_answer": "Use the `--dry-run` flag with `--verbose` to preview changes without modifying your mindmap:\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"MINDMAP_PATH\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --dry-run --verbose\n```\n\nThis shows all matches and proposed links without writing to the output file. See `skill_mindmap_linking.md` for more options.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_003_q2", "cluster_id": "skill_mindmap_linking_003", "question": "I want to see what changes will be made without modifying my mindmap", "answer": "Use the `--dry-run` flag with `--verbose` to preview all proposed changes without modifying your mindmap:\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"MINDMAP_PATH\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --dry-run --verbose\n```\n\nThis will show all matched Pearltrees, proposed link labels (PP, PT, PT?), and semantic similarities without writing any changes to disk.", "question_type": "long", "topics": ["Mindmap", "Mindmap Linking", "Preview"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "dry-run", "preview", "testing"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["scripts/mindmap/link_pearltrees.py", "docs/QUICKSTART_MINDMAP_LINKING.md"], "original_answer": "Use the `--dry-run` flag with `--verbose` to preview changes without modifying your mindmap:\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"MINDMAP_PATH\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --dry-run --verbose\n```\n\nThis shows all matches and proposed links without writing to the output file. See `skill_mindmap_linking.md` for more options.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_003_q3", "cluster_id": "skill_mindmap_linking_003", "question": "How do I test mindmap linking without saving?", "answer": "Use the `--dry-run` flag with `--verbose` to preview all matching and proposed links without modifying your mindmap:\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"MINDMAP_PATH\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --dry-run --verbose\n```\n\nThe `--dry-run` flag prevents any output file from being written, while `--verbose` shows detailed matching results. You can add other flags like `--embeddings` and `--projection-model` if you want to test with semantic matching as well.", "question_type": "long", "topics": ["Mindmap", "Mindmap Linking", "Preview"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "dry-run", "preview", "testing"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["scripts/mindmap/link_pearltrees.py", "docs/QUICKSTART_MINDMAP_LINKING.md"], "original_answer": "Use the `--dry-run` flag with `--verbose` to preview changes without modifying your mindmap:\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"MINDMAP_PATH\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --dry-run --verbose\n```\n\nThis shows all matches and proposed links without writing to the output file. See `skill_mindmap_linking.md` for more options.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_004_q0", "cluster_id": "skill_mindmap_linking_004", "question": "What's the difference between mindmap linking and bookmark filing?", "answer": "Bookmark Filing and Mindmap Linking are complementary tools that use the same projection model but operate in opposite directions:\n\n**Bookmark Filing** takes a new bookmark and finds the best location in your Pearltrees hierarchy to file it. It answers: \"Where should this bookmark go?\"\n\n**Mindmap Linking** takes an existing SimpleMind mindmap and enriches it by connecting its nodes to relevant Pearltrees content. It answers: \"What Pearltrees content relates to this mindmap?\"\n\nBoth use hierarchical semantic matching with the federated projection model (nomic or single-account variants). Choose bookmark filing when adding new content to Pearltrees, and mindmap linking when you want to annotate an existing mindmap with your Pearltrees knowledge base.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Linking", "Integration"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "bookmark-filing", "comparison", "workflow"], "related_skills": ["skill_mindmap_linking.md", "skill_bookmark_filing.md", "skill_semantic_inference.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/README.md", "scripts/infer_pearltrees_federated.py", "education/book-13-semantic-search/15_zero_shot_path_mapping.md", "education/book-13-semantic-search/08_advanced_federation.md"], "original_answer": "Both tools use the same projection model but serve different purposes:\n\n- **Bookmark Filing** (`skill_bookmark_filing.md`): Finds where to save a *new* bookmark in your Pearltrees hierarchy\n- **Mindmap Linking** (`skill_mindmap_linking.md`): Enriches an *existing* SimpleMind mindmap with links to Pearltrees content\n\nUse bookmark filing when adding new bookmarks to Pearltrees. Use mindmap linking when you have a mindmap and want to connect it to your existing Pearltrees knowledge base. Both use hierarchical semantic matching with the same federated projection model.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_004_q1", "cluster_id": "skill_mindmap_linking_004", "question": "How does mindmap linking relate to bookmark filing?", "answer": "Mindmap linking and bookmark filing are complementary tools using the same federated projection model for hierarchical semantic matching, but serve different purposes. Bookmark filing finds optimal locations in your Pearltrees hierarchy to save new bookmarks, while mindmap linking enriches existing SimpleMind mindmaps by connecting them to your current Pearltrees knowledge base. Both leverage the same `pearltrees_federated_nomic.pkl` model to perform semantic similarity matching, allowing either tool to identify relevant Pearltrees content. Choose bookmark filing when organizing new bookmarks into Pearltrees, and mindmap linking when you want to enrich a mindmap with connections to existing Pearltrees content.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Linking", "Integration"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "bookmark-filing", "comparison", "workflow"], "related_skills": ["skill_mindmap_linking.md", "skill_bookmark_filing.md", "skill_semantic_inference.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/README.md", "scripts/infer_pearltrees_federated.py", "education/book-13-semantic-search/15_zero_shot_path_mapping.md", "education/book-13-semantic-search/08_advanced_federation.md"], "original_answer": "Both tools use the same projection model but serve different purposes:\n\n- **Bookmark Filing** (`skill_bookmark_filing.md`): Finds where to save a *new* bookmark in your Pearltrees hierarchy\n- **Mindmap Linking** (`skill_mindmap_linking.md`): Enriches an *existing* SimpleMind mindmap with links to Pearltrees content\n\nUse bookmark filing when adding new bookmarks to Pearltrees. Use mindmap linking when you have a mindmap and want to connect it to your existing Pearltrees knowledge base. Both use hierarchical semantic matching with the same federated projection model.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_004_q2", "cluster_id": "skill_mindmap_linking_004", "question": "Should I use mindmap linking or bookmark filing?", "answer": "Use **bookmark filing** when you want to file a new bookmark into your Pearltrees hierarchy. Use **mindmap linking** when you have an existing SimpleMind mindmap and want to enrich it by connecting its nodes to relevant Pearltrees content. Both tools use the same federated projection model for hierarchical semantic matching, but serve opposite workflows: bookmark filing finds the right place for new content going *into* Pearltrees, while mindmap linking connects content *from* your mindmap to your Pearltrees knowledge base.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Linking", "Integration"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "bookmark-filing", "comparison", "workflow"], "related_skills": ["skill_mindmap_linking.md", "skill_bookmark_filing.md", "skill_semantic_inference.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/README.md", "scripts/infer_pearltrees_federated.py", "education/book-13-semantic-search/15_zero_shot_path_mapping.md", "education/book-13-semantic-search/08_advanced_federation.md"], "original_answer": "Both tools use the same projection model but serve different purposes:\n\n- **Bookmark Filing** (`skill_bookmark_filing.md`): Finds where to save a *new* bookmark in your Pearltrees hierarchy\n- **Mindmap Linking** (`skill_mindmap_linking.md`): Enriches an *existing* SimpleMind mindmap with links to Pearltrees content\n\nUse bookmark filing when adding new bookmarks to Pearltrees. Use mindmap linking when you have a mindmap and want to connect it to your existing Pearltrees knowledge base. Both use hierarchical semantic matching with the same federated projection model.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_004_q3", "cluster_id": "skill_mindmap_linking_004", "question": "When do I use each tool?", "answer": "Use Bookmark Filing when you want to save a new bookmark into your Pearltrees hierarchy\u2014it determines the best location for new content. Use Mindmap Linking when you have an existing SimpleMind mindmap and want to enrich it by connecting its nodes to your Pearltrees knowledge base. Both tools leverage the same hierarchical semantic matching with federated projection models, but they work in opposite directions: bookmark filing moves content into Pearltrees, while mindmap linking brings Pearltrees content into your mindmap.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Linking", "Integration"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "bookmark-filing", "comparison", "workflow"], "related_skills": ["skill_mindmap_linking.md", "skill_bookmark_filing.md", "skill_semantic_inference.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/README.md", "scripts/infer_pearltrees_federated.py", "education/book-13-semantic-search/15_zero_shot_path_mapping.md", "education/book-13-semantic-search/08_advanced_federation.md"], "original_answer": "Both tools use the same projection model but serve different purposes:\n\n- **Bookmark Filing** (`skill_bookmark_filing.md`): Finds where to save a *new* bookmark in your Pearltrees hierarchy\n- **Mindmap Linking** (`skill_mindmap_linking.md`): Enriches an *existing* SimpleMind mindmap with links to Pearltrees content\n\nUse bookmark filing when adding new bookmarks to Pearltrees. Use mindmap linking when you have a mindmap and want to connect it to your existing Pearltrees knowledge base. Both use hierarchical semantic matching with the same federated projection model.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_001_q0", "cluster_id": "skill_mst_folder_grouping_001", "question": "How do I organize my mindmaps into folders by topic?", "answer": "Use the MST folder grouping script to organize your mindmaps into semantically coherent topic folders:\n\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --trees-only --target-size 10 --max-depth 5 \\\n  -o output/mst_folder_structure.json --verbose\n```\n\nThis command uses Minimum Spanning Tree partitioning to automatically group similar mindmaps together by topic. The `--target-size 10` parameter controls how many items go in each folder, and `--max-depth 5` limits folder nesting depth. You can adjust these values based on your collection size and organizational preferences.\n\nAfter generating the folder structure, you can create the actual mindmaps with:\n\n```bash\npython3 scripts/mindmap/generate_mst_mindmaps.py \\\n  --mst-structure output/mst_folder_structure.json \\\n  --output output/mst_mindmaps/ \\\n  --root-name \"My_Collection\"\n```\n\nFor more customization options, see `skill_mst_folder_grouping.md` or run `--help`.", "question_type": "medium", "topics": ["Mindmap", "Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "organization", "clustering", "mst", "folders"], "related_skills": ["skill_mst_folder_grouping.md", "skill_mindmap_cross_links.md", "skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/mst_folder_grouping.py", "scripts/mindmap/hierarchy_objective.py", "education/book-13-semantic-search/07_density_scoring.md", "education/book-13-semantic-search/14_scale_free_networks.md"], "original_answer": "Use the MST folder grouping script to organize mindmaps into semantically coherent folders:\n\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --trees-only --target-size 10 --max-depth 5 \\\n  -o output/mst_folder_structure.json --verbose\n```\n\nThis uses Minimum Spanning Tree partitioning to group similar mindmaps together. See `skill_mst_folder_grouping.md` for more options.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_001_q1", "cluster_id": "skill_mst_folder_grouping_001", "question": "Can I group mindmaps by semantic similarity?", "answer": "Yes. Use the MST folder grouping script to organize mindmaps into semantically coherent folders based on similarity:\n\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --trees-only --target-size 10 --max-depth 5 \\\n  -o output/mst_folder_structure.json --verbose\n```\n\nThis uses Minimum Spanning Tree partitioning to automatically group similar mindmaps together and create a folder hierarchy. You can customize the target folder size and maximum depth with the flags shown. See `skill_mst_folder_grouping.md` for additional options like different clustering methods and tree sources.", "question_type": "medium", "topics": ["Mindmap", "Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "organization", "clustering", "mst", "folders"], "related_skills": ["skill_mst_folder_grouping.md", "skill_mindmap_cross_links.md", "skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/mst_folder_grouping.py", "scripts/mindmap/hierarchy_objective.py", "education/book-13-semantic-search/07_density_scoring.md", "education/book-13-semantic-search/14_scale_free_networks.md"], "original_answer": "Use the MST folder grouping script to organize mindmaps into semantically coherent folders:\n\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --trees-only --target-size 10 --max-depth 5 \\\n  -o output/mst_folder_structure.json --verbose\n```\n\nThis uses Minimum Spanning Tree partitioning to group similar mindmaps together. See `skill_mst_folder_grouping.md` for more options.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_001_q2", "cluster_id": "skill_mst_folder_grouping_001", "question": "How do I cluster mindmaps automatically?", "answer": "Use the MST folder grouping script to automatically organize mindmaps into semantically coherent folders:\n\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --trees-only --target-size 10 --max-depth 5 \\\n  -o output/mst_folder_structure.json --verbose\n```\n\nThis uses Minimum Spanning Tree partitioning to group similar mindmaps by semantic similarity. Adjust `--target-size` to control folder size and `--max-depth` for folder nesting depth. For more options like using curated hierarchies or hybrid mode, see the skill documentation.", "question_type": "medium", "topics": ["Mindmap", "Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "organization", "clustering", "mst", "folders"], "related_skills": ["skill_mst_folder_grouping.md", "skill_mindmap_cross_links.md", "skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/mst_folder_grouping.py", "scripts/mindmap/hierarchy_objective.py", "education/book-13-semantic-search/07_density_scoring.md", "education/book-13-semantic-search/14_scale_free_networks.md"], "original_answer": "Use the MST folder grouping script to organize mindmaps into semantically coherent folders:\n\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --trees-only --target-size 10 --max-depth 5 \\\n  -o output/mst_folder_structure.json --verbose\n```\n\nThis uses Minimum Spanning Tree partitioning to group similar mindmaps together. See `skill_mst_folder_grouping.md` for more options.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_001_q3", "cluster_id": "skill_mst_folder_grouping_001", "question": "What's the best way to organize a collection of mindmaps?", "answer": "Use the MST folder grouping script to organize mindmaps into semantically coherent folder hierarchies. The script automatically groups similar mindmaps together using Minimum Spanning Tree partitioning:\n\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --trees-only --target-size 10 --max-depth 5 \\\n  -o output/mst_folder_structure.json --verbose\n```\n\nKey parameters:\n- `--target-size`: Target number of items per folder (default 8)\n- `--max-depth`: Maximum folder nesting depth (default 4)\n- `--tree-source`: Choose `mst` (automatic), `curated` (manual), or `hybrid` (both)\n\nAfter generating the structure, create mindmaps from it:\n\n```bash\npython3 scripts/mindmap/generate_mst_mindmaps.py \\\n  --mst-structure output/mst_folder_structure.json \\\n  --output output/mst_mindmaps/\n```\n\nSee `skill_mst_folder_grouping.md` for additional options like different clustering methods and hybrid mode with embedding blending.", "question_type": "medium", "topics": ["Mindmap", "Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "organization", "clustering", "mst", "folders"], "related_skills": ["skill_mst_folder_grouping.md", "skill_mindmap_cross_links.md", "skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/mst_folder_grouping.py", "scripts/mindmap/hierarchy_objective.py", "education/book-13-semantic-search/07_density_scoring.md", "education/book-13-semantic-search/14_scale_free_networks.md"], "original_answer": "Use the MST folder grouping script to organize mindmaps into semantically coherent folders:\n\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --trees-only --target-size 10 --max-depth 5 \\\n  -o output/mst_folder_structure.json --verbose\n```\n\nThis uses Minimum Spanning Tree partitioning to group similar mindmaps together. See `skill_mst_folder_grouping.md` for more options.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_002_q0", "cluster_id": "skill_mst_folder_grouping_002", "question": "How do I control how many items are in each folder?", "answer": "Use the `--target-size` option to control how many items appear in each folder:\n\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --target-size 10 \\\n  -o output/folders.json\n```\n\nThe default is 8 items per folder. Increase this value for larger folders, or decrease it for smaller, more granular organization. You can also use `--max-depth` to control how deeply folders nest.", "question_type": "long", "topics": ["Mindmap", "MST Folder Grouping", "Configuration"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "mst", "configuration", "folder-size"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/mst_folder_grouping.py"], "original_answer": "Use the `--target-size` option to control the target number of items per folder:\n\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --target-size 8 \\\n  --max-depth 3 \\\n  -o output/folders.json\n```\n\nThe default is 8 items per folder. Use `--max-depth` to limit folder nesting depth. See `skill_mst_folder_grouping.md` for all options.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_002_q1", "cluster_id": "skill_mst_folder_grouping_002", "question": "Can I adjust the folder size when organizing mindmaps?", "answer": "Yes, use the `--target-size` option to adjust the target number of items per folder when organizing mindmaps:\n\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --target-size 10 \\\n  --max-depth 5 \\\n  -o output/folders.json\n```\n\nThe default is 8 items per folder. You can also use `--max-depth` to control how deeply folders can be nested. For all available options, run `python3 scripts/mindmap/mst_folder_grouping.py --help`.", "question_type": "long", "topics": ["Mindmap", "MST Folder Grouping", "Configuration"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "mst", "configuration", "folder-size"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/mst_folder_grouping.py"], "original_answer": "Use the `--target-size` option to control the target number of items per folder:\n\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --target-size 8 \\\n  --max-depth 3 \\\n  -o output/folders.json\n```\n\nThe default is 8 items per folder. Use `--max-depth` to limit folder nesting depth. See `skill_mst_folder_grouping.md` for all options.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_002_q2", "cluster_id": "skill_mst_folder_grouping_002", "question": "How do I make smaller or larger folders?", "answer": "Use the `--target-size` option to control the target number of items per folder. The default is 8 items per folder. For smaller folders, use a lower value like `--target-size 5`. For larger folders, use a higher value like `--target-size 15`. Example:\n\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --target-size 5 \\\n  --max-depth 3 \\\n  -o output/folders.json\n```\n\nYou can also use `--max-depth` to limit folder nesting depth, which affects overall folder sizes.", "question_type": "long", "topics": ["Mindmap", "MST Folder Grouping", "Configuration"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "mst", "configuration", "folder-size"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/mst_folder_grouping.py"], "original_answer": "Use the `--target-size` option to control the target number of items per folder:\n\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --target-size 8 \\\n  --max-depth 3 \\\n  -o output/folders.json\n```\n\nThe default is 8 items per folder. Use `--max-depth` to limit folder nesting depth. See `skill_mst_folder_grouping.md` for all options.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_002_q3", "cluster_id": "skill_mst_folder_grouping_002", "question": "What if I want fewer items per folder?", "answer": "Use the `--target-size` option to control the target number of items per folder. For example, to set 5 items per folder instead of the default 8:\n\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --target-size 5 \\\n  -o output/folders.json\n```\n\nLower values create more folders with fewer items each. You can also use `--max-depth` to control how deeply folders can nest.", "question_type": "long", "topics": ["Mindmap", "MST Folder Grouping", "Configuration"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "mst", "configuration", "folder-size"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/mst_folder_grouping.py"], "original_answer": "Use the `--target-size` option to control the target number of items per folder:\n\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --target-size 8 \\\n  --max-depth 3 \\\n  -o output/folders.json\n```\n\nThe default is 8 items per folder. Use `--max-depth` to limit folder nesting depth. See `skill_mst_folder_grouping.md` for all options.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_003_q0", "cluster_id": "skill_mst_folder_grouping_003", "question": "Can I use my own folder hierarchy instead of automatic clustering?", "answer": "Yes, you can use your own folder hierarchy instead of automatic clustering. Use `--tree-source curated` to apply only your curated hierarchy, or `--tree-source hybrid` to combine your curated folders with automatic attachment of unorganized items.\n\nCurated only:\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --tree-source curated \\\n  -o output/folders.json\n```\n\nHybrid mode (curated + auto-attach orphans):\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --tree-source hybrid \\\n  --embed-blend 0.3 \\\n  -o output/folders.json\n```\n\nThe `--embed-blend` parameter controls how much the embedding influences orphan attachment in hybrid mode.", "question_type": "long", "topics": ["Mindmap", "MST Folder Grouping", "Hybrid Mode"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "mst", "curated", "hybrid", "manual"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/mst_folder_grouping.py", "education/book-13-semantic-search/08_advanced_federation.md"], "original_answer": "Yes, use `--tree-source curated` to use your curated hierarchy, or `--tree-source hybrid` to combine curated folders with automatic attachment of orphaned items:\n\n```bash\n# Curated only\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --tree-source curated \\\n  -o output/folders.json\n\n# Hybrid (curated + orphan attachment)\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --tree-source hybrid \\\n  --embed-blend 0.3 \\\n  -o output/folders.json\n```\n\nSee `skill_mst_folder_grouping.md` for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_003_q1", "cluster_id": "skill_mst_folder_grouping_003", "question": "How do I use a curated folder structure?", "answer": "To use a curated folder structure, run the MST folder grouping script with `--tree-source curated`:\n\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --tree-source curated \\\n  -o output/folders.json\n```\n\nIf you want to combine your curated hierarchy with automatic attachment of orphaned items, use `--tree-source hybrid` instead:\n\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --tree-source hybrid \\\n  --embed-blend 0.3 \\\n  -o output/folders.json\n```\n\nThe `--embed-blend` parameter controls how orphaned items are attached (default 0.3). The output JSON file contains your folder structure ready for mindmap generation.", "question_type": "long", "topics": ["Mindmap", "MST Folder Grouping", "Hybrid Mode"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "mst", "curated", "hybrid", "manual"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/mst_folder_grouping.py", "education/book-13-semantic-search/08_advanced_federation.md"], "original_answer": "Yes, use `--tree-source curated` to use your curated hierarchy, or `--tree-source hybrid` to combine curated folders with automatic attachment of orphaned items:\n\n```bash\n# Curated only\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --tree-source curated \\\n  -o output/folders.json\n\n# Hybrid (curated + orphan attachment)\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --tree-source hybrid \\\n  --embed-blend 0.3 \\\n  -o output/folders.json\n```\n\nSee `skill_mst_folder_grouping.md` for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_003_q2", "cluster_id": "skill_mst_folder_grouping_003", "question": "Can I combine manual and automatic organization?", "answer": "Yes, you can combine manual and automatic organization using two approaches:\n\n1. **Curated only**: Use your manually-created hierarchy without automatic clustering:\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --tree-source curated \\\n  -o output/folders.json\n```\n\n2. **Hybrid mode**: Combine your curated folders with automatic attachment of orphaned items:\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --tree-source hybrid \\\n  --embed-blend 0.3 \\\n  -o output/folders.json\n```\n\nHybrid mode preserves your manual organization while automatically placing unclassified items into appropriate folders based on semantic similarity. Adjust `--embed-blend` to control the balance between curated and automatic attachment.", "question_type": "long", "topics": ["Mindmap", "MST Folder Grouping", "Hybrid Mode"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "mst", "curated", "hybrid", "manual"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/mst_folder_grouping.py", "education/book-13-semantic-search/08_advanced_federation.md"], "original_answer": "Yes, use `--tree-source curated` to use your curated hierarchy, or `--tree-source hybrid` to combine curated folders with automatic attachment of orphaned items:\n\n```bash\n# Curated only\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --tree-source curated \\\n  -o output/folders.json\n\n# Hybrid (curated + orphan attachment)\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --tree-source hybrid \\\n  --embed-blend 0.3 \\\n  -o output/folders.json\n```\n\nSee `skill_mst_folder_grouping.md` for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_003_q3", "cluster_id": "skill_mst_folder_grouping_003", "question": "What if I already have some folders defined?", "answer": "Yes, you can use your existing folders with the MST folder grouping tool. Use `--tree-source curated` to apply the semantic clustering algorithm only to your predefined hierarchy, or `--tree-source hybrid` to keep your curated folders and automatically attach orphaned items to the nearest semantic match:\n\n```bash\n# Use only your curated folders\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --tree-source curated \\\n  -o output/folders.json\n\n# Keep curated folders and auto-attach orphans\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --tree-source hybrid \\\n  --embed-blend 0.3 \\\n  -o output/folders.json\n```\n\nThe `hybrid` mode is useful when you have a base folder structure you want to preserve but need to organize items that don't fit into existing categories.", "question_type": "long", "topics": ["Mindmap", "MST Folder Grouping", "Hybrid Mode"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "mst", "curated", "hybrid", "manual"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/mst_folder_grouping.py", "education/book-13-semantic-search/08_advanced_federation.md"], "original_answer": "Yes, use `--tree-source curated` to use your curated hierarchy, or `--tree-source hybrid` to combine curated folders with automatic attachment of orphaned items:\n\n```bash\n# Curated only\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --tree-source curated \\\n  -o output/folders.json\n\n# Hybrid (curated + orphan attachment)\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --tree-source hybrid \\\n  --embed-blend 0.3 \\\n  -o output/folders.json\n```\n\nSee `skill_mst_folder_grouping.md` for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_004_q0", "cluster_id": "skill_mst_folder_grouping_004", "question": "How do I generate mindmaps from the folder structure?", "answer": "After generating the folder structure with MST partitioning, use the mindmap generation script:\n\n```bash\npython3 scripts/mindmap/generate_mst_mindmaps.py \\\n  --mst-structure output/mst_folder_structure.json \\\n  --output output/mst_mindmaps/ \\\n  --root-name \"My_Collection\"\n```\n\nThis converts the MST folder structure JSON into actual mindmap files. The `--root-name` parameter sets the collection name, and files are written to the output directory.", "question_type": "long", "topics": ["Mindmap", "MST Folder Grouping", "Generation"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "mst", "generation", "output"], "related_skills": ["skill_mst_folder_grouping.md", "skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/generate_mst_mindmaps.py", "scripts/mindmap/mst_folder_grouping.py"], "original_answer": "After generating the folder structure, use the mindmap generation script:\n\n```bash\npython3 scripts/mindmap/generate_mst_mindmaps.py \\\n  --mst-structure output/mst_folder_structure.json \\\n  --output output/mst_mindmaps/ \\\n  --root-name \"My_Collection\"\n```\n\nThis creates actual mindmap files from the MST folder structure. See `skill_mst_folder_grouping.md` for more details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_004_q1", "cluster_id": "skill_mst_folder_grouping_004", "question": "Can I create mindmap files from the clustering results?", "answer": "Yes. After generating the folder structure with MST clustering, use the mindmap generation script to create actual mindmap files:\n\n```bash\npython3 scripts/mindmap/generate_mst_mindmaps.py \\\n  --mst-structure output/mst_folder_structure.json \\\n  --output output/mst_mindmaps/ \\\n  --root-name \"My_Collection\"\n```\n\nThis converts your clustering results into organized mindmap files that visualize the semantic hierarchy.", "question_type": "long", "topics": ["Mindmap", "MST Folder Grouping", "Generation"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "mst", "generation", "output"], "related_skills": ["skill_mst_folder_grouping.md", "skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/generate_mst_mindmaps.py", "scripts/mindmap/mst_folder_grouping.py"], "original_answer": "After generating the folder structure, use the mindmap generation script:\n\n```bash\npython3 scripts/mindmap/generate_mst_mindmaps.py \\\n  --mst-structure output/mst_folder_structure.json \\\n  --output output/mst_mindmaps/ \\\n  --root-name \"My_Collection\"\n```\n\nThis creates actual mindmap files from the MST folder structure. See `skill_mst_folder_grouping.md` for more details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_004_q2", "cluster_id": "skill_mst_folder_grouping_004", "question": "How do I turn folder structure into actual mindmaps?", "answer": "After generating the folder structure with MST partitioning, use the mindmap generation script to convert it into actual mindmap files:\n\n```bash\npython3 scripts/mindmap/generate_mst_mindmaps.py \\\n  --mst-structure output/mst_folder_structure.json \\\n  --output output/mst_mindmaps/ \\\n  --root-name \"My_Collection\"\n```\n\nThis script takes your folder structure JSON and generates the corresponding mindmap files. The `--root-name` parameter sets the top-level folder name for your collection.", "question_type": "long", "topics": ["Mindmap", "MST Folder Grouping", "Generation"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "mst", "generation", "output"], "related_skills": ["skill_mst_folder_grouping.md", "skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/generate_mst_mindmaps.py", "scripts/mindmap/mst_folder_grouping.py"], "original_answer": "After generating the folder structure, use the mindmap generation script:\n\n```bash\npython3 scripts/mindmap/generate_mst_mindmaps.py \\\n  --mst-structure output/mst_folder_structure.json \\\n  --output output/mst_mindmaps/ \\\n  --root-name \"My_Collection\"\n```\n\nThis creates actual mindmap files from the MST folder structure. See `skill_mst_folder_grouping.md` for more details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_004_q3", "cluster_id": "skill_mst_folder_grouping_004", "question": "What do I do after running MST folder grouping?", "answer": "After running MST folder grouping to generate your folder structure, use the mindmap generation script to create actual mindmap files:\n\n```bash\npython3 scripts/mindmap/generate_mst_mindmaps.py \\\n  --mst-structure output/mst_folder_structure.json \\\n  --output output/mst_mindmaps/ \\\n  --root-name \"My_Collection\"\n```\n\nThis converts the MST folder hierarchy into visualizable mindmap files organized by semantic similarity.", "question_type": "long", "topics": ["Mindmap", "MST Folder Grouping", "Generation"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "mst", "generation", "output"], "related_skills": ["skill_mst_folder_grouping.md", "skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/generate_mst_mindmaps.py", "scripts/mindmap/mst_folder_grouping.py"], "original_answer": "After generating the folder structure, use the mindmap generation script:\n\n```bash\npython3 scripts/mindmap/generate_mst_mindmaps.py \\\n  --mst-structure output/mst_folder_structure.json \\\n  --output output/mst_mindmaps/ \\\n  --root-name \"My_Collection\"\n```\n\nThis creates actual mindmap files from the MST folder structure. See `skill_mst_folder_grouping.md` for more details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_001_q0", "cluster_id": "skill_folder_suggestion_001", "question": "Where should I save this mindmap?", "answer": "Use the folder suggestion tool to find the best folder for your mindmap based on semantic similarity. Run `python3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"` to get folder recommendations with probability scores. If you don't have the tree ID, use `--title \"MINDMAP_TITLE\"` instead. The tool will show you the best matching folders ranked by fit percentage.", "question_type": "medium", "topics": ["Mindmap", "Folder Suggestion"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "organization", "inference"], "related_skills": ["skill_folder_suggestion.md", "skill_semantic_inference.md"], "related_docs": ["scripts/mindmap/suggest_folder.py", "scripts/mindmap/README.md"], "original_answer": "Use the folder suggestion tool to find the best fit based on semantic similarity. Run `python3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"` or use `--title` if you don't have the ID yet.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_001_q1", "cluster_id": "skill_folder_suggestion_001", "question": "Suggest a folder for my mindmap.", "answer": "Use the folder suggestion tool to find the best fit for your mindmap based on semantic similarity. Run `python3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"` to get folder suggestions with probability scores, or use `--title \"MINDMAP_TITLE\"` if you don't have the tree ID. The tool will show you the current folder and ranked alternatives with match percentages to help you decide.", "question_type": "medium", "topics": ["Mindmap", "Folder Suggestion"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "organization", "inference"], "related_skills": ["skill_folder_suggestion.md", "skill_semantic_inference.md"], "related_docs": ["scripts/mindmap/suggest_folder.py", "scripts/mindmap/README.md"], "original_answer": "Use the folder suggestion tool to find the best fit based on semantic similarity. Run `python3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"` or use `--title` if you don't have the ID yet.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_001_q2", "cluster_id": "skill_folder_suggestion_001", "question": "Which folder is the best fit for this tree?", "answer": "Use the folder suggestion tool to determine the best fit for your tree based on semantic similarity. Run `python3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"` with your tree's ID, or use `--title \"MINDMAP_TITLE\"` if you only have the title. The tool will analyze your mindmap and rank suggested folders with confidence scores, with >50% indicating a strong match.", "question_type": "medium", "topics": ["Mindmap", "Folder Suggestion"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "organization", "inference"], "related_skills": ["skill_folder_suggestion.md", "skill_semantic_inference.md"], "related_docs": ["scripts/mindmap/suggest_folder.py", "scripts/mindmap/README.md"], "original_answer": "Use the folder suggestion tool to find the best fit based on semantic similarity. Run `python3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"` or use `--title` if you don't have the ID yet.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_001_q3", "cluster_id": "skill_folder_suggestion_001", "question": "Find the right category for this mindmap.", "answer": "Use the folder suggestion tool to find the best category for your mindmap. Run `python3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"` to get category suggestions ranked by semantic similarity. If you don't have the tree ID, use `--title \"MINDMAP_TITLE\"` instead. The tool will show you the top matching categories with confidence percentages to help you pick the right one.", "question_type": "medium", "topics": ["Mindmap", "Folder Suggestion"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "organization", "inference"], "related_skills": ["skill_folder_suggestion.md", "skill_semantic_inference.md"], "related_docs": ["scripts/mindmap/suggest_folder.py", "scripts/mindmap/README.md"], "original_answer": "Use the folder suggestion tool to find the best fit based on semantic similarity. Run `python3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"` or use `--title` if you don't have the ID yet.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_002_q0", "cluster_id": "skill_folder_suggestion_002", "question": "How do I check for misplaced mindmaps in a folder?", "answer": "To check for misplaced mindmaps in a folder, run: `python3 scripts/mindmap/suggest_folder.py --check-folder \"FOLDER_PATH\" --threshold 0.5`. This scans the directory and compares each mindmap's content against the folder's semantic projection, flagging items that fall below your confidence threshold. Use a lower threshold (e.g., 0.3) for stricter checking or higher (e.g., 0.7) for lenient checking.", "question_type": "long", "topics": ["Mindmap", "Folder Suggestion"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "maintenance", "qa"], "related_skills": ["skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/suggest_folder.py", "docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "You can scan a directory for misplaced items using the check command: `python3 scripts/mindmap/suggest_folder.py --check-folder \"FOLDER_PATH\" --threshold 0.5`. This compares the content against the folder's semantic projection.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_002_q1", "cluster_id": "skill_folder_suggestion_002", "question": "Scan a folder for mindmaps that don't belong.", "answer": "You can scan a folder for misplaced mindmaps using: `python3 scripts/mindmap/suggest_folder.py --check-folder \"FOLDER_PATH\" --threshold 0.5`. This command compares each mindmap in the folder against the folder's semantic projection and flags items with low confidence scores, helping you identify mindmaps that don't semantically belong in that location.", "question_type": "long", "topics": ["Mindmap", "Folder Suggestion"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "maintenance", "qa"], "related_skills": ["skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/suggest_folder.py", "docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "You can scan a directory for misplaced items using the check command: `python3 scripts/mindmap/suggest_folder.py --check-folder \"FOLDER_PATH\" --threshold 0.5`. This compares the content against the folder's semantic projection.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_002_q2", "cluster_id": "skill_folder_suggestion_002", "question": "Can I validate the organization of my mindmap directory?", "answer": "Yes, you can validate your mindmap directory organization using the folder suggestion tool. Run `python3 scripts/mindmap/suggest_folder.py --check-folder \"FOLDER_PATH\" --threshold 0.5` to scan the directory and identify misplaced mindmaps. This command compares each mindmap's semantic content against the folder's semantic projection and flags items that don't fit well. You can adjust the threshold value (0.5 is a good starting point) to control sensitivity\u2014higher values flag more misplacements, lower values are more lenient.", "question_type": "long", "topics": ["Mindmap", "Folder Suggestion"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "maintenance", "qa"], "related_skills": ["skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/suggest_folder.py", "docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "You can scan a directory for misplaced items using the check command: `python3 scripts/mindmap/suggest_folder.py --check-folder \"FOLDER_PATH\" --threshold 0.5`. This compares the content against the folder's semantic projection.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_002_q3", "cluster_id": "skill_folder_suggestion_002", "question": "Find incorrectly filed trees.", "answer": "To find incorrectly filed trees, use the check command: `python3 scripts/mindmap/suggest_folder.py --check-folder \"FOLDER_PATH\" --threshold 0.5`. This scans all mindmaps in a folder and compares their semantic content against the folder's projection to identify misplaced items. Lower confidence matches below your threshold indicate trees that may belong in different folders.", "question_type": "long", "topics": ["Mindmap", "Folder Suggestion"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "maintenance", "qa"], "related_skills": ["skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/suggest_folder.py", "docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "You can scan a directory for misplaced items using the check command: `python3 scripts/mindmap/suggest_folder.py --check-folder \"FOLDER_PATH\" --threshold 0.5`. This compares the content against the folder's semantic projection.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_003_q0", "cluster_id": "skill_folder_suggestion_003", "question": "What is required to generate mindmap folder suggestions?", "answer": "To generate mindmap folder suggestions, you must first build folder projections by running `python3 scripts/mindmap/build_folder_projections.py` with three required arguments: `--embeddings` (embeddings file), `--index` (index file), and `--output` (output projections database). Once the W matrices are built, you can then use `python3 scripts/mindmap/suggest_folder.py` with options like `--tree-id`, `--title`, or `--check-folder` to generate suggestions.", "question_type": "long", "topics": ["Mindmap", "Folder Suggestion"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "setup", "training"], "related_skills": ["skill_folder_suggestion.md", "skill_train_model.md"], "related_docs": ["scripts/mindmap/build_folder_projections.py"], "original_answer": "You must first build folder projections (W matrices). Run `python3 scripts/mindmap/build_folder_projections.py` providing the embeddings, index, and output database path before requesting suggestions.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_003_q1", "cluster_id": "skill_folder_suggestion_003", "question": "Why isn't folder suggestion working?", "answer": "Folder suggestion requires built folder projections (W matrices) as a prerequisite. Run `python3 scripts/mindmap/build_folder_projections.py` with your embeddings file, index file, and desired output database path. Once projections are built, folder suggestion will work via `python3 scripts/mindmap/suggest_folder.py`. If you've already built projections but suggestion still isn't working, verify the projection database path is correctly specified and the embeddings/index files are accessible.", "question_type": "long", "topics": ["Mindmap", "Folder Suggestion"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "setup", "training"], "related_skills": ["skill_folder_suggestion.md", "skill_train_model.md"], "related_docs": ["scripts/mindmap/build_folder_projections.py"], "original_answer": "You must first build folder projections (W matrices). Run `python3 scripts/mindmap/build_folder_projections.py` providing the embeddings, index, and output database path before requesting suggestions.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "Answer assumes projections haven't been built. If user reports the tool still fails after building projections, additional troubleshooting (file paths, data format, permissions) would be needed."}
{"pair_id": "skill_folder_suggestion_003_q2", "cluster_id": "skill_folder_suggestion_003", "question": "Do I need to train a model for folder suggestions?", "answer": "No, you don't need to train a model. You only need to build folder projections first by running `python3 scripts/mindmap/build_folder_projections.py` with your embeddings file, index file, and output database path. This creates the W matrices that enable folder suggestions without additional model training.", "question_type": "long", "topics": ["Mindmap", "Folder Suggestion"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "setup", "training"], "related_skills": ["skill_folder_suggestion.md", "skill_train_model.md"], "related_docs": ["scripts/mindmap/build_folder_projections.py"], "original_answer": "You must first build folder projections (W matrices). Run `python3 scripts/mindmap/build_folder_projections.py` providing the embeddings, index, and output database path before requesting suggestions.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_003_q3", "cluster_id": "skill_folder_suggestion_003", "question": "Prerequisites for suggest_folder.py", "answer": "Before using suggest_folder.py, you must build folder projections by running: `python3 scripts/mindmap/build_folder_projections.py --embeddings \"EMBEDDINGS_FILE\" --index \"INDEX_FILE\" --output \"PROJECTIONS_DB\"`. This generates the W matrices (Procrustes projection matrices) needed for semantic similarity matching across folders. Once projections are built, you can then use suggest_folder.py to get folder suggestions by tree ID or title.", "question_type": "long", "topics": ["Mindmap", "Folder Suggestion"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "setup", "training"], "related_skills": ["skill_folder_suggestion.md", "skill_train_model.md"], "related_docs": ["scripts/mindmap/build_folder_projections.py"], "original_answer": "You must first build folder projections (W matrices). Run `python3 scripts/mindmap/build_folder_projections.py` providing the embeddings, index, and output database path before requesting suggestions.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_004_q0", "cluster_id": "skill_folder_suggestion_004", "question": "How do I interpret the probability score in folder suggestions?", "answer": "Probability scores in folder suggestions are interpreted as follows: scores above 50% indicate a strong match and the current folder is likely correct; scores between 25-50% represent a good match with minor ambiguity about placement; scores below 25% suggest the placement is ambiguous with multiple valid folder options. These thresholds help you assess confidence in the suggested folder organization.", "question_type": "long", "topics": ["Mindmap", "Folder Suggestion"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "metrics", "scoring"], "related_skills": ["skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/suggest_folder.py"], "original_answer": "Scores over 50% indicate a strong match where the current folder is likely correct. Scores between 25-50% are good matches with minor ambiguity, while scores under 25% suggest the placement is ambiguous with multiple valid options.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_004_q1", "cluster_id": "skill_folder_suggestion_004", "question": "Is a 30% match good for a folder suggestion?", "answer": "A 30% match is considered a good match with minor ambiguity. According to the folder suggestion guidance, scores between 25-50% indicate the mindmap fits well in its current folder but there may be some uncertainty. This suggests the placement is reasonable, though other folders could also be valid options.", "question_type": "long", "topics": ["Mindmap", "Folder Suggestion"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "metrics", "scoring"], "related_skills": ["skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/suggest_folder.py"], "original_answer": "Scores over 50% indicate a strong match where the current folder is likely correct. Scores between 25-50% are good matches with minor ambiguity, while scores under 25% suggest the placement is ambiguous with multiple valid options.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_004_q2", "cluster_id": "skill_folder_suggestion_004", "question": "How confident is the folder recommendation?", "answer": "Folder recommendation confidence is determined by the probability score: scores over 50% indicate a strong match with high confidence that the current folder is correct, scores between 25-50% represent good matches with minor ambiguity and moderate confidence, and scores under 25% suggest the placement is ambiguous with low confidence and multiple valid folder options.", "question_type": "long", "topics": ["Mindmap", "Folder Suggestion"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "metrics", "scoring"], "related_skills": ["skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/suggest_folder.py"], "original_answer": "Scores over 50% indicate a strong match where the current folder is likely correct. Scores between 25-50% are good matches with minor ambiguity, while scores under 25% suggest the placement is ambiguous with multiple valid options.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_004_q3", "cluster_id": "skill_folder_suggestion_004", "question": "Understanding suggest_folder output", "answer": "Scores over 50% indicate a strong match where the current folder is likely correct. Scores between 25-50% are good matches with minor ambiguity, while scores under 25% suggest the placement is ambiguous with multiple valid options. When interpreting output from suggest_folder, use these thresholds to determine if a mindmap's folder assignment is appropriate or if it should be reconsidered.", "question_type": "long", "topics": ["Mindmap", "Folder Suggestion"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "metrics", "scoring"], "related_skills": ["skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/suggest_folder.py"], "original_answer": "Scores over 50% indicate a strong match where the current folder is likely correct. Scores between 25-50% are good matches with minor ambiguity, while scores under 25% suggest the placement is ambiguous with multiple valid options.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_001_q0", "cluster_id": "skill_mindmap_cross_links_001", "question": "How do I create clickable links between different mindmap files locally?", "answer": "To create clickable links between mindmap files locally, build an index of your mindmap directory using `python3 scripts/mindmap/build_index.py output/mindmaps/ -o output/mindmaps/index.json`, then run `python3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx --index output/mindmaps/index.json` to automatically insert `cloudmapref` links that enable local navigation between mindmaps without external URLs.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "linking", "cross-reference", "navigation"], "related_skills": ["skill_mindmap_cross_links.md", "skill_mindmap_linking.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/build_index.py", "scripts/mindmap/add_relative_links.py"], "original_answer": "To link mindmaps, first build an index of your files using `scripts/mindmap/build_index.py`. Then, run `scripts/mindmap/add_relative_links.py` pointing to that index to insert `cloudmapref` links automatically.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_001_q1", "cluster_id": "skill_mindmap_cross_links_001", "question": "How to cross-reference multiple mindmaps?", "answer": "To cross-reference multiple mindmaps, use a two-step process: First, build an index of all your mindmap files by running `python3 scripts/mindmap/build_index.py output/mindmaps/ -o output/mindmaps/index.json`. Then, add cross-links between them by running `python3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx --index output/mindmaps/index.json`. This automatically inserts `cloudmapref` links that enable local navigation between mindmaps without external URLs. You can preview changes first using the `--dry-run --verbose` flags.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "linking", "cross-reference", "navigation"], "related_skills": ["skill_mindmap_cross_links.md", "skill_mindmap_linking.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/build_index.py", "scripts/mindmap/add_relative_links.py"], "original_answer": "To link mindmaps, first build an index of your files using `scripts/mindmap/build_index.py`. Then, run `scripts/mindmap/add_relative_links.py` pointing to that index to insert `cloudmapref` links automatically.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_001_q2", "cluster_id": "skill_mindmap_cross_links_001", "question": "Can I link one mindmap to another without external URLs?", "answer": "Yes, you can link mindmaps to each other without external URLs using `cloudmapref` links. Build an index of your mindmap directory with `python3 scripts/mindmap/build_index.py output/mindmaps/ -o output/mindmaps/index.json`, then add cross-links by running `python3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx --index output/mindmaps/index.json`. This creates local navigation links between mindmaps without requiring external URLs.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "linking", "cross-reference", "navigation"], "related_skills": ["skill_mindmap_cross_links.md", "skill_mindmap_linking.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/build_index.py", "scripts/mindmap/add_relative_links.py"], "original_answer": "To link mindmaps, first build an index of your files using `scripts/mindmap/build_index.py`. Then, run `scripts/mindmap/add_relative_links.py` pointing to that index to insert `cloudmapref` links automatically.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_001_q3", "cluster_id": "skill_mindmap_cross_links_001", "question": "What is the process for connecting separate mindmap files?", "answer": "To connect separate mindmap files, first build an index of your mindmap directory using `python3 scripts/mindmap/build_index.py output/mindmaps/ -o output/mindmaps/index.json`. Then run `python3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx --index output/mindmaps/index.json` to automatically insert `cloudmapref` links between the files for local navigation.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "linking", "cross-reference", "navigation"], "related_skills": ["skill_mindmap_cross_links.md", "skill_mindmap_linking.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/build_index.py", "scripts/mindmap/add_relative_links.py"], "original_answer": "To link mindmaps, first build an index of your files using `scripts/mindmap/build_index.py`. Then, run `scripts/mindmap/add_relative_links.py` pointing to that index to insert `cloudmapref` links automatically.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_002_q0", "cluster_id": "skill_mindmap_cross_links_002", "question": "How can I rename a mindmap file without breaking the links pointing to it?", "answer": "Use `scripts/mindmap/rename_mindmap.py` to rename mindmap files while preserving links. For an explicit new name, run: `python3 scripts/mindmap/rename_mindmap.py --mindmap \"MINDMAP_PATH\" --new-name \"New_Name.smmx\"`. To auto-generate the name from the root topic, use `--titled` instead of `--new-name`. The script automatically updates all `cloudmapref` links in other mindmaps that point to the renamed file, preventing broken references.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "renaming", "maintenance", "refactoring"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py", "scripts/mindmap/README.md"], "original_answer": "Use the `scripts/mindmap/rename_mindmap.py` utility. Providing the `--mindmap` path and `--new-name` will rename the file and update any existing links in your project to point to the new location.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_002_q1", "cluster_id": "skill_mindmap_cross_links_002", "question": "Is there a safe way to rename mindmaps?", "answer": "Yes. Use `scripts/mindmap/rename_mindmap.py` to safely rename mindmaps. The utility automatically updates all `cloudmapref` links pointing to the renamed file throughout your project. For a single mindmap, run: `python3 scripts/mindmap/rename_mindmap.py --mindmap \"PATH\" --new-name \"New_Name.smmx\"`. For batch renaming with auto-generated names from root topics, use `--batch \"DIR\" --titled`. Always preview changes first with `--dry-run --verbose` before applying updates.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "renaming", "maintenance", "refactoring"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py", "scripts/mindmap/README.md"], "original_answer": "Use the `scripts/mindmap/rename_mindmap.py` utility. Providing the `--mindmap` path and `--new-name` will rename the file and update any existing links in your project to point to the new location.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_002_q2", "cluster_id": "skill_mindmap_cross_links_002", "question": "How do I update references when I change a mindmap's filename?", "answer": "Use `scripts/mindmap/rename_mindmap.py` to update references when changing a mindmap's filename. Provide the `--mindmap` path and `--new-name` parameter: `python3 scripts/mindmap/rename_mindmap.py --mindmap \"MINDMAP_PATH\" --new-name \"New_Name.smmx\"`. This renames the file and automatically updates all `cloudmapref` links pointing to it throughout your project. For batch renaming multiple mindmaps, use the `--batch` flag with `--titled` to auto-generate names from root topics.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "renaming", "maintenance", "refactoring"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py", "scripts/mindmap/README.md"], "original_answer": "Use the `scripts/mindmap/rename_mindmap.py` utility. Providing the `--mindmap` path and `--new-name` will rename the file and update any existing links in your project to point to the new location.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_002_q3", "cluster_id": "skill_mindmap_cross_links_002", "question": "Rename mindmap and preserve links", "answer": "Use `python3 scripts/mindmap/rename_mindmap.py` with the `--mindmap` parameter to specify the file and `--new-name` to set the new filename. This utility automatically updates all cross-links (cloudmapref references) throughout your project to point to the renamed mindmap. For auto-generating names from the mindmap's root topic, use the `--titled` flag instead of `--new-name`. To preview changes before applying them, add `--dry-run`.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "renaming", "maintenance", "refactoring"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py", "scripts/mindmap/README.md"], "original_answer": "Use the `scripts/mindmap/rename_mindmap.py` utility. Providing the `--mindmap` path and `--new-name` will rename the file and update any existing links in your project to point to the new location.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_003_q0", "cluster_id": "skill_mindmap_cross_links_003", "question": "How do I automatically rename all my mindmaps to match their main topic titles?", "answer": "You can automatically rename all mindmaps to match their root topic titles using `python3 scripts/mindmap/rename_mindmap.py --batch \"MINDMAP_DIR\" --titled`. This generates names from each mindmap's main topic. Use `--dry-run` first to preview the changes before applying them.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "batch-processing", "automation", "renaming"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py", "scripts/mindmap/README.md"], "original_answer": "You can perform a batch rename using `scripts/mindmap/rename_mindmap.py` with the `--batch [DIRECTORY]` and `--titled` flags. It is recommended to add `--dry-run` first to preview the changes.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_003_q1", "cluster_id": "skill_mindmap_cross_links_003", "question": "Batch rename mindmaps based on content", "answer": "To batch rename mindmaps based on their content, use `scripts/mindmap/rename_mindmap.py` with the `--batch [DIRECTORY]` and `--titled` flags. The `--titled` flag auto-generates names from each mindmap's root topic. Preview changes first with `--dry-run`: `python3 scripts/mindmap/rename_mindmap.py --batch \"MINDMAP_DIR\" --titled --dry-run`, then run without `--dry-run` to apply the changes.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "batch-processing", "automation", "renaming"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py", "scripts/mindmap/README.md"], "original_answer": "You can perform a batch rename using `scripts/mindmap/rename_mindmap.py` with the `--batch [DIRECTORY]` and `--titled` flags. It is recommended to add `--dry-run` first to preview the changes.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_003_q2", "cluster_id": "skill_mindmap_cross_links_003", "question": "Auto-title mindmap files from root node", "answer": "Use `python3 scripts/mindmap/rename_mindmap.py --batch \"MINDMAP_DIR\" --titled` to automatically rename all mindmap files based on their root node titles. Add `--dry-run` first to preview the changes before applying them.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "batch-processing", "automation", "renaming"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py", "scripts/mindmap/README.md"], "original_answer": "You can perform a batch rename using `scripts/mindmap/rename_mindmap.py` with the `--batch [DIRECTORY]` and `--titled` flags. It is recommended to add `--dry-run` first to preview the changes.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_003_q3", "cluster_id": "skill_mindmap_cross_links_003", "question": "Bulk rename mindmaps tool", "answer": "Use `python3 scripts/mindmap/rename_mindmap.py --batch \"MINDMAP_DIR\" --titled` to bulk rename all mindmaps in a directory based on their root topic. Add `--dry-run` first to preview changes without applying them. For other output formats or additional options, use `--help`.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "batch-processing", "automation", "renaming"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py", "scripts/mindmap/README.md"], "original_answer": "You can perform a batch rename using `scripts/mindmap/rename_mindmap.py` with the `--batch [DIRECTORY]` and `--titled` flags. It is recommended to add `--dry-run` first to preview the changes.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_004_q0", "cluster_id": "skill_mindmap_cross_links_004", "question": "How do I see which mindmaps link to a specific file?", "answer": "Run `python3 scripts/mindmap/build_reverse_index.py \"MINDMAP_DIR\" -o \"REVERSE_INDEX_FILE\"` on your mindmap directory to generate a reverse index file. This index shows which mindmaps link to each specific file by mapping incoming connections (backlinks) for each map. You can then query this file to see all mindmaps that reference a particular file.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "backlinks", "analysis", "indexing"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/build_reverse_index.py", "scripts/mindmap/index_store.py"], "original_answer": "Run `scripts/mindmap/build_reverse_index.py` on your mindmap directory to generate a reverse index file (backlinks) showing incoming connections for each map.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_004_q1", "cluster_id": "skill_mindmap_cross_links_004", "question": "Generate a list of backlinks for mindmaps", "answer": "Run `python3 scripts/mindmap/build_reverse_index.py \"MINDMAP_DIR\" -o \"REVERSE_INDEX_FILE\"` to generate a reverse index file that lists all backlinks (incoming connections) for each mindmap. This creates a backlinks index showing which mindmaps link to each other.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "backlinks", "analysis", "indexing"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/build_reverse_index.py", "scripts/mindmap/index_store.py"], "original_answer": "Run `scripts/mindmap/build_reverse_index.py` on your mindmap directory to generate a reverse index file (backlinks) showing incoming connections for each map.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_004_q2", "cluster_id": "skill_mindmap_cross_links_004", "question": "How to build a reverse index for mindmap connections?", "answer": "Run `python3 scripts/mindmap/build_reverse_index.py \"MINDMAP_DIR\" -o \"REVERSE_INDEX_FILE\"` on your mindmap directory to generate a reverse index file showing all incoming backlinks to each mindmap. This creates a map of which mindmaps reference each target, useful for understanding connection dependencies.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "backlinks", "analysis", "indexing"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/build_reverse_index.py", "scripts/mindmap/index_store.py"], "original_answer": "Run `scripts/mindmap/build_reverse_index.py` on your mindmap directory to generate a reverse index file (backlinks) showing incoming connections for each map.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_004_q3", "cluster_id": "skill_mindmap_cross_links_004", "question": "Find all references to a mindmap", "answer": "Run `python3 scripts/mindmap/build_reverse_index.py \"MINDMAP_DIR\" -o \"REVERSE_INDEX_FILE\"` on your mindmap directory to generate a reverse index file showing all incoming `cloudmapref` links (backlinks) for each mindmap. This reverse index identifies which other mindmaps reference a specific mindmap.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "backlinks", "analysis", "indexing"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/build_reverse_index.py", "scripts/mindmap/index_store.py"], "original_answer": "Run `scripts/mindmap/build_reverse_index.py` on your mindmap directory to generate a reverse index file (backlinks) showing incoming connections for each map.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_001_q0", "cluster_id": "skill_mindmap_linking_001", "question": "How do I link a SimpleMind mindmap to Pearltrees?", "answer": "To link a SimpleMind mindmap to Pearltrees, use the mindmap linking skill with the command: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --output \"OUTPUT_PATH\"`. This performs hierarchical semantic matching to enrich your mindmap with Pearltrees links. For better results, add the projection model flag: `--projection-model models/pearltrees_federated_nomic.pkl`. You can also include URL matching with `--url-db` or preview changes with `--dry-run` before applying them.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "pearltrees", "linking", "automation"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/link_pearltrees.py", "scripts/mindmap/README.md"], "original_answer": "Use `skill_mindmap_linking` to enrich SimpleMind mindmaps with Pearltrees links using hierarchical semantic matching. The basic command is `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --output \"OUTPUT_PATH\"`.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_001_q1", "cluster_id": "skill_mindmap_linking_001", "question": "Connect mindmap to Pearltrees", "answer": "To connect a mindmap to Pearltrees, use the mindmap linking skill with `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --output \"OUTPUT_PATH\"`. This performs title-based matching to enrich SimpleMind mindmaps with Pearltrees links. For better semantic matching, add `--embeddings datasets/pearltrees_combined_embeddings.npz --projection-model models/pearltrees_federated_nomic.pkl`. Use `--dry-run --verbose` to preview changes before applying them.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "pearltrees", "linking", "automation"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/link_pearltrees.py", "scripts/mindmap/README.md"], "original_answer": "Use `skill_mindmap_linking` to enrich SimpleMind mindmaps with Pearltrees links using hierarchical semantic matching. The basic command is `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --output \"OUTPUT_PATH\"`.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_001_q2", "cluster_id": "skill_mindmap_linking_001", "question": "Enrich mindmap with Pearltrees links", "answer": "To enrich a mindmap with Pearltrees links, use the mindmap linking skill with `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --output \"OUTPUT_PATH\"`. This performs hierarchical semantic matching to connect mindmap nodes to Pearltrees. For better results, add embeddings and projection model flags: `--embeddings datasets/pearltrees_combined_embeddings.npz --projection-model models/pearltrees_federated_nomic.pkl`. Output nodes are labeled PT (exact match), PT? (fuzzy match), or PP (URL match).", "question_type": "medium", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "pearltrees", "linking", "automation"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/link_pearltrees.py", "scripts/mindmap/README.md"], "original_answer": "Use `skill_mindmap_linking` to enrich SimpleMind mindmaps with Pearltrees links using hierarchical semantic matching. The basic command is `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --output \"OUTPUT_PATH\"`.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_001_q3", "cluster_id": "skill_mindmap_linking_001", "question": "Match mindmap nodes to Pearltrees", "answer": "Use the `skill_mindmap_linking` skill to match mindmap nodes to Pearltrees. Run `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --output \"OUTPUT_PATH\"` for basic title matching. For semantic matching, add `--embeddings datasets/pearltrees_combined_embeddings.npz --projection-model models/pearltrees_federated_nomic.pkl`. Matched nodes receive labels: PP (PearlPage URL match), PT (exact title match), or PT? (fuzzy semantic match).", "question_type": "medium", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "pearltrees", "linking", "automation"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/link_pearltrees.py", "scripts/mindmap/README.md"], "original_answer": "Use `skill_mindmap_linking` to enrich SimpleMind mindmaps with Pearltrees links using hierarchical semantic matching. The basic command is `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --output \"OUTPUT_PATH\"`.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_002_q0", "cluster_id": "skill_mindmap_linking_002", "question": "How can I improve the accuracy of mindmap linking using semantic search?", "answer": "To improve mindmap linking accuracy with semantic search, use hierarchical projection by including embeddings and a projection model. Run: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --embeddings datasets/pearltrees_combined_embeddings.npz --projection-model models/pearltrees_federated_nomic.pkl --output \"OUTPUT_PATH\"`. This enables semantic similarity matching beyond basic title matching. For additional accuracy, include `--pearls reports/pearltrees_targets_full_pearls.jsonl` for extended title matching, `--url-db data/databases/children_index.db` for URL-based matching, and adjust `--threshold` (default 0.7) to balance precision and recall.", "question_type": "long", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "semantic-search", "ai", "accuracy"], "related_skills": ["skill_mindmap_linking.md", "skill_train_model.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "models/pearltrees_federated_nomic.pkl"], "original_answer": "For better accuracy, use hierarchical projection by including the embeddings and projection model. Run: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --embeddings datasets/pearltrees_combined_embeddings.npz --projection-model models/pearltrees_federated_nomic.pkl --output \"OUTPUT_PATH\"`.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_002_q1", "cluster_id": "skill_mindmap_linking_002", "question": "Use AI models for mindmap linking", "answer": "To use AI models for mindmap linking, include the embeddings and projection model flags for hierarchical semantic matching. Run: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --embeddings datasets/pearltrees_combined_embeddings.npz --projection-model models/pearltrees_federated_nomic.pkl --output \"OUTPUT_PATH\"`. The system automatically selects the appropriate embedder (Nomic 768D or MiniLM 384D) based on the model's embedding dimensions. This enables semantic similarity matching above a configurable threshold, producing PT? labels for fuzzy matches in addition to exact PP and PT matches.", "question_type": "long", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "semantic-search", "ai", "accuracy"], "related_skills": ["skill_mindmap_linking.md", "skill_train_model.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "models/pearltrees_federated_nomic.pkl"], "original_answer": "For better accuracy, use hierarchical projection by including the embeddings and projection model. Run: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --embeddings datasets/pearltrees_combined_embeddings.npz --projection-model models/pearltrees_federated_nomic.pkl --output \"OUTPUT_PATH\"`.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_002_q2", "cluster_id": "skill_mindmap_linking_002", "question": "Enable fuzzy matching for mindmaps", "answer": "Fuzzy matching for mindmaps is enabled by using hierarchical semantic projection. Include the `--embeddings` and `--projection-model` flags to enable fuzzy matching: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --embeddings datasets/pearltrees_combined_embeddings.npz --projection-model models/pearltrees_federated_nomic.pkl --output \"OUTPUT_PATH\"`. This produces nodes labeled **PT?** for fuzzy matches above the confidence threshold.", "question_type": "long", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "semantic-search", "ai", "accuracy"], "related_skills": ["skill_mindmap_linking.md", "skill_train_model.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "models/pearltrees_federated_nomic.pkl"], "original_answer": "For better accuracy, use hierarchical projection by including the embeddings and projection model. Run: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --embeddings datasets/pearltrees_combined_embeddings.npz --projection-model models/pearltrees_federated_nomic.pkl --output \"OUTPUT_PATH\"`.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_002_q3", "cluster_id": "skill_mindmap_linking_002", "question": "How to use hierarchical projection for mindmaps", "answer": "To use hierarchical projection for mindmaps, include the embeddings and projection model flags when linking. Run: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --embeddings datasets/pearltrees_combined_embeddings.npz --projection-model models/pearltrees_federated_nomic.pkl --output \"OUTPUT_PATH\"`. This enables semantic similarity matching across the hierarchy for more accurate Pearltrees linking.", "question_type": "long", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "semantic-search", "ai", "accuracy"], "related_skills": ["skill_mindmap_linking.md", "skill_train_model.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "models/pearltrees_federated_nomic.pkl"], "original_answer": "For better accuracy, use hierarchical projection by including the embeddings and projection model. Run: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --embeddings datasets/pearltrees_combined_embeddings.npz --projection-model models/pearltrees_federated_nomic.pkl --output \"OUTPUT_PATH\"`.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_003_q0", "cluster_id": "skill_mindmap_linking_003", "question": "Can I match mindmap nodes based on URLs instead of just titles?", "answer": "Yes, you can match mindmap nodes based on URLs by providing a URL database. Add the `--url-db data/databases/children_index.db` flag to your `link_pearltrees.py` command. This enables URL matching to identify PearlPages (labeled 'PP') when a node's URL matches a PagePearl's external URL. Example: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --url-db data/databases/children_index.db --output \"OUTPUT_PATH\"`", "question_type": "long", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "url-matching", "database", "configuration"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["scripts/mindmap/link_pearltrees.py", "scripts/mindmap/README.md"], "original_answer": "Yes, you can enable URL matching to identify PearlPages ('PP' label) by providing a URL database. Add the `--url-db data/databases/children_index.db` flag to your `link_pearltrees.py` command.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_003_q1", "cluster_id": "skill_mindmap_linking_003", "question": "Link mindmap nodes by URL", "answer": "Yes, you can link mindmap nodes by URL to identify PearlPages (marked with 'PP' label). Add the `--url-db data/databases/children_index.db` flag to your `link_pearltrees.py` command. This enables URL matching so that nodes whose URLs match PagePearl external URLs are automatically linked. Example: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --url-db data/databases/children_index.db --output \"OUTPUT_PATH\"`", "question_type": "long", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "url-matching", "database", "configuration"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["scripts/mindmap/link_pearltrees.py", "scripts/mindmap/README.md"], "original_answer": "Yes, you can enable URL matching to identify PearlPages ('PP' label) by providing a URL database. Add the `--url-db data/databases/children_index.db` flag to your `link_pearltrees.py` command.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_003_q2", "cluster_id": "skill_mindmap_linking_003", "question": "How to find PearlPages in mindmaps", "answer": "To find PearlPages in mindmaps, use the `link_pearltrees.py` script with URL matching enabled. Add the `--url-db data/databases/children_index.db` flag to match node URLs against PagePearl external URLs. Nodes that match will be labeled with 'PP' (PearlPage). Example: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --url-db data/databases/children_index.db --output \"OUTPUT_PATH\"`", "question_type": "long", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "url-matching", "database", "configuration"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["scripts/mindmap/link_pearltrees.py", "scripts/mindmap/README.md"], "original_answer": "Yes, you can enable URL matching to identify PearlPages ('PP' label) by providing a URL database. Add the `--url-db data/databases/children_index.db` flag to your `link_pearltrees.py` command.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_003_q3", "cluster_id": "skill_mindmap_linking_003", "question": "Enable URL database for mindmap linking", "answer": "To enable URL database for mindmap linking, add the `--url-db data/databases/children_index.db` flag to the `link_pearltrees.py` command. This enables URL matching to identify PearlPages (marked with 'PP' label) by matching node URLs against the database of external URLs from PagePearls.", "question_type": "long", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "url-matching", "database", "configuration"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["scripts/mindmap/link_pearltrees.py", "scripts/mindmap/README.md"], "original_answer": "Yes, you can enable URL matching to identify PearlPages ('PP' label) by providing a URL database. Add the `--url-db data/databases/children_index.db` flag to your `link_pearltrees.py` command.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_004_q0", "cluster_id": "skill_mindmap_linking_004", "question": "How do I preview mindmap linking changes without saving them?", "answer": "Use the `--dry-run` and `--verbose` flags together to preview mindmap linking changes without saving them. Run: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --dry-run --verbose`. The `--dry-run` flag prevents writing to the output file while `--verbose` displays the matching results that would be applied.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "testing", "dry-run", "preview"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/link_pearltrees.py"], "original_answer": "Use the `--dry-run` and `--verbose` flags to preview changes without writing to the output file. Example: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --dry-run --verbose`.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_004_q1", "cluster_id": "skill_mindmap_linking_004", "question": "Dry run for mindmap linking", "answer": "To preview mindmap linking changes without writing output, use the `--dry-run` and `--verbose` flags: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --dry-run --verbose`. This shows which Pearltrees nodes would be linked (with PP, PT, or PT? labels) without modifying any files.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "testing", "dry-run", "preview"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/link_pearltrees.py"], "original_answer": "Use the `--dry-run` and `--verbose` flags to preview changes without writing to the output file. Example: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --dry-run --verbose`.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_004_q2", "cluster_id": "skill_mindmap_linking_004", "question": "Test mindmap connection settings", "answer": "To test mindmap connection settings, use the `--dry-run` and `--verbose` flags to preview changes without writing to the output file. This allows you to verify your configuration before committing changes. Example: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --dry-run --verbose`. You can also add other flags like `--embeddings`, `--projection-model`, or `--url-db` to test the full configuration.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "testing", "dry-run", "preview"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/link_pearltrees.py"], "original_answer": "Use the `--dry-run` and `--verbose` flags to preview changes without writing to the output file. Example: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --dry-run --verbose`.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_004_q3", "cluster_id": "skill_mindmap_linking_004", "question": "Check what nodes will be linked in mindmap", "answer": "Use the `--dry-run` and `--verbose` flags to preview which nodes will be linked without modifying the output file. Run: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --dry-run --verbose`. This will show you all matching nodes with their labels (PP for PearlPage, PT for exact Pearltree matches, PT? for fuzzy matches) before committing changes.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "testing", "dry-run", "preview"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/link_pearltrees.py"], "original_answer": "Use the `--dry-run` and `--verbose` flags to preview changes without writing to the output file. Example: `python3 scripts/mindmap/link_pearltrees.py --mindmap \"MINDMAP_PATH\" --trees reports/pearltrees_targets_s243a.jsonl --dry-run --verbose`.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_001_q0", "cluster_id": "skill_mst_folder_grouping_001", "question": "How do I organize my mindmaps into a folder hierarchy based on their meaning?", "answer": "You can organize mindmaps by semantic meaning using the MST Folder Grouping tool. Run `python3 scripts/mindmap/mst_folder_grouping.py --trees-only --target-size 10 --max-depth 5 -o output/mst_folder_structure.json` to generate a semantic folder hierarchy. The tool uses Minimum Spanning Tree partitioning to group similar mindmaps together. Adjust `--target-size` to control how many items per folder (default 8) and `--max-depth` to limit folder nesting depth (default 4). After generating the structure, use `python3 scripts/mindmap/generate_mst_mindmaps.py --mst-structure output/mst_folder_structure.json --output output/mst_mindmaps/` to create the actual mindmap files organized in folders.", "question_type": "medium", "topics": ["Mindmap", "MST Folder Grouping"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "organization", "clustering", "semantic"], "related_skills": ["skill_mst_folder_grouping.md", "skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/mst_folder_grouping.py", "scripts/mindmap/README.md", "education/book-13-semantic-search/07_density_scoring.md"], "original_answer": "You can organize mindmaps using the MST Folder Grouping tool. Run `python3 scripts/mindmap/mst_folder_grouping.py --trees-only --target-size 10 -o output.json` to generate a semantic hierarchy. Adjust `--target-size` to control how many items go into each folder.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_001_q1", "cluster_id": "skill_mst_folder_grouping_001", "question": "Can UnifyWeaver group my mindmaps by semantic similarity?", "answer": "Yes, UnifyWeaver can group your mindmaps by semantic similarity using the MST Folder Grouping tool. This organizes mindmaps into semantically coherent folder hierarchies. Run `python3 scripts/mindmap/mst_folder_grouping.py --trees-only --target-size 10 -o output.json` to generate the folder structure. Use `--target-size` to control how many items per folder (default 8), and `--max-depth` to limit folder depth (default 4). After generating the structure, use `python3 scripts/mindmap/generate_mst_mindmaps.py` to create the actual mindmaps from the hierarchy.", "question_type": "medium", "topics": ["Mindmap", "MST Folder Grouping"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "organization", "clustering", "semantic"], "related_skills": ["skill_mst_folder_grouping.md", "skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/mst_folder_grouping.py", "scripts/mindmap/README.md", "education/book-13-semantic-search/07_density_scoring.md"], "original_answer": "You can organize mindmaps using the MST Folder Grouping tool. Run `python3 scripts/mindmap/mst_folder_grouping.py --trees-only --target-size 10 -o output.json` to generate a semantic hierarchy. Adjust `--target-size` to control how many items go into each folder.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_001_q2", "cluster_id": "skill_mst_folder_grouping_001", "question": "I want to arrange my mindmap collection into folders automatically.", "answer": "You can organize mindmaps into semantic folders automatically using the MST Folder Grouping tool. Run `python3 scripts/mindmap/mst_folder_grouping.py --trees-only --target-size 10 --max-depth 5 -o output/mst_folder_structure.json` to generate a hierarchical folder structure. The `--target-size` parameter controls how many items per folder (default 8), and `--max-depth` limits folder nesting depth (default 4). After generating the structure, use `python3 scripts/mindmap/generate_mst_mindmaps.py --mst-structure output/mst_folder_structure.json --output output/mst_mindmaps/` to create the organized mindmaps.", "question_type": "medium", "topics": ["Mindmap", "MST Folder Grouping"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "organization", "clustering", "semantic"], "related_skills": ["skill_mst_folder_grouping.md", "skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/mst_folder_grouping.py", "scripts/mindmap/README.md", "education/book-13-semantic-search/07_density_scoring.md"], "original_answer": "You can organize mindmaps using the MST Folder Grouping tool. Run `python3 scripts/mindmap/mst_folder_grouping.py --trees-only --target-size 10 -o output.json` to generate a semantic hierarchy. Adjust `--target-size` to control how many items go into each folder.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_002_q0", "cluster_id": "skill_mst_folder_grouping_002", "question": "How can I cluster a subset of mindmaps, like just the physics ones?", "answer": "Use the `--subset` option with the MST grouping script to cluster only physics mindmaps. Run: `python3 scripts/mindmap/mst_folder_grouping.py --subset physics --target-size 8 --max-depth 3 --verbose`. This partitions only mindmaps matching the physics subset criteria, creating a semantically coherent folder hierarchy for just those items.", "question_type": "long", "topics": ["Mindmap", "MST Folder Grouping"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "subset", "filtering", "clustering"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/mst_folder_grouping.py", "education/book-13-semantic-search/08_advanced_federation.md"], "original_answer": "Use the `--subset` option with the MST grouping script. For example: `python3 scripts/mindmap/mst_folder_grouping.py --subset physics --target-size 8`. This partitions only the mindmaps matching the subset criteria.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_002_q1", "cluster_id": "skill_mst_folder_grouping_002", "question": "Is there a way to run the folder grouper on only specific topics?", "answer": "Yes. Use the `--subset` option to filter by topic. For example: `python3 scripts/mindmap/mst_folder_grouping.py --subset physics --target-size 8 --max-depth 3`. This will partition only mindmaps matching that subset criteria before applying the MST grouping algorithm.", "question_type": "long", "topics": ["Mindmap", "MST Folder Grouping"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "subset", "filtering", "clustering"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/mst_folder_grouping.py", "education/book-13-semantic-search/08_advanced_federation.md"], "original_answer": "Use the `--subset` option with the MST grouping script. For example: `python3 scripts/mindmap/mst_folder_grouping.py --subset physics --target-size 8`. This partitions only the mindmaps matching the subset criteria.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_002_q2", "cluster_id": "skill_mst_folder_grouping_002", "question": "Filter the clustering to a specific subset.", "answer": "Use the `--subset` option with the MST grouping script to filter clustering to a specific subset. For example: `python3 scripts/mindmap/mst_folder_grouping.py --subset physics --target-size 8 --max-depth 3`. This will partition only the mindmaps matching your subset criteria (like \"physics\"), allowing you to organize a targeted collection separately from the full dataset.", "question_type": "long", "topics": ["Mindmap", "MST Folder Grouping"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "subset", "filtering", "clustering"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/mst_folder_grouping.py", "education/book-13-semantic-search/08_advanced_federation.md"], "original_answer": "Use the `--subset` option with the MST grouping script. For example: `python3 scripts/mindmap/mst_folder_grouping.py --subset physics --target-size 8`. This partitions only the mindmaps matching the subset criteria.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_003_q0", "cluster_id": "skill_mst_folder_grouping_003", "question": "Can I combine my existing manual folder structure with automatic grouping?", "answer": "Yes, use the 'hybrid' tree source to combine your existing manual folder structure with automatic grouping. Run `python3 scripts/mindmap/mst_folder_grouping.py --tree-source hybrid --embed-blend 0.3`. This preserves your curated hierarchy while automatically attaching orphan mindmaps based on semantic similarity. The `--embed-blend` parameter controls the balance between structure preservation and semantic attachment.", "question_type": "long", "topics": ["Mindmap", "MST Folder Grouping"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "hybrid", "curation", "automation"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/mst_folder_grouping.py", "scripts/mindmap/hierarchy_objective.py"], "original_answer": "Yes, use the 'hybrid' tree source. Run `python3 scripts/mindmap/mst_folder_grouping.py --tree-source hybrid --embed-blend 0.3`. This respects your curated hierarchy while attaching unorganized (orphan) mindmaps based on semantic proximity.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_003_q1", "cluster_id": "skill_mst_folder_grouping_003", "question": "How do I attach orphaned mindmaps to my curated folders?", "answer": "Use the 'hybrid' tree source mode to attach orphaned mindmaps to your curated folders. Run: `python3 scripts/mindmap/mst_folder_grouping.py --tree-source hybrid --embed-blend 0.3 -o OUTPUT_JSON`. This preserves your existing curated hierarchy while automatically attaching unorganized mindmaps based on semantic similarity. The `--embed-blend 0.3` parameter controls how much weight is given to embeddings when deciding attachment placement.", "question_type": "long", "topics": ["Mindmap", "MST Folder Grouping"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "hybrid", "curation", "automation"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/mst_folder_grouping.py", "scripts/mindmap/hierarchy_objective.py"], "original_answer": "Yes, use the 'hybrid' tree source. Run `python3 scripts/mindmap/mst_folder_grouping.py --tree-source hybrid --embed-blend 0.3`. This respects your curated hierarchy while attaching unorganized (orphan) mindmaps based on semantic proximity.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_003_q2", "cluster_id": "skill_mst_folder_grouping_003", "question": "I want to use hybrid mode for mindmap organization.", "answer": "To use hybrid mode for mindmap organization, run: `python3 scripts/mindmap/mst_folder_grouping.py --tree-source hybrid --embed-blend 0.3 -o output/mst_folder_structure.json`. This mode combines your curated hierarchy with automatic attachment of orphan mindmaps based on semantic similarity. The `--embed-blend 0.3` parameter weights the embedding-based similarity at 30% when determining optimal placements.", "question_type": "long", "topics": ["Mindmap", "MST Folder Grouping"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "hybrid", "curation", "automation"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/mst_folder_grouping.py", "scripts/mindmap/hierarchy_objective.py"], "original_answer": "Yes, use the 'hybrid' tree source. Run `python3 scripts/mindmap/mst_folder_grouping.py --tree-source hybrid --embed-blend 0.3`. This respects your curated hierarchy while attaching unorganized (orphan) mindmaps based on semantic proximity.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_004_q0", "cluster_id": "skill_mst_folder_grouping_004", "question": "After generating the folder structure JSON, how do I create the actual mindmap files?", "answer": "After generating the folder structure JSON, use the generator script to create the actual mindmap files: `python3 scripts/mindmap/generate_mst_mindmaps.py --mst-structure output/mst_folder_structure.json --output output/mst_mindmaps/ --root-name \"My_Collection\"`. This script reads your generated structure and creates the physical mindmap files that reflect the semantic hierarchy you defined.", "question_type": "long", "topics": ["Mindmap", "MST Folder Grouping"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "generation", "json", "workflow"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/generate_mst_mindmaps.py", "scripts/mindmap/README.md"], "original_answer": "Once you have the structure JSON, use the generator script: `python3 scripts/mindmap/generate_mst_mindmaps.py --mst-structure output/mst_folder_structure.json --output output/mst_mindmaps/`. This creates the physical mindmap files reflecting the generated hierarchy.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_004_q1", "cluster_id": "skill_mst_folder_grouping_004", "question": "I have the MST structure output, what is the next step?", "answer": "Once you have the MST structure JSON output, use the generator script to create physical mindmap files: `python3 scripts/mindmap/generate_mst_mindmaps.py --mst-structure output/mst_folder_structure.json --output output/mst_mindmaps/ --root-name \"My_Collection\"`. This converts the folder hierarchy structure into actual mindmap files that reflect your semantic grouping.", "question_type": "long", "topics": ["Mindmap", "MST Folder Grouping"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "generation", "json", "workflow"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/generate_mst_mindmaps.py", "scripts/mindmap/README.md"], "original_answer": "Once you have the structure JSON, use the generator script: `python3 scripts/mindmap/generate_mst_mindmaps.py --mst-structure output/mst_folder_structure.json --output output/mst_mindmaps/`. This creates the physical mindmap files reflecting the generated hierarchy.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_004_q2", "cluster_id": "skill_mst_folder_grouping_004", "question": "Generate mindmaps from the folder grouping JSON.", "answer": "Use the generator script to create mindmap files from your folder structure JSON: `python3 scripts/mindmap/generate_mst_mindmaps.py --mst-structure output/mst_folder_structure.json --output output/mst_mindmaps/ --root-name \"My_Collection\"`. This reads the MST structure JSON and generates the corresponding mindmap files in your output directory, with folder hierarchies reflected in the mindmap organization.", "question_type": "long", "topics": ["Mindmap", "MST Folder Grouping"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "generation", "json", "workflow"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/generate_mst_mindmaps.py", "scripts/mindmap/README.md"], "original_answer": "Once you have the structure JSON, use the generator script: `python3 scripts/mindmap/generate_mst_mindmaps.py --mst-structure output/mst_folder_structure.json --output output/mst_mindmaps/`. This creates the physical mindmap files reflecting the generated hierarchy.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_001_q0", "cluster_id": "skill_folder_suggestion_001", "question": "Where should I move a mindmap that might be in the wrong folder?", "answer": "To move a mindmap that might be in the wrong folder, use the folder suggestion tool to find the best location:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"\n```\n\nOr search by mindmap title:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --title \"MINDMAP_TITLE\"\n```\n\nThe tool returns suggested folders ranked by probability scores. A probability over 50% indicates a strong semantic match for where the mindmap should be moved. Review the top suggestions and move the mindmap accordingly. See skill_folder_suggestion.md for additional options like filtering by account or checking for other misplacements in the hierarchy.", "question_type": "medium", "topics": ["Mindmap", "Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "organization", "folder", "classification"], "related_skills": ["skill_bookmark_tools.md", "skill_bookmark_filing.md", "skill_mst_folder_grouping.md", "skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/README.md", "docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "You can suggest the best folder for a mindmap using semantic similarity. Use:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"\n```\n\nOr search by title:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --title \"MINDMAP_TITLE\"\n```\n\nThe output shows suggested folders with probability scores\u2014over 50% indicates a strong match. See skill_folder_suggestion.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_001_q1", "cluster_id": "skill_folder_suggestion_001", "question": "How do I check if a mindmap is in the right folder?", "answer": "To check if a mindmap is in the right folder, use the folder suggestion tool to find the semantically best folder for it:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"\n```\n\nOr search by title:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --title \"MINDMAP_TITLE\"\n```\n\nThe output shows suggested folders with probability scores. If the current folder matches the top suggestion with >50% probability, the mindmap is well-placed. Lower scores indicate the item may be misplaced.", "question_type": "medium", "topics": ["Mindmap", "Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "organization", "folder", "classification"], "related_skills": ["skill_bookmark_tools.md", "skill_bookmark_filing.md", "skill_mst_folder_grouping.md", "skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/README.md", "docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "You can suggest the best folder for a mindmap using semantic similarity. Use:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"\n```\n\nOr search by title:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --title \"MINDMAP_TITLE\"\n```\n\nThe output shows suggested folders with probability scores\u2014over 50% indicates a strong match. See skill_folder_suggestion.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_001_q2", "cluster_id": "skill_folder_suggestion_001", "question": "Can I get suggestions for where to organize a mindmap?", "answer": "Yes, you can get suggestions for where to organize a mindmap using semantic similarity. Use the folder suggestion tool:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"\n```\n\nOr search by mindmap title:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --title \"MINDMAP_TITLE\"\n```\n\nThe output shows suggested folders ranked by probability scores\u2014scores over 50% indicate strong placement matches. This uses federated projection models trained on Pearltrees hierarchy data to find semantically appropriate locations for your mindmap.", "question_type": "medium", "topics": ["Mindmap", "Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "organization", "folder", "classification"], "related_skills": ["skill_bookmark_tools.md", "skill_bookmark_filing.md", "skill_mst_folder_grouping.md", "skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/README.md", "docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "You can suggest the best folder for a mindmap using semantic similarity. Use:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"\n```\n\nOr search by title:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --title \"MINDMAP_TITLE\"\n```\n\nThe output shows suggested folders with probability scores\u2014over 50% indicates a strong match. See skill_folder_suggestion.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_002_q0", "cluster_id": "skill_folder_suggestion_002", "question": "How do I find multiple misplaced mindmaps in a folder?", "answer": "You can check an entire folder for misplaced mindmaps using the suggest_folder.py script with the --check-folder flag:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --check-folder \"FOLDER_PATH\" --threshold 0.5\n```\n\nThis scans all mindmaps in the specified folder and identifies those that appear misplaced based on semantic similarity. The threshold parameter (default 0.5) controls the confidence level required to flag a mindmap as misplaced\u2014lower thresholds are more sensitive. The output will show suggested better placements for each flagged item.", "question_type": "medium", "topics": ["Mindmap", "Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "folder", "batch", "validation"], "related_skills": ["skill_bookmark_tools.md", "skill_mst_folder_grouping.md", "skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/README.md", "docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "You can check an entire folder for misplacements:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --check-folder \"FOLDER_PATH\" --threshold 0.5\n```\n\nThe threshold parameter (default 0.5) controls how confident a suggestion must be before flagging a mindmap as misplaced. This will scan all mindmaps and suggest improvements. See skill_folder_suggestion.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_002_q1", "cluster_id": "skill_folder_suggestion_002", "question": "Can I scan an entire folder for mindmaps that are in the wrong location?", "answer": "Yes, you can scan an entire folder for misplaced mindmaps using the folder suggestion tool. Run:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --check-folder \"FOLDER_PATH\" --threshold 0.5\n```\n\nThis scans all mindmaps in the folder and flags those that may be in the wrong location. The threshold parameter (0.0-1.0, default 0.5) controls sensitivity\u2014lower values flag more potential misplacements, higher values only flag confident suggestions. See skill_folder_suggestion.md for additional options and interpretation of results.", "question_type": "medium", "topics": ["Mindmap", "Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "folder", "batch", "validation"], "related_skills": ["skill_bookmark_tools.md", "skill_mst_folder_grouping.md", "skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/README.md", "docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "You can check an entire folder for misplacements:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --check-folder \"FOLDER_PATH\" --threshold 0.5\n```\n\nThe threshold parameter (default 0.5) controls how confident a suggestion must be before flagging a mindmap as misplaced. This will scan all mindmaps and suggest improvements. See skill_folder_suggestion.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_002_q2", "cluster_id": "skill_folder_suggestion_002", "question": "How do I identify misplaced mindmaps across a directory?", "answer": "You can identify misplaced mindmaps across a directory by running:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --check-folder \"FOLDER_PATH\" --threshold 0.5\n```\n\nThis scans all mindmaps in the folder and flags those where the current placement confidence is below the threshold (default 0.5). Lower threshold values flag more potential misplacements. The tool uses semantic similarity to compare each mindmap against the folder hierarchy and suggests better placement options when found.", "question_type": "medium", "topics": ["Mindmap", "Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "folder", "batch", "validation"], "related_skills": ["skill_bookmark_tools.md", "skill_mst_folder_grouping.md", "skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/README.md", "docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "You can check an entire folder for misplacements:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --check-folder \"FOLDER_PATH\" --threshold 0.5\n```\n\nThe threshold parameter (default 0.5) controls how confident a suggestion must be before flagging a mindmap as misplaced. This will scan all mindmaps and suggest improvements. See skill_folder_suggestion.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_003_q0", "cluster_id": "skill_folder_suggestion_003", "question": "What do the probability scores mean when suggesting folders?", "answer": "Probability scores indicate the semantic similarity between a mindmap and each suggested folder, showing how well the mindmap's content aligns with that folder. Scores above 50% represent strong matches with high confidence, 25-50% indicates good matches with some overlap to other folders, and below 25% suggests ambiguous cases where multiple folders might be valid. Higher scores mean better semantic similarity to the folder's content based on the trained federated model.", "question_type": "medium", "topics": ["Mindmap", "Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["scoring", "confidence", "interpretation"], "related_skills": ["skill_semantic_inference.md", "skill_train_model.md", "skill_folder_suggestion.md"], "related_docs": ["education/book-13-semantic-search/05_semantic_playbook.md", "education/book-13-semantic-search/07_density_scoring.md"], "original_answer": "Probability scores indicate how well a mindmap matches each suggested folder:\n\n- **Over 50%**: Strong match\u2014high confidence this is the right folder\n- **25-50%**: Good match with minor ambiguity\u2014mindmap fits but has some overlap with other folders\n- **Below 25%**: Ambiguous\u2014multiple valid options, manual review recommended\n\nHigher scores mean better semantic similarity to the folder's content. See skill_folder_suggestion.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_003_q1", "cluster_id": "skill_folder_suggestion_003", "question": "How do I interpret folder suggestion confidence scores?", "answer": "Folder suggestion confidence scores represent the semantic similarity between your content and each suggested folder:\n\n- **Over 50%**: Strong match\u2014the model is confident this folder is appropriate for your content\n- **25-50%**: Moderate match\u2014your content fits well but may also belong in other folders\n- **Below 25%**: Weak match\u2014the suggestion is uncertain; consider reviewing multiple options or creating a new folder\n\nHigher scores indicate stronger semantic alignment with the folder's existing content and theme. Use the confidence threshold parameter to filter suggestions based on your certainty requirements.", "question_type": "medium", "topics": ["Mindmap", "Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["scoring", "confidence", "interpretation"], "related_skills": ["skill_semantic_inference.md", "skill_train_model.md", "skill_folder_suggestion.md"], "related_docs": ["education/book-13-semantic-search/05_semantic_playbook.md", "education/book-13-semantic-search/07_density_scoring.md"], "original_answer": "Probability scores indicate how well a mindmap matches each suggested folder:\n\n- **Over 50%**: Strong match\u2014high confidence this is the right folder\n- **25-50%**: Good match with minor ambiguity\u2014mindmap fits but has some overlap with other folders\n- **Below 25%**: Ambiguous\u2014multiple valid options, manual review recommended\n\nHigher scores mean better semantic similarity to the folder's content. See skill_folder_suggestion.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_003_q2", "cluster_id": "skill_folder_suggestion_003", "question": "What does a 30% probability score tell me about a folder suggestion?", "answer": "A 30% probability score indicates a good match with minor ambiguity. At this level, the mindmap fits the suggested folder but has notable overlap with other folder categories. This score falls in the 25-50% range, meaning the suggestion is reasonable but warrants consideration of alternatives. Manual review of competing folder options is recommended before filing, as the semantic similarity is moderate rather than strong.", "question_type": "medium", "topics": ["Mindmap", "Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["scoring", "confidence", "interpretation"], "related_skills": ["skill_semantic_inference.md", "skill_train_model.md", "skill_folder_suggestion.md"], "related_docs": ["education/book-13-semantic-search/05_semantic_playbook.md", "education/book-13-semantic-search/07_density_scoring.md"], "original_answer": "Probability scores indicate how well a mindmap matches each suggested folder:\n\n- **Over 50%**: Strong match\u2014high confidence this is the right folder\n- **25-50%**: Good match with minor ambiguity\u2014mindmap fits but has some overlap with other folders\n- **Below 25%**: Ambiguous\u2014multiple valid options, manual review recommended\n\nHigher scores mean better semantic similarity to the folder's content. See skill_folder_suggestion.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_004_q0", "cluster_id": "skill_folder_suggestion_004", "question": "How do I get folder suggestions in JSON format?", "answer": "Use the `--json` flag with the semantic search script to get folder suggestions in JSON format:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated_single.pkl \\\n  --query \"BOOKMARK_TITLE\" \\\n  --top-k 10 --json\n```\n\nThis outputs results as machine-readable JSON, useful for automation or further processing. You can also filter by account or use account-specific models with the same `--json` flag.", "question_type": "long", "topics": ["Mindmap", "Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["json", "output", "automation", "export"], "related_skills": ["skill_bookmark_filing.md", "skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/README.md"], "original_answer": "Use the `--json` flag to get machine-readable output:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\" --json\n```\n\nThis outputs results in JSON format, useful for automation or further processing. See skill_folder_suggestion.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "Base answer references 'suggest_folder.py' script which doesn't match the actual scripts in the skill document (infer_pearltrees_federated.py). Corrected to use the actual script, but this discrepancy lowers confidence in whether base answer was authoritative."}
{"pair_id": "skill_folder_suggestion_004_q1", "cluster_id": "skill_folder_suggestion_004", "question": "Can I export folder suggestions as JSON?", "answer": "Yes, you can export folder suggestions as JSON using the `--json` flag with the semantic search script:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated_single.pkl \\\n  --query \"BOOKMARK_TITLE\" \\\n  --top-k 10 --json\n```\n\nThis outputs machine-readable JSON results, useful for automation or further processing. You can also filter by account using the `--account` flag if needed.", "question_type": "long", "topics": ["Mindmap", "Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["json", "output", "automation", "export"], "related_skills": ["skill_bookmark_filing.md", "skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/README.md"], "original_answer": "Use the `--json` flag to get machine-readable output:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\" --json\n```\n\nThis outputs results in JSON format, useful for automation or further processing. See skill_folder_suggestion.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "Base answer references a different script (mindmap/suggest_folder.py) than the actual skill documentation (infer_pearltrees_federated.py). The skill document shows JSON output is available via the federated model script, but the base answer may be outdated or refer to a different tool. Confidence reduced due to this discrepancy between base answer and actual implementation."}
{"pair_id": "skill_folder_suggestion_004_q2", "cluster_id": "skill_folder_suggestion_004", "question": "How do I get structured output for automation?", "answer": "Use the `--json` flag to get machine-readable JSON output for automation:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated_single.pkl \\\n  --query \"BOOKMARK_TITLE\" \\\n  --top-k 10 --json\n```\n\nThis outputs results in structured JSON format, suitable for automation, further processing, or integration with other tools. The output includes semantic scores and folder paths that can be parsed programmatically.", "question_type": "long", "topics": ["Mindmap", "Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["json", "output", "automation", "export"], "related_skills": ["skill_bookmark_filing.md", "skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/README.md"], "original_answer": "Use the `--json` flag to get machine-readable output:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\" --json\n```\n\nThis outputs results in JSON format, useful for automation or further processing. See skill_folder_suggestion.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "The base answer references 'mindmap/suggest_folder.py' but the skill document uses 'infer_pearltrees_federated.py' for the primary semantic search command. The file path in the base answer may be outdated or incorrect. Tailored answer uses the correct script from the skill document but lacks specific output schema details that would be helpful for automation."}
{"pair_id": "skill_folder_suggestion_005_q0", "cluster_id": "skill_folder_suggestion_005", "question": "What do I need to set up before using folder suggestions?", "answer": "Before using folder suggestions, train a federated model: `python scripts/train_pearltrees_federated.py --input data.jsonl`. Then build projections with `python scripts/build_lda_projection.py`. The folder suggestion tool uses these embeddings to match bookmarks to appropriate folders.", "question_type": "medium", "topics": ["Mindmap", "Setup"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["setup", "prerequisites", "initialization"], "related_skills": ["skill_train_model.md", "skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/README.md", "docs/design/FEDERATED_MODEL_FORMAT.md", "education/book-14-ai-training/03_lda_projection.md"], "original_answer": "You must first build folder projections using:\n\n```bash\npython3 scripts/mindmap/build_folder_projections.py \\\n  --embeddings \"EMBEDDINGS_FILE\" \\\n  --index \"INDEX_FILE\" \\\n  --output \"PROJECTIONS_DB\"\n```\n\nThis creates the semantic models used for suggestions. Once built, you can use the suggestion tool repeatedly. See skill_folder_suggestion.md for details.", "answer_tailored": true, "confidence": 0.85, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_folder_suggestion_005_q1", "cluster_id": "skill_folder_suggestion_005", "question": "What prerequisites are needed for the folder suggestion tool?", "answer": "To use the folder suggestion tool, you need to first train a federated model using `python3 scripts/train_pearltrees_federated.py` with your JSONL data and an output model file. The input JSONL must contain `target_text` fields with materialized folder paths (e.g., \"Science/Physics/Quantum Mechanics\"). Once the model is trained and saved as a .pkl file, you can use the folder suggestion tool. You'll also need embeddings generated from one of the supported models (nomic-ai/nomic-embed-text-v1.5 recommended, or sentence-transformers/all-MiniLM-L6-v2 for faster processing).", "question_type": "medium", "topics": ["Mindmap", "Setup"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["setup", "prerequisites", "initialization"], "related_skills": ["skill_train_model.md", "skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/README.md", "docs/design/FEDERATED_MODEL_FORMAT.md", "education/book-14-ai-training/03_lda_projection.md"], "original_answer": "You must first build folder projections using:\n\n```bash\npython3 scripts/mindmap/build_folder_projections.py \\\n  --embeddings \"EMBEDDINGS_FILE\" \\\n  --index \"INDEX_FILE\" \\\n  --output \"PROJECTIONS_DB\"\n```\n\nThis creates the semantic models used for suggestions. Once built, you can use the suggestion tool repeatedly. See skill_folder_suggestion.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "The base answer references 'build_folder_projections.py' but the skill document describes 'train_pearltrees_federated.py' as the primary training method. The two scripts may serve different purposes, creating uncertainty about which is the correct prerequisite. Additionally, the base answer doesn't mention the need for input JSONL data format or embedding model selection, which are important prerequisites."}
{"pair_id": "skill_folder_suggestion_005_q2", "cluster_id": "skill_folder_suggestion_005", "question": "How do I prepare the folder projection model?", "answer": "To prepare the folder projection model, run:\n\n```bash\npython3 scripts/mindmap/build_folder_projections.py \\\n  --embeddings \"EMBEDDINGS_FILE\" \\\n  --index \"INDEX_FILE\" \\\n  --output \"PROJECTIONS_DB\"\n```\n\nThis builds the semantic projection models needed for folder suggestion. The command requires embeddings and an index file as inputs, and outputs a projections database. Once prepared, you can use this model repeatedly with the folder suggestion tool.", "question_type": "medium", "topics": ["Mindmap", "Setup"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["setup", "prerequisites", "initialization"], "related_skills": ["skill_train_model.md", "skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/README.md", "docs/design/FEDERATED_MODEL_FORMAT.md", "education/book-14-ai-training/03_lda_projection.md"], "original_answer": "You must first build folder projections using:\n\n```bash\npython3 scripts/mindmap/build_folder_projections.py \\\n  --embeddings \"EMBEDDINGS_FILE\" \\\n  --index \"INDEX_FILE\" \\\n  --output \"PROJECTIONS_DB\"\n```\n\nThis creates the semantic models used for suggestions. Once built, you can use the suggestion tool repeatedly. See skill_folder_suggestion.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_folder_suggestion_006_q0", "cluster_id": "skill_folder_suggestion_006", "question": "Can I get verbose output showing more details about folder suggestions?", "answer": "Use the `--verbose` flag with the folder suggestion script for detailed output:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\" --verbose\n```\n\nThis displays additional details about the semantic matching process, including projection fit scores and confidence metrics that explain how folders are being suggested.", "question_type": "long", "topics": ["Mindmap", "Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["verbose", "debugging", "detailed-output"], "related_skills": ["skill_train_model.md", "skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/README.md", "education/book-13-semantic-search/08_advanced_federation.md"], "original_answer": "Use the `--verbose` flag for detailed output:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\" --verbose\n```\n\nThis shows additional information about the semantic matching process and projection fit scores. See skill_folder_suggestion.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer references 'skill_folder_suggestion.md' which may not be the most direct resource. The answer assumes the user already knows the basic command structure and tree ID format. No mention of what specific verbose details are shown (e.g., score breakdowns, matching candidates ranked by confidence)."}
{"pair_id": "skill_folder_suggestion_006_q1", "cluster_id": "skill_folder_suggestion_006", "question": "How do I see detailed information about folder matching?", "answer": "Use the `--verbose` flag when running folder suggestion to see detailed information about semantic matching:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\" --verbose\n```\n\nThis displays additional output including projection fit scores and detailed matching process information. For complete documentation, refer to skill_folder_suggestion.md.", "question_type": "long", "topics": ["Mindmap", "Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["verbose", "debugging", "detailed-output"], "related_skills": ["skill_train_model.md", "skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/README.md", "education/book-13-semantic-search/08_advanced_federation.md"], "original_answer": "Use the `--verbose` flag for detailed output:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\" --verbose\n```\n\nThis shows additional information about the semantic matching process and projection fit scores. See skill_folder_suggestion.md for details.", "answer_tailored": true, "confidence": 0.75, "confidence_issues": "The base answer references skill_folder_suggestion.md but the actual skill document provided (skill_train_federated_model.md) doesn't contain folder suggestion details. The answer assumes the --verbose flag exists and works as described, but this isn't verified in the provided skill documentation. There's uncertainty about what specific details --verbose actually outputs."}
{"pair_id": "skill_folder_suggestion_006_q2", "cluster_id": "skill_folder_suggestion_006", "question": "How do I enable debug output for folder suggestions?", "answer": "Use the `--verbose` flag when running folder suggestion commands for debug output:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\" --verbose\n```\n\nThis displays detailed information about the semantic matching process and projection fit scores, helping you understand how folders are being suggested.", "question_type": "long", "topics": ["Mindmap", "Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["verbose", "debugging", "detailed-output"], "related_skills": ["skill_train_model.md", "skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/README.md", "education/book-13-semantic-search/08_advanced_federation.md"], "original_answer": "Use the `--verbose` flag for detailed output:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\" --verbose\n```\n\nThis shows additional information about the semantic matching process and projection fit scores. See skill_folder_suggestion.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_bookmark_tools_001_q0", "cluster_id": "skill_mindmap_bookmark_tools_001", "question": "How do I organize my mindmaps into folders?", "answer": "Use the mindmap organization tools to semantically cluster your SimpleMind (.smmx) files into folders. First, build an index with `python3 scripts/mindmap/build_index.py output/ -o index.json`, then organize using MST-based grouping with `python3 scripts/mindmap/mst_folder_grouping.py --target-size 10 --max-depth 5 -o folder_structure.json`. This uses semantic embeddings to automatically create folder hierarchies based on topic similarity. The resulting folder structure balances organization depth with manageable folder sizes. See skill_mindmap_organization.md for detailed configuration options.", "question_type": "medium", "topics": ["Mindmap", "Mindmap & Bookmark Tools (Master)"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "organization", "clustering", "folders"], "related_skills": ["skill_mindmap_tools.md", "skill_mindmap_organization.md", "skill_mindmap_bookmark_tools.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/README.md"], "original_answer": "Use the mindmap organization tools to semantically cluster your SimpleMind (.smmx) files into folders. Build an index with `python3 scripts/mindmap/build_index.py output/ -o index.json`, then organize using MST-based grouping with `python3 scripts/mindmap/mst_folder_grouping.py --target-size 10 --max-depth 5 -o folder_structure.json`. This uses semantic embeddings to find natural topic boundaries. See skill_mindmap_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_bookmark_tools_001_q1", "cluster_id": "skill_mindmap_bookmark_tools_001", "question": "How do I semantically cluster my mindmaps?", "answer": "To semantically cluster your mindmaps, use the MST-based folder grouping tool. First, build an index with `python3 scripts/mindmap/build_index.py output/ -o index.json` to generate semantic embeddings of your SimpleMind files. Then run `python3 scripts/mindmap/mst_folder_grouping.py --target-size 10 --max-depth 5 -o folder_structure.json` to organize them into folders based on semantic similarity. This approach automatically discovers natural topic boundaries using embedding distances and minimum spanning tree algorithms.", "question_type": "medium", "topics": ["Mindmap", "Mindmap & Bookmark Tools (Master)"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "organization", "clustering", "folders"], "related_skills": ["skill_mindmap_tools.md", "skill_mindmap_organization.md", "skill_mindmap_bookmark_tools.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/README.md"], "original_answer": "Use the mindmap organization tools to semantically cluster your SimpleMind (.smmx) files into folders. Build an index with `python3 scripts/mindmap/build_index.py output/ -o index.json`, then organize using MST-based grouping with `python3 scripts/mindmap/mst_folder_grouping.py --target-size 10 --max-depth 5 -o folder_structure.json`. This uses semantic embeddings to find natural topic boundaries. See skill_mindmap_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_mindmap_bookmark_tools_001_q2", "cluster_id": "skill_mindmap_bookmark_tools_001", "question": "How can I organize SimpleMind files by topic?", "answer": "Use the mindmap organization tools to semantically cluster your SimpleMind (.smmx) files into topic-based folders. First, build an index with `python3 scripts/mindmap/build_index.py output/ -o index.json`. Then organize using MST-based grouping with `python3 scripts/mindmap/mst_folder_grouping.py --target-size 10 --max-depth 5 -o folder_structure.json`. This uses semantic embeddings to automatically identify natural topic boundaries and group related mindmaps together. For more details, see skill_mindmap_organization.md.", "question_type": "medium", "topics": ["Mindmap", "Mindmap & Bookmark Tools (Master)"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "organization", "clustering", "folders"], "related_skills": ["skill_mindmap_tools.md", "skill_mindmap_organization.md", "skill_mindmap_bookmark_tools.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/README.md"], "original_answer": "Use the mindmap organization tools to semantically cluster your SimpleMind (.smmx) files into folders. Build an index with `python3 scripts/mindmap/build_index.py output/ -o index.json`, then organize using MST-based grouping with `python3 scripts/mindmap/mst_folder_grouping.py --target-size 10 --max-depth 5 -o folder_structure.json`. This uses semantic embeddings to find natural topic boundaries. See skill_mindmap_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_bookmark_tools_002_q0", "cluster_id": "skill_mindmap_bookmark_tools_002", "question": "How do I file bookmarks into my Pearltrees collection?", "answer": "To file bookmarks into your Pearltrees collection, use the bookmark filing assistant. First, get folder suggestions by running `python3 scripts/infer_pearltrees_federated.py --model models/pearltrees_federated.pkl --query \"Your bookmark title\" --top-k 10 --tree` to see semantic candidates organized in a tree view. For LLM-assisted filing that helps you choose the best folder, use `python3 scripts/bookmark_filing_assistant.py --bookmark \"Title\" --url \"https://...\" --provider claude`. The system uses federated projection models trained on your Pearltrees hierarchy to identify the most relevant folders for your bookmarks.", "question_type": "medium", "topics": ["Bookmark", "Mindmap & Bookmark Tools (Master)"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["bookmark", "filing", "pearltrees", "folder-suggestion"], "related_skills": ["skill_bookmark_tools.md", "skill_bookmark_filing.md", "skill_folder_suggestion.md", "skill_mindmap_bookmark_tools.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/README.md"], "original_answer": "Use the bookmark filing assistant to find the best folder for new bookmarks. Get folder suggestions with `python3 scripts/infer_pearltrees_federated.py --model models/pearltrees_federated.pkl --query \"Your bookmark title\" --top-k 10 --tree`, or use the LLM-assisted filing with `python3 scripts/bookmark_filing_assistant.py --bookmark \"Title\" --url \"https://...\" --provider claude`. The system uses federated projection models trained on your Pearltrees hierarchy. See skill_mindmap_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_bookmark_tools_002_q1", "cluster_id": "skill_mindmap_bookmark_tools_002", "question": "How do I organize bookmarks into the right folders?", "answer": "To organize bookmarks into the right folders, use the bookmark filing assistant. Run `python3 scripts/infer_pearltrees_federated.py --model models/pearltrees_federated.pkl --query \"Your bookmark title\" --top-k 10 --tree` to get semantic folder candidates with a tree view, or use `python3 scripts/bookmark_filing_assistant.py --bookmark \"Title\" --url \"https://...\" --provider claude` for LLM-assisted selection. The system uses federated projection models trained on your Pearltrees hierarchy to suggest the best folders. For collections, use `python3 scripts/mindmap/mst_folder_grouping.py` to build hierarchies from flat items.", "question_type": "medium", "topics": ["Bookmark", "Mindmap & Bookmark Tools (Master)"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["bookmark", "filing", "pearltrees", "folder-suggestion"], "related_skills": ["skill_bookmark_tools.md", "skill_bookmark_filing.md", "skill_folder_suggestion.md", "skill_mindmap_bookmark_tools.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/README.md"], "original_answer": "Use the bookmark filing assistant to find the best folder for new bookmarks. Get folder suggestions with `python3 scripts/infer_pearltrees_federated.py --model models/pearltrees_federated.pkl --query \"Your bookmark title\" --top-k 10 --tree`, or use the LLM-assisted filing with `python3 scripts/bookmark_filing_assistant.py --bookmark \"Title\" --url \"https://...\" --provider claude`. The system uses federated projection models trained on your Pearltrees hierarchy. See skill_mindmap_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_bookmark_tools_002_q2", "cluster_id": "skill_mindmap_bookmark_tools_002", "question": "What's the best way to suggest folders for new bookmarks?", "answer": "The best way to suggest folders for new bookmarks is to use the folder suggestion tool with semantic search. For single items, use `python3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\" --verbose` to get probability-based folder recommendations based on semantic similarity and Procrustes projection. For batch operations, use `python3 scripts/infer_pearltrees_federated.py --model models/pearltrees_federated.pkl --query \"Your bookmark title\" --top-k 10 --tree` to see semantic candidates in a tree view. You can also use the LLM-assisted booking filing with `python3 scripts/bookmark_filing_assistant.py --bookmark \"Title\" --url \"https://...\" --provider claude` for more intelligent selections. The system uses federated projection models trained on your Pearltrees hierarchy data.", "question_type": "medium", "topics": ["Bookmark", "Mindmap & Bookmark Tools (Master)"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["bookmark", "filing", "pearltrees", "folder-suggestion"], "related_skills": ["skill_bookmark_tools.md", "skill_bookmark_filing.md", "skill_folder_suggestion.md", "skill_mindmap_bookmark_tools.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/README.md"], "original_answer": "Use the bookmark filing assistant to find the best folder for new bookmarks. Get folder suggestions with `python3 scripts/infer_pearltrees_federated.py --model models/pearltrees_federated.pkl --query \"Your bookmark title\" --top-k 10 --tree`, or use the LLM-assisted filing with `python3 scripts/bookmark_filing_assistant.py --bookmark \"Title\" --url \"https://...\" --provider claude`. The system uses federated projection models trained on your Pearltrees hierarchy. See skill_mindmap_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer conflates two different use cases: 'bookmark filing assistant' (which files bookmarks) vs 'folder suggestion' (which suggests where to place items). The tailored answer clarifies the distinction and emphasizes folder_suggestion.py as the primary tool for suggestions, while noting that bookmark_filing_assistant is an alternative for LLM-assisted selection."}
{"pair_id": "skill_mindmap_bookmark_tools_003_q0", "cluster_id": "skill_mindmap_bookmark_tools_003", "question": "How do I link my mindmaps to Pearltrees?", "answer": "To link your mindmaps to Pearltrees, use the linking tool: `python3 scripts/mindmap/link_pearltrees.py --mindmap output/physics.smmx --trees reports/pearltrees_targets.jsonl --projection-model models/federated.pkl --output output/physics_enriched.smmx`. This identifies semantically related Pearltrees collections and embeds them as URL references (`urllink` attributes) in your mindmap topics. For cross-links between your own mindmaps, use `python3 scripts/mindmap/add_relative_links.py output/*.smmx --index index.json` to create local navigation paths (`cloudmapref` attributes).", "question_type": "medium", "topics": ["Mindmap", "Mindmap & Bookmark Tools (Master)"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "pearltrees", "linking", "enrichment"], "related_skills": ["skill_mindmap_tools.md", "skill_mindmap_references.md", "skill_mindmap_linking.md", "skill_mindmap_bookmark_tools.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "Enrich your mindmaps with Pearltrees links using the linking tool: `python3 scripts/mindmap/link_pearltrees.py --mindmap output/physics.smmx --trees reports/pearltrees_targets.jsonl --projection-model models/federated.pkl --output output/physics_enriched.smmx`. This finds semantically related Pearltrees collections and embeds them as references in your mindmap. You can also add cross-links between mindmaps with `python3 scripts/mindmap/add_relative_links.py output/*.smmx --index index.json`. See skill_mindmap_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer assumes users have a federated model and pre-processed Pearltrees targets available. The command examples are specific to this project's setup and may need adaptation for different environments or data sources."}
{"pair_id": "skill_mindmap_bookmark_tools_003_q1", "cluster_id": "skill_mindmap_bookmark_tools_003", "question": "Can I enrich mindmaps with Pearltrees references?", "answer": "Yes, you can enrich mindmaps with Pearltrees references. Use the linking tool: `python3 scripts/mindmap/link_pearltrees.py --mindmap output/physics.smmx --trees reports/pearltrees_targets.jsonl --projection-model models/federated.pkl --output output/physics_enriched.smmx`. This finds semantically related Pearltrees collections and embeds them as references in your mindmap. You can also add cross-links between mindmaps with `python3 scripts/mindmap/add_relative_links.py output/*.smmx --index index.json`.", "question_type": "medium", "topics": ["Mindmap", "Mindmap & Bookmark Tools (Master)"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "pearltrees", "linking", "enrichment"], "related_skills": ["skill_mindmap_tools.md", "skill_mindmap_references.md", "skill_mindmap_linking.md", "skill_mindmap_bookmark_tools.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "Enrich your mindmaps with Pearltrees links using the linking tool: `python3 scripts/mindmap/link_pearltrees.py --mindmap output/physics.smmx --trees reports/pearltrees_targets.jsonl --projection-model models/federated.pkl --output output/physics_enriched.smmx`. This finds semantically related Pearltrees collections and embeds them as references in your mindmap. You can also add cross-links between mindmaps with `python3 scripts/mindmap/add_relative_links.py output/*.smmx --index index.json`. See skill_mindmap_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer references skill_mindmap_bookmark_tools.md for details, but the question only asks about Pearltrees enrichment. The answer could be more directly focused on Pearltrees specifically without the cross-links mention."}
{"pair_id": "skill_mindmap_bookmark_tools_003_q2", "cluster_id": "skill_mindmap_bookmark_tools_003", "question": "How do I connect mindmap nodes to Pearltrees collections?", "answer": "Connect mindmap nodes to Pearltrees collections using the linking tool: `python3 scripts/mindmap/link_pearltrees.py --mindmap output/physics.smmx --trees reports/pearltrees_targets.jsonl --projection-model models/federated.pkl --output output/physics_enriched.smmx`. This tool finds semantically related Pearltrees collections and embeds them as `urllink` references directly into your mindmap nodes. The enriched mindmap will contain clickable links to the corresponding Pearltrees pages.", "question_type": "medium", "topics": ["Mindmap", "Mindmap & Bookmark Tools (Master)"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "pearltrees", "linking", "enrichment"], "related_skills": ["skill_mindmap_tools.md", "skill_mindmap_references.md", "skill_mindmap_linking.md", "skill_mindmap_bookmark_tools.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "Enrich your mindmaps with Pearltrees links using the linking tool: `python3 scripts/mindmap/link_pearltrees.py --mindmap output/physics.smmx --trees reports/pearltrees_targets.jsonl --projection-model models/federated.pkl --output output/physics_enriched.smmx`. This finds semantically related Pearltrees collections and embeds them as references in your mindmap. You can also add cross-links between mindmaps with `python3 scripts/mindmap/add_relative_links.py output/*.smmx --index index.json`. See skill_mindmap_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "Base answer mentions the linking tool but doesn't explicitly clarify that this embeds links INTO the mindmap nodes themselves (via the urllink attribute). Also assumes the script and model files exist without confirmation. The base answer mixes in unrelated cross-linking advice which dilutes focus on the specific question."}
{"pair_id": "skill_mindmap_bookmark_tools_004_q0", "cluster_id": "skill_mindmap_bookmark_tools_004", "question": "How do I visualize my embedding clusters and folder hierarchies?", "answer": "Use the Density Explorer tool to visualize your embedding clusters and folder hierarchies. Start the Flask API with `python tools/density_explorer/flask_api.py --port 5000`, then run `cd tools/density_explorer/vue && npm run dev` and open http://localhost:5173. The tool displays your embeddings in a 2D projection, shows clustering quality, and overlays tree structures (MST or J-Guided) to visualize your folder hierarchies. You can toggle the tree visibility, adjust depth filtering, and explore density manifolds to understand semantic relationships and organization patterns in your data. For quick exploration without building the Vue frontend, use the Streamlit alternative: `streamlit run tools/density_explorer/streamlit_app.py`.", "question_type": "medium", "topics": ["Visualization", "Mindmap & Bookmark Tools (Master)"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["visualization", "embedding", "density-explorer", "clusters"], "related_skills": ["skill_density_explorer.md", "skill_mindmap_bookmark_tools.md"], "related_docs": ["scripts/mindmap/README.md"], "original_answer": "Start the density explorer to visualize embeddings, trees, and clusters: `python tools/density_explorer/flask_api.py --port 5000`, then in another terminal run `cd tools/density_explorer/vue && npm run dev` and open http://localhost:5173. The density explorer shows semantic relationships between your mindmaps and Pearltrees collections, helping you understand cluster structure and organization quality. See skill_mindmap_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_bookmark_tools_004_q1", "cluster_id": "skill_mindmap_bookmark_tools_004", "question": "Can I explore my mindmap and bookmark collections visually?", "answer": "Yes, use the density explorer to visualize your mindmap and bookmark collections. Start the Flask API with `python tools/density_explorer/flask_api.py --port 5000`, then run `cd tools/density_explorer/vue && npm run dev` and open http://localhost:5173. The visualization shows semantic relationships between your mindmaps and Pearltrees collections, helping you understand how they cluster and organize together. You can toggle tree overlays, adjust density settings, and explore the embedding space interactively. For quick exploration without building the Vue frontend, you can also use `streamlit run tools/density_explorer/streamlit_app.py`.", "question_type": "medium", "topics": ["Visualization", "Mindmap & Bookmark Tools (Master)"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["visualization", "embedding", "density-explorer", "clusters"], "related_skills": ["skill_density_explorer.md", "skill_mindmap_bookmark_tools.md"], "related_docs": ["scripts/mindmap/README.md"], "original_answer": "Start the density explorer to visualize embeddings, trees, and clusters: `python tools/density_explorer/flask_api.py --port 5000`, then in another terminal run `cd tools/density_explorer/vue && npm run dev` and open http://localhost:5173. The density explorer shows semantic relationships between your mindmaps and Pearltrees collections, helping you understand cluster structure and organization quality. See skill_mindmap_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_bookmark_tools_004_q2", "cluster_id": "skill_mindmap_bookmark_tools_004", "question": "How do I use the density explorer tool?", "answer": "To use the density explorer tool, start the Flask API with `python tools/density_explorer/flask_api.py --port 5000`, then in another terminal run `cd tools/density_explorer/vue && npm run dev` and open http://localhost:5173. The tool visualizes embeddings and tree structures to explore clustering quality and semantic relationships. Prepare your data as an .npz file with embeddings, titles, and optional texts. You can toggle between MST and J-Guided tree types, adjust density bandwidth and grid size, and filter by tree depth. Alternatively, use the Streamlit app with `streamlit run tools/density_explorer/streamlit_app.py` for quick exploration without building the Vue frontend.", "question_type": "medium", "topics": ["Visualization", "Mindmap & Bookmark Tools (Master)"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["visualization", "embedding", "density-explorer", "clusters"], "related_skills": ["skill_density_explorer.md", "skill_mindmap_bookmark_tools.md"], "related_docs": ["scripts/mindmap/README.md"], "original_answer": "Start the density explorer to visualize embeddings, trees, and clusters: `python tools/density_explorer/flask_api.py --port 5000`, then in another terminal run `cd tools/density_explorer/vue && npm run dev` and open http://localhost:5173. The density explorer shows semantic relationships between your mindmaps and Pearltrees collections, helping you understand cluster structure and organization quality. See skill_mindmap_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_bookmark_tools_005_q0", "cluster_id": "skill_mindmap_bookmark_tools_005", "question": "How do I set up the complete workflow from data to organized mindmaps?", "answer": "To set up the complete workflow from data to organized mindmaps: (1) Prepare your data in JSONL format with text content; (2) Train a projection model using `python3 scripts/train_pearltrees_federated.py reports/pearltrees_targets.jsonl models/federated.pkl --model nomic-ai/nomic-embed-text-v1.5 --cluster-method mst`; (3) Generate mindmaps with `python3 scripts/generate_mindmap.py --data source.jsonl --output-dir output/`; (4) Build the searchable index with `python3 scripts/mindmap/build_index.py output/ -o index.json`; (5) Enrich mindmaps with Pearltrees links using the linking tool to connect references; (6) Organize content into folders using MST-based grouping from the trained model; (7) Visualize and explore the result in density explorer by running `python tools/density_explorer/flask_api.py --port 5000` and accessing http://localhost:5173. Each step builds on the previous one to create a hierarchical, semantically organized knowledge structure.", "question_type": "long", "topics": ["Mindmap", "Mindmap & Bookmark Tools (Master)"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["workflow", "end-to-end", "setup", "integration"], "related_skills": ["skill_ml_tools.md", "skill_data_tools.md", "skill_mindmap_bookmark_tools.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/README.md"], "original_answer": "Follow the end-to-end workflow: (1) Train a projection model with `python3 scripts/train_pearltrees_federated.py reports/pearltrees_targets.jsonl models/federated.pkl`; (2) Generate mindmaps with `python3 scripts/generate_mindmap.py --data source.jsonl --output-dir output/`; (3) Build index with `python3 scripts/mindmap/build_index.py output/ -o index.json`; (4) Enrich with Pearltrees links using the linking tool; (5) Organize into folders with MST grouping; (6) Visualize in density explorer. See skill_mindmap_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "Base answer references skill_mindmap_bookmark_tools.md for details, but the specific data preparation step and embedding model selection are not explicitly mentioned in the base answer. The tailored version adds these practical details from the skill document context. The base answer also uses generic script names that may not match exact command syntax."}
{"pair_id": "skill_mindmap_bookmark_tools_005_q1", "cluster_id": "skill_mindmap_bookmark_tools_005", "question": "What's the full end-to-end process for managing mindmaps and bookmarks?", "answer": "The end-to-end process for managing mindmaps and bookmarks involves six key steps: (1) Train a projection model using `python3 scripts/train_pearltrees_federated.py reports/pearltrees_targets.jsonl models/federated.pkl` to establish the embedding space; (2) Generate mindmaps from your data with `python3 scripts/generate_mindmap.py --data source.jsonl --output-dir output/`; (3) Build an index for efficient lookup using `python3 scripts/mindmap/build_index.py output/ -o index.json`; (4) Enrich mindmaps with Pearltrees links by resolving cross-references using the linking tool; (5) Organize content into folders using MST (Minimum Spanning Tree) clustering for hierarchical grouping; (6) Visualize the entire structure in density explorer by running `python tools/density_explorer/flask_api.py --port 5000` and accessing the Vue interface at http://localhost:5173. This workflow combines embedding-based organization with visual exploration of your bookmark and mindmap hierarchy.", "question_type": "long", "topics": ["Mindmap", "Mindmap & Bookmark Tools (Master)"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["workflow", "end-to-end", "setup", "integration"], "related_skills": ["skill_ml_tools.md", "skill_data_tools.md", "skill_mindmap_bookmark_tools.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/README.md"], "original_answer": "Follow the end-to-end workflow: (1) Train a projection model with `python3 scripts/train_pearltrees_federated.py reports/pearltrees_targets.jsonl models/federated.pkl`; (2) Generate mindmaps with `python3 scripts/generate_mindmap.py --data source.jsonl --output-dir output/`; (3) Build index with `python3 scripts/mindmap/build_index.py output/ -o index.json`; (4) Enrich with Pearltrees links using the linking tool; (5) Organize into folders with MST grouping; (6) Visualize in density explorer. See skill_mindmap_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer references 'skill_mindmap_bookmark_tools.md' but the provided skill document is 'skill_ml_tools.md'. The steps are technically sound but lack detail on the Pearltrees linking enrichment step, which is mentioned but not fully explained in the base material provided."}
{"pair_id": "skill_mindmap_bookmark_tools_005_q2", "cluster_id": "skill_mindmap_bookmark_tools_005", "question": "How do I train models and organize everything together?", "answer": "To train models and organize everything together: (1) Train a federated projection model using `python3 scripts/train_pearltrees_federated.py reports/pearltrees_targets.jsonl models/federated.pkl --model nomic-ai/nomic-embed-text-v1.5 --cluster-method mst` to create embeddings and clustering; (2) Generate mindmaps from your organized data with `python3 scripts/generate_mindmap.py --data source.jsonl --output-dir output/`; (3) Build a searchable index with `python3 scripts/mindmap/build_index.py output/ -o index.json`; (4) Enrich the index with Pearltrees links and metadata; (5) Use MST clustering to organize items into hierarchical folders; (6) Visualize results in the density explorer. This creates an end-to-end pipeline from raw data through training, organization, and interactive exploration.", "question_type": "long", "topics": ["Mindmap", "Mindmap & Bookmark Tools (Master)"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["workflow", "end-to-end", "setup", "integration"], "related_skills": ["skill_ml_tools.md", "skill_data_tools.md", "skill_mindmap_bookmark_tools.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/README.md"], "original_answer": "Follow the end-to-end workflow: (1) Train a projection model with `python3 scripts/train_pearltrees_federated.py reports/pearltrees_targets.jsonl models/federated.pkl`; (2) Generate mindmaps with `python3 scripts/generate_mindmap.py --data source.jsonl --output-dir output/`; (3) Build index with `python3 scripts/mindmap/build_index.py output/ -o index.json`; (4) Enrich with Pearltrees links using the linking tool; (5) Organize into folders with MST grouping; (6) Visualize in density explorer. See skill_mindmap_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer assumes familiarity with the skill hierarchy structure and file organization. The tailored answer adds specific model selection (nomic-embed-text) and clustering method (mst) which are recommended defaults but the question asks 'how to organize everything together' which is partially about project structure\u2014this answer focuses on the technical workflow rather than filesystem/project organization details."}
{"pair_id": "skill_mindmap_bookmark_tools_006_q0", "cluster_id": "skill_mindmap_bookmark_tools_006", "question": "Which embedding model should I use for best quality vs. faster inference?", "answer": "For best quality, use nomic-embed-text-v1.5 (768D) via the `pearltrees_federated_nomic.pkl` model\u2014it provides superior semantic accuracy for Q/A and folder suggestions. For faster inference, use all-MiniLM-L6-v2 (384D) via `pearltrees_federated_single.pkl`\u2014it's significantly faster with acceptable quality loss. Choose nomic when semantic precision matters most; choose MiniLM when latency is critical. Both models are pre-trained on your Pearltrees hierarchy. For custom requirements, train with `skill_train_model.md`.", "question_type": "long", "topics": ["Mindmap", "Mindmap & Bookmark Tools (Master)"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["models", "embeddings", "nomic", "minilm", "performance"], "related_skills": ["skill_ml_tools.md", "skill_embedding_models.md", "skill_mindmap_bookmark_tools.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "The system provides two trained projection models: `pearltrees_federated_nomic.pkl` uses Nomic embeddings (768D) for best quality and semantic accuracy, while `pearltrees_federated_single.pkl` uses MiniLM (384D) for faster inference with slightly lower quality. Choose nomic for highest quality folder suggestions and linking; choose MiniLM when speed is critical. Both are trained on your Pearltrees hierarchy. Train custom models with `skill_train_model.md` from the ML tools. See skill_mindmap_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_bookmark_tools_006_q1", "cluster_id": "skill_mindmap_bookmark_tools_006", "question": "What's the difference between nomic and MiniLM models?", "answer": "Nomic (nomic-embed-text-v1.5) and MiniLM (all-MiniLM-L6-v2) are embedding models with different trade-offs. Nomic produces 768-dimensional embeddings with superior semantic search quality, especially for asymmetric queries like Q/A tasks, making it ideal for accurate folder suggestions and semantic linking. MiniLM produces 384-dimensional embeddings and is significantly faster with lower memory usage, making it suitable when performance is critical and slightly reduced quality is acceptable. In UnifyWeaver, pearltrees_federated_nomic.pkl uses Nomic for best quality, while pearltrees_federated_single.pkl uses MiniLM for speed. Choose Nomic for highest accuracy in semantic search; choose MiniLM when inference speed or resource constraints are primary concerns.", "question_type": "long", "topics": ["Mindmap", "Mindmap & Bookmark Tools (Master)"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["models", "embeddings", "nomic", "minilm", "performance"], "related_skills": ["skill_ml_tools.md", "skill_embedding_models.md", "skill_mindmap_bookmark_tools.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "The system provides two trained projection models: `pearltrees_federated_nomic.pkl` uses Nomic embeddings (768D) for best quality and semantic accuracy, while `pearltrees_federated_single.pkl` uses MiniLM (384D) for faster inference with slightly lower quality. Choose nomic for highest quality folder suggestions and linking; choose MiniLM when speed is critical. Both are trained on your Pearltrees hierarchy. Train custom models with `skill_train_model.md` from the ML tools. See skill_mindmap_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_mindmap_bookmark_tools_006_q2", "cluster_id": "skill_mindmap_bookmark_tools_006", "question": "How do I choose between federated_nomic and federated_single models?", "answer": "Choose between federated_nomic and federated_single based on your priority: Use federated_nomic (768D Nomic embeddings) for the highest quality semantic search and folder suggestions\u2014it provides superior asymmetric search capabilities for Q/A tasks. Use federated_single (384D MiniLM) when inference speed and resource efficiency are more important than peak quality. Both models are trained on your Pearltrees hierarchy using Procrustes projection. If you need a custom model optimized for your specific use case, train one using `skill_train_model.md`.", "question_type": "long", "topics": ["Mindmap", "Mindmap & Bookmark Tools (Master)"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["models", "embeddings", "nomic", "minilm", "performance"], "related_skills": ["skill_ml_tools.md", "skill_embedding_models.md", "skill_mindmap_bookmark_tools.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "The system provides two trained projection models: `pearltrees_federated_nomic.pkl` uses Nomic embeddings (768D) for best quality and semantic accuracy, while `pearltrees_federated_single.pkl` uses MiniLM (384D) for faster inference with slightly lower quality. Choose nomic for highest quality folder suggestions and linking; choose MiniLM when speed is critical. Both are trained on your Pearltrees hierarchy. Train custom models with `skill_train_model.md` from the ML tools. See skill_mindmap_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_001_q0", "cluster_id": "skill_mindmap_cross_links_001", "question": "How do I connect mindmaps to link to each other?", "answer": "To connect mindmaps to link to each other, build an index of your mindmaps directory, then use that index to add cloudmapref links between them:\n\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o output/mindmaps/index.json\npython3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx --index output/mindmaps/index.json\n```\n\nThis creates local navigation links (cloudmapref attributes) that allow mindmaps to reference each other without requiring external URLs. For a preview of changes before applying them, use the `--dry-run --verbose` flags with the second command.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["linking", "navigation", "local-references"], "related_skills": ["skill_mindmap_cross_links.md", "skill_mindmap_linking.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/add_relative_links.py", "scripts/mindmap/build_index.py"], "original_answer": "Build an index of your mindmaps, then add cloudmapref links between them:\n\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o output/mindmaps/index.json\npython3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx --index output/mindmaps/index.json\n```\n\nThis creates local navigation links without external URLs. See skill_mindmap_cross_links.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_001_q1", "cluster_id": "skill_mindmap_cross_links_001", "question": "How do I link mindmaps together?", "answer": "To link mindmaps together, build an index of your mindmaps first, then add cloudmapref links between them:\n\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o output/mindmaps/index.json\npython3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx --index output/mindmaps/index.json\n```\n\nThis creates local navigation links that allow mindmaps to reference each other without requiring external URLs. The cloudmapref links enable users to jump between related mindmaps seamlessly within your collection.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["linking", "navigation", "local-references"], "related_skills": ["skill_mindmap_cross_links.md", "skill_mindmap_linking.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/add_relative_links.py", "scripts/mindmap/build_index.py"], "original_answer": "Build an index of your mindmaps, then add cloudmapref links between them:\n\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o output/mindmaps/index.json\npython3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx --index output/mindmaps/index.json\n```\n\nThis creates local navigation links without external URLs. See skill_mindmap_cross_links.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_001_q2", "cluster_id": "skill_mindmap_cross_links_001", "question": "How do I create references between mindmaps?", "answer": "Build an index of your mindmaps, then add cloudmapref links between them:\n\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o output/mindmaps/index.json\npython3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx --index output/mindmaps/index.json\n```\n\nThis creates local navigation links (cloudmapref attributes) between mindmaps without requiring external URLs. You can preview changes with --dry-run before applying them.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["linking", "navigation", "local-references"], "related_skills": ["skill_mindmap_cross_links.md", "skill_mindmap_linking.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/add_relative_links.py", "scripts/mindmap/build_index.py"], "original_answer": "Build an index of your mindmaps, then add cloudmapref links between them:\n\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o output/mindmaps/index.json\npython3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx --index output/mindmaps/index.json\n```\n\nThis creates local navigation links without external URLs. See skill_mindmap_cross_links.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_001_q3", "cluster_id": "skill_mindmap_cross_links_001", "question": "Can I make mindmaps reference each other locally?", "answer": "Yes, you can make mindmaps reference each other locally using cloudmapref links. Build an index of your mindmaps directory, then use it to add cross-links:\n\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o output/mindmaps/index.json\npython3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx --index output/mindmaps/index.json\n```\n\nThis creates local navigation links between mindmaps without requiring external URLs. The cloudmapref attributes enable mindmaps to reference each other directly. For details and additional options, see skill_mindmap_cross_links.md.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["linking", "navigation", "local-references"], "related_skills": ["skill_mindmap_cross_links.md", "skill_mindmap_linking.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/add_relative_links.py", "scripts/mindmap/build_index.py"], "original_answer": "Build an index of your mindmaps, then add cloudmapref links between them:\n\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o output/mindmaps/index.json\npython3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx --index output/mindmaps/index.json\n```\n\nThis creates local navigation links without external URLs. See skill_mindmap_cross_links.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_002_q0", "cluster_id": "skill_mindmap_cross_links_002", "question": "How do I preview cross-link changes before applying them?", "answer": "Use the `--dry-run` flag with `--verbose` to preview cross-link changes before applying them:\n\n```bash\npython3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx \\\n  --index output/mindmaps/index.json \\\n  --dry-run --verbose\n```\n\nThis command shows exactly what `cloudmapref` links will be added to your mindmaps without modifying any files. Run this first to verify the changes are correct before removing the `--dry-run` flag to apply them.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["dry-run", "preview", "testing"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/add_relative_links.py"], "original_answer": "Use the dry-run flag with verbose output to preview changes:\n\n```bash\npython3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx \\\n  --index output/mindmaps/index.json \\\n  --dry-run --verbose\n```\n\nThis shows exactly what links will be added without modifying files. See skill_mindmap_cross_links.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_002_q1", "cluster_id": "skill_mindmap_cross_links_002", "question": "Can I see what cross-links will be added?", "answer": "Yes. Use the `--dry-run` flag with `--verbose` to preview cross-links before applying them:\n\n```bash\npython3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx \\\n  --index output/mindmaps/index.json \\\n  --dry-run --verbose\n```\n\nThis shows exactly which `cloudmapref` links will be added to your mindmaps without modifying any files.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["dry-run", "preview", "testing"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/add_relative_links.py"], "original_answer": "Use the dry-run flag with verbose output to preview changes:\n\n```bash\npython3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx \\\n  --index output/mindmaps/index.json \\\n  --dry-run --verbose\n```\n\nThis shows exactly what links will be added without modifying files. See skill_mindmap_cross_links.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_002_q2", "cluster_id": "skill_mindmap_cross_links_002", "question": "How do I test mindmap links safely?", "answer": "Use the dry-run flag with verbose output to preview all changes without modifying files:\n\n```bash\npython3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx \\\n  --index output/mindmaps/index.json \\\n  --dry-run --verbose\n```\n\nThis displays exactly what links will be added, allowing you to review the changes before applying them. For additional testing options, see the full documentation in scripts/mindmap/README.md.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["dry-run", "preview", "testing"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/add_relative_links.py"], "original_answer": "Use the dry-run flag with verbose output to preview changes:\n\n```bash\npython3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx \\\n  --index output/mindmaps/index.json \\\n  --dry-run --verbose\n```\n\nThis shows exactly what links will be added without modifying files. See skill_mindmap_cross_links.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_002_q3", "cluster_id": "skill_mindmap_cross_links_002", "question": "How do I do a dry run of link addition?", "answer": "Use the `--dry-run` flag with `--verbose` to preview link additions without modifying files:\n\n```bash\npython3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx \\\n  --index output/mindmaps/index.json \\\n  --dry-run --verbose\n```\n\nThis shows exactly what links will be added before committing changes.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["dry-run", "preview", "testing"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/add_relative_links.py"], "original_answer": "Use the dry-run flag with verbose output to preview changes:\n\n```bash\npython3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx \\\n  --index output/mindmaps/index.json \\\n  --dry-run --verbose\n```\n\nThis shows exactly what links will be added without modifying files. See skill_mindmap_cross_links.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_003_q0", "cluster_id": "skill_mindmap_cross_links_003", "question": "How do I rename a mindmap while keeping its cross-links intact?", "answer": "Use `rename_mindmap.py` to rename while automatically updating all cross-link references:\n\n```bash\n# Auto-generate name from root topic\npython3 scripts/mindmap/rename_mindmap.py --mindmap \"path/to/mindmap.smmx\" --titled\n\n# Or specify explicit name\npython3 scripts/mindmap/rename_mindmap.py --mindmap \"path/to/mindmap.smmx\" --new-name \"New_Name.smmx\"\n```\n\nThe script preserves all `cloudmapref` cross-links automatically by updating references in other mindmaps that point to the renamed file.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["rename", "refactoring", "preservation"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/rename_mindmap.py"], "original_answer": "Use `rename_mindmap.py` to rename while updating all link references:\n\n```bash\n# Auto-generate name from root topic\npython3 scripts/mindmap/rename_mindmap.py --mindmap \"path/to/mindmap.smmx\" --titled\n\n# Or specify explicit name\npython3 scripts/mindmap/rename_mindmap.py --mindmap \"path/to/mindmap.smmx\" --new-name \"New_Name.smmx\"\n```\n\nThis preserves all cross-link references automatically. See skill_mindmap_cross_links.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_003_q1", "cluster_id": "skill_mindmap_cross_links_003", "question": "How do I rename mindmaps without breaking links?", "answer": "Use `rename_mindmap.py` to rename mindmaps while preserving all cross-link references:\n\n```bash\n# Auto-generate name from root topic\npython3 scripts/mindmap/rename_mindmap.py --mindmap \"path/to/mindmap.smmx\" --titled\n\n# Or specify an explicit name\npython3 scripts/mindmap/rename_mindmap.py --mindmap \"path/to/mindmap.smmx\" --new-name \"New_Name.smmx\"\n```\n\nThe script automatically updates all `cloudmapref` links that point to this mindmap, so renamed mindmaps remain properly connected to other mindmaps without breaking references.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["rename", "refactoring", "preservation"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/rename_mindmap.py"], "original_answer": "Use `rename_mindmap.py` to rename while updating all link references:\n\n```bash\n# Auto-generate name from root topic\npython3 scripts/mindmap/rename_mindmap.py --mindmap \"path/to/mindmap.smmx\" --titled\n\n# Or specify explicit name\npython3 scripts/mindmap/rename_mindmap.py --mindmap \"path/to/mindmap.smmx\" --new-name \"New_Name.smmx\"\n```\n\nThis preserves all cross-link references automatically. See skill_mindmap_cross_links.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_003_q2", "cluster_id": "skill_mindmap_cross_links_003", "question": "Can I rename a mindmap and preserve references?", "answer": "Yes, you can rename a mindmap and preserve references using `rename_mindmap.py`. This script automatically updates all cross-link references when renaming:\n\n```bash\n# Auto-generate name from root topic\npython3 scripts/mindmap/rename_mindmap.py --mindmap \"path/to/mindmap.smmx\" --titled\n\n# Or specify an explicit name\npython3 scripts/mindmap/rename_mindmap.py --mindmap \"path/to/mindmap.smmx\" --new-name \"New_Name.smmx\"\n```\n\nThe script handles all reference updates automatically, so your cloudmapref links remain valid after renaming.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["rename", "refactoring", "preservation"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/rename_mindmap.py"], "original_answer": "Use `rename_mindmap.py` to rename while updating all link references:\n\n```bash\n# Auto-generate name from root topic\npython3 scripts/mindmap/rename_mindmap.py --mindmap \"path/to/mindmap.smmx\" --titled\n\n# Or specify explicit name\npython3 scripts/mindmap/rename_mindmap.py --mindmap \"path/to/mindmap.smmx\" --new-name \"New_Name.smmx\"\n```\n\nThis preserves all cross-link references automatically. See skill_mindmap_cross_links.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_003_q3", "cluster_id": "skill_mindmap_cross_links_003", "question": "How do I update mindmap names?", "answer": "Use `rename_mindmap.py` to rename mindmaps while automatically updating all link references:\n\n```bash\n# Auto-generate name from root topic\npython3 scripts/mindmap/rename_mindmap.py --mindmap \"path/to/mindmap.smmx\" --titled\n\n# Or specify an explicit name\npython3 scripts/mindmap/rename_mindmap.py --mindmap \"path/to/mindmap.smmx\" --new-name \"New_Name.smmx\"\n```\n\nFor batch renaming all mindmaps:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py --batch \"MINDMAP_DIR\" --titled --dry-run\n```\n\nThis ensures all cross-link references are preserved when renaming.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["rename", "refactoring", "preservation"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/rename_mindmap.py"], "original_answer": "Use `rename_mindmap.py` to rename while updating all link references:\n\n```bash\n# Auto-generate name from root topic\npython3 scripts/mindmap/rename_mindmap.py --mindmap \"path/to/mindmap.smmx\" --titled\n\n# Or specify explicit name\npython3 scripts/mindmap/rename_mindmap.py --mindmap \"path/to/mindmap.smmx\" --new-name \"New_Name.smmx\"\n```\n\nThis preserves all cross-link references automatically. See skill_mindmap_cross_links.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_004_q0", "cluster_id": "skill_mindmap_cross_links_004", "question": "How do I batch rename multiple mindmaps at once?", "answer": "Use the batch rename command to process all mindmaps in a directory at once:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py --batch \"output/mindmaps/\" --titled --dry-run\n```\n\nThe `--titled` flag automatically generates names from each mindmap's root topic. Use `--dry-run` first to preview changes before applying them. Remove `--dry-run` to execute the rename operation.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["batch-rename", "bulk-operations", "automation"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/rename_mindmap.py"], "original_answer": "Use batch rename mode to process all mindmaps in a directory:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py --batch \"output/mindmaps/\" --titled --dry-run\n```\n\nRemove `--dry-run` to apply changes. The `--titled` flag auto-generates names from root topics. See skill_mindmap_cross_links.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_004_q1", "cluster_id": "skill_mindmap_cross_links_004", "question": "How do I rename all mindmaps in a directory?", "answer": "Use batch rename mode to process all mindmaps in a directory:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py --batch \"output/mindmaps/\" --titled --dry-run\n```\n\nRemove `--dry-run` to apply changes. The `--titled` flag auto-generates names from root topics. For explicit naming, use `--new-name` with individual files instead.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["batch-rename", "bulk-operations", "automation"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/rename_mindmap.py"], "original_answer": "Use batch rename mode to process all mindmaps in a directory:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py --batch \"output/mindmaps/\" --titled --dry-run\n```\n\nRemove `--dry-run` to apply changes. The `--titled` flag auto-generates names from root topics. See skill_mindmap_cross_links.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_004_q2", "cluster_id": "skill_mindmap_cross_links_004", "question": "Can I rename mindmaps in bulk?", "answer": "Yes, you can rename mindmaps in bulk using batch rename mode. Run:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py --batch \"output/mindmaps/\" --titled --dry-run\n```\n\nThe `--titled` flag automatically generates names from each mindmap's root topic. Use `--dry-run` first to preview changes, then remove it to apply the renaming. All cross-references will be updated automatically.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["batch-rename", "bulk-operations", "automation"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/rename_mindmap.py"], "original_answer": "Use batch rename mode to process all mindmaps in a directory:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py --batch \"output/mindmaps/\" --titled --dry-run\n```\n\nRemove `--dry-run` to apply changes. The `--titled` flag auto-generates names from root topics. See skill_mindmap_cross_links.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_004_q3", "cluster_id": "skill_mindmap_cross_links_004", "question": "How do I auto-generate names for multiple mindmaps?", "answer": "Use batch rename mode with the `--titled` flag to auto-generate names for multiple mindmaps from their root topics:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py --batch \"output/mindmaps/\" --titled --dry-run\n```\n\nPreview changes with `--dry-run` first. Remove the flag to apply the renaming. Each mindmap will be renamed based on its root topic text.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["batch-rename", "bulk-operations", "automation"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/rename_mindmap.py"], "original_answer": "Use batch rename mode to process all mindmaps in a directory:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py --batch \"output/mindmaps/\" --titled --dry-run\n```\n\nRemove `--dry-run` to apply changes. The `--titled` flag auto-generates names from root topics. See skill_mindmap_cross_links.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_005_q0", "cluster_id": "skill_mindmap_cross_links_005", "question": "How do I create a backlinks index to see which mindmaps reference each other?", "answer": "Build a reverse index to track backlinks between mindmaps:\n\n```bash\npython3 scripts/mindmap/build_reverse_index.py \"output/mindmaps/\" -o \"output/mindmaps/reverse_index.json\"\n```\n\nThis command creates a reverse index file that shows which mindmaps reference each other, allowing you to see all backlinks and understand the dependency relationships between your mindmaps. The output is a JSON file mapping each mindmap to the other mindmaps that link to it.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["backlinks", "reverse-index", "dependencies"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/build_reverse_index.py"], "original_answer": "Build a reverse index to track backlinks:\n\n```bash\npython3 scripts/mindmap/build_reverse_index.py \"output/mindmaps/\" -o \"output/mindmaps/reverse_index.json\"\n```\n\nThis creates an index showing which mindmaps reference each other, useful for understanding link dependencies. See skill_mindmap_cross_links.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_005_q1", "cluster_id": "skill_mindmap_cross_links_005", "question": "How do I build a reverse index of mindmap links?", "answer": "Build a reverse index to track backlinks using:\n\n```bash\npython3 scripts/mindmap/build_reverse_index.py \"output/mindmaps/\" -o \"output/mindmaps/reverse_index.json\"\n```\n\nThis creates an index showing which mindmaps reference each other, useful for understanding link dependencies and managing cross-reference relationships.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["backlinks", "reverse-index", "dependencies"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/build_reverse_index.py"], "original_answer": "Build a reverse index to track backlinks:\n\n```bash\npython3 scripts/mindmap/build_reverse_index.py \"output/mindmaps/\" -o \"output/mindmaps/reverse_index.json\"\n```\n\nThis creates an index showing which mindmaps reference each other, useful for understanding link dependencies. See skill_mindmap_cross_links.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_005_q2", "cluster_id": "skill_mindmap_cross_links_005", "question": "Can I see incoming links to a mindmap?", "answer": "Yes, you can view incoming links to a mindmap by building a reverse index that tracks backlinks:\n\n```bash\npython3 scripts/mindmap/build_reverse_index.py \"output/mindmaps/\" -o \"output/mindmaps/reverse_index.json\"\n```\n\nThis creates an index showing which mindmaps reference each other, allowing you to see all incoming links to any mindmap and understand link dependencies.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["backlinks", "reverse-index", "dependencies"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/build_reverse_index.py"], "original_answer": "Build a reverse index to track backlinks:\n\n```bash\npython3 scripts/mindmap/build_reverse_index.py \"output/mindmaps/\" -o \"output/mindmaps/reverse_index.json\"\n```\n\nThis creates an index showing which mindmaps reference each other, useful for understanding link dependencies. See skill_mindmap_cross_links.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_005_q3", "cluster_id": "skill_mindmap_cross_links_005", "question": "How do I find all mindmaps that link to a specific mindmap?", "answer": "Build a reverse index to find all mindmaps that link to a specific mindmap:\n\n```bash\npython3 scripts/mindmap/build_reverse_index.py \"output/mindmaps/\" -o \"output/mindmaps/reverse_index.json\n```\n\nThis creates a reverse index (backlinks index) that shows which mindmaps reference each other. You can then query this index to find all incoming links to any specific mindmap, making it easy to understand link dependencies and map relationships.", "question_type": "long", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["backlinks", "reverse-index", "dependencies"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/build_reverse_index.py"], "original_answer": "Build a reverse index to track backlinks:\n\n```bash\npython3 scripts/mindmap/build_reverse_index.py \"output/mindmaps/\" -o \"output/mindmaps/reverse_index.json\"\n```\n\nThis creates an index showing which mindmaps reference each other, useful for understanding link dependencies. See skill_mindmap_cross_links.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_006_q0", "cluster_id": "skill_mindmap_cross_links_006", "question": "What index formats can I use for mindmap linking?", "answer": "Three index formats are available for mindmap linking:\n\n- **JSON** (`.json`) - Human-readable format, best for small-to-medium collections\n- **TSV** (`.tsv`) - Tab-separated format, ideal for shell scripting and automation\n- **SQLite** (`.db`) - Database format, best for large collections\n\nSpecify the format by using the appropriate file extension in the `-o` parameter when building indexes with `build_index.py` or `build_reverse_index.py`.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["index-formats", "configuration", "performance"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/build_index.py", "scripts/mindmap/index_store.py"], "original_answer": "Three index formats are available:\n\n- **JSON** (`.json`) - Human-readable, best for small-to-medium collections\n- **TSV** (`.tsv`) - Tab-separated, ideal for shell scripting\n- **SQLite** (`.db`) - Database format, best for large collections\n\nSpecify the format by the file extension in the `-o` parameter when building indexes. See skill_mindmap_cross_links.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_006_q1", "cluster_id": "skill_mindmap_cross_links_006", "question": "What file formats do mindmap indexes support?", "answer": "Mindmap indexes support three file formats: JSON (.json) for human-readable storage suitable for small-to-medium collections, TSV (.tsv) for tab-separated values ideal for shell scripting, and SQLite (.db) for database format best for large collections. Specify the format by the file extension in the `-o` parameter when building indexes with `build_index.py`.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["index-formats", "configuration", "performance"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/build_index.py", "scripts/mindmap/index_store.py"], "original_answer": "Three index formats are available:\n\n- **JSON** (`.json`) - Human-readable, best for small-to-medium collections\n- **TSV** (`.tsv`) - Tab-separated, ideal for shell scripting\n- **SQLite** (`.db`) - Database format, best for large collections\n\nSpecify the format by the file extension in the `-o` parameter when building indexes. See skill_mindmap_cross_links.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_006_q2", "cluster_id": "skill_mindmap_cross_links_006", "question": "Should I use JSON, TSV, or SQLite for mindmap indexes?", "answer": "Choose based on your use case:\n\n- **JSON** (`.json`) - Use for small-to-medium collections where human readability matters. Good for initial setup and debugging.\n- **TSV** (`.tsv`) - Use when scripting with shell tools that need tab-separated data. Ideal for automation pipelines.\n- **SQLite** (`.db`) - Use for large collections where query performance and scalability are important.\n\nSpecify the format by file extension in the `-o` parameter: `build_index.py output/mindmaps/ -o output/mindmaps/index.json` (or `.tsv` or `.db`).", "question_type": "medium", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["index-formats", "configuration", "performance"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/build_index.py", "scripts/mindmap/index_store.py"], "original_answer": "Three index formats are available:\n\n- **JSON** (`.json`) - Human-readable, best for small-to-medium collections\n- **TSV** (`.tsv`) - Tab-separated, ideal for shell scripting\n- **SQLite** (`.db`) - Database format, best for large collections\n\nSpecify the format by the file extension in the `-o` parameter when building indexes. See skill_mindmap_cross_links.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_cross_links_006_q3", "cluster_id": "skill_mindmap_cross_links_006", "question": "Which index format is best for my use case?", "answer": "Choose your index format based on collection size and workflow: JSON (`.json`) for small-to-medium collections if you need human readability, TSV (`.tsv`) if you're automating with shell scripts, or SQLite (`.db`) for large collections. Specify the format by file extension in the `-o` parameter: `python3 scripts/mindmap/build_index.py output/mindmaps/ -o output/mindmaps/index.json`", "question_type": "medium", "topics": ["Mindmap", "Mindmap Cross-Links"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["index-formats", "configuration", "performance"], "related_skills": ["skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/mindmap/build_index.py", "scripts/mindmap/index_store.py"], "original_answer": "Three index formats are available:\n\n- **JSON** (`.json`) - Human-readable, best for small-to-medium collections\n- **TSV** (`.tsv`) - Tab-separated, ideal for shell scripting\n- **SQLite** (`.db`) - Database format, best for large collections\n\nSpecify the format by the file extension in the `-o` parameter when building indexes. See skill_mindmap_cross_links.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_index_001_q0", "cluster_id": "skill_mindmap_index_001", "question": "How do I find a mindmap file by its tree ID?", "answer": "Use the forward index to map tree IDs to file paths. Build it with:\n\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o index.json\n```\n\nThen lookup by ID using Python:\n\n```python\nfrom scripts.mindmap.index_store import create_index_store\nstore = create_index_store('index.json')\npath = store.get('10390825')  # Returns folder/id10390825.smmx or None\n```\n\nOr query SQLite directly:\n\n```bash\nsqlite3 index.db \"SELECT path FROM mindmap_index WHERE tree_id='10390825'\"\n```\n\nChoose the format (JSON, TSV, or SQLite) based on your use case: JSON for small collections, TSV for shell scripts, or SQLite for large indexes with frequent lookups.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Index"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["lookup", "forward-index", "tree-id"], "related_skills": ["skill_mindmap_index.md"], "related_docs": ["scripts/mindmap/build_index.py", "scripts/mindmap/index_store.py"], "original_answer": "Use the forward index to map tree IDs to file paths. Build it with:\n\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o index.json\n```\n\nThen lookup by ID:\n\n```python\nstore = create_index_store('index.json')\npath = store.get('10390825')  # Returns folder/id10390825.smmx or None\n```\n\nOr with SQLite:\n\n```bash\nsqlite3 index.db \"SELECT path FROM mindmap_index WHERE tree_id='10390825'\"\n```\n\nSee skill_mindmap_index.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_index_001_q1", "cluster_id": "skill_mindmap_index_001", "question": "Where is mindmap id10390825 located?", "answer": "To find where mindmap id10390825 is located, use the forward index. First build it:\n\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o index.json\n```\n\nThen lookup the ID:\n\n```python\nfrom scripts.mindmap.index_store import create_index_store\nstore = create_index_store('index.json')\npath = store.get('10390825')  # Returns the file path, e.g., Gods_of_Earth_and_Nature/id10390825.smmx\n```\n\nAlternatively with SQLite:\n\n```bash\nsqlite3 index.db \"SELECT path FROM mindmap_index WHERE tree_id='10390825'\"\n```", "question_type": "medium", "topics": ["Mindmap", "Mindmap Index"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["lookup", "forward-index", "tree-id"], "related_skills": ["skill_mindmap_index.md"], "related_docs": ["scripts/mindmap/build_index.py", "scripts/mindmap/index_store.py"], "original_answer": "Use the forward index to map tree IDs to file paths. Build it with:\n\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o index.json\n```\n\nThen lookup by ID:\n\n```python\nstore = create_index_store('index.json')\npath = store.get('10390825')  # Returns folder/id10390825.smmx or None\n```\n\nOr with SQLite:\n\n```bash\nsqlite3 index.db \"SELECT path FROM mindmap_index WHERE tree_id='10390825'\"\n```\n\nSee skill_mindmap_index.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_index_001_q2", "cluster_id": "skill_mindmap_index_001", "question": "How do I look up a mindmap by ID?", "answer": "Use the forward index to map tree IDs to file paths. First, build the index from your mindmap directory:\n\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o index.json\n```\n\nThen lookup a mindmap by ID using Python:\n\n```python\nfrom scripts.mindmap.index_store import create_index_store\n\nstore = create_index_store('index.json')\npath = store.get('10390825')  # Returns 'folder/id10390825.smmx' or None\n```\n\nAlternatively, use SQLite for faster lookups on large collections:\n\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o index.db\nsqlite3 index.db \"SELECT path FROM mindmap_index WHERE tree_id='10390825'\"\n```", "question_type": "medium", "topics": ["Mindmap", "Mindmap Index"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["lookup", "forward-index", "tree-id"], "related_skills": ["skill_mindmap_index.md"], "related_docs": ["scripts/mindmap/build_index.py", "scripts/mindmap/index_store.py"], "original_answer": "Use the forward index to map tree IDs to file paths. Build it with:\n\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o index.json\n```\n\nThen lookup by ID:\n\n```python\nstore = create_index_store('index.json')\npath = store.get('10390825')  # Returns folder/id10390825.smmx or None\n```\n\nOr with SQLite:\n\n```bash\nsqlite3 index.db \"SELECT path FROM mindmap_index WHERE tree_id='10390825'\"\n```\n\nSee skill_mindmap_index.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_index_002_q0", "cluster_id": "skill_mindmap_index_002", "question": "What index format should I use for my mindmap collection?", "answer": "Choose your mindmap index format based on collection size and access patterns:\n\n**JSON** - Use for small collections (<10K files) and development. Human-readable and easy to debug.\n\n**TSV** - Use if you need Unix pipeline integration with grep/awk. Tab-separated format is shell-friendly.\n\n**SQLite** - Use for large collections (>10K files) with frequent random lookups. Most efficient for production systems.\n\nAll three formats have identical APIs, so you can switch between them. Build with:\n\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o index.json   # JSON\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o index.tsv    # TSV\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o index.db     # SQLite\n```\n\nFor small collections, JSON is recommended. For large production systems, SQLite provides the best performance.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Index"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["storage-format", "json", "tsv", "sqlite"], "related_skills": ["skill_mindmap_index.md"], "related_docs": ["scripts/mindmap/build_index.py", "scripts/mindmap/index_store.py"], "original_answer": "Choose based on your collection size and use case:\n\n**JSON** - Human-readable, best for small collections (<10K files) and development.\n\n**TSV** - Tab-separated, shell-friendly for grep/awk processing and Unix pipelines.\n\n**SQLite** - Efficient for large collections (>10K files) with frequent random lookups.\n\nBuild with:\n\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o index.json   # JSON\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o index.tsv    # TSV\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o index.db     # SQLite\n```\n\nAll formats have identical APIs. See skill_mindmap_index.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_index_002_q1", "cluster_id": "skill_mindmap_index_002", "question": "Should I use JSON, TSV, or SQLite for my index?", "answer": "Choose based on your collection size and use case:\n\n**JSON** - Human-readable, best for small collections (<10K files) and development.\n\n**TSV** - Tab-separated, shell-friendly for grep/awk processing and Unix pipelines.\n\n**SQLite** - Efficient for large collections (>10K files) with frequent random lookups.\n\nBuild with:\n\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o index.json   # JSON\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o index.tsv    # TSV\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o index.db     # SQLite\n```\n\nAll formats have identical APIs, so switching between them is straightforward.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Index"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["storage-format", "json", "tsv", "sqlite"], "related_skills": ["skill_mindmap_index.md"], "related_docs": ["scripts/mindmap/build_index.py", "scripts/mindmap/index_store.py"], "original_answer": "Choose based on your collection size and use case:\n\n**JSON** - Human-readable, best for small collections (<10K files) and development.\n\n**TSV** - Tab-separated, shell-friendly for grep/awk processing and Unix pipelines.\n\n**SQLite** - Efficient for large collections (>10K files) with frequent random lookups.\n\nBuild with:\n\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o index.json   # JSON\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o index.tsv    # TSV\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o index.db     # SQLite\n```\n\nAll formats have identical APIs. See skill_mindmap_index.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_index_002_q2", "cluster_id": "skill_mindmap_index_002", "question": "Which index storage format is best?", "answer": "Choose based on your collection size and use case:\n\n**JSON** - Human-readable, best for small collections (<10K files) and development. Easy to inspect and debug.\n\n**TSV** - Tab-separated, shell-friendly for grep/awk processing and Unix pipelines. Ideal if you need to query the index from bash scripts.\n\n**SQLite** - Efficient for large collections (>10K files) with frequent random lookups. Provides the best performance for high-volume access patterns.\n\nBuild with:\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o index.json   # JSON\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o index.tsv    # TSV\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o index.db     # SQLite\n```\n\nAll three formats share an identical API, so you can switch between them without code changes.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Index"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["storage-format", "json", "tsv", "sqlite"], "related_skills": ["skill_mindmap_index.md"], "related_docs": ["scripts/mindmap/build_index.py", "scripts/mindmap/index_store.py"], "original_answer": "Choose based on your collection size and use case:\n\n**JSON** - Human-readable, best for small collections (<10K files) and development.\n\n**TSV** - Tab-separated, shell-friendly for grep/awk processing and Unix pipelines.\n\n**SQLite** - Efficient for large collections (>10K files) with frequent random lookups.\n\nBuild with:\n\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o index.json   # JSON\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o index.tsv    # TSV\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o index.db     # SQLite\n```\n\nAll formats have identical APIs. See skill_mindmap_index.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_index_002_q3", "cluster_id": "skill_mindmap_index_002", "question": "What's the difference between JSON and SQLite indexes?", "answer": "JSON and SQLite indexes differ in readability, performance, and use case. JSON is human-readable and ideal for small collections (<10K files) and development work\u2014you can inspect the index directly and easily debug it. SQLite is optimized for large collections (>10K files) with frequent random lookups, offering better performance through database indexing and efficient memory usage. TSV is a third option for shell scripting with grep/awk. All three formats support identical programmatic APIs via `create_index_store()`, so choose based on your collection size and workflow: JSON for development/debugging, SQLite for production with large data, TSV for Unix pipeline integration.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Index"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["storage-format", "json", "tsv", "sqlite"], "related_skills": ["skill_mindmap_index.md"], "related_docs": ["scripts/mindmap/build_index.py", "scripts/mindmap/index_store.py"], "original_answer": "Choose based on your collection size and use case:\n\n**JSON** - Human-readable, best for small collections (<10K files) and development.\n\n**TSV** - Tab-separated, shell-friendly for grep/awk processing and Unix pipelines.\n\n**SQLite** - Efficient for large collections (>10K files) with frequent random lookups.\n\nBuild with:\n\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o index.json   # JSON\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o index.tsv    # TSV\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o index.db     # SQLite\n```\n\nAll formats have identical APIs. See skill_mindmap_index.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_index_003_q0", "cluster_id": "skill_mindmap_index_003", "question": "How do I find which mindmaps link to a specific mindmap?", "answer": "Build a reverse index to track which mindmaps link to a specific mindmap:\n\n```bash\npython3 scripts/mindmap/build_reverse_index.py output/mindmaps/ -o backlinks.json\n```\n\nThen query for linkers:\n\n```python\nfrom scripts.mindmap.index_store import ReverseIndex\n\nreverse = ReverseIndex('backlinks.json')\nlinkers = reverse.get_linkers('10390825')\nprint(f\"Mindmaps linking to 10390825: {linkers}\")\n```\n\nThis is particularly useful before renaming or reorganizing mindmaps\u2014you can identify all dependent mindmaps that reference the target before making changes.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Index"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["reverse-index", "backlinks", "cross-references"], "related_skills": ["skill_mindmap_index.md", "skill_mindmap_rename.md"], "related_docs": ["scripts/mindmap/build_reverse_index.py", "scripts/mindmap/index_store.py"], "original_answer": "Build a reverse index to track backlinks:\n\n```bash\npython3 scripts/mindmap/build_reverse_index.py output/mindmaps/ -o backlinks.json\n```\n\nThen find linkers:\n\n```python\nfrom scripts.mindmap.index_store import ReverseIndex\n\nreverse = ReverseIndex('backlinks.json')\nlinkers = reverse.get_linkers('10390825')\nprint(f\"Mindmaps linking to 10390825: {linkers}\")\n```\n\nThis is essential for rename operations\u2014find all mindmaps that need updating before renaming. See skill_mindmap_index.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_index_003_q1", "cluster_id": "skill_mindmap_index_003", "question": "How do I create a reverse index?", "answer": "Build a reverse index to track which mindmaps link to each other using:\n\n```bash\npython3 scripts/mindmap/build_reverse_index.py output/mindmaps/ -o backlinks.json\n```\n\nThen query the reverse index programmatically:\n\n```python\nfrom scripts.mindmap.index_store import ReverseIndex\n\nreverse = ReverseIndex('backlinks.json')\nlinkers = reverse.get_linkers('10390825')\nprint(f\"Mindmaps linking to 10390825: {linkers}\")\n```\n\nThis is particularly useful for rename operations\u2014you can identify all mindmaps that reference a target before making changes.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Index"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["reverse-index", "backlinks", "cross-references"], "related_skills": ["skill_mindmap_index.md", "skill_mindmap_rename.md"], "related_docs": ["scripts/mindmap/build_reverse_index.py", "scripts/mindmap/index_store.py"], "original_answer": "Build a reverse index to track backlinks:\n\n```bash\npython3 scripts/mindmap/build_reverse_index.py output/mindmaps/ -o backlinks.json\n```\n\nThen find linkers:\n\n```python\nfrom scripts.mindmap.index_store import ReverseIndex\n\nreverse = ReverseIndex('backlinks.json')\nlinkers = reverse.get_linkers('10390825')\nprint(f\"Mindmaps linking to 10390825: {linkers}\")\n```\n\nThis is essential for rename operations\u2014find all mindmaps that need updating before renaming. See skill_mindmap_index.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_index_003_q2", "cluster_id": "skill_mindmap_index_003", "question": "What are backlinks in mindmaps?", "answer": "Backlinks in mindmaps are references from one mindmap to another. A reverse index tracks which mindmaps link to a specific mindmap. You can build this using: `python3 scripts/mindmap/build_reverse_index.py output/mindmaps/ -o backlinks.json`. Then query it programmatically:\n\n```python\nfrom scripts.mindmap.index_store import ReverseIndex\nreverse = ReverseIndex('backlinks.json')\nlinkers = reverse.get_linkers('10390825')\nprint(f\"Mindmaps linking to 10390825: {linkers}\")\n```\n\nThis is useful for tracking dependencies\u2014before renaming or reorganizing a mindmap, you can identify all mindmaps that reference it and need updating.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Index"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["reverse-index", "backlinks", "cross-references"], "related_skills": ["skill_mindmap_index.md", "skill_mindmap_rename.md"], "related_docs": ["scripts/mindmap/build_reverse_index.py", "scripts/mindmap/index_store.py"], "original_answer": "Build a reverse index to track backlinks:\n\n```bash\npython3 scripts/mindmap/build_reverse_index.py output/mindmaps/ -o backlinks.json\n```\n\nThen find linkers:\n\n```python\nfrom scripts.mindmap.index_store import ReverseIndex\n\nreverse = ReverseIndex('backlinks.json')\nlinkers = reverse.get_linkers('10390825')\nprint(f\"Mindmaps linking to 10390825: {linkers}\")\n```\n\nThis is essential for rename operations\u2014find all mindmaps that need updating before renaming. See skill_mindmap_index.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer explains how to find backlinks but doesn't explicitly define what backlinks are conceptually. The tailored answer adds this definition but assumes the user understands the reverse index concept without further explanation."}
{"pair_id": "skill_mindmap_index_003_q3", "cluster_id": "skill_mindmap_index_003", "question": "How do I track cross-references between mindmaps?", "answer": "To track cross-references between mindmaps, build a reverse index that identifies which mindmaps link to each other:\n\n```bash\npython3 scripts/mindmap/build_reverse_index.py output/mindmaps/ -o backlinks.json\n```\n\nThen query the reverse index to find all mindmaps linking to a specific tree ID:\n\n```python\nfrom scripts.mindmap.index_store import ReverseIndex\n\nreverse = ReverseIndex('backlinks.json')\nlinkers = reverse.get_linkers('10390825')\nprint(f\"Mindmaps linking to 10390825: {linkers}\")\n```\n\nThe reverse index maps each mindmap to all the mindmaps that reference it. This is particularly useful before performing rename operations, as it shows you which mindmaps need updating when a referenced mindmap changes.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Index"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["reverse-index", "backlinks", "cross-references"], "related_skills": ["skill_mindmap_index.md", "skill_mindmap_rename.md"], "related_docs": ["scripts/mindmap/build_reverse_index.py", "scripts/mindmap/index_store.py"], "original_answer": "Build a reverse index to track backlinks:\n\n```bash\npython3 scripts/mindmap/build_reverse_index.py output/mindmaps/ -o backlinks.json\n```\n\nThen find linkers:\n\n```python\nfrom scripts.mindmap.index_store import ReverseIndex\n\nreverse = ReverseIndex('backlinks.json')\nlinkers = reverse.get_linkers('10390825')\nprint(f\"Mindmaps linking to 10390825: {linkers}\")\n```\n\nThis is essential for rename operations\u2014find all mindmaps that need updating before renaming. See skill_mindmap_index.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_index_004_q0", "cluster_id": "skill_mindmap_index_004", "question": "How do I programmatically look up and manage mindmap indexes in Python?", "answer": "Use the index store API for programmatic access to mindmap indexes in Python:\n\n```python\nfrom scripts.mindmap.index_store import create_index_store\n\nstore = create_index_store('index.json')  # Auto-detects format from extension\n\n# Lookup operations\npath = store.get('10390825')           # Get path or None\nexists = store.contains('10390825')    # Check existence\nabs_path = store.resolve_path('10390825')  # Get absolute path\n\n# Modify operations\nstore.set('12345678', 'folder/id12345678.smmx')\nstore.delete('12345678')\n\n# Iteration and counting\nfor tree_id, path in store.items():\n    print(f\"{tree_id} -> {path}\")\ntotal = store.count()\n```\n\nFor performance with frequent lookups, wrap with caching:\n\n```python\nfrom scripts.mindmap.index_store import CachedStore, SQLiteStore\n\nstore = CachedStore(SQLiteStore('index.db'), preload=True)\n```\n\nThe API works identically across JSON, TSV, and SQLite storage formats\u2014choose based on your use case (development/debugging vs. large collections).", "question_type": "long", "topics": ["Mindmap", "Mindmap Index"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["api", "python", "lookup", "caching"], "related_skills": ["skill_mindmap_index.md"], "related_docs": ["scripts/mindmap/index_store.py"], "original_answer": "Use the index store API for programmatic access:\n\n```python\nfrom scripts.mindmap.index_store import create_index_store\n\nstore = create_index_store('index.json')  # Auto-detects format\n\n# Lookup\npath = store.get('10390825')           # Get path or None\nexists = store.contains('10390825')    # Check existence\nabs_path = store.resolve_path('10390825')  # Full path\n\n# Modify\nstore.set('12345678', 'folder/id12345678.smmx')\nstore.delete('12345678')\n\n# Iterate and count\nfor tree_id, path in store.items():\n    print(f\"{tree_id} -> {path}\")\nprint(f\"Total: {store.count()}\")\n```\n\nFor frequent lookups, use caching:\n\n```python\nfrom scripts.mindmap.index_store import CachedStore, SQLiteStore\n\nstore = CachedStore(SQLiteStore('index.db'), preload=True)\n```\n\nSee skill_mindmap_index.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_index_004_q1", "cluster_id": "skill_mindmap_index_004", "question": "How do I use the index store API?", "answer": "Use the index store API for programmatic access:\n\n```python\nfrom scripts.mindmap.index_store import create_index_store\n\nstore = create_index_store('index.json')  # Auto-detects format from extension\n\n# Lookup operations\npath = store.get('10390825')                    # Returns path or None\nexists = store.contains('10390825')             # Check if tree_id exists\nabs_path = store.resolve_path('10390825')       # Get absolute file path\n\n# Modification operations\nstore.set('12345678', 'folder/id12345678.smmx') # Add or update entry\nstore.delete('12345678')                         # Remove entry\n\n# Iteration and statistics\nfor tree_id, path in store.items():\n    print(f\"{tree_id} -> {path}\")\nprint(f\"Total entries: {store.count()}\")\n```\n\nThe API supports multiple storage backends (JSON, TSV, SQLite) with identical methods. For frequent lookups on large indexes, enable caching:\n\n```python\nfrom scripts.mindmap.index_store import CachedStore, SQLiteStore\n\nstore = CachedStore(SQLiteStore('index.db'), preload=True)\n```", "question_type": "long", "topics": ["Mindmap", "Mindmap Index"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["api", "python", "lookup", "caching"], "related_skills": ["skill_mindmap_index.md"], "related_docs": ["scripts/mindmap/index_store.py"], "original_answer": "Use the index store API for programmatic access:\n\n```python\nfrom scripts.mindmap.index_store import create_index_store\n\nstore = create_index_store('index.json')  # Auto-detects format\n\n# Lookup\npath = store.get('10390825')           # Get path or None\nexists = store.contains('10390825')    # Check existence\nabs_path = store.resolve_path('10390825')  # Full path\n\n# Modify\nstore.set('12345678', 'folder/id12345678.smmx')\nstore.delete('12345678')\n\n# Iterate and count\nfor tree_id, path in store.items():\n    print(f\"{tree_id} -> {path}\")\nprint(f\"Total: {store.count()}\")\n```\n\nFor frequent lookups, use caching:\n\n```python\nfrom scripts.mindmap.index_store import CachedStore, SQLiteStore\n\nstore = CachedStore(SQLiteStore('index.db'), preload=True)\n```\n\nSee skill_mindmap_index.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_index_004_q2", "cluster_id": "skill_mindmap_index_004", "question": "Can I check if a mindmap exists in the index?", "answer": "Yes, use the `contains()` method to check if a mindmap exists in the index:\n\n```python\nfrom scripts.mindmap.index_store import create_index_store\n\nstore = create_index_store('index.json')  # Auto-detects format (JSON, TSV, or SQLite)\nexists = store.contains('10390825')  # Returns True or False\n```\n\nAlternatively, you can use `get()` which returns the path if found or `None` if not:\n\n```python\npath = store.get('10390825')\nif path:\n    print(f\"Mindmap found at: {path}\")\nelse:\n    print(\"Mindmap not in index\")\n```\n\nFor shell scripts, use grep with the TSV format:\n\n```bash\ngrep \"^10390825\\t\" index.tsv && echo \"Found\" || echo \"Not found\"\n```\n\nOr with SQLite:\n\n```bash\nsqlite3 index.db \"SELECT EXISTS(SELECT 1 FROM mindmap_index WHERE tree_id='10390825')\"\n```", "question_type": "long", "topics": ["Mindmap", "Mindmap Index"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["api", "python", "lookup", "caching"], "related_skills": ["skill_mindmap_index.md"], "related_docs": ["scripts/mindmap/index_store.py"], "original_answer": "Use the index store API for programmatic access:\n\n```python\nfrom scripts.mindmap.index_store import create_index_store\n\nstore = create_index_store('index.json')  # Auto-detects format\n\n# Lookup\npath = store.get('10390825')           # Get path or None\nexists = store.contains('10390825')    # Check existence\nabs_path = store.resolve_path('10390825')  # Full path\n\n# Modify\nstore.set('12345678', 'folder/id12345678.smmx')\nstore.delete('12345678')\n\n# Iterate and count\nfor tree_id, path in store.items():\n    print(f\"{tree_id} -> {path}\")\nprint(f\"Total: {store.count()}\")\n```\n\nFor frequent lookups, use caching:\n\n```python\nfrom scripts.mindmap.index_store import CachedStore, SQLiteStore\n\nstore = CachedStore(SQLiteStore('index.db'), preload=True)\n```\n\nSee skill_mindmap_index.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_index_004_q3", "cluster_id": "skill_mindmap_index_004", "question": "How do I iterate through all indexed mindmaps?", "answer": "To iterate through all indexed mindmaps, use the index store API's `items()` method:\n\n```python\nfrom scripts.mindmap.index_store import create_index_store\n\nstore = create_index_store('index.json')  # Auto-detects format (JSON, TSV, or SQLite)\n\n# Iterate through all tree_id and path pairs\nfor tree_id, path in store.items():\n    print(f\"{tree_id} -> {path}\")\n\n# Get total count\nprint(f\"Total mindmaps: {store.count()}\")\n```\n\nThis works identically across all storage formats (JSON, TSV, SQLite). For large indexes with frequent access patterns, use caching:\n\n```python\nfrom scripts.mindmap.index_store import CachedStore, SQLiteStore\n\nstore = CachedStore(SQLiteStore('index.db'), preload=True)\nfor tree_id, path in store.items():\n    process(tree_id, path)\n```", "question_type": "long", "topics": ["Mindmap", "Mindmap Index"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["api", "python", "lookup", "caching"], "related_skills": ["skill_mindmap_index.md"], "related_docs": ["scripts/mindmap/index_store.py"], "original_answer": "Use the index store API for programmatic access:\n\n```python\nfrom scripts.mindmap.index_store import create_index_store\n\nstore = create_index_store('index.json')  # Auto-detects format\n\n# Lookup\npath = store.get('10390825')           # Get path or None\nexists = store.contains('10390825')    # Check existence\nabs_path = store.resolve_path('10390825')  # Full path\n\n# Modify\nstore.set('12345678', 'folder/id12345678.smmx')\nstore.delete('12345678')\n\n# Iterate and count\nfor tree_id, path in store.items():\n    print(f\"{tree_id} -> {path}\")\nprint(f\"Total: {store.count()}\")\n```\n\nFor frequent lookups, use caching:\n\n```python\nfrom scripts.mindmap.index_store import CachedStore, SQLiteStore\n\nstore = CachedStore(SQLiteStore('index.db'), preload=True)\n```\n\nSee skill_mindmap_index.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_index_005_q0", "cluster_id": "skill_mindmap_index_005", "question": "How do I use the index with other mindmap tools?", "answer": "To integrate the index with other mindmap tools, first build the index from your mindmap directory using `python3 scripts/mindmap/build_index.py output/mindmaps/ -o index.json`. Then pass this index to other tools:\n\n**Add cross-links between mindmaps:**\n```bash\npython3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx --index index.json\n```\n\n**Rename mindmaps with automatic backlink updates:**\n```bash\npython3 scripts/mindmap/rename_mindmap.py --mindmap output/mindmaps/id10390825.smmx --titled --index index.json\n```\n\n**Generate new mindmaps with automatic cloudmapref links:**\n```bash\npython3 scripts/generate_mindmap.py --data pearltrees.jsonl --output output/mindmaps/id12345.smmx --index index.json\n```\n\nThe `--index` flag tells each tool where to find the mindmap lookup table, enabling them to resolve tree IDs to file paths and maintain consistency across your mindmap collection.", "question_type": "long", "topics": ["Mindmap", "Mindmap Index"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["integration", "cross-links", "rename", "generator"], "related_skills": ["skill_mindmap_index.md", "skill_mindmap_rename.md", "skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/add_relative_links.py", "scripts/mindmap/rename_mindmap.py", "scripts/generate_mindmap.py"], "original_answer": "Integrate the index with other mindmap tools:\n\n**Add cross-links:**\n\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o index.json\npython3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx --index index.json\n```\n\n**Rename with automatic backlink updates:**\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py --mindmap output/mindmaps/id10390825.smmx --titled --index index.json\n```\n\n**Generate with automatic cloudmapref links:**\n\n```bash\npython3 scripts/generate_mindmap.py --data pearltrees.jsonl --output output/mindmaps/id12345.smmx --index index.json\n```\n\nSee skill_mindmap_index.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The answer assumes users have these specific tool scripts available (add_relative_links.py, rename_mindmap.py, generate_mindmap.py) but doesn't explain what each tool does or why you'd use them. It's practical but could benefit from brief descriptions of each integration use case."}
{"pair_id": "skill_mindmap_index_005_q1", "cluster_id": "skill_mindmap_index_005", "question": "How do I add cross-links using an index?", "answer": "To add cross-links using an index, first build the index from your mindmap directory, then use the add_relative_links script with the index parameter:\n\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o index.json\npython3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx --index index.json\n```\n\nThe index enables the tool to resolve tree IDs to file paths, allowing it to create relative links between mindmaps. You can also use the index when generating new mindmaps to automatically create cloudmapref links:\n\n```bash\npython3 scripts/generate_mindmap.py --data pearltrees.jsonl --output output/mindmaps/id12345.smmx --index index.json\n```", "question_type": "long", "topics": ["Mindmap", "Mindmap Index"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["integration", "cross-links", "rename", "generator"], "related_skills": ["skill_mindmap_index.md", "skill_mindmap_rename.md", "skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/add_relative_links.py", "scripts/mindmap/rename_mindmap.py", "scripts/generate_mindmap.py"], "original_answer": "Integrate the index with other mindmap tools:\n\n**Add cross-links:**\n\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o index.json\npython3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx --index index.json\n```\n\n**Rename with automatic backlink updates:**\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py --mindmap output/mindmaps/id10390825.smmx --titled --index index.json\n```\n\n**Generate with automatic cloudmapref links:**\n\n```bash\npython3 scripts/generate_mindmap.py --data pearltrees.jsonl --output output/mindmaps/id12345.smmx --index index.json\n```\n\nSee skill_mindmap_index.md for details.", "answer_tailored": true, "confidence": 0.75, "confidence_issues": "The base answer assumes add_relative_links.py exists and accepts --index parameter, but this is not confirmed in the skill document. The document shows index integration examples but doesn't explicitly document the cross-linking workflow or what parameters these scripts actually accept."}
{"pair_id": "skill_mindmap_index_005_q2", "cluster_id": "skill_mindmap_index_005", "question": "How do I pass the index to the mindmap generator?", "answer": "To pass the index to the mindmap generator, use the `--index` flag when running the generate command:\n\n```bash\npython3 scripts/generate_mindmap.py --data pearltrees.jsonl --output output/mindmaps/id12345.smmx --index index.json\n```\n\nFirst build your index from the mindmap directory:\n\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o index.json\n```\n\nThe generator will use this index to automatically create cloudmapref links to existing mindmaps, enabling cross-references between generated mindmaps and your existing collection.", "question_type": "long", "topics": ["Mindmap", "Mindmap Index"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["integration", "cross-links", "rename", "generator"], "related_skills": ["skill_mindmap_index.md", "skill_mindmap_rename.md", "skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/add_relative_links.py", "scripts/mindmap/rename_mindmap.py", "scripts/generate_mindmap.py"], "original_answer": "Integrate the index with other mindmap tools:\n\n**Add cross-links:**\n\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o index.json\npython3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx --index index.json\n```\n\n**Rename with automatic backlink updates:**\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py --mindmap output/mindmaps/id10390825.smmx --titled --index index.json\n```\n\n**Generate with automatic cloudmapref links:**\n\n```bash\npython3 scripts/generate_mindmap.py --data pearltrees.jsonl --output output/mindmaps/id12345.smmx --index index.json\n```\n\nSee skill_mindmap_index.md for details.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null}
{"pair_id": "skill_mindmap_index_005_q3", "cluster_id": "skill_mindmap_index_005", "question": "Can the rename tool use the index?", "answer": "Yes, the rename tool can use the index. When renaming a mindmap, pass the index file with the `--index` flag:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py --mindmap output/mindmaps/id10390825.smmx --titled --index index.json\n```\n\nThe index enables the rename tool to automatically update backlinks across other mindmaps that reference the renamed file. This ensures cross-references remain valid after renaming operations.", "question_type": "long", "topics": ["Mindmap", "Mindmap Index"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["integration", "cross-links", "rename", "generator"], "related_skills": ["skill_mindmap_index.md", "skill_mindmap_rename.md", "skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/add_relative_links.py", "scripts/mindmap/rename_mindmap.py", "scripts/generate_mindmap.py"], "original_answer": "Integrate the index with other mindmap tools:\n\n**Add cross-links:**\n\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o index.json\npython3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx --index index.json\n```\n\n**Rename with automatic backlink updates:**\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py --mindmap output/mindmaps/id10390825.smmx --titled --index index.json\n```\n\n**Generate with automatic cloudmapref links:**\n\n```bash\npython3 scripts/generate_mindmap.py --data pearltrees.jsonl --output output/mindmaps/id12345.smmx --index index.json\n```\n\nSee skill_mindmap_index.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer assumes the rename_mindmap.py script exists and supports the --index flag, but this is not explicitly verified in the provided skill document. The exact mechanism for how backlink updates work during rename is inferred rather than explicitly stated."}
{"pair_id": "skill_mindmap_index_006_q0", "cluster_id": "skill_mindmap_index_006", "question": "How do I query a SQLite mindmap index from the command line?", "answer": "Query SQLite mindmap indexes from the command line using sqlite3:\n\n```bash\n# Count all entries\nsqlite3 index.db \"SELECT COUNT(*) FROM mindmap_index\"\n\n# Find mindmap by tree ID\nsqlite3 index.db \"SELECT path FROM mindmap_index WHERE tree_id='10390825'\"\n\n# Find mindmaps by path pattern\nsqlite3 index.db \"SELECT * FROM mindmap_index WHERE path LIKE '%Physics%'\"\n```\n\nThe index uses this schema:\n- `mindmap_index` table with `tree_id` (PRIMARY KEY) and `path` columns\n- `metadata` table for storing index metadata\n\nFor simpler shell scripting, use TSV format instead:\n\n```bash\nawk -F'\\t' '$1 == \"10390825\" {print $2}' index.tsv\n```", "question_type": "long", "topics": ["Mindmap", "Mindmap Index"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["sqlite", "query", "sql", "command-line"], "related_skills": ["skill_mindmap_index.md"], "related_docs": ["scripts/mindmap/build_index.py"], "original_answer": "Query SQLite indexes directly:\n\n```bash\n# Count all entries\nsqlite3 index.db \"SELECT COUNT(*) FROM mindmap_index\"\n\n# Find by tree ID\nsqlite3 index.db \"SELECT path FROM mindmap_index WHERE tree_id='10390825'\"\n\n# Find by path pattern\nsqlite3 index.db \"SELECT * FROM mindmap_index WHERE path LIKE '%Physics%'\"\n```\n\nThe SQLite schema includes:\n- `mindmap_index` table with `tree_id` (PRIMARY KEY) and `path` columns\n- `metadata` table for storing index metadata\n\nFor awk-friendly querying, use TSV format instead:\n\n```bash\nawk -F'\\t' '$1 == \"10390825\" {print $2}' index.tsv\n```\n\nSee skill_mindmap_index.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_index_006_q1", "cluster_id": "skill_mindmap_index_006", "question": "How do I search the index with SQL?", "answer": "To search the mindmap index with SQL, query the SQLite database directly:\n\n```bash\n# Count all entries\nsqlite3 index.db \"SELECT COUNT(*) FROM mindmap_index\"\n\n# Find by tree ID\nsqlite3 index.db \"SELECT path FROM mindmap_index WHERE tree_id='10390825'\"\n\n# Find by path pattern\nsqlite3 index.db \"SELECT * FROM mindmap_index WHERE path LIKE '%Physics%'\"\n```\n\nThe index uses this schema:\n- `mindmap_index` table with `tree_id` (PRIMARY KEY) and `path` columns\n- `metadata` table for storing index metadata\n\nFor programmatic access in Python:\n\n```python\nimport sqlite3\nconn = sqlite3.connect('index.db')\ncursor = conn.cursor()\ncursor.execute('SELECT path FROM mindmap_index WHERE tree_id = ?', ('10390825',))\nresult = cursor.fetchone()\n```\n\nIf you prefer awk-compatible queries, use TSV format instead and query with awk or grep.", "question_type": "long", "topics": ["Mindmap", "Mindmap Index"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["sqlite", "query", "sql", "command-line"], "related_skills": ["skill_mindmap_index.md"], "related_docs": ["scripts/mindmap/build_index.py"], "original_answer": "Query SQLite indexes directly:\n\n```bash\n# Count all entries\nsqlite3 index.db \"SELECT COUNT(*) FROM mindmap_index\"\n\n# Find by tree ID\nsqlite3 index.db \"SELECT path FROM mindmap_index WHERE tree_id='10390825'\"\n\n# Find by path pattern\nsqlite3 index.db \"SELECT * FROM mindmap_index WHERE path LIKE '%Physics%'\"\n```\n\nThe SQLite schema includes:\n- `mindmap_index` table with `tree_id` (PRIMARY KEY) and `path` columns\n- `metadata` table for storing index metadata\n\nFor awk-friendly querying, use TSV format instead:\n\n```bash\nawk -F'\\t' '$1 == \"10390825\" {print $2}' index.tsv\n```\n\nSee skill_mindmap_index.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_index_006_q2", "cluster_id": "skill_mindmap_index_006", "question": "How do I count entries in a SQLite index?", "answer": "To count entries in a SQLite index, use:\n\n```bash\nsqlite3 index.db \"SELECT COUNT(*) FROM mindmap_index\"\n```\n\nThis queries the `mindmap_index` table which stores all tree_id and path mappings. The result shows the total number of mindmap entries in your index.\n\nIf you need to count entries matching specific criteria:\n\n```bash\n# Count entries with a specific path pattern\nsqlite3 index.db \"SELECT COUNT(*) FROM mindmap_index WHERE path LIKE '%Physics%'\"\n```", "question_type": "long", "topics": ["Mindmap", "Mindmap Index"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["sqlite", "query", "sql", "command-line"], "related_skills": ["skill_mindmap_index.md"], "related_docs": ["scripts/mindmap/build_index.py"], "original_answer": "Query SQLite indexes directly:\n\n```bash\n# Count all entries\nsqlite3 index.db \"SELECT COUNT(*) FROM mindmap_index\"\n\n# Find by tree ID\nsqlite3 index.db \"SELECT path FROM mindmap_index WHERE tree_id='10390825'\"\n\n# Find by path pattern\nsqlite3 index.db \"SELECT * FROM mindmap_index WHERE path LIKE '%Physics%'\"\n```\n\nThe SQLite schema includes:\n- `mindmap_index` table with `tree_id` (PRIMARY KEY) and `path` columns\n- `metadata` table for storing index metadata\n\nFor awk-friendly querying, use TSV format instead:\n\n```bash\nawk -F'\\t' '$1 == \"10390825\" {print $2}' index.tsv\n```\n\nSee skill_mindmap_index.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_index_006_q3", "cluster_id": "skill_mindmap_index_006", "question": "How do I find mindmaps by path pattern?", "answer": "To find mindmaps by path pattern, query the SQLite index using LIKE clauses:\n\n```bash\n# Find all mindmaps with 'Physics' in the path\nsqlite3 index.db \"SELECT * FROM mindmap_index WHERE path LIKE '%Physics%'\"\n\n# Find mindmaps in a specific directory\nsqlite3 index.db \"SELECT * FROM mindmap_index WHERE path LIKE 'Gods_of_Earth_and_Nature/%'\"\n```\n\nFor TSV format, use grep or awk instead:\n\n```bash\n# Find paths containing 'Physics'\ngrep 'Physics' index.tsv\n\n# Extract tree IDs for paths matching a pattern\nawk -F'\\t' '$2 ~ /Physics/ {print $1}' index.tsv\n```\n\nIf using the Python API:\n\n```python\nfrom scripts.mindmap.index_store import create_index_store\n\nstore = create_index_store('index.db')\n# Use raw SQL for pattern matching\nresults = store.db.execute(\n    \"SELECT * FROM mindmap_index WHERE path LIKE ?\",\n    ('%Physics%',)\n).fetchall()\n```", "question_type": "long", "topics": ["Mindmap", "Mindmap Index"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["sqlite", "query", "sql", "command-line"], "related_skills": ["skill_mindmap_index.md"], "related_docs": ["scripts/mindmap/build_index.py"], "original_answer": "Query SQLite indexes directly:\n\n```bash\n# Count all entries\nsqlite3 index.db \"SELECT COUNT(*) FROM mindmap_index\"\n\n# Find by tree ID\nsqlite3 index.db \"SELECT path FROM mindmap_index WHERE tree_id='10390825'\"\n\n# Find by path pattern\nsqlite3 index.db \"SELECT * FROM mindmap_index WHERE path LIKE '%Physics%'\"\n```\n\nThe SQLite schema includes:\n- `mindmap_index` table with `tree_id` (PRIMARY KEY) and `path` columns\n- `metadata` table for storing index metadata\n\nFor awk-friendly querying, use TSV format instead:\n\n```bash\nawk -F'\\t' '$1 == \"10390825\" {print $2}' index.tsv\n```\n\nSee skill_mindmap_index.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_indexing_001_q0", "cluster_id": "skill_mindmap_indexing_001", "question": "How do I track where all my mindmaps are located?", "answer": "Use the forward index builder to map tree IDs to file paths:\n\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o index.json\n```\n\nThis creates a JSON file that maps each mindmap's tree ID to its file path, so you can quickly look up any mindmap's location by ID. The output format is auto-detected from the extension\u2014use `.json` for human-readable output, `.tsv` for shell scripting, or `.db` for SQLite if you have a large number of mindmaps.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Indexing"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["indexing", "lookup", "file-tracking"], "related_skills": ["skill_mindmap_indexing.md"], "related_docs": ["scripts/mindmap/build_index.py", "scripts/mindmap/index_store.py"], "original_answer": "Use the forward index builder to map tree IDs to file paths:\n\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o index.json\n```\n\nThis creates a JSON file showing where each mindmap is stored, making it easy to look up locations by ID. You can also use TSV or SQLite format by changing the output extension. See skill_mindmap_indexing.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_indexing_001_q1", "cluster_id": "skill_mindmap_indexing_001", "question": "How can I find a mindmap by its ID?", "answer": "Use the forward index builder to map tree IDs to file paths:\n\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o index.json\n```\n\nThis creates a JSON file with a mapping like:\n```json\n{\n  \"index\": {\n    \"10390825\": \"Physics/id10390825.smmx\",\n    \"75009241\": \"Math/id75009241.smmx\"\n  }\n}\n```\n\nYou can then look up any tree ID to find its file path. The output format can be JSON, TSV, or SQLite by changing the output file extension.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Indexing"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["indexing", "lookup", "file-tracking"], "related_skills": ["skill_mindmap_indexing.md"], "related_docs": ["scripts/mindmap/build_index.py", "scripts/mindmap/index_store.py"], "original_answer": "Use the forward index builder to map tree IDs to file paths:\n\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o index.json\n```\n\nThis creates a JSON file showing where each mindmap is stored, making it easy to look up locations by ID. You can also use TSV or SQLite format by changing the output extension. See skill_mindmap_indexing.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_indexing_001_q2", "cluster_id": "skill_mindmap_indexing_001", "question": "How do I build an index of my mindmap locations?", "answer": "Use the forward index builder to map tree IDs to file paths:\n\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o index.json\n```\n\nThis creates a JSON file mapping each tree ID to its file path. For example:\n```json\n{\n  \"index\": {\n    \"10390825\": \"Physics/id10390825.smmx\",\n    \"75009241\": \"Math/id75009241.smmx\"\n  }\n}\n```\n\nYou can also use TSV or SQLite format by changing the output file extension to `.tsv` or `.db` respectively. Use JSON for development and human-readable output, TSV for shell script processing, or SQLite for large indexes with frequent queries.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Indexing"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["indexing", "lookup", "file-tracking"], "related_skills": ["skill_mindmap_indexing.md"], "related_docs": ["scripts/mindmap/build_index.py", "scripts/mindmap/index_store.py"], "original_answer": "Use the forward index builder to map tree IDs to file paths:\n\n```bash\npython3 scripts/mindmap/build_index.py output/mindmaps/ -o index.json\n```\n\nThis creates a JSON file showing where each mindmap is stored, making it easy to look up locations by ID. You can also use TSV or SQLite format by changing the output extension. See skill_mindmap_indexing.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_indexing_002_q0", "cluster_id": "skill_mindmap_indexing_002", "question": "How do I find out what mindmaps reference a specific mindmap?", "answer": "Build a reverse index to track which mindmaps reference a specific mindmap:\n\n```bash\npython3 scripts/mindmap/build_reverse_index.py output/mindmaps/ -o backlinks.json\n```\n\nThe resulting `backlinks.json` file maps each mindmap ID to a list of mindmap IDs that reference it. For example:\n\n```json\n{\n  \"10390825\": [\"75009241\", \"12345678\"]\n}\n```\n\nThis tells you that mindmap 10390825 is referenced by mindmaps 75009241 and 12345678. The reverse index lets you quickly identify all dependencies pointing to a specific mindmap.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Indexing"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["backlinks", "references", "dependencies"], "related_skills": ["skill_mindmap_indexing.md"], "related_docs": ["scripts/mindmap/build_reverse_index.py", "scripts/mindmap/index_store.py"], "original_answer": "Build a reverse index to track which mindmaps reference which:\n\n```bash\npython3 scripts/mindmap/build_reverse_index.py output/mindmaps/ -o backlinks.json\n```\n\nThe result shows which mindmaps link to each other. For example, if mindmap 10390825 is referenced by 75009241, the reverse index will list that relationship. This helps you understand the dependency graph between your mindmaps. See skill_mindmap_indexing.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_indexing_002_q1", "cluster_id": "skill_mindmap_indexing_002", "question": "How can I see backlinks between mindmaps?", "answer": "Build a reverse index to track which mindmaps reference which:\n\n```bash\npython3 scripts/mindmap/build_reverse_index.py output/mindmaps/ -o backlinks.json\n```\n\nThis generates a JSON file where each tree ID maps to a list of mindmaps that reference it. For example:\n\n```json\n{\n  \"10390825\": [\"75009241\", \"12345678\"],\n  \"75009241\": [\"10390825\"]\n}\n```\n\nThis means mindmap 10390825 is referenced by mindmaps 75009241 and 12345678, while 75009241 is referenced by 10390825. This reverse mapping lets you see the dependency graph and understand which mindmaps depend on each other.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Indexing"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["backlinks", "references", "dependencies"], "related_skills": ["skill_mindmap_indexing.md"], "related_docs": ["scripts/mindmap/build_reverse_index.py", "scripts/mindmap/index_store.py"], "original_answer": "Build a reverse index to track which mindmaps reference which:\n\n```bash\npython3 scripts/mindmap/build_reverse_index.py output/mindmaps/ -o backlinks.json\n```\n\nThe result shows which mindmaps link to each other. For example, if mindmap 10390825 is referenced by 75009241, the reverse index will list that relationship. This helps you understand the dependency graph between your mindmaps. See skill_mindmap_indexing.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_indexing_002_q2", "cluster_id": "skill_mindmap_indexing_002", "question": "Which mindmaps link to this one?", "answer": "Build a reverse index to track which mindmaps reference a specific one:\n\n```bash\npython3 scripts/mindmap/build_reverse_index.py output/mindmaps/ -o backlinks.json\n```\n\nThe reverse index maps tree IDs to the mindmaps that link to them. For example, if you want to know which mindmaps link to mindmap 10390825, the reverse index will show you all the IDs that reference it (e.g., [75009241, 12345678]). This helps you understand the dependency graph and trace all incoming references to a specific mindmap.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Indexing"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["backlinks", "references", "dependencies"], "related_skills": ["skill_mindmap_indexing.md"], "related_docs": ["scripts/mindmap/build_reverse_index.py", "scripts/mindmap/index_store.py"], "original_answer": "Build a reverse index to track which mindmaps reference which:\n\n```bash\npython3 scripts/mindmap/build_reverse_index.py output/mindmaps/ -o backlinks.json\n```\n\nThe result shows which mindmaps link to each other. For example, if mindmap 10390825 is referenced by 75009241, the reverse index will list that relationship. This helps you understand the dependency graph between your mindmaps. See skill_mindmap_indexing.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_indexing_003_q0", "cluster_id": "skill_mindmap_indexing_003", "question": "I renamed a mindmap file - how do I update all the links to it?", "answer": "Use the rename tool with your index to automatically update all references:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --mindmap output/mindmaps/id10390825.smmx \\\n  --new-name \"Quantum_Physics_10390825.smmx\" \\\n  --index index.json\n```\n\nThis command renames the file and automatically updates all `cloudmapref` attributes in other mindmaps that reference it. For batch renaming or additional options, see skill_mindmap_rename.md.", "question_type": "long", "topics": ["Mindmap", "Mindmap Indexing"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["renaming", "file-operations", "link-updates"], "related_skills": ["skill_mindmap_indexing.md", "skill_mindmap_rename.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py"], "original_answer": "Use the rename tool with your index to automatically update all references:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --mindmap output/mindmaps/id10390825.smmx \\\n  --new-name \"Quantum_Physics_10390825.smmx\" \\\n  --index index.json\n```\n\nThis renames the file and automatically updates all `cloudmapref` attributes in mindmaps that reference it. See skill_mindmap_rename.md for batch renaming and other options. See skill_mindmap_indexing.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_indexing_003_q1", "cluster_id": "skill_mindmap_indexing_003", "question": "How do I rename a mindmap without breaking cross-references?", "answer": "Use the rename tool with your index to automatically update all references:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --mindmap output/mindmaps/id10390825.smmx \\\n  --new-name \"Quantum_Physics_10390825.smmx\" \\\n  --index index.json\n```\n\nThis renames the file and automatically updates all `cloudmapref` attributes in any mindmaps that reference it. For batch renaming or additional options, refer to skill_mindmap_rename.md.", "question_type": "long", "topics": ["Mindmap", "Mindmap Indexing"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["renaming", "file-operations", "link-updates"], "related_skills": ["skill_mindmap_indexing.md", "skill_mindmap_rename.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py"], "original_answer": "Use the rename tool with your index to automatically update all references:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --mindmap output/mindmaps/id10390825.smmx \\\n  --new-name \"Quantum_Physics_10390825.smmx\" \\\n  --index index.json\n```\n\nThis renames the file and automatically updates all `cloudmapref` attributes in mindmaps that reference it. See skill_mindmap_rename.md for batch renaming and other options. See skill_mindmap_indexing.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_indexing_003_q2", "cluster_id": "skill_mindmap_indexing_003", "question": "What's the best way to rename a mindmap safely?", "answer": "Use the rename tool with your index to automatically update all references. Run:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --mindmap output/mindmaps/id10390825.smmx \\\n  --new-name \"Quantum_Physics_10390825.smmx\" \\\n  --index index.json\n```\n\nThis renames the file and automatically updates all `cloudmapref` attributes in mindmaps that reference it, preventing broken links. For batch renaming or other options, see skill_mindmap_rename.md.", "question_type": "long", "topics": ["Mindmap", "Mindmap Indexing"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["renaming", "file-operations", "link-updates"], "related_skills": ["skill_mindmap_indexing.md", "skill_mindmap_rename.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py"], "original_answer": "Use the rename tool with your index to automatically update all references:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --mindmap output/mindmaps/id10390825.smmx \\\n  --new-name \"Quantum_Physics_10390825.smmx\" \\\n  --index index.json\n```\n\nThis renames the file and automatically updates all `cloudmapref` attributes in mindmaps that reference it. See skill_mindmap_rename.md for batch renaming and other options. See skill_mindmap_indexing.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_indexing_004_q0", "cluster_id": "skill_mindmap_indexing_004", "question": "What's the best format for storing my mindmap index - JSON, TSV, or SQLite?", "answer": "Choose your mindmap index format based on your specific needs:\n\n**JSON** - Best for development and small-to-medium indexes. It's human-readable, easy to inspect and edit manually, and works well when you're actively developing the indexing system.\n\n**TSV** - Ideal if you plan to process indexes with shell scripts, awk, grep, or other command-line text tools. It integrates seamlessly into Unix pipelines.\n\n**SQLite** - Recommended for large indexes, applications requiring frequent queries, or multi-process access where concurrent read/write is needed.\n\nThe build tool auto-detects your choice by file extension:\n```bash\npython3 scripts/mindmap/build_index.py output/ -o index.json   # JSON\npython3 scripts/mindmap/build_index.py output/ -o index.tsv    # TSV\npython3 scripts/mindmap/build_index.py output/ -o index.db     # SQLite\n```\n\nStart with JSON for simplicity, then migrate to TSV or SQLite if your use case requires it.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Indexing"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["storage", "formats", "performance"], "related_skills": ["skill_mindmap_indexing.md"], "related_docs": ["scripts/mindmap/index_store.py"], "original_answer": "Choose based on your use case:\n\n- **JSON**: Good for development and small indexes, human-readable\n- **TSV**: Works well with shell scripts and text processing tools\n- **SQLite**: Best for large indexes, frequent queries, and concurrent access\n\nThe tool auto-detects the format by file extension:\n\n```bash\npython3 scripts/mindmap/build_index.py output/ -o index.json   # JSON\npython3 scripts/mindmap/build_index.py output/ -o index.tsv    # TSV\npython3 scripts/mindmap/build_index.py output/ -o index.db     # SQLite\n```\n\nSee skill_mindmap_indexing.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_indexing_004_q1", "cluster_id": "skill_mindmap_indexing_004", "question": "Should I use JSON or SQLite for my index?", "answer": "Choose your index format based on your use case:\n\n- **JSON**: Best for development and small indexes. Human-readable, easy to inspect and modify manually.\n- **TSV**: Works well if you process indexes with shell scripts, awk, or grep.\n- **SQLite**: Best for large indexes, frequent queries, and concurrent access from multiple processes.\n\nThe tool auto-detects the format by file extension:\n\n```bash\npython3 scripts/mindmap/build_index.py output/ -o index.json   # JSON\npython3 scripts/mindmap/build_index.py output/ -o index.tsv    # TSV\npython3 scripts/mindmap/build_index.py output/ -o index.db     # SQLite\n```", "question_type": "medium", "topics": ["Mindmap", "Mindmap Indexing"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["storage", "formats", "performance"], "related_skills": ["skill_mindmap_indexing.md"], "related_docs": ["scripts/mindmap/index_store.py"], "original_answer": "Choose based on your use case:\n\n- **JSON**: Good for development and small indexes, human-readable\n- **TSV**: Works well with shell scripts and text processing tools\n- **SQLite**: Best for large indexes, frequent queries, and concurrent access\n\nThe tool auto-detects the format by file extension:\n\n```bash\npython3 scripts/mindmap/build_index.py output/ -o index.json   # JSON\npython3 scripts/mindmap/build_index.py output/ -o index.tsv    # TSV\npython3 scripts/mindmap/build_index.py output/ -o index.db     # SQLite\n```\n\nSee skill_mindmap_indexing.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_indexing_004_q2", "cluster_id": "skill_mindmap_indexing_004", "question": "Which storage format is best for large mindmap collections?", "answer": "For large mindmap collections, SQLite is the best storage format. It's optimized for large indexes, handles frequent queries efficiently, and supports concurrent access. JSON works well for development and small indexes but becomes unwieldy as your collection grows. TSV is useful for shell scripting and text processing but isn't ideal for large-scale queries.\n\nTo use SQLite, simply use a .db extension when building your index:\n\n```bash\npython3 scripts/mindmap/build_index.py output/ -o index.db\n```\n\nThe tool auto-detects the format by file extension, so no additional configuration is needed.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Indexing"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["storage", "formats", "performance"], "related_skills": ["skill_mindmap_indexing.md"], "related_docs": ["scripts/mindmap/index_store.py"], "original_answer": "Choose based on your use case:\n\n- **JSON**: Good for development and small indexes, human-readable\n- **TSV**: Works well with shell scripts and text processing tools\n- **SQLite**: Best for large indexes, frequent queries, and concurrent access\n\nThe tool auto-detects the format by file extension:\n\n```bash\npython3 scripts/mindmap/build_index.py output/ -o index.json   # JSON\npython3 scripts/mindmap/build_index.py output/ -o index.tsv    # TSV\npython3 scripts/mindmap/build_index.py output/ -o index.db     # SQLite\n```\n\nSee skill_mindmap_indexing.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_indexing_005_q0", "cluster_id": "skill_mindmap_indexing_005", "question": "I reorganized my mindmap folders - how do I make sure my index is still valid?", "answer": "After reorganizing your mindmap folders, rebuild your index and update the cross-links to ensure validity:\n\n1. Rebuild the forward index to map tree IDs to their new file paths:\n```bash\npython3 scripts/mindmap/build_index.py output/organized/ -o index.json\n```\n\n2. Update all cloudmapref links in your mindmaps to use the new relative paths:\n```bash\npython3 scripts/mindmap/add_relative_links.py output/organized/**/*.smmx \\\n  --index index.json --update\n```\n\n3. Verify that your index and files are consistent:\n```bash\npython3 scripts/mindmap/verify_index.py --index index.json --dir output/\n```\n\nThis ensures that all tree ID mappings reflect the new folder structure and all cross-references (cloudmapref attributes) point to valid locations.", "question_type": "long", "topics": ["Mindmap", "Mindmap Indexing"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["reorganization", "consistency", "verification"], "related_skills": ["skill_mindmap_indexing.md", "skill_mindmap_organization.md"], "related_docs": ["scripts/mindmap/build_index.py", "scripts/mindmap/add_relative_links.py"], "original_answer": "After reorganizing folders, rebuild your index and update the cross-links:\n\n```bash\n# 1. Rebuild the forward index\npython3 scripts/mindmap/build_index.py output/organized/ -o index.json\n\n# 2. Update cloudmapref links to use new paths\npython3 scripts/mindmap/add_relative_links.py output/organized/**/*.smmx \\\n  --index index.json --update\n```\n\nYou can also verify consistency with:\n\n```bash\npython3 scripts/mindmap/verify_index.py --index index.json --dir output/\n```\n\nSee skill_mindmap_indexing.md for details.", "answer_tailored": true, "confidence": 0.75, "confidence_issues": "The base answer assumes add_relative_links.py exists and works as described, but this script is not mentioned in the provided skill document excerpt. The verify_index.py script is also assumed to exist. Without confirmation these tools are available, confidence is moderately reduced."}
{"pair_id": "skill_mindmap_indexing_005_q1", "cluster_id": "skill_mindmap_indexing_005", "question": "How do I rebuild the index after moving files?", "answer": "After reorganizing folders, rebuild your index and update the cross-links:\n\n```bash\n# 1. Rebuild the forward index\npython3 scripts/mindmap/build_index.py output/organized/ -o index.json\n\n# 2. Update cloudmapref links to use new paths\npython3 scripts/mindmap/add_relative_links.py output/organized/**/*.smmx \\\n  --index index.json --update\n```\n\nYou can also verify consistency with:\n\n```bash\npython3 scripts/mindmap/verify_index.py --index index.json --dir output/\n```\n\nThe rebuild process:\n1. Scans the new directory structure to map tree IDs to their new file paths\n2. Updates all cloudmapref attributes in mindmaps to reflect the reorganized paths\n3. Verifies that all cross-links remain valid after the move\n\nFor detailed information about the indexing system and storage backend options, see skill_mindmap_indexing.md.", "question_type": "long", "topics": ["Mindmap", "Mindmap Indexing"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["reorganization", "consistency", "verification"], "related_skills": ["skill_mindmap_indexing.md", "skill_mindmap_organization.md"], "related_docs": ["scripts/mindmap/build_index.py", "scripts/mindmap/add_relative_links.py"], "original_answer": "After reorganizing folders, rebuild your index and update the cross-links:\n\n```bash\n# 1. Rebuild the forward index\npython3 scripts/mindmap/build_index.py output/organized/ -o index.json\n\n# 2. Update cloudmapref links to use new paths\npython3 scripts/mindmap/add_relative_links.py output/organized/**/*.smmx \\\n  --index index.json --update\n```\n\nYou can also verify consistency with:\n\n```bash\npython3 scripts/mindmap/verify_index.py --index index.json --dir output/\n```\n\nSee skill_mindmap_indexing.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer references 'add_relative_links.py' and 'verify_index.py' scripts that are not documented in the provided skill document excerpt. The actual implementation details of what these scripts do and whether they exist in the codebase are unclear, reducing confidence in the technical accuracy of the specific command syntax."}
{"pair_id": "skill_mindmap_indexing_005_q2", "cluster_id": "skill_mindmap_indexing_005", "question": "What should I do after reorganizing my mindmap structure?", "answer": "After reorganizing your mindmap structure, follow these steps to maintain index consistency:\n\n1. **Rebuild the forward index** to map tree IDs to their new file paths:\n```bash\npython3 scripts/mindmap/build_index.py output/organized/ -o index.json\n```\n\n2. **Update all cloudmapref links** to use the new paths:\n```bash\npython3 scripts/mindmap/add_relative_links.py output/organized/**/*.smmx \\\n  --index index.json --update\n```\n\n3. **Verify consistency** to ensure all references are valid:\n```bash\npython3 scripts/mindmap/verify_index.py --index index.json --dir output/\n```\n\nThis ensures that all cross-references between mindmaps remain valid after moving or reorganizing files. The index tracks tree ID locations, and the update script automatically fixes any broken cloudmapref paths.", "question_type": "long", "topics": ["Mindmap", "Mindmap Indexing"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["reorganization", "consistency", "verification"], "related_skills": ["skill_mindmap_indexing.md", "skill_mindmap_organization.md"], "related_docs": ["scripts/mindmap/build_index.py", "scripts/mindmap/add_relative_links.py"], "original_answer": "After reorganizing folders, rebuild your index and update the cross-links:\n\n```bash\n# 1. Rebuild the forward index\npython3 scripts/mindmap/build_index.py output/organized/ -o index.json\n\n# 2. Update cloudmapref links to use new paths\npython3 scripts/mindmap/add_relative_links.py output/organized/**/*.smmx \\\n  --index index.json --update\n```\n\nYou can also verify consistency with:\n\n```bash\npython3 scripts/mindmap/verify_index.py --index index.json --dir output/\n```\n\nSee skill_mindmap_indexing.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer references 'add_relative_links.py' which may not be the primary tool for updating cross-links post-reorganization. The 'rename_mindmap.py' tool mentioned in the skill document might be more appropriate for systematic updates. Additionally, 'verify_index.py' availability is not confirmed in the provided skill document."}
{"pair_id": "skill_mindmap_indexing_006_q0", "cluster_id": "skill_mindmap_indexing_006", "question": "How do I batch rename multiple mindmaps to include their titles?", "answer": "Use the batch rename feature with the `--titled` flag to rename multiple mindmaps to include their titles:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --batch output/mindmaps/ \\\n  --titled \\\n  --index index.json\n```\n\nThis renames all mindmaps from `id12345.smmx` format to `Title_12345.smmx` format, automatically updating all `cloudmapref` references in other mindmaps. Ensure your index is up-to-date before running this command.", "question_type": "long", "topics": ["Mindmap", "Mindmap Indexing"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["batch-operations", "renaming", "titled-format"], "related_skills": ["skill_mindmap_indexing.md", "skill_mindmap_rename.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py"], "original_answer": "Use the batch rename feature with the `--titled` flag:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --batch output/mindmaps/ \\\n  --titled \\\n  --index index.json\n```\n\nThis renames all mindmaps from the format `id12345.smmx` to `Title_12345.smmx` and automatically updates all references in other mindmaps to point to the new names. Make sure you have an up-to-date index before running this. See skill_mindmap_indexing.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer references 'skill_mindmap_indexing.md' but the skill document provided is 'skill_mindmap_indexing' (the .md extension may be implied). Also, the batch rename feature with `--titled` flag is mentioned but not fully documented in the provided skill document excerpt, which is truncated."}
{"pair_id": "skill_mindmap_indexing_006_q1", "cluster_id": "skill_mindmap_indexing_006", "question": "Can I rename all my mindmaps from id12345.smmx to Title_12345.smmx at once?", "answer": "Yes, you can rename all your mindmaps from id12345.smmx to Title_12345.smmx at once using the batch rename feature. Run:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --batch output/mindmaps/ \\\n  --titled \\\n  --index index.json\n```\n\nThis renames all mindmaps to the Title_ID format and automatically updates all cloudmapref references in other mindmaps to point to the new names. Ensure your index is up-to-date before running this command.", "question_type": "long", "topics": ["Mindmap", "Mindmap Indexing"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["batch-operations", "renaming", "titled-format"], "related_skills": ["skill_mindmap_indexing.md", "skill_mindmap_rename.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py"], "original_answer": "Use the batch rename feature with the `--titled` flag:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --batch output/mindmaps/ \\\n  --titled \\\n  --index index.json\n```\n\nThis renames all mindmaps from the format `id12345.smmx` to `Title_12345.smmx` and automatically updates all references in other mindmaps to point to the new names. Make sure you have an up-to-date index before running this. See skill_mindmap_indexing.md for details.", "answer_tailored": true, "confidence": 0.75, "confidence_issues": "The base answer references skill_mindmap_indexing.md which doesn't exist in the provided skill document (only skill_mindmap_index.md and skill_mindmap_rename.md are mentioned). The batch rename feature with --titled flag is documented but not extensively detailed in the provided skill document excerpt, so confidence in the exact command syntax is moderate."}
{"pair_id": "skill_mindmap_indexing_006_q2", "cluster_id": "skill_mindmap_indexing_006", "question": "What's the quickest way to rename many mindmaps with titles?", "answer": "Use the batch rename feature with the `--titled` flag to rename many mindmaps at once:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --batch output/mindmaps/ \\\n  --titled \\\n  --index index.json\n```\n\nThis renames all mindmaps from `id12345.smmx` format to `Title_12345.smmx` using their titles, and automatically updates all `cloudmapref` references in other mindmaps to point to the new names. Ensure you have an up-to-date index before running this command.", "question_type": "long", "topics": ["Mindmap", "Mindmap Indexing"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["batch-operations", "renaming", "titled-format"], "related_skills": ["skill_mindmap_indexing.md", "skill_mindmap_rename.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py"], "original_answer": "Use the batch rename feature with the `--titled` flag:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --batch output/mindmaps/ \\\n  --titled \\\n  --index index.json\n```\n\nThis renames all mindmaps from the format `id12345.smmx` to `Title_12345.smmx` and automatically updates all references in other mindmaps to point to the new names. Make sure you have an up-to-date index before running this. See skill_mindmap_indexing.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "The base answer references a `--titled` flag and batch rename feature, but the skill document doesn't show these exact flags being demonstrated. The rename script shown uses `--mindmap` with a single file, not `--batch`. The batch functionality and `--titled` flag appear to exist based on the context, but aren't fully documented in the provided skill document excerpt, creating uncertainty about exact syntax and behavior."}
{"pair_id": "skill_mindmap_linking_001_q0", "cluster_id": "skill_mindmap_linking_001", "question": "How do I connect my exported mindmap to Pearltrees?", "answer": "Use the mindmap linking tool to automatically connect your mindmap to Pearltrees. Run this command:\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"your_mindmap.txt\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --projection-model models/pearltrees_federated_nomic.pkl \\\n  --output \"output_mindmap.txt\"\n```\n\nThis matches your mindmap nodes to Pearltrees content using semantic matching and adds child nodes with labels: PP (PearlPage URL match), PT (exact title match), or PT? (fuzzy semantic match).", "question_type": "medium", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "linking", "pearltrees", "semantic-matching"], "related_skills": ["skill_mindmap_linking.md", "skill_bookmark_filing.md", "skill_semantic_inference.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/README.md", "scripts/mindmap/link_pearltrees.py"], "original_answer": "Use the mindmap linking tool to automatically connect your mindmap to Pearltrees. Start with the basic command:\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"your_mindmap.txt\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --projection-model models/pearltrees_federated_nomic.pkl \\\n  --output \"output_mindmap.txt\"\n```\n\nThis matches mindmap nodes to Pearltrees content using semantic matching and creates child nodes with labels indicating the match type (PP for PearlPage, PT for Pearltree, PT? for fuzzy matches). See skill_mindmap_linking.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_001_q1", "cluster_id": "skill_mindmap_linking_001", "question": "How can I link a mindmap to Pearltrees?", "answer": "Use the mindmap linking tool to automatically connect your mindmap to Pearltrees. The basic command is:\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"your_mindmap.txt\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --output \"output_mindmap.txt\"\n```\n\nThis matches mindmap nodes to Pearltrees content by title. For semantic matching, add the projection model:\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"your_mindmap.txt\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --projection-model models/pearltrees_federated_nomic.pkl \\\n  --output \"output_mindmap.txt\"\n```\n\nMatched nodes are added as children with labels: PP (PearlPage - URL match), PT (Pearltree - exact title match), or PT? (fuzzy semantic match). Use `--help` to see all options including URL matching, custom thresholds, and dry-run mode.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "linking", "pearltrees", "semantic-matching"], "related_skills": ["skill_mindmap_linking.md", "skill_bookmark_filing.md", "skill_semantic_inference.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/README.md", "scripts/mindmap/link_pearltrees.py"], "original_answer": "Use the mindmap linking tool to automatically connect your mindmap to Pearltrees. Start with the basic command:\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"your_mindmap.txt\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --projection-model models/pearltrees_federated_nomic.pkl \\\n  --output \"output_mindmap.txt\"\n```\n\nThis matches mindmap nodes to Pearltrees content using semantic matching and creates child nodes with labels indicating the match type (PP for PearlPage, PT for Pearltree, PT? for fuzzy matches). See skill_mindmap_linking.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_001_q2", "cluster_id": "skill_mindmap_linking_001", "question": "Can I enrich my mindmap with Pearltrees links?", "answer": "Yes, you can enrich your mindmap with Pearltrees links using the mindmap linking tool. Run this command to automatically connect your mindmap nodes to Pearltrees content:\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"your_mindmap.txt\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --projection-model models/pearltrees_federated_nomic.pkl \\\n  --output \"output_mindmap.txt\"\n```\n\nThe tool matches mindmap nodes to Pearltrees content using semantic matching and adds child nodes with labels indicating the match type: PP (PearlPage - URL match), PT (Pearltree - exact title match), or PT? (fuzzy semantic match). For more options and advanced features like URL matching or dry runs, see the skill documentation.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "linking", "pearltrees", "semantic-matching"], "related_skills": ["skill_mindmap_linking.md", "skill_bookmark_filing.md", "skill_semantic_inference.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/README.md", "scripts/mindmap/link_pearltrees.py"], "original_answer": "Use the mindmap linking tool to automatically connect your mindmap to Pearltrees. Start with the basic command:\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"your_mindmap.txt\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --projection-model models/pearltrees_federated_nomic.pkl \\\n  --output \"output_mindmap.txt\"\n```\n\nThis matches mindmap nodes to Pearltrees content using semantic matching and creates child nodes with labels indicating the match type (PP for PearlPage, PT for Pearltree, PT? for fuzzy matches). See skill_mindmap_linking.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_001_q3", "cluster_id": "skill_mindmap_linking_001", "question": "How do I add Pearltrees connections to my mindmap?", "answer": "Use the mindmap linking tool to automatically connect your mindmap to Pearltrees. Run this command:\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"your_mindmap.txt\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --projection-model models/pearltrees_federated_nomic.pkl \\\n  --output \"output_mindmap.txt\"\n```\n\nThis matches your mindmap nodes to Pearltrees content using semantic matching and adds child nodes with labels showing the match type:\n- **PP**: PearlPage (URL match)\n- **PT**: Pearltree (exact title match)\n- **PT?**: Pearltree (fuzzy semantic match)\n\nFor simpler title-only matching without the projection model, omit the `--projection-model` flag. For advanced options like URL matching or custom thresholds, see the skill documentation.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "linking", "pearltrees", "semantic-matching"], "related_skills": ["skill_mindmap_linking.md", "skill_bookmark_filing.md", "skill_semantic_inference.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/README.md", "scripts/mindmap/link_pearltrees.py"], "original_answer": "Use the mindmap linking tool to automatically connect your mindmap to Pearltrees. Start with the basic command:\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"your_mindmap.txt\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --projection-model models/pearltrees_federated_nomic.pkl \\\n  --output \"output_mindmap.txt\"\n```\n\nThis matches mindmap nodes to Pearltrees content using semantic matching and creates child nodes with labels indicating the match type (PP for PearlPage, PT for Pearltree, PT? for fuzzy matches). See skill_mindmap_linking.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_002_q0", "cluster_id": "skill_mindmap_linking_002", "question": "What's the difference between the different match labels (PP, PT, PT?)?", "answer": "When linking mindmaps to Pearltrees, nodes receive labels indicating the match type:\n\n- **PP (PearlPage)**: The node's URL directly matches a PagePearl's external URL. Requires `--url-db` flag to enable.\n- **PT (Pearltree)**: An exact title match with a Pearltree, including disambiguated titles.\n- **PT? (Pearltree fuzzy)**: A semantic similarity match scoring above the threshold (default 0.7). Requires `--embeddings` and `--projection-model` flags.\n\nUse `--url-db`, `--embeddings`, and `--projection-model` flags to enable all matching types.", "question_type": "long", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["matching", "labels", "semantic-search", "url-matching"], "related_skills": ["skill_mindmap_linking.md", "skill_semantic_inference.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/link_pearltrees.py"], "original_answer": "When linking mindmaps, nodes are labeled to indicate the type of match found:\n\n- **PP (PearlPage)**: Node URL directly matches a PagePearl's external URL\n- **PT (Pearltree)**: Exact title match, including disambiguated titles\n- **PT? (Pearltree fuzzy)**: Semantic similarity match above the configured threshold (default 0.7)\n\nTo use URL matching for PP labels, include `--url-db data/databases/children_index.db`. For semantic matching, include `--embeddings` and `--projection-model`. See skill_mindmap_linking.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_002_q1", "cluster_id": "skill_mindmap_linking_002", "question": "What do PP, PT, and PT? mean in linked mindmaps?", "answer": "In linked mindmaps, output labels indicate the type of match found:\n\n- **PP (PearlPage)**: Node URL directly matches a PagePearl's external URL\n- **PT (Pearltree)**: Exact title match, including disambiguated titles\n- **PT? (Pearltree fuzzy)**: Semantic similarity match above the configured threshold (default 0.7)", "question_type": "long", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["matching", "labels", "semantic-search", "url-matching"], "related_skills": ["skill_mindmap_linking.md", "skill_semantic_inference.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/link_pearltrees.py"], "original_answer": "When linking mindmaps, nodes are labeled to indicate the type of match found:\n\n- **PP (PearlPage)**: Node URL directly matches a PagePearl's external URL\n- **PT (Pearltree)**: Exact title match, including disambiguated titles\n- **PT? (Pearltree fuzzy)**: Semantic similarity match above the configured threshold (default 0.7)\n\nTo use URL matching for PP labels, include `--url-db data/databases/children_index.db`. For semantic matching, include `--embeddings` and `--projection-model`. See skill_mindmap_linking.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_002_q2", "cluster_id": "skill_mindmap_linking_002", "question": "How are matches labeled when linking mindmaps?", "answer": "When linking mindmaps to Pearltrees, matches are labeled with three types:\n\n- **PP (PearlPage)**: The node's URL directly matches a PagePearl's external URL (requires `--url-db` flag)\n- **PT (Pearltree)**: Exact title match between the mindmap node and a Pearltree, including disambiguated titles\n- **PT? (Pearltree fuzzy)**: Semantic similarity match above the configured threshold (default 0.7, requires `--embeddings` and `--projection-model` flags)\n\nThese labels appear as child nodes added during the linking process, allowing you to see exactly how each connection was made.", "question_type": "long", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["matching", "labels", "semantic-search", "url-matching"], "related_skills": ["skill_mindmap_linking.md", "skill_semantic_inference.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/link_pearltrees.py"], "original_answer": "When linking mindmaps, nodes are labeled to indicate the type of match found:\n\n- **PP (PearlPage)**: Node URL directly matches a PagePearl's external URL\n- **PT (Pearltree)**: Exact title match, including disambiguated titles\n- **PT? (Pearltree fuzzy)**: Semantic similarity match above the configured threshold (default 0.7)\n\nTo use URL matching for PP labels, include `--url-db data/databases/children_index.db`. For semantic matching, include `--embeddings` and `--projection-model`. See skill_mindmap_linking.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_003_q0", "cluster_id": "skill_mindmap_linking_003", "question": "How can I preview the linking changes before saving?", "answer": "Use the `--dry-run` flag with `--verbose` to preview all linking changes without modifying your mindmap:\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"your_mindmap.txt\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --dry-run --verbose\n```\n\nThis displays which nodes would be matched, their assigned labels (PP, PT, or PT?), and confidence scores without making any changes to your file. Review the output and run without `--dry-run` once you're satisfied.", "question_type": "long", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["dry-run", "preview", "debugging"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/link_pearltrees.py"], "original_answer": "Use the `--dry-run` flag with `--verbose` to preview all changes without modifying your mindmap:\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"your_mindmap.txt\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --dry-run --verbose\n```\n\nThis shows which nodes would be matched and what labels would be assigned, so you can review before committing to the changes. See skill_mindmap_linking.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_003_q1", "cluster_id": "skill_mindmap_linking_003", "question": "Can I see what changes will be made without saving?", "answer": "Yes, use the `--dry-run` flag with `--verbose` to preview all changes without saving:\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"your_mindmap.txt\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --dry-run --verbose\n```\n\nThis will show which nodes would be matched and what labels would be assigned (PP, PT, or PT?) without modifying your mindmap file.", "question_type": "long", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["dry-run", "preview", "debugging"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/link_pearltrees.py"], "original_answer": "Use the `--dry-run` flag with `--verbose` to preview all changes without modifying your mindmap:\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"your_mindmap.txt\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --dry-run --verbose\n```\n\nThis shows which nodes would be matched and what labels would be assigned, so you can review before committing to the changes. See skill_mindmap_linking.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_003_q2", "cluster_id": "skill_mindmap_linking_003", "question": "How do I do a dry run of mindmap linking?", "answer": "Use the `--dry-run` flag with `--verbose` to preview all changes without modifying your mindmap:\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"your_mindmap.txt\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --dry-run --verbose\n```\n\nThis shows which nodes would be matched and what labels (PP, PT, PT?) would be assigned before you commit to the changes.", "question_type": "long", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["dry-run", "preview", "debugging"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/link_pearltrees.py"], "original_answer": "Use the `--dry-run` flag with `--verbose` to preview all changes without modifying your mindmap:\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"your_mindmap.txt\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --dry-run --verbose\n```\n\nThis shows which nodes would be matched and what labels would be assigned, so you can review before committing to the changes. See skill_mindmap_linking.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_004_q0", "cluster_id": "skill_mindmap_linking_004", "question": "What's the minimum setup needed to link a mindmap to Pearltrees?", "answer": "The minimum setup needed to link a mindmap to Pearltrees requires only two things:\n\n1. Your mindmap file (exported from SimpleMind)\n2. The Pearltrees trees data file\n\nRun this command:\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"your_mindmap.txt\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --output \"output_mindmap.txt\"\n```\n\nThis performs title-based matching to connect mindmap nodes to Pearltrees. For improved matching accuracy, you can optionally add `--embeddings`, `--projection-model`, and `--url-db` flags to enable semantic similarity matching and URL-based linking.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["setup", "requirements", "minimal-config"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/link_pearltrees.py"], "original_answer": "The minimum requirement is just the Pearltrees trees data for title matching:\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"your_mindmap.txt\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --output \"output_mindmap.txt\"\n```\n\nFor better matching quality, add `--embeddings`, `--projection-model`, and `--url-db` options. The recommended setup uses all available data sources for hierarchical semantic matching. See skill_mindmap_linking.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_004_q1", "cluster_id": "skill_mindmap_linking_004", "question": "What data do I need to link a mindmap?", "answer": "To link a mindmap, you need at minimum the Pearltrees trees data file for title matching. Run:\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"your_mindmap.txt\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --output \"output_mindmap.txt\"\n```\n\nFor better matching quality, optionally add:\n- `--embeddings datasets/pearltrees_combined_embeddings.npz` - enables semantic similarity matching\n- `--projection-model models/pearltrees_federated_nomic.pkl` - hierarchical projection for improved accuracy\n- `--url-db data/databases/children_index.db` - URL matching for PagePearl links\n- `--pearls reports/pearltrees_targets_full_pearls.jsonl` - additional pearl data for matching\n\nThe recommended setup uses all data sources for the best results.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["setup", "requirements", "minimal-config"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/link_pearltrees.py"], "original_answer": "The minimum requirement is just the Pearltrees trees data for title matching:\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"your_mindmap.txt\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --output \"output_mindmap.txt\"\n```\n\nFor better matching quality, add `--embeddings`, `--projection-model`, and `--url-db` options. The recommended setup uses all available data sources for hierarchical semantic matching. See skill_mindmap_linking.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_004_q2", "cluster_id": "skill_mindmap_linking_004", "question": "Can I do basic mindmap linking without embeddings?", "answer": "Yes, you can do basic mindmap linking without embeddings. The minimum requirement is just the Pearltrees trees data for title matching:\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"your_mindmap.txt\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --output \"output_mindmap.txt\"\n```\n\nThis performs exact title matching to link your mindmap nodes to Pearltrees. For improved matching quality and hierarchical semantic matching, you can optionally add embeddings and projection models, but they are not required for basic linking.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["setup", "requirements", "minimal-config"], "related_skills": ["skill_mindmap_linking.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "scripts/mindmap/link_pearltrees.py"], "original_answer": "The minimum requirement is just the Pearltrees trees data for title matching:\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"your_mindmap.txt\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --output \"output_mindmap.txt\"\n```\n\nFor better matching quality, add `--embeddings`, `--projection-model`, and `--url-db` options. The recommended setup uses all available data sources for hierarchical semantic matching. See skill_mindmap_linking.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_005_q0", "cluster_id": "skill_mindmap_linking_005", "question": "Which projection model should I use for faster linking?", "answer": "Use **pearltrees_federated_single.pkl** (384D embeddings) for faster linking. It offers faster inference with lower memory usage compared to pearltrees_federated_nomic.pkl (768D), though with slightly lower matching accuracy. Both models use the same hierarchical matching approach, and the model automatically selects the appropriate embedder based on embedding dimensions.", "question_type": "long", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["models", "performance", "embeddings"], "related_skills": ["skill_mindmap_linking.md", "skill_train_model.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "scripts/mindmap/link_pearltrees.py"], "original_answer": "Two models are available:\n\n- **pearltrees_federated_nomic.pkl** (768D embeddings): General matching with higher accuracy\n- **pearltrees_federated_single.pkl** (384D embeddings): Faster inference with lower memory usage\n\nThe model automatically selects the appropriate embedder based on embedding dimensions. Use `pearltrees_federated_nomic.pkl` for best matching quality (recommended), or `pearltrees_federated_single.pkl` if you need faster processing. Both use the same hierarchical matching approach. See skill_mindmap_linking.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_005_q1", "cluster_id": "skill_mindmap_linking_005", "question": "What's the difference between the projection models?", "answer": "Two projection models are available: **pearltrees_federated_nomic.pkl** uses 768-dimensional Nomic embeddings for general matching with higher accuracy, while **pearltrees_federated_single.pkl** uses 384-dimensional MiniLM embeddings for faster inference with lower memory usage. The model automatically selects the appropriate embedder based on embedding dimensions. Use the Nomic model for best matching quality (recommended), or the MiniLM model if you need faster processing. Both use the same hierarchical matching approach.", "question_type": "long", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["models", "performance", "embeddings"], "related_skills": ["skill_mindmap_linking.md", "skill_train_model.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "scripts/mindmap/link_pearltrees.py"], "original_answer": "Two models are available:\n\n- **pearltrees_federated_nomic.pkl** (768D embeddings): General matching with higher accuracy\n- **pearltrees_federated_single.pkl** (384D embeddings): Faster inference with lower memory usage\n\nThe model automatically selects the appropriate embedder based on embedding dimensions. Use `pearltrees_federated_nomic.pkl` for best matching quality (recommended), or `pearltrees_federated_single.pkl` if you need faster processing. Both use the same hierarchical matching approach. See skill_mindmap_linking.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_005_q2", "cluster_id": "skill_mindmap_linking_005", "question": "Should I use nomic or MiniLM for mindmap linking?", "answer": "For mindmap linking, use **pearltrees_federated_nomic.pkl** for best matching quality (recommended), or **pearltrees_federated_single.pkl** if you need faster processing. Nomic (768D) provides higher accuracy, while MiniLM (384D) is faster with lower memory usage. The model automatically selects the appropriate embedder based on embedding dimensions, so you only need to specify which `.pkl` file to use via the `--projection-model` flag.", "question_type": "long", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["models", "performance", "embeddings"], "related_skills": ["skill_mindmap_linking.md", "skill_train_model.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "scripts/mindmap/link_pearltrees.py"], "original_answer": "Two models are available:\n\n- **pearltrees_federated_nomic.pkl** (768D embeddings): General matching with higher accuracy\n- **pearltrees_federated_single.pkl** (384D embeddings): Faster inference with lower memory usage\n\nThe model automatically selects the appropriate embedder based on embedding dimensions. Use `pearltrees_federated_nomic.pkl` for best matching quality (recommended), or `pearltrees_federated_single.pkl` if you need faster processing. Both use the same hierarchical matching approach. See skill_mindmap_linking.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_006_q0", "cluster_id": "skill_mindmap_linking_006", "question": "How do I adjust the matching sensitivity when linking a mindmap?", "answer": "Use the `--threshold` parameter to control semantic matching sensitivity when linking a mindmap to Pearltrees. The default is 0.7.\n\nHigher values (0.8-0.9) require closer semantic similarity, reducing false matches but potentially missing valid connections. Lower values (0.5-0.6) allow looser matches, finding more connections but with increased false positives.\n\nExample with adjusted threshold:\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"your_mindmap.txt\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --embeddings datasets/pearltrees_combined_embeddings.npz \\\n  --projection-model models/pearltrees_federated_nomic.pkl \\\n  --threshold 0.75 \\\n  --output \"output_mindmap.txt\"\n```\n\nUse `--verbose` flag to see matching details and test different threshold values to find the best balance for your data.", "question_type": "long", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["threshold", "sensitivity", "tuning", "fuzzy-matching"], "related_skills": ["skill_mindmap_linking.md", "skill_semantic_inference.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "education/book-13-semantic-search/05_semantic_playbook.md", "scripts/mindmap/link_pearltrees.py"], "original_answer": "Use the `--threshold` parameter to adjust semantic matching sensitivity (default is 0.7):\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"your_mindmap.txt\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --embeddings datasets/pearltrees_combined_embeddings.npz \\\n  --projection-model models/pearltrees_federated_nomic.pkl \\\n  --threshold 0.8 \\\n  --output \"output_mindmap.txt\"\n```\n\nHigher threshold (e.g., 0.8-0.9) requires closer semantic similarity, reducing false matches. Lower threshold (e.g., 0.5-0.6) allows looser matches, finding more connections. Pair with `--verbose` to test different values. See skill_mindmap_linking.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_006_q1", "cluster_id": "skill_mindmap_linking_006", "question": "How do I change the matching threshold?", "answer": "Use the `--threshold` parameter to adjust semantic matching sensitivity. The default is 0.7. Higher values (0.8-0.9) require closer semantic similarity and reduce false matches. Lower values (0.5-0.6) allow looser matches and find more connections.\n\nExample:\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"your_mindmap.txt\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --embeddings datasets/pearltrees_combined_embeddings.npz \\\n  --projection-model models/pearltrees_federated_nomic.pkl \\\n  --threshold 0.8 \\\n  --output \"output_mindmap.txt\"\n```\n\nUse `--verbose` to test different threshold values and see matching results.", "question_type": "long", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["threshold", "sensitivity", "tuning", "fuzzy-matching"], "related_skills": ["skill_mindmap_linking.md", "skill_semantic_inference.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "education/book-13-semantic-search/05_semantic_playbook.md", "scripts/mindmap/link_pearltrees.py"], "original_answer": "Use the `--threshold` parameter to adjust semantic matching sensitivity (default is 0.7):\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"your_mindmap.txt\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --embeddings datasets/pearltrees_combined_embeddings.npz \\\n  --projection-model models/pearltrees_federated_nomic.pkl \\\n  --threshold 0.8 \\\n  --output \"output_mindmap.txt\"\n```\n\nHigher threshold (e.g., 0.8-0.9) requires closer semantic similarity, reducing false matches. Lower threshold (e.g., 0.5-0.6) allows looser matches, finding more connections. Pair with `--verbose` to test different values. See skill_mindmap_linking.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_linking_006_q2", "cluster_id": "skill_mindmap_linking_006", "question": "Can I make the fuzzy matching stricter or more lenient?", "answer": "Yes, use the `--threshold` parameter to adjust semantic matching sensitivity. Higher values (0.8-0.9) make fuzzy matching stricter by requiring closer semantic similarity, reducing false matches. Lower values (0.5-0.6) make it more lenient, finding more connections. The default is 0.7. For example:\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"your_mindmap.txt\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --embeddings datasets/pearltrees_combined_embeddings.npz \\\n  --projection-model models/pearltrees_federated_nomic.pkl \\\n  --threshold 0.8 \\\n  --output \"output_mindmap.txt\"\n```\n\nUse `--verbose` to test different threshold values and see which matches are found at each sensitivity level.", "question_type": "long", "topics": ["Mindmap", "Mindmap Linking"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["threshold", "sensitivity", "tuning", "fuzzy-matching"], "related_skills": ["skill_mindmap_linking.md", "skill_semantic_inference.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "education/book-13-semantic-search/05_semantic_playbook.md", "scripts/mindmap/link_pearltrees.py"], "original_answer": "Use the `--threshold` parameter to adjust semantic matching sensitivity (default is 0.7):\n\n```bash\npython3 scripts/mindmap/link_pearltrees.py \\\n  --mindmap \"your_mindmap.txt\" \\\n  --trees reports/pearltrees_targets_s243a.jsonl \\\n  --embeddings datasets/pearltrees_combined_embeddings.npz \\\n  --projection-model models/pearltrees_federated_nomic.pkl \\\n  --threshold 0.8 \\\n  --output \"output_mindmap.txt\"\n```\n\nHigher threshold (e.g., 0.8-0.9) requires closer semantic similarity, reducing false matches. Lower threshold (e.g., 0.5-0.6) allows looser matches, finding more connections. Pair with `--verbose` to test different values. See skill_mindmap_linking.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_organization_001_q0", "cluster_id": "skill_mindmap_organization_001", "question": "How do I organize my mindmaps into folders?", "answer": "To organize your mindmaps into folders, use semantic embeddings and MST partitioning. First, generate embeddings with `python3 scripts/generate_embeddings.py --input mindmaps/*.smmx --output embeddings.npz --model nomic-ai/nomic-embed-text-v1.5`. Then build the folder hierarchy using `python3 scripts/mindmap/mst_folder_grouping.py --embeddings embeddings.npz --target-size 10 --max-depth 5 -o folder_structure.json`. Finally, evaluate the structure quality with `python3 scripts/mindmap/hierarchy_objective.py --tree folder_structure.json --embeddings embeddings.npz`. Adjust `--target-size` to control how many items go in each folder and `--max-depth` to limit nesting levels.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["organization", "clustering", "folder-structure"], "related_skills": ["skill_mindmap_organization.md"], "related_docs": ["scripts/mindmap/mst_folder_grouping.py", "scripts/mindmap/hierarchy_objective.py"], "original_answer": "To organize mindmaps into folders, use semantic embeddings and MST partitioning:\n\n1. Generate embeddings: `python3 scripts/generate_embeddings.py --input mindmaps/*.smmx --output embeddings.npz --model nomic-ai/nomic-embed-text-v1.5`\n2. Build folder structure: `python3 scripts/mindmap/mst_folder_grouping.py --embeddings embeddings.npz --target-size 10 --max-depth 5 -o folder_structure.json`\n3. Evaluate quality: `python3 scripts/mindmap/hierarchy_objective.py --tree folder_structure.json --embeddings embeddings.npz`\n\nAdjust `--target-size` for folder sizes and `--max-depth` for nesting levels. See skill_mindmap_organization.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_organization_001_q1", "cluster_id": "skill_mindmap_organization_001", "question": "Can I automatically group mindmaps into folders?", "answer": "Yes, you can automatically group mindmaps into folders using semantic embeddings and MST (Minimum Spanning Tree) partitioning. First, generate embeddings for your mindmaps using `python3 scripts/generate_embeddings.py --input mindmaps/*.smmx --output embeddings.npz --model nomic-ai/nomic-embed-text-v1.5`. Then build the folder hierarchy with `python3 scripts/mindmap/mst_folder_grouping.py --embeddings embeddings.npz --target-size 10 --max-depth 5 -o folder_structure.json`. You can adjust `--target-size` to control how many items go in each folder and `--max-depth` to limit nesting levels. Optionally, evaluate the quality of your hierarchy with `python3 scripts/mindmap/hierarchy_objective.py --tree folder_structure.json --embeddings embeddings.npz`.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["organization", "clustering", "folder-structure"], "related_skills": ["skill_mindmap_organization.md"], "related_docs": ["scripts/mindmap/mst_folder_grouping.py", "scripts/mindmap/hierarchy_objective.py"], "original_answer": "To organize mindmaps into folders, use semantic embeddings and MST partitioning:\n\n1. Generate embeddings: `python3 scripts/generate_embeddings.py --input mindmaps/*.smmx --output embeddings.npz --model nomic-ai/nomic-embed-text-v1.5`\n2. Build folder structure: `python3 scripts/mindmap/mst_folder_grouping.py --embeddings embeddings.npz --target-size 10 --max-depth 5 -o folder_structure.json`\n3. Evaluate quality: `python3 scripts/mindmap/hierarchy_objective.py --tree folder_structure.json --embeddings embeddings.npz`\n\nAdjust `--target-size` for folder sizes and `--max-depth` for nesting levels. See skill_mindmap_organization.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_organization_001_q2", "cluster_id": "skill_mindmap_organization_001", "question": "How can I create a folder structure from my mindmaps?", "answer": "To create a folder structure from your mindmaps, use semantic embeddings and MST partitioning. First, generate embeddings with `python3 scripts/generate_embeddings.py --input mindmaps/*.smmx --output embeddings.npz --model nomic-ai/nomic-embed-text-v1.5`. Then build the folder hierarchy using `python3 scripts/mindmap/mst_folder_grouping.py --embeddings embeddings.npz --target-size 10 --max-depth 5 -o folder_structure.json`. Adjust `--target-size` to control how many items go in each folder and `--max-depth` to set nesting levels. Optionally evaluate the structure quality with `python3 scripts/mindmap/hierarchy_objective.py --tree folder_structure.json --embeddings embeddings.npz`.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["organization", "clustering", "folder-structure"], "related_skills": ["skill_mindmap_organization.md"], "related_docs": ["scripts/mindmap/mst_folder_grouping.py", "scripts/mindmap/hierarchy_objective.py"], "original_answer": "To organize mindmaps into folders, use semantic embeddings and MST partitioning:\n\n1. Generate embeddings: `python3 scripts/generate_embeddings.py --input mindmaps/*.smmx --output embeddings.npz --model nomic-ai/nomic-embed-text-v1.5`\n2. Build folder structure: `python3 scripts/mindmap/mst_folder_grouping.py --embeddings embeddings.npz --target-size 10 --max-depth 5 -o folder_structure.json`\n3. Evaluate quality: `python3 scripts/mindmap/hierarchy_objective.py --tree folder_structure.json --embeddings embeddings.npz`\n\nAdjust `--target-size` for folder sizes and `--max-depth` for nesting levels. See skill_mindmap_organization.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_organization_002_q0", "cluster_id": "skill_mindmap_organization_002", "question": "What's the difference between flat and deep folder hierarchies?", "answer": "Folder depth in mindmap hierarchies reflects a trade-off between navigation simplicity and organizational granularity. Flat hierarchies (max-depth 2, target-size 20) use fewer, larger folders that are quick to browse but group dissimilar items together. Deep hierarchies (max-depth 5, target-size 8) create many small, highly specific folders that require more navigation to reach items but provide precise categorization. Balanced hierarchies (max-depth 4, target-size 12) offer a middle ground suitable for most use cases. Choose flat structures for broad topic categories where users expect to scan many items, deep structures for specialized collections where items have fine distinctions, and balanced structures as a reasonable default when unsure.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["hierarchy", "organization", "structure"], "related_skills": ["skill_mindmap_organization.md"], "related_docs": ["scripts/mindmap/mst_folder_grouping.py"], "original_answer": "Folder depth depends on your needs:\n- **Flat** (`--max-depth 2 --target-size 20`): Few large folders, easy navigation\n- **Deep** (`--max-depth 5 --target-size 8`): Many small folders, fine-grained organization\n- **Balanced** (`--max-depth 4 --target-size 12`): Good default for general use\n\nUse flat for broad categories, deep for detailed organization. See skill_mindmap_organization.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_mindmap_organization_002_q1", "cluster_id": "skill_mindmap_organization_002", "question": "Should I use many small folders or a few large folders?", "answer": "The choice between folder structures depends on your organizational needs:\n\n**Flat structures** (`--max-depth 2`, `--target-size 20`) work best when you want broad categorical grouping with minimal navigation overhead. Use this when you have a smaller collection or prefer quick access to major categories.\n\n**Deep structures** (`--max-depth 5`, `--target-size 8`) are better for detailed, fine-grained organization across large collections. This allows precise categorization but requires more navigation to find items.\n\n**Balanced approach** (`--max-depth 4`, `--target-size 12`) provides a middle ground suitable for most general use cases, balancing navigability with organizational specificity.\n\nChoose based on your collection size and how specifically you need to segment items. You can evaluate which structure works best using the hierarchy objective function (J score) to measure quality.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["hierarchy", "organization", "structure"], "related_skills": ["skill_mindmap_organization.md"], "related_docs": ["scripts/mindmap/mst_folder_grouping.py"], "original_answer": "Folder depth depends on your needs:\n- **Flat** (`--max-depth 2 --target-size 20`): Few large folders, easy navigation\n- **Deep** (`--max-depth 5 --target-size 8`): Many small folders, fine-grained organization\n- **Balanced** (`--max-depth 4 --target-size 12`): Good default for general use\n\nUse flat for broad categories, deep for detailed organization. See skill_mindmap_organization.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "Base answer doesn't explain the practical tradeoff clearly\u2014why choose one over the other beyond folder count. Answer infers reasoning about collection size and navigation, which adds value but isn't explicit in the base material."}
{"pair_id": "skill_mindmap_organization_002_q2", "cluster_id": "skill_mindmap_organization_002", "question": "How deep should my folder structure be?", "answer": "Folder depth depends on your collection size and navigation preferences:\n\n- **Shallow** (`--max-depth 2`, `--target-size 20`): 1-2 levels, few large folders, fastest navigation\n- **Balanced** (`--max-depth 4`, `--target-size 12`): 3-4 levels, moderate folders, good for most collections\n- **Deep** (`--max-depth 5`, `--target-size 8`): 4-5 levels, many small folders, detailed organization\n\nChoose based on: larger collections benefit from deeper structures to keep folders manageable; smaller collections stay organized with shallow depth. The objective function J = D/(1+H) automatically balances semantic distance against depth penalty, so start with `--max-depth 4` as a sensible default.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["hierarchy", "organization", "structure"], "related_skills": ["skill_mindmap_organization.md"], "related_docs": ["scripts/mindmap/mst_folder_grouping.py"], "original_answer": "Folder depth depends on your needs:\n- **Flat** (`--max-depth 2 --target-size 20`): Few large folders, easy navigation\n- **Deep** (`--max-depth 5 --target-size 8`): Many small folders, fine-grained organization\n- **Balanced** (`--max-depth 4 --target-size 12`): Good default for general use\n\nUse flat for broad categories, deep for detailed organization. See skill_mindmap_organization.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_mindmap_organization_003_q0", "cluster_id": "skill_mindmap_organization_003", "question": "How can I check if my folder hierarchy is well-organized?", "answer": "Use the hierarchy objective function to evaluate your folder structure quality:\n\n```bash\npython3 scripts/mindmap/hierarchy_objective.py \\\n  --tree folder_structure.json \\\n  --embeddings embeddings.npz\n```\n\nThis outputs three metrics:\n- **J (Objective)** - Lower is better. J < 0.15 indicates a well-organized hierarchy. If J > 0.3, consider J-guided tree optimization for better balance.\n- **D (Semantic Distance)** - Average semantic distance within folders. Lower values mean tighter semantic groupings.\n- **H (Entropy Gain)** - Measures organization improvement. Higher indicates better hierarchical structure.\n\nIf your scores aren't optimal, you can re-run MST partitioning with adjusted `--target-size` or `--max-depth` parameters, or switch to J-guided tree optimization for a more balanced structure.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["evaluation", "quality", "optimization"], "related_skills": ["skill_mindmap_organization.md", "skill_hierarchy_objective.md"], "related_docs": ["scripts/mindmap/hierarchy_objective.py"], "original_answer": "Use the hierarchy objective function to evaluate structure quality:\n\n```bash\npython3 scripts/mindmap/hierarchy_objective.py \\\n  --tree folder_structure.json \\\n  --embeddings embeddings.npz\n```\n\nOutputs the objective J (lower is better), semantic distance D, and entropy gain H. A J score below 0.15 indicates a well-organized hierarchy. If J > 0.3, try J-guided tree optimization. See skill_mindmap_organization.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_organization_003_q1", "cluster_id": "skill_mindmap_organization_003", "question": "What makes a good folder structure?", "answer": "A good folder structure is one where semantically similar mindmaps are grouped together, creating a balanced hierarchy. Evaluate it using the hierarchy objective function J = D/(1+H), where D is semantic distance and H is entropy gain. Run: `python3 scripts/mindmap/hierarchy_objective.py --tree folder_structure.json --embeddings embeddings.npz`. A J score below 0.15 indicates excellent organization. Scores above 0.3 suggest the hierarchy needs optimization\u2014try J-guided tree optimization instead of basic MST partitioning. Key qualities: items within folders should have high semantic similarity, folder depth should be reasonable (max 5 levels), and each folder should contain roughly 10 items (adjustable via `--target-size`).", "question_type": "medium", "topics": ["Mindmap", "Mindmap Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["evaluation", "quality", "optimization"], "related_skills": ["skill_mindmap_organization.md", "skill_hierarchy_objective.md"], "related_docs": ["scripts/mindmap/hierarchy_objective.py"], "original_answer": "Use the hierarchy objective function to evaluate structure quality:\n\n```bash\npython3 scripts/mindmap/hierarchy_objective.py \\\n  --tree folder_structure.json \\\n  --embeddings embeddings.npz\n```\n\nOutputs the objective J (lower is better), semantic distance D, and entropy gain H. A J score below 0.15 indicates a well-organized hierarchy. If J > 0.3, try J-guided tree optimization. See skill_mindmap_organization.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_mindmap_organization_003_q2", "cluster_id": "skill_mindmap_organization_003", "question": "How do I evaluate hierarchy quality?", "answer": "Use the hierarchy objective function to evaluate how well your folder structure organizes mindmaps semantically:\n\n```bash\npython3 scripts/mindmap/hierarchy_objective.py \\\n  --tree folder_structure.json \\\n  --embeddings embeddings.npz\n```\n\nThis outputs three metrics:\n- **J (Objective)** - Overall quality score (lower is better). J < 0.15 indicates good organization; J > 0.3 suggests optimization needed.\n- **D (Semantic Distance)** - Average dissimilarity within folders. Lower values mean more coherent groupings.\n- **H (Entropy Gain)** - Information gain from the hierarchy. Indicates how much structure improves over flat organization.\n\nIf your J score is high, use J-guided tree optimization instead of basic MST partitioning for better balanced hierarchies.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["evaluation", "quality", "optimization"], "related_skills": ["skill_mindmap_organization.md", "skill_hierarchy_objective.md"], "related_docs": ["scripts/mindmap/hierarchy_objective.py"], "original_answer": "Use the hierarchy objective function to evaluate structure quality:\n\n```bash\npython3 scripts/mindmap/hierarchy_objective.py \\\n  --tree folder_structure.json \\\n  --embeddings embeddings.npz\n```\n\nOutputs the objective J (lower is better), semantic distance D, and entropy gain H. A J score below 0.15 indicates a well-organized hierarchy. If J > 0.3, try J-guided tree optimization. See skill_mindmap_organization.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_organization_004_q0", "cluster_id": "skill_mindmap_organization_004", "question": "Where should I put a new mindmap in my existing folder structure?", "answer": "Use the folder suggestion tool to find the best place for new items in your existing folder structure:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py \\\n  --item new_mindmap.smmx \\\n  --structure folder_structure.json \\\n  --embeddings embeddings.npz\n```\n\nThis tool analyzes your new item's semantic embedding and recommends the most appropriate folder from your existing hierarchy. The suggestion is based on semantic similarity to items already in your folder structure.", "question_type": "long", "topics": ["Mindmap", "Mindmap Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["suggestion", "new-items", "placement"], "related_skills": ["skill_mindmap_organization.md", "skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/suggest_folder.py"], "original_answer": "Use the folder suggestion tool to find the best place for new items:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py \\\n  --item new_mindmap.smmx \\\n  --structure folder_structure.json \\\n  --embeddings embeddings.npz\n```\n\nThe tool analyzes the new item's semantic embedding and recommends the most appropriate folder from your existing hierarchy. See skill_mindmap_organization.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_organization_004_q1", "cluster_id": "skill_mindmap_organization_004", "question": "How do I add a new item to organized folders?", "answer": "To add a new item to organized folders, use the folder suggestion tool to find the best placement:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py \\\n  --item new_mindmap.smmx \\\n  --structure folder_structure.json \\\n  --embeddings embeddings.npz\n```\n\nThis tool analyzes your new item's semantic embedding and recommends the most appropriate existing folder from your hierarchy based on semantic similarity. The tool will output the suggested folder path and confidence score for the placement.", "question_type": "long", "topics": ["Mindmap", "Mindmap Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["suggestion", "new-items", "placement"], "related_skills": ["skill_mindmap_organization.md", "skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/suggest_folder.py"], "original_answer": "Use the folder suggestion tool to find the best place for new items:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py \\\n  --item new_mindmap.smmx \\\n  --structure folder_structure.json \\\n  --embeddings embeddings.npz\n```\n\nThe tool analyzes the new item's semantic embedding and recommends the most appropriate folder from your existing hierarchy. See skill_mindmap_organization.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_organization_004_q2", "cluster_id": "skill_mindmap_organization_004", "question": "Can the system suggest a folder for new mindmaps?", "answer": "Yes, the system can suggest folders for new mindmaps using the folder suggestion tool. Run `python3 scripts/mindmap/suggest_folder.py --item new_mindmap.smmx --structure folder_structure.json --embeddings embeddings.npz` to analyze the new item's semantic embedding and get recommendations for the best folder in your existing hierarchy.", "question_type": "long", "topics": ["Mindmap", "Mindmap Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["suggestion", "new-items", "placement"], "related_skills": ["skill_mindmap_organization.md", "skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/suggest_folder.py"], "original_answer": "Use the folder suggestion tool to find the best place for new items:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py \\\n  --item new_mindmap.smmx \\\n  --structure folder_structure.json \\\n  --embeddings embeddings.npz\n```\n\nThe tool analyzes the new item's semantic embedding and recommends the most appropriate folder from your existing hierarchy. See skill_mindmap_organization.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_organization_005_q0", "cluster_id": "skill_mindmap_organization_005", "question": "What's the difference between MST and J-guided organization?", "answer": "MST (Minimum Spanning Tree) and J-guided organization differ in their approach and trade-offs:\n\n**MST Organization**\n- Faster computation\n- Creates initial folder structure quickly\n- May produce long chains in the hierarchy\n- Better for rapid initial organization\n\n**J-Guided Organization**\n- Slower computation\n- Optimizes the J objective function (J = D/(1+H))\n- Produces more balanced hierarchies\n- Better quality structure but takes more time\n\n**When to use each:**\n- Start with MST if you need fast results\n- Switch to J-guided if MST quality is poor (J objective > 0.3)\n\nTo use J-guided organization:\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --tree-type j-guided \\\n  --target-size 10 \\\n  -o output.json\n```\n\nUse the hierarchy objective evaluation to measure quality and decide if switching approaches is worthwhile.", "question_type": "long", "topics": ["Mindmap", "Mindmap Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mst", "j-guided", "algorithm", "optimization"], "related_skills": ["skill_mindmap_organization.md", "skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/mst_folder_grouping.py"], "original_answer": "Two organization approaches offer different trade-offs:\n- **MST**: Faster, creates initial structure, may produce long chains\n- **J-Guided**: Slower but produces more balanced hierarchies by optimizing the J objective\n\nStart with MST for speed. If quality is poor (J > 0.3), use J-guided:\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --tree-type j-guided --target-size 10 -o output.json\n```\n\nSee skill_mindmap_organization.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_mindmap_organization_005_q1", "cluster_id": "skill_mindmap_organization_005", "question": "Should I use MST or J-guided tree for organizing?", "answer": "Choose between two organization approaches based on your priorities:\n\n**MST (Minimum Spanning Tree)**: Faster initial organization, good for quick hierarchies, but may create long chains of folders.\n\n**J-Guided Trees**: Slower computation, but produces more balanced hierarchies optimized by the J objective function (J = D/(1+H)).\n\nStart with MST for speed. If your hierarchy quality is poor (J score > 0.3), switch to J-guided:\n\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --tree-type j-guided --target-size 10 -o output.json\n```\n\nEvaluate hierarchy quality with:\n```bash\npython3 scripts/mindmap/hierarchy_objective.py \\\n  --tree output.json --embeddings embeddings.npy\n```\n\nLower J values indicate better balanced, semantically coherent structures.", "question_type": "long", "topics": ["Mindmap", "Mindmap Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mst", "j-guided", "algorithm", "optimization"], "related_skills": ["skill_mindmap_organization.md", "skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/mst_folder_grouping.py"], "original_answer": "Two organization approaches offer different trade-offs:\n- **MST**: Faster, creates initial structure, may produce long chains\n- **J-Guided**: Slower but produces more balanced hierarchies by optimizing the J objective\n\nStart with MST for speed. If quality is poor (J > 0.3), use J-guided:\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --tree-type j-guided --target-size 10 -o output.json\n```\n\nSee skill_mindmap_organization.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_organization_005_q2", "cluster_id": "skill_mindmap_organization_005", "question": "Which organization method is better?", "answer": "MST (Minimum Spanning Tree) is faster for initial organization but may produce long chains, while J-guided is slower but creates more balanced hierarchies by optimizing the J objective function. Start with MST for speed\u2014if the quality is poor (J > 0.3), switch to J-guided using the `--tree-type j-guided` flag. Use the hierarchy_objective.py script to evaluate which approach produces better results for your specific mindmap collection.", "question_type": "long", "topics": ["Mindmap", "Mindmap Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mst", "j-guided", "algorithm", "optimization"], "related_skills": ["skill_mindmap_organization.md", "skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/mst_folder_grouping.py"], "original_answer": "Two organization approaches offer different trade-offs:\n- **MST**: Faster, creates initial structure, may produce long chains\n- **J-Guided**: Slower but produces more balanced hierarchies by optimizing the J objective\n\nStart with MST for speed. If quality is poor (J > 0.3), use J-guided:\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --tree-type j-guided --target-size 10 -o output.json\n```\n\nSee skill_mindmap_organization.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_organization_006_q0", "cluster_id": "skill_mindmap_organization_006", "question": "Can I combine manual curation with automatic organization?", "answer": "Yes, you can combine manual curation with automatic organization using the hybrid approach. Run: `python3 scripts/mindmap/mst_folder_grouping.py --tree-source hybrid --embeddings embeddings.npz -o output.json`. This starts from your existing curated hierarchy and automatically places orphaned items into appropriate folders based on semantic embeddings. For fully manual control, use `--tree-source curated`; for fully automatic, use `--tree-source mst`. This lets you leverage human judgment for your most important categories while letting the system handle placement of new or uncategorized items.", "question_type": "long", "topics": ["Mindmap", "Mindmap Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["hybrid", "curation", "manual-automatic"], "related_skills": ["skill_mindmap_organization.md", "skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/mst_folder_grouping.py"], "original_answer": "You can blend automatic and manual organization with the hybrid approach:\n\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --tree-source hybrid --embeddings embeddings.npz -o output.json\n```\n\nOr use fully curated structure: `--tree-source curated`. The hybrid mode starts from your existing curated hierarchy and automatically places orphaned items. For fully automatic, use `--tree-source mst`. See skill_mindmap_organization.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "The base answer references a hybrid mode that may not be fully documented or implemented. The command syntax and flag names should be verified against the actual script. The answer assumes the script supports these exact parameters without confirmation from the codebase."}
{"pair_id": "skill_mindmap_organization_006_q1", "cluster_id": "skill_mindmap_organization_006", "question": "How do I use my existing folder structure with automatic organization?", "answer": "You can blend automatic and manual organization using the hybrid approach. Run `python3 scripts/mindmap/mst_folder_grouping.py --tree-source hybrid --embeddings embeddings.npz -o output.json` to start from your existing curated hierarchy and automatically place orphaned items. For fully automatic organization without manual structure, use `--tree-source mst`. For a fully curated approach that respects your existing structure, use `--tree-source curated`. The hybrid mode is ideal when you want to preserve your manual folder organization while filling gaps automatically.", "question_type": "long", "topics": ["Mindmap", "Mindmap Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["hybrid", "curation", "manual-automatic"], "related_skills": ["skill_mindmap_organization.md", "skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/mst_folder_grouping.py"], "original_answer": "You can blend automatic and manual organization with the hybrid approach:\n\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --tree-source hybrid --embeddings embeddings.npz -o output.json\n```\n\nOr use fully curated structure: `--tree-source curated`. The hybrid mode starts from your existing curated hierarchy and automatically places orphaned items. For fully automatic, use `--tree-source mst`. See skill_mindmap_organization.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_organization_006_q2", "cluster_id": "skill_mindmap_organization_006", "question": "Can I start with curated folders and auto-organize the rest?", "answer": "Yes, you can blend manual curation with automatic organization using hybrid mode. Start with your curated folder structure, then run hybrid organization to automatically place items not yet categorized:\n\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --tree-source hybrid \\\n  --embeddings embeddings.npz \\\n  -o output.json\n```\n\nThis mode preserves your existing curated hierarchy while using MST partitioning to automatically organize uncategorized items into appropriate folders based on semantic embeddings. For fully automatic organization without manual input, use `--tree-source mst`. For fully manual control, use `--tree-source curated`. See skill_mindmap_organization.md for configuration details and parameter tuning options.", "question_type": "long", "topics": ["Mindmap", "Mindmap Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["hybrid", "curation", "manual-automatic"], "related_skills": ["skill_mindmap_organization.md", "skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/mst_folder_grouping.py"], "original_answer": "You can blend automatic and manual organization with the hybrid approach:\n\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --tree-source hybrid --embeddings embeddings.npz -o output.json\n```\n\nOr use fully curated structure: `--tree-source curated`. The hybrid mode starts from your existing curated hierarchy and automatically places orphaned items. For fully automatic, use `--tree-source mst`. See skill_mindmap_organization.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "Base answer could clarify whether curated folders are locked during hybrid mode, and what exactly constitutes 'orphaned items' in the context of an existing manual structure."}
{"pair_id": "skill_mindmap_references_001_q0", "cluster_id": "skill_mindmap_references_001", "question": "How do I link mindmaps together?", "answer": "SimpleMind mindmaps support two types of links for connecting mindmaps together: use `cloudmapref=\"../Physics/id10390825.smmx\"` to link to other local mindmap files for offline navigation, and `urllink=\"https://www.pearltrees.com/s243a/physics/id12345\"` to link to external URLs like Pearltrees. Add both links to nodes simultaneously, or control their placement with the `--url-nodes` parameter when generating mindmaps. Build an index first with `python3 scripts/mindmap/build_index.py`, then use `add_relative_links.py` to automatically add cloudmapref attributes based on Pearltrees URLs found in your mindmaps.", "question_type": "medium", "topics": ["Mindmap", "Mindmap References"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["linking", "connections", "references"], "related_skills": ["skill_mindmap_references.md", "skill_mindmap_linking.md", "skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/add_relative_links.py", "scripts/mindmap/link_pearltrees.py", "scripts/generate_mindmap.py"], "original_answer": "SimpleMind mindmaps support two types of links: External URLs using `urllink` attribute (for Pearltrees or websites) and local references using `cloudmapref` attribute (for other mindmap files). Add both simultaneously to nodes, or control placement with `--url-nodes` parameter when generating mindmaps. Use `cloudmapref=\"../Physics/id10390825.smmx\"` for local navigation and `urllink=\"https://www.pearltrees.com/s243a/physics/id12345\"` for external links. See skill_mindmap_references.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_references_001_q1", "cluster_id": "skill_mindmap_references_001", "question": "How can I create connections between mindmaps?", "answer": "SimpleMind mindmaps support two types of links for creating connections: External URLs using the `urllink` attribute (to link to Pearltrees or websites) and local references using the `cloudmapref` attribute (to link to other mindmap files). Add both link types to nodes simultaneously, or control their placement using the `--url-nodes` parameter when generating mindmaps. Use `cloudmapref=\"../Physics/id10390825.smmx\"` for offline navigation between local mindmap files and `urllink=\"https://www.pearltrees.com/s243a/physics/id12345\"` for external web-based navigation. The linking pipeline involves: (1) building an index of mindmap locations, (2) adding cross-links with cloudmapref attributes, and (3) optionally enriching with Pearltrees data using URL, title, or semantic matching.", "question_type": "medium", "topics": ["Mindmap", "Mindmap References"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["linking", "connections", "references"], "related_skills": ["skill_mindmap_references.md", "skill_mindmap_linking.md", "skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/add_relative_links.py", "scripts/mindmap/link_pearltrees.py", "scripts/generate_mindmap.py"], "original_answer": "SimpleMind mindmaps support two types of links: External URLs using `urllink` attribute (for Pearltrees or websites) and local references using `cloudmapref` attribute (for other mindmap files). Add both simultaneously to nodes, or control placement with `--url-nodes` parameter when generating mindmaps. Use `cloudmapref=\"../Physics/id10390825.smmx\"` for local navigation and `urllink=\"https://www.pearltrees.com/s243a/physics/id12345\"` for external links. See skill_mindmap_references.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_references_001_q2", "cluster_id": "skill_mindmap_references_001", "question": "How do I reference other mindmap files?", "answer": "To reference other mindmap files, use the `cloudmapref` attribute with a relative path to the target mindmap file. For example: `cloudmapref=\"../Physics/id10390825.smmx\"`. This allows offline navigation between mindmaps in your collection. You can add cloudmapref automatically using the linking pipeline: first build an index with `python3 scripts/mindmap/build_index.py`, then add cross-links with `python3 scripts/mindmap/add_relative_links.py`. Optionally pair cloudmapref with `urllink` attributes to also link to external Pearltrees pages.", "question_type": "medium", "topics": ["Mindmap", "Mindmap References"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["linking", "connections", "references"], "related_skills": ["skill_mindmap_references.md", "skill_mindmap_linking.md", "skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/add_relative_links.py", "scripts/mindmap/link_pearltrees.py", "scripts/generate_mindmap.py"], "original_answer": "SimpleMind mindmaps support two types of links: External URLs using `urllink` attribute (for Pearltrees or websites) and local references using `cloudmapref` attribute (for other mindmap files). Add both simultaneously to nodes, or control placement with `--url-nodes` parameter when generating mindmaps. Use `cloudmapref=\"../Physics/id10390825.smmx\"` for local navigation and `urllink=\"https://www.pearltrees.com/s243a/physics/id12345\"` for external links. See skill_mindmap_references.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_references_002_q0", "cluster_id": "skill_mindmap_references_002", "question": "How do I connect mindmaps to Pearltrees?", "answer": "To connect mindmaps to Pearltrees, use the enrichment pipeline. Run `python3 scripts/mindmap/link_pearltrees.py` with your mindmap file, Pearltrees targets data, and a projection model to add Pearltrees URLs to matching nodes. The script uses URL matching, title matching, or semantic embeddings to connect nodes. For a complete workflow: first build mindmaps recursively, create an index with `build_index.py`, add cross-links with `add_relative_links.py` to create local navigation, then enrich with `link_pearltrees.py` to add external Pearltrees URLs.", "question_type": "long", "topics": ["Mindmap", "Mindmap References"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["pearltrees", "enrichment", "linking"], "related_skills": ["skill_mindmap_references.md", "skill_mindmap_linking.md"], "related_docs": ["scripts/mindmap/link_pearltrees.py", "scripts/generate_mindmap.py", "scripts/mindmap/build_index.py"], "original_answer": "Use the enrichment pipeline to add Pearltrees URLs to your mindmaps. First, run `python3 scripts/mindmap/link_pearltrees.py --mindmap your_mindmap.smmx --trees reports/pearltrees_targets.jsonl --embeddings datasets/embeddings.npz --projection-model models/model.pkl --output enriched.smmx`. This matches nodes using URL matching, title matching, or semantic embeddings. For a fresh collection, build mindmaps recursively, create an index, then add cross-links. See skill_mindmap_references.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_references_002_q1", "cluster_id": "skill_mindmap_references_002", "question": "How can I add Pearltrees links to mindmap nodes?", "answer": "To add Pearltrees links to mindmap nodes, use the enrichment pipeline: run `python3 scripts/mindmap/link_pearltrees.py --mindmap your_mindmap.smmx --trees reports/pearltrees_targets.jsonl --embeddings datasets/embeddings.npz --projection-model models/model.pkl --output enriched.smmx`. This script matches nodes to Pearltrees using three strategies: URL matching (exact match), title matching (normalized titles), and semantic embeddings (for nodes without exact matches). The output mindmap will have `urllink` attributes pointing to Pearltrees URLs and `cloudmapref` attributes for local navigation.", "question_type": "long", "topics": ["Mindmap", "Mindmap References"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["pearltrees", "enrichment", "linking"], "related_skills": ["skill_mindmap_references.md", "skill_mindmap_linking.md"], "related_docs": ["scripts/mindmap/link_pearltrees.py", "scripts/generate_mindmap.py", "scripts/mindmap/build_index.py"], "original_answer": "Use the enrichment pipeline to add Pearltrees URLs to your mindmaps. First, run `python3 scripts/mindmap/link_pearltrees.py --mindmap your_mindmap.smmx --trees reports/pearltrees_targets.jsonl --embeddings datasets/embeddings.npz --projection-model models/model.pkl --output enriched.smmx`. This matches nodes using URL matching, title matching, or semantic embeddings. For a fresh collection, build mindmaps recursively, create an index, then add cross-links. See skill_mindmap_references.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_references_002_q2", "cluster_id": "skill_mindmap_references_002", "question": "How do I enrich mindmaps with Pearltrees URLs?", "answer": "To enrich mindmaps with Pearltrees URLs, use the enrichment pipeline: `python3 scripts/mindmap/link_pearltrees.py --mindmap your_mindmap.smmx --trees reports/pearltrees_targets.jsonl --embeddings datasets/embeddings.npz --projection-model models/model.pkl --output enriched.smmx`. This command matches nodes to Pearltrees entries using URL matching, title matching, or semantic embeddings, and adds the corresponding `urllink` attributes to your mindmap nodes.", "question_type": "long", "topics": ["Mindmap", "Mindmap References"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["pearltrees", "enrichment", "linking"], "related_skills": ["skill_mindmap_references.md", "skill_mindmap_linking.md"], "related_docs": ["scripts/mindmap/link_pearltrees.py", "scripts/generate_mindmap.py", "scripts/mindmap/build_index.py"], "original_answer": "Use the enrichment pipeline to add Pearltrees URLs to your mindmaps. First, run `python3 scripts/mindmap/link_pearltrees.py --mindmap your_mindmap.smmx --trees reports/pearltrees_targets.jsonl --embeddings datasets/embeddings.npz --projection-model models/model.pkl --output enriched.smmx`. This matches nodes using URL matching, title matching, or semantic embeddings. For a fresh collection, build mindmaps recursively, create an index, then add cross-links. See skill_mindmap_references.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_mindmap_references_003_q0", "cluster_id": "skill_mindmap_references_003", "question": "What are cloudmapref and urllink attributes?", "answer": "SimpleMind mindmaps support two link attributes for connecting content. The `urllink` attribute links to external web pages, typically Pearltrees URLs like `https://www.pearltrees.com/s243a/physics/id12345`. The `cloudmapref` attribute links to local mindmap files using relative paths like `../Physics/id12345.smmx`. Both attributes can exist on the same node, allowing users to choose between web-based navigation (urllink) or offline local navigation (cloudmapref). Use urllink for enriching content with external metadata and cloudmapref for creating portable collections that work without internet access.", "question_type": "medium", "topics": ["Mindmap", "Mindmap References"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["attributes", "links", "reference"], "related_skills": ["skill_mindmap_references.md"], "related_docs": [], "original_answer": "SimpleMind supports two link attributes: `urllink` links to external web pages (Pearltrees or websites) and `cloudmapref` links to local mindmap files using relative paths. Use `urllink=\"https://www.pearltrees.com/...\"` for offline-optional links, and `cloudmapref=\"../Science/Physics.smmx\"` for portable offline navigation. Both can exist on the same node for dual access methods. See skill_mindmap_references.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_references_003_q1", "cluster_id": "skill_mindmap_references_003", "question": "What's the difference between cloudmapref and urllink?", "answer": "SimpleMind mindmaps support two types of link attributes:\n\n**urllink** - Links to external web pages, typically Pearltrees URLs. Use this to connect to online resources or the original Pearltrees page. Example: `urllink=\"https://www.pearltrees.com/s243a/physics/id12345\"`\n\n**cloudmapref** - Links to other local mindmap files using relative paths. Use this for offline navigation between mindmaps in your collection. Example: `cloudmapref=\"../Physics/id12345.smmx\"`\n\nBoth can coexist on the same node, giving users the choice between online access (urllink) and local offline navigation (cloudmapref). This makes your mindmap collection portable and functional whether or not internet is available.", "question_type": "medium", "topics": ["Mindmap", "Mindmap References"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["attributes", "links", "reference"], "related_skills": ["skill_mindmap_references.md"], "related_docs": [], "original_answer": "SimpleMind supports two link attributes: `urllink` links to external web pages (Pearltrees or websites) and `cloudmapref` links to local mindmap files using relative paths. Use `urllink=\"https://www.pearltrees.com/...\"` for offline-optional links, and `cloudmapref=\"../Science/Physics.smmx\"` for portable offline navigation. Both can exist on the same node for dual access methods. See skill_mindmap_references.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_references_003_q2", "cluster_id": "skill_mindmap_references_003", "question": "How do I use cloudmapref in mindmaps?", "answer": "cloudmapref is a SimpleMind attribute that creates links to local mindmap files using relative paths, enabling offline navigation between mindmaps. Use the syntax `cloudmapref=\"../FolderName/filename.smmx\"` to reference other mindmap files in your collection. cloudmapref works alongside urllink (which points to external URLs like Pearltrees) - you can place both on the same node for dual access methods. Use cloudmapref when you want portable collections that work without internet access and for fast local browsing between interconnected mindmaps.", "question_type": "medium", "topics": ["Mindmap", "Mindmap References"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["attributes", "links", "reference"], "related_skills": ["skill_mindmap_references.md"], "related_docs": [], "original_answer": "SimpleMind supports two link attributes: `urllink` links to external web pages (Pearltrees or websites) and `cloudmapref` links to local mindmap files using relative paths. Use `urllink=\"https://www.pearltrees.com/...\"` for offline-optional links, and `cloudmapref=\"../Science/Physics.smmx\"` for portable offline navigation. Both can exist on the same node for dual access methods. See skill_mindmap_references.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_references_004_q0", "cluster_id": "skill_mindmap_references_004", "question": "How do I add cross-references between mindmaps?", "answer": "To add cross-references between mindmaps, first build an index of your mindmap file locations using `python3 scripts/mindmap/build_index.py output/mindmaps/ -o index.json`. Then run `python3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx --index index.json` to automatically scan each mindmap for Pearltrees URLs and add `cloudmapref` attributes that link to the corresponding local mindmap files. This enables offline navigation between interconnected mindmaps. If you've reorganized files, use the `--update` flag to rebuild the links.", "question_type": "long", "topics": ["Mindmap", "Mindmap References"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["cross-links", "indexing", "navigation"], "related_skills": ["skill_mindmap_references.md", "skill_mindmap_cross_links.md", "skill_mindmap_indexing.md"], "related_docs": ["scripts/mindmap/build_index.py", "scripts/mindmap/add_relative_links.py"], "original_answer": "First, build an index of your mindmap locations: `python3 scripts/mindmap/build_index.py output/mindmaps/ -o index.json`. Then add cross-links with `python3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx --index index.json`. This scans each mindmap for Pearltrees URLs and automatically adds `cloudmapref` attributes pointing to the corresponding local files. Use `--update` flag if you've reorganized files and need to rebuild links. See skill_mindmap_references.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_references_004_q1", "cluster_id": "skill_mindmap_references_004", "question": "How can I create internal mindmap navigation?", "answer": "To create internal mindmap navigation, build an index of your mindmap locations with `python3 scripts/mindmap/build_index.py output/mindmaps/ -o index.json`. Then add cross-links using `python3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx --index index.json`. This command scans each mindmap for Pearltrees URLs and automatically adds `cloudmapref` attributes that point to corresponding local mindmap files, enabling offline navigation between connected mindmaps. Use the `--update` flag if you've reorganized files and need to rebuild the links.", "question_type": "long", "topics": ["Mindmap", "Mindmap References"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["cross-links", "indexing", "navigation"], "related_skills": ["skill_mindmap_references.md", "skill_mindmap_cross_links.md", "skill_mindmap_indexing.md"], "related_docs": ["scripts/mindmap/build_index.py", "scripts/mindmap/add_relative_links.py"], "original_answer": "First, build an index of your mindmap locations: `python3 scripts/mindmap/build_index.py output/mindmaps/ -o index.json`. Then add cross-links with `python3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx --index index.json`. This scans each mindmap for Pearltrees URLs and automatically adds `cloudmapref` attributes pointing to the corresponding local files. Use `--update` flag if you've reorganized files and need to rebuild links. See skill_mindmap_references.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_references_004_q2", "cluster_id": "skill_mindmap_references_004", "question": "How do I build links between local mindmap files?", "answer": "To build links between local mindmap files, first create an index of your mindmap locations with `python3 scripts/mindmap/build_index.py output/mindmaps/ -o index.json`. Then run `python3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx --index index.json` to automatically add `cloudmapref` attributes that point to corresponding local mindmap files. This command scans each mindmap for Pearltrees URLs and generates the relative path references needed for offline navigation between mindmaps.", "question_type": "long", "topics": ["Mindmap", "Mindmap References"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["cross-links", "indexing", "navigation"], "related_skills": ["skill_mindmap_references.md", "skill_mindmap_cross_links.md", "skill_mindmap_indexing.md"], "related_docs": ["scripts/mindmap/build_index.py", "scripts/mindmap/add_relative_links.py"], "original_answer": "First, build an index of your mindmap locations: `python3 scripts/mindmap/build_index.py output/mindmaps/ -o index.json`. Then add cross-links with `python3 scripts/mindmap/add_relative_links.py output/mindmaps/*.smmx --index index.json`. This scans each mindmap for Pearltrees URLs and automatically adds `cloudmapref` attributes pointing to the corresponding local files. Use `--update` flag if you've reorganized files and need to rebuild links. See skill_mindmap_references.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_references_005_q0", "cluster_id": "skill_mindmap_references_005", "question": "How do I create a linked collection of mindmaps from scratch?", "answer": "To create a linked collection of mindmaps from scratch, follow this three-step pipeline: (1) Generate mindmaps recursively from Pearltrees using `python3 scripts/generate_mindmap.py --cluster-url https://www.pearltrees.com/s243a --recursive --output-dir output/mindmaps/`. (2) Build an index of mindmap locations with `python3 scripts/mindmap/build_index.py output/mindmaps/ -o index.json`. (3) Add cross-links between mindmaps using `python3 scripts/mindmap/add_relative_links.py output/mindmaps/**/*.smmx --index index.json`. This creates a fully navigable collection where each mindmap has both `cloudmapref` attributes for local offline navigation and `urllink` attributes for external Pearltrees references.", "question_type": "long", "topics": ["Mindmap", "Mindmap References"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["workflow", "generation", "collection"], "related_skills": ["skill_mindmap_references.md"], "related_docs": ["scripts/generate_mindmap.py", "scripts/mindmap/build_index.py", "scripts/mindmap/add_relative_links.py"], "original_answer": "Follow the three-step linking pipeline: (1) Generate mindmaps recursively from Pearltrees: `python3 scripts/generate_mindmap.py --cluster-url https://www.pearltrees.com/s243a --recursive --output-dir output/mindmaps/`. (2) Build an index: `python3 scripts/mindmap/build_index.py output/mindmaps/ -o index.json`. (3) Add cross-links: `python3 scripts/mindmap/add_relative_links.py output/mindmaps/**/*.smmx --index index.json`. This creates a fully navigable collection with both local `cloudmapref` and external `urllink` attributes. See skill_mindmap_references.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_references_005_q1", "cluster_id": "skill_mindmap_references_005", "question": "How can I build a complete mindmap collection with links?", "answer": "To build a complete mindmap collection with links, follow this three-step pipeline: (1) Generate mindmaps recursively from Pearltrees using `python3 scripts/generate_mindmap.py --cluster-url https://www.pearltrees.com/s243a --recursive --output-dir output/mindmaps/`. (2) Create an index of mindmap locations with `python3 scripts/mindmap/build_index.py output/mindmaps/ -o index.json`. (3) Add cross-links between mindmaps using `python3 scripts/mindmap/add_relative_links.py output/mindmaps/**/*.smmx --index index.json`. This creates a fully navigable collection where each mindmap has both `cloudmapref` attributes for local offline navigation and `urllink` attributes pointing to the original Pearltrees URLs.", "question_type": "long", "topics": ["Mindmap", "Mindmap References"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["workflow", "generation", "collection"], "related_skills": ["skill_mindmap_references.md"], "related_docs": ["scripts/generate_mindmap.py", "scripts/mindmap/build_index.py", "scripts/mindmap/add_relative_links.py"], "original_answer": "Follow the three-step linking pipeline: (1) Generate mindmaps recursively from Pearltrees: `python3 scripts/generate_mindmap.py --cluster-url https://www.pearltrees.com/s243a --recursive --output-dir output/mindmaps/`. (2) Build an index: `python3 scripts/mindmap/build_index.py output/mindmaps/ -o index.json`. (3) Add cross-links: `python3 scripts/mindmap/add_relative_links.py output/mindmaps/**/*.smmx --index index.json`. This creates a fully navigable collection with both local `cloudmapref` and external `urllink` attributes. See skill_mindmap_references.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_references_005_q2", "cluster_id": "skill_mindmap_references_005", "question": "How do I generate and link multiple mindmaps together?", "answer": "To generate and link multiple mindmaps together, follow this three-step pipeline: (1) Generate mindmaps recursively from Pearltrees using `python3 scripts/generate_mindmap.py --cluster-url https://www.pearltrees.com/s243a --recursive --output-dir output/mindmaps/`. (2) Build an index of all generated mindmaps with `python3 scripts/mindmap/build_index.py output/mindmaps/ -o index.json`. (3) Add cross-links between mindmaps using `python3 scripts/mindmap/add_relative_links.py output/mindmaps/**/*.smmx --index index.json`. This creates a fully navigable collection where each mindmap has both `cloudmapref` attributes for local offline navigation and `urllink` attributes pointing to the original Pearltrees URLs.", "question_type": "long", "topics": ["Mindmap", "Mindmap References"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["workflow", "generation", "collection"], "related_skills": ["skill_mindmap_references.md"], "related_docs": ["scripts/generate_mindmap.py", "scripts/mindmap/build_index.py", "scripts/mindmap/add_relative_links.py"], "original_answer": "Follow the three-step linking pipeline: (1) Generate mindmaps recursively from Pearltrees: `python3 scripts/generate_mindmap.py --cluster-url https://www.pearltrees.com/s243a --recursive --output-dir output/mindmaps/`. (2) Build an index: `python3 scripts/mindmap/build_index.py output/mindmaps/ -o index.json`. (3) Add cross-links: `python3 scripts/mindmap/add_relative_links.py output/mindmaps/**/*.smmx --index index.json`. This creates a fully navigable collection with both local `cloudmapref` and external `urllink` attributes. See skill_mindmap_references.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_references_006_q0", "cluster_id": "skill_mindmap_references_006", "question": "How do I choose between putting URLs on main nodes versus child nodes?", "answer": "When generating mindmaps, use the `--url-nodes` parameter to control link placement. The default (`--url-nodes both`) places both `urllink` and `cloudmapref` on the same node. Use `--url-nodes url` to place URLs on the main labeled node with `cloudmapref` on a square child node. Use `--url-nodes map` to reverse this, placing `cloudmapref` on the main node with URLs on children. This parameter lets you optimize the mindmap structure and navigation based on your preference for whether you want external URLs or local references more prominent.", "question_type": "long", "topics": ["Mindmap", "Mindmap References"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["generation", "strategy", "organization"], "related_skills": ["skill_mindmap_references.md"], "related_docs": ["scripts/generate_mindmap.py"], "original_answer": "When generating mindmaps, control link placement with the `--url-nodes` parameter: Use no parameter or `--url-nodes both` (default) to place both `urllink` and `cloudmapref` on the same node. Use `--url-nodes url` to place URLs on the main labeled node with `cloudmapref` on a square child. Use `--url-nodes map` to reverse this, placing `cloudmapref` on the main node with URLs on children. This affects how the mindmap looks and navigates while keeping both link types available. See skill_mindmap_references.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_references_006_q1", "cluster_id": "skill_mindmap_references_006", "question": "How can I control where URLs appear in generated mindmaps?", "answer": "When generating mindmaps, control link placement with the `--url-nodes` parameter. Use no parameter or `--url-nodes both` (default) to place both `urllink` and `cloudmapref` on the same node. Use `--url-nodes url` to place URLs on the main labeled node with `cloudmapref` on a square child node. Use `--url-nodes map` to reverse this, placing `cloudmapref` on the main node with URLs on child nodes. This controls the visual layout and navigation structure while keeping both link types available.", "question_type": "long", "topics": ["Mindmap", "Mindmap References"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["generation", "strategy", "organization"], "related_skills": ["skill_mindmap_references.md"], "related_docs": ["scripts/generate_mindmap.py"], "original_answer": "When generating mindmaps, control link placement with the `--url-nodes` parameter: Use no parameter or `--url-nodes both` (default) to place both `urllink` and `cloudmapref` on the same node. Use `--url-nodes url` to place URLs on the main labeled node with `cloudmapref` on a square child. Use `--url-nodes map` to reverse this, placing `cloudmapref` on the main node with URLs on children. This affects how the mindmap looks and navigates while keeping both link types available. See skill_mindmap_references.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_references_006_q2", "cluster_id": "skill_mindmap_references_006", "question": "What's the difference between --url-nodes url and --url-nodes map?", "answer": "The `--url-nodes` parameter controls where links are placed on mindmap nodes. `--url-nodes url` places `urllink` attributes on the main labeled node and `cloudmapref` on a square child node. `--url-nodes map` reverses this, placing `cloudmapref` on the main labeled node and `urllink` on child nodes. Both strategies keep both link types available but affect visual organization and navigation flow. The default behavior (no parameter or `--url-nodes both`) places both link types on the same node.", "question_type": "long", "topics": ["Mindmap", "Mindmap References"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["generation", "strategy", "organization"], "related_skills": ["skill_mindmap_references.md"], "related_docs": ["scripts/generate_mindmap.py"], "original_answer": "When generating mindmaps, control link placement with the `--url-nodes` parameter: Use no parameter or `--url-nodes both` (default) to place both `urllink` and `cloudmapref` on the same node. Use `--url-nodes url` to place URLs on the main labeled node with `cloudmapref` on a square child. Use `--url-nodes map` to reverse this, placing `cloudmapref` on the main node with URLs on children. This affects how the mindmap looks and navigates while keeping both link types available. See skill_mindmap_references.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_rename_001_q0", "cluster_id": "skill_mindmap_rename_001", "question": "How do I rename mindmap files to have meaningful names instead of IDs?", "answer": "Use the rename tool with the `--titled` flag to auto-generate meaningful names from your mindmap's root topic. For a single file:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --mindmap output/mindmaps/id10380971.smmx \\\n  --titled\n```\n\nThis automatically generates a filename like `Quantum_Mechanics_id10380971.smmx` based on the root topic text. To rename all mindmaps in a directory at once:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --batch output/mindmaps/ \\\n  --titled\n```\n\nThe tool also automatically updates all cloudmapref references in other mindmaps that link to the renamed file, so cross-references won't break. If you want to specify an explicit name instead of auto-generating from the root topic, use `--new-name` with your desired filename.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Rename"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["rename", "organization", "mindmap", "batch-operation"], "related_skills": ["skill_mindmap_rename.md", "skill_mindmap_indexing.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py", "scripts/mindmap/index_store.py"], "original_answer": "Use the rename tool with the `--titled` flag to auto-generate names from the root topic:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --mindmap output/mindmaps/id10380971.smmx \\\n  --titled\n```\n\nThis generates `Quantum_Mechanics_id10380971.smmx` format. For batch renaming all mindmaps in a directory:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --batch output/mindmaps/ \\\n  --titled\n```\n\nSee skill_mindmap_rename.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_rename_001_q1", "cluster_id": "skill_mindmap_rename_001", "question": "Can I rename id12345.smmx to something more readable?", "answer": "Yes! Use the rename tool with the `--titled` flag to auto-generate a readable name from the root topic:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --mindmap output/mindmaps/id12345.smmx \\\n  --titled\n```\n\nThis will rename `id12345.smmx` to a format like `RootTopicName_id12345.smmx`. If you want to specify a custom name instead:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --mindmap output/mindmaps/id12345.smmx \\\n  --new-name \"MyCustomName_id12345.smmx\"\n```\n\nThe tool automatically updates all cloudmapref references in other mindmaps that point to this file, so you won't break any cross-links.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Rename"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["rename", "organization", "mindmap", "batch-operation"], "related_skills": ["skill_mindmap_rename.md", "skill_mindmap_indexing.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py", "scripts/mindmap/index_store.py"], "original_answer": "Use the rename tool with the `--titled` flag to auto-generate names from the root topic:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --mindmap output/mindmaps/id10380971.smmx \\\n  --titled\n```\n\nThis generates `Quantum_Mechanics_id10380971.smmx` format. For batch renaming all mindmaps in a directory:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --batch output/mindmaps/ \\\n  --titled\n```\n\nSee skill_mindmap_rename.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_rename_001_q2", "cluster_id": "skill_mindmap_rename_001", "question": "How do I make mindmap filenames human-readable?", "answer": "Use the rename tool with the `--titled` flag to auto-generate human-readable names from the root topic:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --mindmap output/mindmaps/id10380971.smmx \\\n  --titled\n```\n\nThis converts generic IDs like `id10380971.smmx` to meaningful names like `Quantum_Mechanics_id10380971.smmx` by extracting the root topic text. For renaming all mindmaps in a directory at once:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --batch output/mindmaps/ \\\n  --titled\n```\n\nThe tool automatically updates all `cloudmapref` references in other mindmaps to point to the new filenames, so cross-links won't break.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Rename"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["rename", "organization", "mindmap", "batch-operation"], "related_skills": ["skill_mindmap_rename.md", "skill_mindmap_indexing.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py", "scripts/mindmap/index_store.py"], "original_answer": "Use the rename tool with the `--titled` flag to auto-generate names from the root topic:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --mindmap output/mindmaps/id10380971.smmx \\\n  --titled\n```\n\nThis generates `Quantum_Mechanics_id10380971.smmx` format. For batch renaming all mindmaps in a directory:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --batch output/mindmaps/ \\\n  --titled\n```\n\nSee skill_mindmap_rename.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_rename_001_q3", "cluster_id": "skill_mindmap_rename_001", "question": "What's the best way to rename mindmaps?", "answer": "The best way to rename mindmaps is to use the rename tool with the `--titled` flag, which auto-generates meaningful names from the root topic text. For a single mindmap: `python3 scripts/mindmap/rename_mindmap.py --mindmap output/mindmaps/id10380971.smmx --titled` generates names like `Quantum_Mechanics_id10380971.smmx`. For batch renaming all mindmaps in a directory: `python3 scripts/mindmap/rename_mindmap.py --batch output/mindmaps/ --titled`. This approach automatically updates all cloudmapref references across related mindmaps, preserving cross-links while using descriptive titles. For dry runs or custom names, use `--dry-run --verbose` or `--new-name` respectively.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Rename"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["rename", "organization", "mindmap", "batch-operation"], "related_skills": ["skill_mindmap_rename.md", "skill_mindmap_indexing.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py", "scripts/mindmap/index_store.py"], "original_answer": "Use the rename tool with the `--titled` flag to auto-generate names from the root topic:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --mindmap output/mindmaps/id10380971.smmx \\\n  --titled\n```\n\nThis generates `Quantum_Mechanics_id10380971.smmx` format. For batch renaming all mindmaps in a directory:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --batch output/mindmaps/ \\\n  --titled\n```\n\nSee skill_mindmap_rename.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_rename_002_q0", "cluster_id": "skill_mindmap_rename_002", "question": "When I rename a mindmap, how do the cross-reference links get updated?", "answer": "When you rename a mindmap, the rename tool automatically updates cross-reference links by scanning all mindmaps in the directory for `cloudmapref` attributes pointing to the old filename. It then recomputes the relative paths to reference the new filename instead. For example, if you rename `Physics/id10380971.smmx` to `Physics/Quantum_Mechanics_id10380971.smmx`, any mindmap with `cloudmapref=\"../Physics/id10380971.smmx\"` will be automatically updated to `cloudmapref=\"../Physics/Quantum_Mechanics_id10380971.smmx\"`. This keeps all cross-references valid and prevents broken links. You can use `--search-dir` to specify a custom directory to search for references if needed.", "question_type": "long", "topics": ["Mindmap", "Mindmap Rename"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["cross-links", "cloudmapref", "references", "rename"], "related_skills": ["skill_mindmap_rename.md", "skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py", "scripts/mindmap/index_store.py"], "original_answer": "The rename tool automatically scans all mindmaps for `cloudmapref` attributes pointing to the old filename and updates them to use the new name. For example:\n\n```\nBefore: Physics/id10380971.smmx\n        Other/related.smmx has cloudmapref=\"../Physics/id10380971.smmx\"\n\nAfter:  Physics/Quantum_Mechanics_id10380971.smmx\n        Other/related.smmx has cloudmapref=\"../Physics/Quantum_Mechanics_id10380971.smmx\"\n```\n\nThis prevents broken links and keeps cross-references valid. Use `--search-dir` to specify where to search for references if needed.\n\nSee skill_mindmap_rename.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_rename_002_q1", "cluster_id": "skill_mindmap_rename_002", "question": "Will cloudmapref links break if I rename a file?", "answer": "No, cloudmapref links will not break. The rename tool automatically scans all mindmaps for `cloudmapref` attributes pointing to the old filename and updates them to the new name. For example, if you rename `Physics/id10380971.smmx` to `Physics/Quantum_Mechanics_id10380971.smmx`, any mindmap containing `cloudmapref=\"../Physics/id10380971.smmx\"` will be automatically updated to `cloudmapref=\"../Physics/Quantum_Mechanics_id10380971.smmx\"`. This keeps all cross-references valid. You can use `--search-dir` to specify where to search for references if needed.", "question_type": "long", "topics": ["Mindmap", "Mindmap Rename"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["cross-links", "cloudmapref", "references", "rename"], "related_skills": ["skill_mindmap_rename.md", "skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py", "scripts/mindmap/index_store.py"], "original_answer": "The rename tool automatically scans all mindmaps for `cloudmapref` attributes pointing to the old filename and updates them to use the new name. For example:\n\n```\nBefore: Physics/id10380971.smmx\n        Other/related.smmx has cloudmapref=\"../Physics/id10380971.smmx\"\n\nAfter:  Physics/Quantum_Mechanics_id10380971.smmx\n        Other/related.smmx has cloudmapref=\"../Physics/Quantum_Mechanics_id10380971.smmx\"\n```\n\nThis prevents broken links and keeps cross-references valid. Use `--search-dir` to specify where to search for references if needed.\n\nSee skill_mindmap_rename.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_rename_002_q2", "cluster_id": "skill_mindmap_rename_002", "question": "How do cross-links stay valid after renaming?", "answer": "Cross-links stay valid after renaming because the rename tool automatically scans all mindmaps in the project for `cloudmapref` attributes pointing to the old filename and updates them to use the new name. When you rename a mindmap, the tool finds every reference to the old file path and rewrites it with the correct new path, preserving the relative path structure. For example, if `Physics/id10380971.smmx` is renamed to `Physics/Quantum_Mechanics_id10380971.smmx`, any mindmap with `cloudmapref=\"../Physics/id10380971.smmx\"` will automatically be updated to `cloudmapref=\"../Physics/Quantum_Mechanics_id10380971.smmx\"`. You can specify the search directory with `--search-dir` if references exist outside the default location.", "question_type": "long", "topics": ["Mindmap", "Mindmap Rename"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["cross-links", "cloudmapref", "references", "rename"], "related_skills": ["skill_mindmap_rename.md", "skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py", "scripts/mindmap/index_store.py"], "original_answer": "The rename tool automatically scans all mindmaps for `cloudmapref` attributes pointing to the old filename and updates them to use the new name. For example:\n\n```\nBefore: Physics/id10380971.smmx\n        Other/related.smmx has cloudmapref=\"../Physics/id10380971.smmx\"\n\nAfter:  Physics/Quantum_Mechanics_id10380971.smmx\n        Other/related.smmx has cloudmapref=\"../Physics/Quantum_Mechanics_id10380971.smmx\"\n```\n\nThis prevents broken links and keeps cross-references valid. Use `--search-dir` to specify where to search for references if needed.\n\nSee skill_mindmap_rename.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_rename_002_q3", "cluster_id": "skill_mindmap_rename_002", "question": "Does the tool update references automatically?", "answer": "Yes, the tool automatically updates references. When you rename a mindmap, the rename tool scans all other mindmaps for `cloudmapref` attributes pointing to the old filename and updates them to use the new name. For example, if you rename `Physics/id10380971.smmx` to `Physics/Quantum_Mechanics_id10380971.smmx`, any mindmap with `cloudmapref=\"../Physics/id10380971.smmx\"` will be automatically updated to `cloudmapref=\"../Physics/Quantum_Mechanics_id10380971.smmx\"`. This prevents broken links and keeps cross-references valid. Use `--search-dir` to specify where to search for references if needed.", "question_type": "long", "topics": ["Mindmap", "Mindmap Rename"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["cross-links", "cloudmapref", "references", "rename"], "related_skills": ["skill_mindmap_rename.md", "skill_mindmap_cross_links.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py", "scripts/mindmap/index_store.py"], "original_answer": "The rename tool automatically scans all mindmaps for `cloudmapref` attributes pointing to the old filename and updates them to use the new name. For example:\n\n```\nBefore: Physics/id10380971.smmx\n        Other/related.smmx has cloudmapref=\"../Physics/id10380971.smmx\"\n\nAfter:  Physics/Quantum_Mechanics_id10380971.smmx\n        Other/related.smmx has cloudmapref=\"../Physics/Quantum_Mechanics_id10380971.smmx\"\n```\n\nThis prevents broken links and keeps cross-references valid. Use `--search-dir` to specify where to search for references if needed.\n\nSee skill_mindmap_rename.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_rename_003_q0", "cluster_id": "skill_mindmap_rename_003", "question": "Can I rename all my mindmaps at once and avoid breaking links?", "answer": "Yes, you can rename all your mindmaps at once without breaking links. Use batch mode with the `--batch` flag, which safely handles all references:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --batch output/mindmaps/ \\\n  --titled \\\n  --index index.json\n```\n\nThe tool works by: (1) scanning all files to build a complete reference map, (2) updating all cloudmapref attributes to point to the new filenames, and (3) only then renaming the actual files. This ensures no links break in the process.\n\nTo preview changes first without making them:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --batch output/mindmaps/ \\\n  --titled \\\n  --dry-run --verbose\n```", "question_type": "long", "topics": ["Mindmap", "Mindmap Rename"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["batch-operation", "rename", "references", "safe-rename"], "related_skills": ["skill_mindmap_rename.md", "skill_mindmap_indexing.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py", "scripts/mindmap/build_reverse_index.py"], "original_answer": "Yes, use batch mode with the `--batch` flag. The tool scans all files first to build a reference map, then updates all cloudmapref attributes before actually renaming files:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --batch output/mindmaps/ \\\n  --titled \\\n  --index index.json\n```\n\nFor a preview without making changes:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --batch output/mindmaps/ \\\n  --titled \\\n  --dry-run --verbose\n```\n\nBatch mode prevents broken links by updating all references before renaming anything.\n\nSee skill_mindmap_rename.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_rename_003_q1", "cluster_id": "skill_mindmap_rename_003", "question": "How do I batch rename mindmaps without breaking references?", "answer": "Use batch mode with the `--batch` flag to rename all mindmaps while preserving references. The tool automatically scans all files to map dependencies, updates all cloudmapref attributes to point to the new filenames, and only then renames the files:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --batch output/mindmaps/ \\\n  --titled\n```\n\nAdd `--index index.json` if you need to update an index file simultaneously. To preview changes without modifying anything:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --batch output/mindmaps/ \\\n  --titled \\\n  --dry-run --verbose\n```\n\nBatch mode ensures no broken links by updating all cross-references before any files are actually renamed.", "question_type": "long", "topics": ["Mindmap", "Mindmap Rename"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["batch-operation", "rename", "references", "safe-rename"], "related_skills": ["skill_mindmap_rename.md", "skill_mindmap_indexing.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py", "scripts/mindmap/build_reverse_index.py"], "original_answer": "Yes, use batch mode with the `--batch` flag. The tool scans all files first to build a reference map, then updates all cloudmapref attributes before actually renaming files:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --batch output/mindmaps/ \\\n  --titled \\\n  --index index.json\n```\n\nFor a preview without making changes:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --batch output/mindmaps/ \\\n  --titled \\\n  --dry-run --verbose\n```\n\nBatch mode prevents broken links by updating all references before renaming anything.\n\nSee skill_mindmap_rename.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_rename_003_q2", "cluster_id": "skill_mindmap_rename_003", "question": "Is it safe to rename multiple mindmaps together?", "answer": "Yes, batch rename is safe. Use the `--batch` flag to rename multiple mindmaps together. The tool builds a complete reference map of all cloudmapref links first, updates all references across files, and only then renames the files. This prevents broken cross-links.\n\nExample:\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --batch output/mindmaps/ \\\n  --titled \\\n  --index index.json\n```\n\nAlways preview changes first with `--dry-run --verbose` to verify nothing will break before committing the batch operation.", "question_type": "long", "topics": ["Mindmap", "Mindmap Rename"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["batch-operation", "rename", "references", "safe-rename"], "related_skills": ["skill_mindmap_rename.md", "skill_mindmap_indexing.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py", "scripts/mindmap/build_reverse_index.py"], "original_answer": "Yes, use batch mode with the `--batch` flag. The tool scans all files first to build a reference map, then updates all cloudmapref attributes before actually renaming files:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --batch output/mindmaps/ \\\n  --titled \\\n  --index index.json\n```\n\nFor a preview without making changes:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --batch output/mindmaps/ \\\n  --titled \\\n  --dry-run --verbose\n```\n\nBatch mode prevents broken links by updating all references before renaming anything.\n\nSee skill_mindmap_rename.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_rename_003_q3", "cluster_id": "skill_mindmap_rename_003", "question": "What's the strategy for renaming many files?", "answer": "Use batch mode with the `--batch` flag to rename many files efficiently. The tool scans all files first to build a reference map, then updates all cloudmapref attributes before actually renaming files:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --batch output/mindmaps/ \\\n  --titled \\\n  --index index.json\n```\n\nThis strategy prevents broken links by updating all references before renaming anything. For a preview without making changes, add `--dry-run --verbose`:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --batch output/mindmaps/ \\\n  --titled \\\n  --dry-run --verbose\n```", "question_type": "long", "topics": ["Mindmap", "Mindmap Rename"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["batch-operation", "rename", "references", "safe-rename"], "related_skills": ["skill_mindmap_rename.md", "skill_mindmap_indexing.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py", "scripts/mindmap/build_reverse_index.py"], "original_answer": "Yes, use batch mode with the `--batch` flag. The tool scans all files first to build a reference map, then updates all cloudmapref attributes before actually renaming files:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --batch output/mindmaps/ \\\n  --titled \\\n  --index index.json\n```\n\nFor a preview without making changes:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --batch output/mindmaps/ \\\n  --titled \\\n  --dry-run --verbose\n```\n\nBatch mode prevents broken links by updating all references before renaming anything.\n\nSee skill_mindmap_rename.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_rename_004_q0", "cluster_id": "skill_mindmap_rename_004", "question": "How do I specify an exact new filename for a mindmap?", "answer": "Use the `--new-name` flag to specify your exact desired filename:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --mindmap output/mindmaps/id10380971.smmx \\\n  --new-name \"Quantum_Physics_10380971.smmx\"\n```\n\nThe script will rename the file to your specified name and automatically update all cloudmapref references in other mindmaps to point to the new filename.", "question_type": "long", "topics": ["Mindmap", "Mindmap Rename"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["rename", "custom-name", "explicit-rename"], "related_skills": ["skill_mindmap_rename.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py"], "original_answer": "Use the `--new-name` flag with your exact desired filename:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --mindmap output/mindmaps/id10380971.smmx \\\n  --new-name \"Quantum_Physics_10380971.smmx\"\n```\n\nThe tree ID should be preserved in the filename to ensure uniqueness. All cloudmapref references will be automatically updated to the new path.\n\nSee skill_mindmap_rename.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_rename_004_q1", "cluster_id": "skill_mindmap_rename_004", "question": "Can I rename a mindmap to a specific name I choose?", "answer": "Yes, you can rename a mindmap to a specific name you choose using the `--new-name` flag:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --mindmap output/mindmaps/id10380971.smmx \\\n  --new-name \"Your_Custom_Name_10380971.smmx\"\n```\n\nReplace `Your_Custom_Name_10380971.smmx` with your desired filename. The script will automatically update all cloudmapref references in other mindmaps that point to the renamed file, so cross-links remain intact.", "question_type": "long", "topics": ["Mindmap", "Mindmap Rename"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["rename", "custom-name", "explicit-rename"], "related_skills": ["skill_mindmap_rename.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py"], "original_answer": "Use the `--new-name` flag with your exact desired filename:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --mindmap output/mindmaps/id10380971.smmx \\\n  --new-name \"Quantum_Physics_10380971.smmx\"\n```\n\nThe tree ID should be preserved in the filename to ensure uniqueness. All cloudmapref references will be automatically updated to the new path.\n\nSee skill_mindmap_rename.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_rename_004_q2", "cluster_id": "skill_mindmap_rename_004", "question": "What if I don't want auto-generated titles?", "answer": "Use the `--new-name` flag to specify your exact desired filename instead of auto-generating from the root topic:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --mindmap output/mindmaps/id10380971.smmx \\\n  --new-name \"My_Custom_Name_10380971.smmx\"\n```\n\nThis gives you full control over the filename. The script will still automatically update all cloudmapref references in other mindmaps to point to your new filename.", "question_type": "long", "topics": ["Mindmap", "Mindmap Rename"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["rename", "custom-name", "explicit-rename"], "related_skills": ["skill_mindmap_rename.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py"], "original_answer": "Use the `--new-name` flag with your exact desired filename:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --mindmap output/mindmaps/id10380971.smmx \\\n  --new-name \"Quantum_Physics_10380971.smmx\"\n```\n\nThe tree ID should be preserved in the filename to ensure uniqueness. All cloudmapref references will be automatically updated to the new path.\n\nSee skill_mindmap_rename.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_rename_004_q3", "cluster_id": "skill_mindmap_rename_004", "question": "How do I use a custom filename?", "answer": "Use the `--new-name` flag to specify your exact desired filename:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --mindmap output/mindmaps/id10380971.smmx \\\n  --new-name \"Quantum_Physics_10380971.smmx\"\n```\n\nReplace `output/mindmaps/id10380971.smmx` with your mindmap path and `Quantum_Physics_10380971.smmx` with your desired filename. The script will automatically update all cloudmapref references in other mindmaps to point to the new path.", "question_type": "long", "topics": ["Mindmap", "Mindmap Rename"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["rename", "custom-name", "explicit-rename"], "related_skills": ["skill_mindmap_rename.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py"], "original_answer": "Use the `--new-name` flag with your exact desired filename:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --mindmap output/mindmaps/id10380971.smmx \\\n  --new-name \"Quantum_Physics_10380971.smmx\"\n```\n\nThe tree ID should be preserved in the filename to ensure uniqueness. All cloudmapref references will be automatically updated to the new path.\n\nSee skill_mindmap_rename.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_rename_005_q0", "cluster_id": "skill_mindmap_rename_005", "question": "I want shorter filenames without the 'id' prefix. How do I do that?", "answer": "Use the `--no-id-prefix` flag to omit the 'id' prefix from your renamed mindmaps:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --mindmap output/mindmaps/id10380971.smmx \\\n  --titled \\\n  --no-id-prefix\n```\n\nThis generates `Quantum_Mechanics_10380971.smmx` instead of `Quantum_Mechanics_id10380971.smmx`. For batch renaming with shorter filenames, you can also combine `--max-title` to limit the title length:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --batch output/to_share/ \\\n  --titled \\\n  --max-title 30 \\\n  --no-id-prefix\n```", "question_type": "medium", "topics": ["Mindmap", "Mindmap Rename"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["rename", "filename-format", "title-length"], "related_skills": ["skill_mindmap_rename.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py"], "original_answer": "Use the `--no-id-prefix` flag to omit the 'id' prefix:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --mindmap output/mindmaps/id10380971.smmx \\\n  --titled \\\n  --no-id-prefix\n```\n\nThis creates `Quantum_Mechanics_10380971.smmx` instead of `Quantum_Mechanics_id10380971.smmx`. You can also limit title length with `--max-title 30`:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --batch output/to_share/ \\\n  --titled \\\n  --max-title 30 \\\n  --no-id-prefix\n```\n\nSee skill_mindmap_rename.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_rename_005_q1", "cluster_id": "skill_mindmap_rename_005", "question": "Can I remove the 'id' prefix from filenames?", "answer": "Yes. Use the `--no-id-prefix` flag to remove the 'id' prefix from filenames:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --mindmap output/mindmaps/id10380971.smmx \\\n  --titled \\\n  --no-id-prefix\n```\n\nThis creates `Quantum_Mechanics_10380971.smmx` instead of `Quantum_Mechanics_id10380971.smmx`. For batch operations:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --batch output/mindmaps/ \\\n  --titled \\\n  --no-id-prefix\n```", "question_type": "medium", "topics": ["Mindmap", "Mindmap Rename"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["rename", "filename-format", "title-length"], "related_skills": ["skill_mindmap_rename.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py"], "original_answer": "Use the `--no-id-prefix` flag to omit the 'id' prefix:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --mindmap output/mindmaps/id10380971.smmx \\\n  --titled \\\n  --no-id-prefix\n```\n\nThis creates `Quantum_Mechanics_10380971.smmx` instead of `Quantum_Mechanics_id10380971.smmx`. You can also limit title length with `--max-title 30`:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --batch output/to_share/ \\\n  --titled \\\n  --max-title 30 \\\n  --no-id-prefix\n```\n\nSee skill_mindmap_rename.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_rename_005_q2", "cluster_id": "skill_mindmap_rename_005", "question": "How do I create shorter filenames with just title and number?", "answer": "Use the `--no-id-prefix` flag to create shorter filenames with just the title and number:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --mindmap output/mindmaps/id10380971.smmx \\\n  --titled \\\n  --no-id-prefix\n```\n\nThis generates `Quantum_Mechanics_10380971.smmx` instead of `Quantum_Mechanics_id10380971.smmx`. For batch renaming with shorter titles, combine with `--max-title`:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --batch output/to_share/ \\\n  --titled \\\n  --max-title 30 \\\n  --no-id-prefix\n```", "question_type": "medium", "topics": ["Mindmap", "Mindmap Rename"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["rename", "filename-format", "title-length"], "related_skills": ["skill_mindmap_rename.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py"], "original_answer": "Use the `--no-id-prefix` flag to omit the 'id' prefix:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --mindmap output/mindmaps/id10380971.smmx \\\n  --titled \\\n  --no-id-prefix\n```\n\nThis creates `Quantum_Mechanics_10380971.smmx` instead of `Quantum_Mechanics_id10380971.smmx`. You can also limit title length with `--max-title 30`:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --batch output/to_share/ \\\n  --titled \\\n  --max-title 30 \\\n  --no-id-prefix\n```\n\nSee skill_mindmap_rename.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_rename_005_q3", "cluster_id": "skill_mindmap_rename_005", "question": "Is there a way to use Title_12345 format instead of Title_id12345?", "answer": "Yes, use the `--no-id-prefix` flag to omit the 'id' prefix from the filename:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --mindmap output/mindmaps/id10380971.smmx \\\n  --titled \\\n  --no-id-prefix\n```\n\nThis generates `Quantum_Mechanics_10380971.smmx` instead of `Quantum_Mechanics_id10380971.smmx`. The flag works with both single file and batch rename operations.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Rename"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["rename", "filename-format", "title-length"], "related_skills": ["skill_mindmap_rename.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py"], "original_answer": "Use the `--no-id-prefix` flag to omit the 'id' prefix:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --mindmap output/mindmaps/id10380971.smmx \\\n  --titled \\\n  --no-id-prefix\n```\n\nThis creates `Quantum_Mechanics_10380971.smmx` instead of `Quantum_Mechanics_id10380971.smmx`. You can also limit title length with `--max-title 30`:\n\n```bash\npython3 scripts/mindmap/rename_mindmap.py \\\n  --batch output/to_share/ \\\n  --titled \\\n  --max-title 30 \\\n  --no-id-prefix\n```\n\nSee skill_mindmap_rename.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_rename_006_q0", "cluster_id": "skill_mindmap_rename_006", "question": "What happens if two mindmaps have the same root topic? Will they collide?", "answer": "No collision occurs because the tree ID is always preserved as a suffix, ensuring uniqueness. Even if two mindmaps share the same root topic like \"Physics\", they generate distinct filenames:\n\n- Physics_id12345.smmx\n- Physics_id67890.smmx\n\nThe ID suffix guarantees each mindmap has a unique filename regardless of title duplication, preventing file overwrites and maintaining referential integrity in cloudmapref links.", "question_type": "long", "topics": ["Mindmap", "Mindmap Rename"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["collision-detection", "uniqueness", "filename-safety"], "related_skills": ["skill_mindmap_rename.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py"], "original_answer": "No collision occurs because the tree ID is always preserved as a suffix, ensuring uniqueness. Even if two mindmaps have the same root topic \"Physics\", they generate different filenames:\n\n```\nPhysics_id12345.smmx\nPhysics_id67890.smmx\n```\n\nThe ID suffix guarantees no two mindmaps will have identical filenames, regardless of their titles. This prevents overwrites and maintains referential integrity in cloudmapref links.\n\nSee skill_mindmap_rename.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_rename_006_q1", "cluster_id": "skill_mindmap_rename_006", "question": "Can I have duplicate titles in mindmap filenames?", "answer": "No, you cannot have duplicate titles in mindmap filenames because the tree ID is always preserved as a suffix. Even if two mindmaps share the same root topic like \"Physics\", they generate unique filenames: Physics_id12345.smmx and Physics_id67890.smmx. The ID suffix guarantees uniqueness and prevents file overwrites while maintaining referential integrity in cloudmapref links.", "question_type": "long", "topics": ["Mindmap", "Mindmap Rename"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["collision-detection", "uniqueness", "filename-safety"], "related_skills": ["skill_mindmap_rename.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py"], "original_answer": "No collision occurs because the tree ID is always preserved as a suffix, ensuring uniqueness. Even if two mindmaps have the same root topic \"Physics\", they generate different filenames:\n\n```\nPhysics_id12345.smmx\nPhysics_id67890.smmx\n```\n\nThe ID suffix guarantees no two mindmaps will have identical filenames, regardless of their titles. This prevents overwrites and maintains referential integrity in cloudmapref links.\n\nSee skill_mindmap_rename.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_rename_006_q2", "cluster_id": "skill_mindmap_rename_006", "question": "How does the tool prevent filename collisions?", "answer": "The tool prevents filename collisions by always preserving the tree ID as a suffix in the renamed file. Even if multiple mindmaps have identical root topic titles, they generate unique filenames because each has a different ID. For example, two mindmaps titled \"Physics\" become `Physics_id12345.smmx` and `Physics_id67890.smmx`. This ID-based uniqueness guarantee ensures no two files can have the same name, preventing overwrites and maintaining the integrity of cloudmapref cross-references.", "question_type": "long", "topics": ["Mindmap", "Mindmap Rename"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["collision-detection", "uniqueness", "filename-safety"], "related_skills": ["skill_mindmap_rename.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py"], "original_answer": "No collision occurs because the tree ID is always preserved as a suffix, ensuring uniqueness. Even if two mindmaps have the same root topic \"Physics\", they generate different filenames:\n\n```\nPhysics_id12345.smmx\nPhysics_id67890.smmx\n```\n\nThe ID suffix guarantees no two mindmaps will have identical filenames, regardless of their titles. This prevents overwrites and maintains referential integrity in cloudmapref links.\n\nSee skill_mindmap_rename.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_rename_006_q3", "cluster_id": "skill_mindmap_rename_006", "question": "What if multiple mindmaps have the same name?", "answer": "No collision occurs because the tree ID is always preserved as a suffix, ensuring uniqueness. Even if two mindmaps have the same root topic (e.g., \"Physics\"), they generate different filenames:\n\n- Physics_id12345.smmx\n- Physics_id67890.smmx\n\nThe ID suffix guarantees no two mindmaps will have identical filenames, preventing overwrites and maintaining referential integrity in cloudmapref links.", "question_type": "long", "topics": ["Mindmap", "Mindmap Rename"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["collision-detection", "uniqueness", "filename-safety"], "related_skills": ["skill_mindmap_rename.md"], "related_docs": ["scripts/mindmap/rename_mindmap.py"], "original_answer": "No collision occurs because the tree ID is always preserved as a suffix, ensuring uniqueness. Even if two mindmaps have the same root topic \"Physics\", they generate different filenames:\n\n```\nPhysics_id12345.smmx\nPhysics_id67890.smmx\n```\n\nThe ID suffix guarantees no two mindmaps will have identical filenames, regardless of their titles. This prevents overwrites and maintains referential integrity in cloudmapref links.\n\nSee skill_mindmap_rename.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_tools_001_q0", "cluster_id": "skill_mindmap_tools_001", "question": "How do I work with mindmap files?", "answer": "To work with mindmap files (.smmx), use SimpleMind mindmap tools to: (1) Generate mindmaps from your data using scripts, (2) Build an index to track file locations, (3) Add cross-references between mindmaps using relative cloudmapref links and external URLs via urllink attributes, (4) Organize mindmaps semantically into folders, and (5) Explore them visually. The .smmx format is a zip archive containing document.xml with topic hierarchies and linking metadata. See skill_mindmap_tools.md for the typical workflow and sub-skills for specific tasks like organization, indexing, and cross-linking.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Tools (Sub-Master)"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "organization", "SimpleMind", "workflow"], "related_skills": ["skill_mindmap_tools.md", "skill_mindmap_organization.md", "skill_mindmap_indexing.md", "skill_mindmap_references.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/generate_mindmap.py"], "original_answer": "Mindmap tools help you manage SimpleMind mindmap files (.smmx). You can organize them semantically, build indexes for lookup, add cross-references between mindmaps, and link to external URLs like Pearltrees. Start by generating mindmaps, building an index, adding links, and organizing into folders. See skill_mindmap_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_tools_001_q1", "cluster_id": "skill_mindmap_tools_001", "question": "What can I do with SimpleMind mindmaps?", "answer": "With SimpleMind mindmaps (.smmx files), you can organize them semantically using embeddings and clustering, build indexes to track file locations and manage renames, create navigable links between mindmaps using cloudmapref, and link to external URLs like Pearltrees using urllink. The typical workflow involves generating mindmaps from data, building an index for lookup, adding cross-links between files, organizing into folders, and visualizing them with tools like the density explorer.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Tools (Sub-Master)"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "organization", "SimpleMind", "workflow"], "related_skills": ["skill_mindmap_tools.md", "skill_mindmap_organization.md", "skill_mindmap_indexing.md", "skill_mindmap_references.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/generate_mindmap.py"], "original_answer": "Mindmap tools help you manage SimpleMind mindmap files (.smmx). You can organize them semantically, build indexes for lookup, add cross-references between mindmaps, and link to external URLs like Pearltrees. Start by generating mindmaps, building an index, adding links, and organizing into folders. See skill_mindmap_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_tools_001_q2", "cluster_id": "skill_mindmap_tools_001", "question": "How do I manage .smmx files?", "answer": "To manage .smmx files, use SimpleMind mindmap tools to organize, index, and link them. You can semantically organize mindmaps using embeddings, build indexes to track file locations, add cross-references between mindmaps using cloudmapref attributes, and link to external URLs. The typical workflow involves: generating mindmaps from data, building an index with build_index.py, adding relative links with add_relative_links.py, organizing into folders with mst_folder_grouping.py, and optionally visualizing with the density explorer. Each .smmx file is a zip archive containing document.xml with topic hierarchies and link attributes (urllink for external URLs, cloudmapref for local mindmap references).", "question_type": "medium", "topics": ["Mindmap", "Mindmap Tools (Sub-Master)"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["mindmap", "organization", "SimpleMind", "workflow"], "related_skills": ["skill_mindmap_tools.md", "skill_mindmap_organization.md", "skill_mindmap_indexing.md", "skill_mindmap_references.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/generate_mindmap.py"], "original_answer": "Mindmap tools help you manage SimpleMind mindmap files (.smmx). You can organize them semantically, build indexes for lookup, add cross-references between mindmaps, and link to external URLs like Pearltrees. Start by generating mindmaps, building an index, adding links, and organizing into folders. See skill_mindmap_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_tools_002_q0", "cluster_id": "skill_mindmap_tools_002", "question": "How do I organize mindmap files?", "answer": "You can organize mindmaps semantically using embeddings and clustering. Use the MST folder grouping tool to automatically suggest folder structures based on semantic similarity: `python3 scripts/mindmap/mst_folder_grouping.py --input output/ --output organized/`. This analyzes your mindmap content and groups related files together into folders. For more details on organization strategies and customization options, see skill_mindmap_organization.md.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Tools (Sub-Master)", "Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["organization", "clustering", "folder-structure"], "related_skills": ["skill_mindmap_tools.md", "skill_mindmap_organization.md"], "related_docs": ["scripts/mindmap/README.md"], "original_answer": "You can organize mindmaps semantically using embeddings and clustering. Use the MST folder grouping tool to automatically suggest folder structures: `python3 scripts/mindmap/mst_folder_grouping.py --input output/ --output organized/`. This groups related mindmaps together based on semantic similarity. See skill_mindmap_tools.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_mindmap_tools_002_q1", "cluster_id": "skill_mindmap_tools_002", "question": "Can I organize mindmaps into folders automatically?", "answer": "Yes, you can automatically organize mindmaps into folders using semantic clustering. Run `python3 scripts/mindmap/mst_folder_grouping.py --input output/ --output organized/` to group related mindmaps together based on semantic similarity. This tool uses embeddings and minimum spanning tree clustering to suggest folder structures that organize your mindmaps semantically.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Tools (Sub-Master)", "Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["organization", "clustering", "folder-structure"], "related_skills": ["skill_mindmap_tools.md", "skill_mindmap_organization.md"], "related_docs": ["scripts/mindmap/README.md"], "original_answer": "You can organize mindmaps semantically using embeddings and clustering. Use the MST folder grouping tool to automatically suggest folder structures: `python3 scripts/mindmap/mst_folder_grouping.py --input output/ --output organized/`. This groups related mindmaps together based on semantic similarity. See skill_mindmap_tools.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer references 'skill_mindmap_organization.md' but doesn't provide specific details about what semantic similarity means in this context or whether the output folders are suggested vs. automatically created. The command syntax and behavior could be clearer for users unfamiliar with the tool."}
{"pair_id": "skill_mindmap_tools_002_q2", "cluster_id": "skill_mindmap_tools_002", "question": "How do I structure mindmap collections?", "answer": "You can organize mindmaps semantically using embeddings and clustering through the MST folder grouping tool. Run `python3 scripts/mindmap/mst_folder_grouping.py --input output/ --output organized/` to automatically group related mindmaps based on semantic similarity. This creates a structured folder hierarchy that organizes your collection logically. For a complete workflow including generation, indexing, and linking before organization, refer to skill_mindmap_tools.md.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Tools (Sub-Master)", "Organization"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["organization", "clustering", "folder-structure"], "related_skills": ["skill_mindmap_tools.md", "skill_mindmap_organization.md"], "related_docs": ["scripts/mindmap/README.md"], "original_answer": "You can organize mindmaps semantically using embeddings and clustering. Use the MST folder grouping tool to automatically suggest folder structures: `python3 scripts/mindmap/mst_folder_grouping.py --input output/ --output organized/`. This groups related mindmaps together based on semantic similarity. See skill_mindmap_tools.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_mindmap_tools_003_q0", "cluster_id": "skill_mindmap_tools_003", "question": "What is the SimpleMind file format?", "answer": "SimpleMind mindmaps use the .smmx format, which is a ZIP archive containing document.xml. The XML structure organizes content within `<simplemind-mindmaps>` elements containing `<mindmap>` and `<topics>` sections. Topics support two key attributes: `urllink` for external URLs (e.g., Pearltrees pages) and `cloudmapref` for relative paths to other local mindmaps. This dual-reference structure enables both external linking and local cross-references between mindmaps.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Tools (Sub-Master)"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["format", ".smmx", "structure", "XML"], "related_skills": ["skill_mindmap_tools.md", "skill_mindmap_references.md"], "related_docs": ["scripts/mindmap/README.md"], "original_answer": "SimpleMind mindmaps use the .smmx format, which is a ZIP archive containing document.xml. Inside, topics can have two key attributes: `urllink` for external URLs (like Pearltrees pages) and `cloudmapref` for relative paths to other local mindmaps. This structure enables both external linking and local cross-references. See skill_mindmap_tools.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_tools_003_q1", "cluster_id": "skill_mindmap_tools_003", "question": "How are .smmx files structured?", "answer": ".smmx files are ZIP archives containing a document.xml file with a SimpleMind XML structure. The root element is <simplemind-mindmaps> containing <mindmap> elements, which have <topics> with nested <topic> elements. Topics can include two key attributes: `urllink` for external URLs (such as Pearltrees pages) and `cloudmapref` for relative paths to other local mindmap files. This dual-attribute structure enables both external linking to web resources and local cross-references between mindmaps.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Tools (Sub-Master)"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["format", ".smmx", "structure", "XML"], "related_skills": ["skill_mindmap_tools.md", "skill_mindmap_references.md"], "related_docs": ["scripts/mindmap/README.md"], "original_answer": "SimpleMind mindmaps use the .smmx format, which is a ZIP archive containing document.xml. Inside, topics can have two key attributes: `urllink` for external URLs (like Pearltrees pages) and `cloudmapref` for relative paths to other local mindmaps. This structure enables both external linking and local cross-references. See skill_mindmap_tools.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mindmap_tools_003_q2", "cluster_id": "skill_mindmap_tools_003", "question": "What does a mindmap file contain?", "answer": "A SimpleMind mindmap file (.smmx) is a ZIP archive containing document.xml. The XML structure includes topics organized hierarchically, where each topic can have two key attributes: `urllink` for external URLs (such as Pearltrees pages) and `cloudmapref` for relative paths to other local mindmaps. This dual-linking capability allows mindmaps to connect both to external web resources and to other mindmaps within the local file system.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Tools (Sub-Master)"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["format", ".smmx", "structure", "XML"], "related_skills": ["skill_mindmap_tools.md", "skill_mindmap_references.md"], "related_docs": ["scripts/mindmap/README.md"], "original_answer": "SimpleMind mindmaps use the .smmx format, which is a ZIP archive containing document.xml. Inside, topics can have two key attributes: `urllink` for external URLs (like Pearltrees pages) and `cloudmapref` for relative paths to other local mindmaps. This structure enables both external linking and local cross-references. See skill_mindmap_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_tools_004_q0", "cluster_id": "skill_mindmap_tools_004", "question": "How do I create an index of my mindmaps?", "answer": "To create an index of your mindmaps, use the command: `python3 scripts/mindmap/build_index.py output/ -o index.json`. This generates forward and reverse indexes that track file locations, helping you find mindmaps and maintain consistency when files are renamed or moved.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Tools (Sub-Master)", "Indexing"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["indexing", "lookup", "consistency", "references"], "related_skills": ["skill_mindmap_tools.md", "skill_mindmap_indexing.md"], "related_docs": ["scripts/mindmap/README.md"], "original_answer": "Build a mindmap index to track file locations and maintain consistency. Use: `python3 scripts/mindmap/build_index.py output/ -o index.json`. This creates forward and reverse indexes that help you find mindmaps and update references when files are renamed or moved. See skill_mindmap_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_tools_004_q1", "cluster_id": "skill_mindmap_tools_004", "question": "Can I track where mindmap files are located?", "answer": "Yes, you can track mindmap file locations by building a mindmap index. Use `python3 scripts/mindmap/build_index.py output/ -o index.json` to create forward and reverse indexes that track where each mindmap file is located. This index helps you find mindmaps quickly and automatically update references when files are renamed or moved.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Tools (Sub-Master)", "Indexing"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["indexing", "lookup", "consistency", "references"], "related_skills": ["skill_mindmap_tools.md", "skill_mindmap_indexing.md"], "related_docs": ["scripts/mindmap/README.md"], "original_answer": "Build a mindmap index to track file locations and maintain consistency. Use: `python3 scripts/mindmap/build_index.py output/ -o index.json`. This creates forward and reverse indexes that help you find mindmaps and update references when files are renamed or moved. See skill_mindmap_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_tools_004_q2", "cluster_id": "skill_mindmap_tools_004", "question": "How do I maintain consistency when renaming mindmaps?", "answer": "To maintain consistency when renaming mindmaps, build a mindmap index using `python3 scripts/mindmap/build_index.py output/ -o index.json`. This creates forward and reverse indexes that track file locations and help you find all references to a mindmap. When renaming files, use the rename script which automatically updates all cloudmapref links in other mindmaps: `python3 scripts/mindmap/mindmap_rename.py old_name.smmx new_name.smmx --index index.json`. This ensures that relative paths in linked mindmaps stay valid after the rename. Rebuild the index after making changes to keep it current.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Tools (Sub-Master)", "Indexing"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["indexing", "lookup", "consistency", "references"], "related_skills": ["skill_mindmap_tools.md", "skill_mindmap_indexing.md"], "related_docs": ["scripts/mindmap/README.md"], "original_answer": "Build a mindmap index to track file locations and maintain consistency. Use: `python3 scripts/mindmap/build_index.py output/ -o index.json`. This creates forward and reverse indexes that help you find mindmaps and update references when files are renamed or moved. See skill_mindmap_tools.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "Base answer mentions indexing but doesn't specify the rename workflow or how to actually update references after renaming. The tailored answer infers a rename script exists based on the skill hierarchy mentioning skill_mindmap_rename.md, but the exact command wasn't provided in the base answer."}
{"pair_id": "skill_mindmap_tools_005_q0", "cluster_id": "skill_mindmap_tools_005", "question": "How do I link mindmaps together?", "answer": "To link mindmaps together, use the `add_relative_links.py` script: `python3 scripts/mindmap/add_relative_links.py output/*.smmx --index index.json`. This creates `cloudmapref` connections between related mindmaps based on your index, allowing you to navigate between files. The script uses your mindmap index to intelligently connect semantically related maps. You can also enrich these links with external Pearltrees URLs if needed.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Tools (Sub-Master)", "References"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["linking", "cross-references", "cloudmapref", "navigation"], "related_skills": ["skill_mindmap_tools.md", "skill_mindmap_references.md", "skill_mindmap_linking.md"], "related_docs": ["scripts/mindmap/README.md"], "original_answer": "Add cross-links between mindmaps using: `python3 scripts/mindmap/add_relative_links.py output/*.smmx --index index.json`. This uses your index to create `cloudmapref` connections between related mindmaps, enabling navigation between files. You can also enrich mindmaps with external Pearltrees links. See skill_mindmap_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_tools_005_q1", "cluster_id": "skill_mindmap_tools_005", "question": "Can I create cross-references between mindmap files?", "answer": "Yes, you can create cross-references between mindmap files using the `add_relative_links.py` script. Run `python3 scripts/mindmap/add_relative_links.py output/*.smmx --index index.json` to automatically generate `cloudmapref` connections between related mindmaps based on your index. This enables direct navigation between mindmap files. You can also enrich mindmaps with external Pearltrees links for additional cross-referencing.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Tools (Sub-Master)", "References"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["linking", "cross-references", "cloudmapref", "navigation"], "related_skills": ["skill_mindmap_tools.md", "skill_mindmap_references.md", "skill_mindmap_linking.md"], "related_docs": ["scripts/mindmap/README.md"], "original_answer": "Add cross-links between mindmaps using: `python3 scripts/mindmap/add_relative_links.py output/*.smmx --index index.json`. This uses your index to create `cloudmapref` connections between related mindmaps, enabling navigation between files. You can also enrich mindmaps with external Pearltrees links. See skill_mindmap_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_tools_005_q2", "cluster_id": "skill_mindmap_tools_005", "question": "How do I add relative links to mindmaps?", "answer": "Add relative links between mindmaps using `python3 scripts/mindmap/add_relative_links.py output/*.smmx --index index.json`. This command uses your index file to create `cloudmapref` connections between related mindmaps, enabling navigation between files. The cloudmapref attribute stores relative paths to other .smmx files within the mindmap XML structure.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Tools (Sub-Master)", "References"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["linking", "cross-references", "cloudmapref", "navigation"], "related_skills": ["skill_mindmap_tools.md", "skill_mindmap_references.md", "skill_mindmap_linking.md"], "related_docs": ["scripts/mindmap/README.md"], "original_answer": "Add cross-links between mindmaps using: `python3 scripts/mindmap/add_relative_links.py output/*.smmx --index index.json`. This uses your index to create `cloudmapref` connections between related mindmaps, enabling navigation between files. You can also enrich mindmaps with external Pearltrees links. See skill_mindmap_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_tools_006_q0", "cluster_id": "skill_mindmap_tools_006", "question": "What's the typical workflow for managing mindmaps?", "answer": "The typical workflow for managing mindmaps involves five sequential steps: (1) Generate mindmaps from Pearltrees data using `python3 scripts/generate_mindmap.py --data data.jsonl --recursive --output-dir output/`, (2) Build an index to track file locations with `python3 scripts/mindmap/build_index.py output/ -o index.json`, (3) Add cross-links between mindmaps using `python3 scripts/mindmap/add_relative_links.py output/*.smmx --index index.json`, (4) Organize into semantic folders with `python3 scripts/mindmap/mst_folder_grouping.py --input output/ --output organized/`, and (5) Visualize and explore using `python tools/density_explorer/flask_api.py`. Each step builds on the previous to create an organized, interconnected collection.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Tools (Sub-Master)"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["workflow", "pipeline", "process", "setup"], "related_skills": ["skill_mindmap_tools.md", "skill_mindmap_organization.md", "skill_mindmap_indexing.md", "skill_mindmap_references.md", "skill_density_explorer.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/generate_mindmap.py"], "original_answer": "The typical workflow is: (1) Generate mindmaps from data using `python3 scripts/generate_mindmap.py`, (2) Build an index with `build_index.py`, (3) Add cross-links with `add_relative_links.py`, (4) Organize into folders with `mst_folder_grouping.py`, and (5) Visualize using the density explorer. Each step builds on the previous one to create a well-organized, interconnected mindmap collection. See skill_mindmap_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_tools_006_q1", "cluster_id": "skill_mindmap_tools_006", "question": "How do I set up mindmaps from start to finish?", "answer": "To set up mindmaps from start to finish: (1) Generate mindmaps from your data source using `python3 scripts/generate_mindmap.py --data your_data.jsonl --recursive --output-dir output/`, (2) Build an index to track mindmap locations with `python3 scripts/mindmap/build_index.py output/ -o index.json`, (3) Add cross-links between mindmaps using `python3 scripts/mindmap/add_relative_links.py output/*.smmx --index index.json`, (4) Organize mindmaps into semantic folders with `python3 scripts/mindmap/mst_folder_grouping.py --input output/ --output organized/`, and (5) Visualize and explore the collection with `python tools/density_explorer/flask_api.py`. Each step builds on the previous to create an organized, interconnected mindmap system.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Tools (Sub-Master)"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["workflow", "pipeline", "process", "setup"], "related_skills": ["skill_mindmap_tools.md", "skill_mindmap_organization.md", "skill_mindmap_indexing.md", "skill_mindmap_references.md", "skill_density_explorer.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/generate_mindmap.py"], "original_answer": "The typical workflow is: (1) Generate mindmaps from data using `python3 scripts/generate_mindmap.py`, (2) Build an index with `build_index.py`, (3) Add cross-links with `add_relative_links.py`, (4) Organize into folders with `mst_folder_grouping.py`, and (5) Visualize using the density explorer. Each step builds on the previous one to create a well-organized, interconnected mindmap collection. See skill_mindmap_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mindmap_tools_006_q2", "cluster_id": "skill_mindmap_tools_006", "question": "What steps should I follow to work with mindmaps?", "answer": "To work with mindmaps, follow this 5-step workflow: (1) Generate mindmaps from your data using `python3 scripts/generate_mindmap.py --data data.jsonl --recursive --output-dir output/`, (2) Build an index to track mindmap locations with `python3 scripts/mindmap/build_index.py output/ -o index.json`, (3) Add cross-links between mindmaps using `python3 scripts/mindmap/add_relative_links.py output/*.smmx --index index.json`, (4) Organize mindmaps into folders semantically with `python3 scripts/mindmap/mst_folder_grouping.py --input output/ --output organized/`, and (5) Visualize and explore your collection with `python tools/density_explorer/flask_api.py`. Each step builds on the previous one to create an organized, interconnected mindmap collection.", "question_type": "medium", "topics": ["Mindmap", "Mindmap Tools (Sub-Master)"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["workflow", "pipeline", "process", "setup"], "related_skills": ["skill_mindmap_tools.md", "skill_mindmap_organization.md", "skill_mindmap_indexing.md", "skill_mindmap_references.md", "skill_density_explorer.md"], "related_docs": ["scripts/mindmap/README.md", "scripts/generate_mindmap.py"], "original_answer": "The typical workflow is: (1) Generate mindmaps from data using `python3 scripts/generate_mindmap.py`, (2) Build an index with `build_index.py`, (3) Add cross-links with `add_relative_links.py`, (4) Organize into folders with `mst_folder_grouping.py`, and (5) Visualize using the density explorer. Each step builds on the previous one to create a well-organized, interconnected mindmap collection. See skill_mindmap_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_001_q0", "cluster_id": "skill_mst_folder_grouping_001", "question": "How do I organize a collection of mindmaps into folders based on semantic similarity?", "answer": "Use the MST (Minimum Spanning Tree) folder grouping tool to automatically organize mindmaps into semantically coherent folder hierarchies. Run: `python3 scripts/mindmap/mst_folder_grouping.py --trees-only --target-size 10 --max-depth 5 -o output/mst_folder_structure.json`. This partitions your collection based on semantic similarity and outputs a JSON file with the folder structure. For custom configurations, adjust `--target-size` (items per folder) and `--max-depth` (folder depth), or use `--tree-source hybrid` to combine curated and automatic grouping. See skill_mst_folder_grouping.md for full options.", "question_type": "medium", "topics": ["Mindmap", "MST Folder Grouping"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["organization", "clustering", "mindmap", "semantic"], "related_skills": ["skill_mst_folder_grouping.md", "skill_bookmark_filing.md", "skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/README.md", "docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "Use the MST (Minimum Spanning Tree) folder grouping tool to automatically partition mindmaps into semantically coherent folder hierarchies. Run: `python3 scripts/mindmap/mst_folder_grouping.py --trees-only --target-size 10 --max-depth 5 -o output/mst_folder_structure.json`. This creates a JSON file with the folder structure based on semantic similarity between mindmaps. See skill_mst_folder_grouping.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_001_q1", "cluster_id": "skill_mst_folder_grouping_001", "question": "How can I group mindmaps semantically?", "answer": "Use the MST (Minimum Spanning Tree) folder grouping tool to automatically organize mindmaps into semantically coherent folder hierarchies. Run: `python3 scripts/mindmap/mst_folder_grouping.py --trees-only --target-size 10 --max-depth 5 -o output/mst_folder_structure.json`. This creates a JSON file with folders grouped by semantic similarity. You can customize the target folder size with `--target-size` and folder depth with `--max-depth`. For other modes, use `--tree-source curated` for curated hierarchies or `--tree-source hybrid` for hybrid mode. See skill_mst_folder_grouping.md for full options.", "question_type": "medium", "topics": ["Mindmap", "MST Folder Grouping"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["organization", "clustering", "mindmap", "semantic"], "related_skills": ["skill_mst_folder_grouping.md", "skill_bookmark_filing.md", "skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/README.md", "docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "Use the MST (Minimum Spanning Tree) folder grouping tool to automatically partition mindmaps into semantically coherent folder hierarchies. Run: `python3 scripts/mindmap/mst_folder_grouping.py --trees-only --target-size 10 --max-depth 5 -o output/mst_folder_structure.json`. This creates a JSON file with the folder structure based on semantic similarity between mindmaps. See skill_mst_folder_grouping.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_001_q2", "cluster_id": "skill_mst_folder_grouping_001", "question": "I want to cluster my mindmaps - how do I do that?", "answer": "Use the MST (Minimum Spanning Tree) folder grouping tool to automatically cluster your mindmaps into semantically coherent folders. Run: `python3 scripts/mindmap/mst_folder_grouping.py --trees-only --target-size 10 --max-depth 5 -o output/mst_folder_structure.json`. This generates a JSON file organizing mindmaps by semantic similarity. Adjust `--target-size` to control folder sizes and `--max-depth` for hierarchy depth. See skill_mst_folder_grouping.md for additional options like `--tree-source` (mst/curated/hybrid) and `--cluster-method` (multilevel/bisection).", "question_type": "medium", "topics": ["Mindmap", "MST Folder Grouping"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["organization", "clustering", "mindmap", "semantic"], "related_skills": ["skill_mst_folder_grouping.md", "skill_bookmark_filing.md", "skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/README.md", "docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "Use the MST (Minimum Spanning Tree) folder grouping tool to automatically partition mindmaps into semantically coherent folder hierarchies. Run: `python3 scripts/mindmap/mst_folder_grouping.py --trees-only --target-size 10 --max-depth 5 -o output/mst_folder_structure.json`. This creates a JSON file with the folder structure based on semantic similarity between mindmaps. See skill_mst_folder_grouping.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_001_q3", "cluster_id": "skill_mst_folder_grouping_001", "question": "Can you organize mindmaps by topic?", "answer": "Yes, you can organize mindmaps by topic using the MST (Minimum Spanning Tree) folder grouping tool. This automatically partitions mindmaps into semantically coherent folder hierarchies based on topic similarity. Run: `python3 scripts/mindmap/mst_folder_grouping.py --trees-only --target-size 10 --max-depth 5 -o output/mst_folder_structure.json` to generate a JSON file with the folder structure. You can customize the target folder size and depth, or use `--subset physics` to test on a specific topic subset first.", "question_type": "medium", "topics": ["Mindmap", "MST Folder Grouping"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["organization", "clustering", "mindmap", "semantic"], "related_skills": ["skill_mst_folder_grouping.md", "skill_bookmark_filing.md", "skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/README.md", "docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "Use the MST (Minimum Spanning Tree) folder grouping tool to automatically partition mindmaps into semantically coherent folder hierarchies. Run: `python3 scripts/mindmap/mst_folder_grouping.py --trees-only --target-size 10 --max-depth 5 -o output/mst_folder_structure.json`. This creates a JSON file with the folder structure based on semantic similarity between mindmaps. See skill_mst_folder_grouping.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_002_q0", "cluster_id": "skill_mst_folder_grouping_002", "question": "What options do I have for configuring folder size and depth when organizing mindmaps?", "answer": "You have two main configuration options for folder organization:\n\n1. **Folder Size**: Use `--target-size` (default: 8) to set the target number of items per folder. For example, `--target-size 10` creates folders with approximately 10 items each.\n\n2. **Folder Depth**: Use `--max-depth` (default: 4) to limit the maximum nesting level of folders. For example, `--max-depth 5` allows up to 5 levels of nested folders.\n\n3. **Clustering Method**: Choose between `--cluster-method multilevel` (default) or `--cluster-method bisection` to control how items are grouped hierarchically.\n\nExample command: `python3 scripts/mindmap/mst_folder_grouping.py --trees-only --target-size 10 --max-depth 5 -o output/mst_folder_structure.json`", "question_type": "long", "topics": ["Mindmap", "MST Folder Grouping"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["configuration", "clustering", "parameters"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md"], "original_answer": "Use `--target-size` (default: 8) to set items per folder and `--max-depth` (default: 4) to limit folder nesting. For example: `python3 scripts/mindmap/mst_folder_grouping.py --trees-only --target-size 10 --max-depth 5 -o output/mst_folder_structure.json`. You can also choose different clustering methods with `--cluster-method` (multilevel or bisection). See skill_mst_folder_grouping.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_002_q1", "cluster_id": "skill_mst_folder_grouping_002", "question": "How can I control how many mindmaps go in each folder?", "answer": "Use the `--target-size` option to control how many items go in each folder. The default is 8, but you can adjust it to your needs. For example, `--target-size 10` puts approximately 10 mindmaps in each folder. You can also use `--max-depth` to limit how deeply nested folders can be, which indirectly controls folder sizes by preventing over-nesting.", "question_type": "long", "topics": ["Mindmap", "MST Folder Grouping"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["configuration", "clustering", "parameters"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md"], "original_answer": "Use `--target-size` (default: 8) to set items per folder and `--max-depth` (default: 4) to limit folder nesting. For example: `python3 scripts/mindmap/mst_folder_grouping.py --trees-only --target-size 10 --max-depth 5 -o output/mst_folder_structure.json`. You can also choose different clustering methods with `--cluster-method` (multilevel or bisection). See skill_mst_folder_grouping.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_002_q2", "cluster_id": "skill_mst_folder_grouping_002", "question": "How do I set the maximum folder depth?", "answer": "Use the `--max-depth` option to set the maximum folder depth. The default is 4. For example: `python3 scripts/mindmap/mst_folder_grouping.py --trees-only --max-depth 5 -o output/mst_folder_structure.json` sets the maximum folder nesting depth to 5 levels.", "question_type": "long", "topics": ["Mindmap", "MST Folder Grouping"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["configuration", "clustering", "parameters"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md"], "original_answer": "Use `--target-size` (default: 8) to set items per folder and `--max-depth` (default: 4) to limit folder nesting. For example: `python3 scripts/mindmap/mst_folder_grouping.py --trees-only --target-size 10 --max-depth 5 -o output/mst_folder_structure.json`. You can also choose different clustering methods with `--cluster-method` (multilevel or bisection). See skill_mst_folder_grouping.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_002_q3", "cluster_id": "skill_mst_folder_grouping_002", "question": "Can I customize the target size for grouped mindmaps?", "answer": "Yes, you can customize the target size for grouped mindmaps using the `--target-size` option (default: 8). This sets the target number of items per folder. For example: `python3 scripts/mindmap/mst_folder_grouping.py --trees-only --target-size 10 --max-depth 5 -o output/mst_folder_structure.json`. You can also control folder nesting depth with `--max-depth` (default: 4) and choose between clustering methods with `--cluster-method` (multilevel or bisection).", "question_type": "long", "topics": ["Mindmap", "MST Folder Grouping"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["configuration", "clustering", "parameters"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md"], "original_answer": "Use `--target-size` (default: 8) to set items per folder and `--max-depth` (default: 4) to limit folder nesting. For example: `python3 scripts/mindmap/mst_folder_grouping.py --trees-only --target-size 10 --max-depth 5 -o output/mst_folder_structure.json`. You can also choose different clustering methods with `--cluster-method` (multilevel or bisection). See skill_mst_folder_grouping.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_003_q0", "cluster_id": "skill_mst_folder_grouping_003", "question": "How do I test the MST folder grouping on a subset of my data before running it on everything?", "answer": "Use the `--subset` option to test on a specific dataset before running full MST clustering. For example: `python3 scripts/mindmap/mst_folder_grouping.py --subset physics --target-size 8 --max-depth 3 --verbose`. The `--verbose` flag provides detailed output during processing so you can observe how the algorithm partitions your data. This lets you experiment with `--target-size` and `--max-depth` settings on a smaller subset before scaling to your entire dataset.", "question_type": "long", "topics": ["Mindmap", "MST Folder Grouping"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["testing", "subset", "validation"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md"], "original_answer": "Use the `--subset` option to test on a specific collection: `python3 scripts/mindmap/mst_folder_grouping.py --subset physics --target-size 8 --max-depth 3 --verbose`. The `--verbose` flag shows detailed output during processing. This is useful for experimenting with settings before running the full MST clustering. See skill_mst_folder_grouping.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_003_q1", "cluster_id": "skill_mst_folder_grouping_003", "question": "Can I try it on a smaller set first?", "answer": "Yes, use the `--subset` option to test on a smaller set first. For example: `python3 scripts/mindmap/mst_folder_grouping.py --subset physics --target-size 8 --max-depth 3 --verbose`. This lets you experiment with settings like target folder size and maximum depth on a specific collection before running the full MST clustering on your entire dataset. The `--verbose` flag shows detailed output during processing.", "question_type": "long", "topics": ["Mindmap", "MST Folder Grouping"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["testing", "subset", "validation"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md"], "original_answer": "Use the `--subset` option to test on a specific collection: `python3 scripts/mindmap/mst_folder_grouping.py --subset physics --target-size 8 --max-depth 3 --verbose`. The `--verbose` flag shows detailed output during processing. This is useful for experimenting with settings before running the full MST clustering. See skill_mst_folder_grouping.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_003_q2", "cluster_id": "skill_mst_folder_grouping_003", "question": "How do I run MST clustering on a subset?", "answer": "Use the `--subset` option with the MST folder grouping script: `python3 scripts/mindmap/mst_folder_grouping.py --subset physics --target-size 8 --max-depth 3 --verbose`. Replace `physics` with your desired subset name. The `--verbose` flag provides detailed processing output, making it ideal for testing different settings on a smaller dataset before running full clustering.", "question_type": "long", "topics": ["Mindmap", "MST Folder Grouping"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["testing", "subset", "validation"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md"], "original_answer": "Use the `--subset` option to test on a specific collection: `python3 scripts/mindmap/mst_folder_grouping.py --subset physics --target-size 8 --max-depth 3 --verbose`. The `--verbose` flag shows detailed output during processing. This is useful for experimenting with settings before running the full MST clustering. See skill_mst_folder_grouping.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_003_q3", "cluster_id": "skill_mst_folder_grouping_003", "question": "How can I test with the physics collection?", "answer": "Use the `--subset physics` option to test the MST folder grouping on the physics collection: `python3 scripts/mindmap/mst_folder_grouping.py --subset physics --target-size 8 --max-depth 3 --verbose`. This runs the clustering algorithm on just the physics data, letting you experiment with settings like target folder size and maximum depth before running the full dataset. The `--verbose` flag provides detailed output during processing.", "question_type": "long", "topics": ["Mindmap", "MST Folder Grouping"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["testing", "subset", "validation"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md"], "original_answer": "Use the `--subset` option to test on a specific collection: `python3 scripts/mindmap/mst_folder_grouping.py --subset physics --target-size 8 --max-depth 3 --verbose`. The `--verbose` flag shows detailed output during processing. This is useful for experimenting with settings before running the full MST clustering. See skill_mst_folder_grouping.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_004_q0", "cluster_id": "skill_mst_folder_grouping_004", "question": "What's the difference between MST, curated, and hybrid tree sources when organizing mindmaps?", "answer": "MST uses automatic semantic clustering based on embedding similarity to organize mindmaps. Curated uses a pre-defined hierarchy you've manually created. Hybrid combines both\u2014it starts with your curated structure and automatically attaches orphaned items to the most semantically similar folders using `--embed-blend` to control the blend ratio (0.0 = pure curated, 1.0 = pure MST). Choose MST for fully automatic organization, curated for manual control, or hybrid when you have a good base structure but want to handle edge cases automatically.", "question_type": "long", "topics": ["Mindmap", "MST Folder Grouping"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["tree-source", "clustering-method", "hierarchy"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "There are three tree sources: `mst` (automatic clustering), `curated` (pre-defined hierarchy), and `hybrid` (curated + orphan attachment). Use `--tree-source curated` for pre-defined hierarchies or `--tree-source hybrid --embed-blend 0.3` to combine curated structure with automatic attachment of unclassified items. Default is MST which uses pure semantic clustering. See skill_mst_folder_grouping.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_004_q1", "cluster_id": "skill_mst_folder_grouping_004", "question": "Should I use curated or MST for folder organization?", "answer": "Use `--tree-source curated` if you have a pre-defined folder hierarchy you want to apply. Use `--tree-source mst` (the default) for automatic semantic clustering based on similarity. Use `--tree-source hybrid` with `--embed-blend 0.3` if you want to start with a curated structure but automatically attach unclassified items. MST is best for discovering natural groupings; curated is best when you already know how items should be organized.", "question_type": "long", "topics": ["Mindmap", "MST Folder Grouping"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["tree-source", "clustering-method", "hierarchy"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "There are three tree sources: `mst` (automatic clustering), `curated` (pre-defined hierarchy), and `hybrid` (curated + orphan attachment). Use `--tree-source curated` for pre-defined hierarchies or `--tree-source hybrid --embed-blend 0.3` to combine curated structure with automatic attachment of unclassified items. Default is MST which uses pure semantic clustering. See skill_mst_folder_grouping.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_004_q2", "cluster_id": "skill_mst_folder_grouping_004", "question": "What does hybrid mode do?", "answer": "Hybrid mode combines curated folder structure with automatic attachment of unclassified items. Use `--tree-source hybrid --embed-blend 0.3` to merge a pre-defined hierarchy with semantic clustering for orphan items. The `--embed-blend` parameter (0.0-1.0) controls the weighting: higher values favor embedding-based attachment, lower values favor structural similarity.", "question_type": "long", "topics": ["Mindmap", "MST Folder Grouping"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["tree-source", "clustering-method", "hierarchy"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "There are three tree sources: `mst` (automatic clustering), `curated` (pre-defined hierarchy), and `hybrid` (curated + orphan attachment). Use `--tree-source curated` for pre-defined hierarchies or `--tree-source hybrid --embed-blend 0.3` to combine curated structure with automatic attachment of unclassified items. Default is MST which uses pure semantic clustering. See skill_mst_folder_grouping.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_004_q3", "cluster_id": "skill_mst_folder_grouping_004", "question": "What are the different tree source options?", "answer": "The MST Folder Grouping skill supports three tree source options via the `--tree-source` parameter: (1) `mst` - performs automatic semantic clustering using Minimum Spanning Tree partitioning (default), (2) `curated` - uses a pre-defined hierarchy, and (3) `hybrid` - combines curated structure with automatic attachment of orphan items. Use `--tree-source curated` for existing hierarchies or `--tree-source hybrid --embed-blend 0.3` to blend curated organization with semantic clustering.", "question_type": "long", "topics": ["Mindmap", "MST Folder Grouping"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["tree-source", "clustering-method", "hierarchy"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "There are three tree sources: `mst` (automatic clustering), `curated` (pre-defined hierarchy), and `hybrid` (curated + orphan attachment). Use `--tree-source curated` for pre-defined hierarchies or `--tree-source hybrid --embed-blend 0.3` to combine curated structure with automatic attachment of unclassified items. Default is MST which uses pure semantic clustering. See skill_mst_folder_grouping.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_005_q0", "cluster_id": "skill_mst_folder_grouping_005", "question": "How do I generate actual mindmaps from the folder structure that MST creates?", "answer": "After generating the folder structure with MST, use the generate script to convert it into actual mindmap files: `python3 scripts/mindmap/generate_mst_mindmaps.py --mst-structure output/mst_folder_structure.json --output output/mst_mindmaps/ --root-name \"My_Collection\"`. This creates visual mindmap files organized according to the semantic hierarchy defined in your MST folder structure.", "question_type": "long", "topics": ["Mindmap", "MST Folder Grouping"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["visualization", "mindmap-generation", "output"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md"], "original_answer": "After generating the folder structure, use the generate script: `python3 scripts/mindmap/generate_mst_mindmaps.py --mst-structure output/mst_folder_structure.json --output output/mst_mindmaps/ --root-name \"My_Collection\"`. This converts the JSON folder structure into visual mindmap files organized by the semantic hierarchy. See skill_mst_folder_grouping.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_005_q1", "cluster_id": "skill_mst_folder_grouping_005", "question": "Can I create mindmaps from the folder grouping?", "answer": "Yes. After generating the folder structure with `python3 scripts/mindmap/mst_folder_grouping.py`, use the generate script to create mindmaps: `python3 scripts/mindmap/generate_mst_mindmaps.py --mst-structure output/mst_folder_structure.json --output output/mst_mindmaps/ --root-name \"My_Collection\"`. This converts the JSON folder structure into visual mindmap files organized by semantic hierarchy.", "question_type": "long", "topics": ["Mindmap", "MST Folder Grouping"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["visualization", "mindmap-generation", "output"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md"], "original_answer": "After generating the folder structure, use the generate script: `python3 scripts/mindmap/generate_mst_mindmaps.py --mst-structure output/mst_folder_structure.json --output output/mst_mindmaps/ --root-name \"My_Collection\"`. This converts the JSON folder structure into visual mindmap files organized by the semantic hierarchy. See skill_mst_folder_grouping.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_005_q2", "cluster_id": "skill_mst_folder_grouping_005", "question": "How do I visualize the MST folder structure?", "answer": "To visualize the MST folder structure, use the generate script: `python3 scripts/mindmap/generate_mst_mindmaps.py --mst-structure output/mst_folder_structure.json --output output/mst_mindmaps/ --root-name \"My_Collection\"`. This converts the JSON folder structure into visual mindmap files organized by the semantic hierarchy.", "question_type": "long", "topics": ["Mindmap", "MST Folder Grouping"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["visualization", "mindmap-generation", "output"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md"], "original_answer": "After generating the folder structure, use the generate script: `python3 scripts/mindmap/generate_mst_mindmaps.py --mst-structure output/mst_folder_structure.json --output output/mst_mindmaps/ --root-name \"My_Collection\"`. This converts the JSON folder structure into visual mindmap files organized by the semantic hierarchy. See skill_mst_folder_grouping.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_005_q3", "cluster_id": "skill_mst_folder_grouping_005", "question": "How do I turn the folder structure into mindmaps?", "answer": "After generating the folder structure with MST partitioning, use the generate script to convert it to mindmaps: `python3 scripts/mindmap/generate_mst_mindmaps.py --mst-structure output/mst_folder_structure.json --output output/mst_mindmaps/ --root-name \"My_Collection\"`. This transforms the JSON hierarchy into visual mindmap files organized by semantic relationships.", "question_type": "long", "topics": ["Mindmap", "MST Folder Grouping"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["visualization", "mindmap-generation", "output"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/README.md"], "original_answer": "After generating the folder structure, use the generate script: `python3 scripts/mindmap/generate_mst_mindmaps.py --mst-structure output/mst_folder_structure.json --output output/mst_mindmaps/ --root-name \"My_Collection\"`. This converts the JSON folder structure into visual mindmap files organized by the semantic hierarchy. See skill_mst_folder_grouping.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_006_q0", "cluster_id": "skill_mst_folder_grouping_006", "question": "How does the MST folder grouping tool balance folder density versus organization quality?", "answer": "MST folder grouping balances folder density versus organization quality using the objective function J = D/(1+H), where D represents folder density and H represents hierarchy depth. This formula ensures folders maintain appropriate item density without creating excessively deep nested structures. The tool optimizes this balance by automatically selecting clustering parameters: `--target-size` controls the ideal number of items per folder (default 8), while `--max-depth` limits folder nesting (default 4). The multilevel and bisection clustering methods work within these constraints to partition mindmaps into semantically coherent groups. You can adjust the trade-off between density and shallow organization by tuning target-size and max-depth parameters when running the tool.", "question_type": "medium", "topics": ["Mindmap", "MST Folder Grouping"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["objective-function", "optimization", "quality-metrics"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/hierarchy_objective.py", "education/book-13-semantic-search/07_density_scoring.md", "education/book-13-semantic-search/08_advanced_federation.md"], "original_answer": "MST folder grouping uses an objective function (J = D/(1+H)) that balances folder density (D) against hierarchy depth (H). This ensures folders are neither too sparse nor too deeply nested. The tool automatically optimizes this balance using multilevel or bisection clustering methods. For technical details on scoring and advanced federation concepts, see the education materials in book-13-semantic-search. See skill_mst_folder_grouping.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_006_q1", "cluster_id": "skill_mst_folder_grouping_006", "question": "What is the J = D/(1+H) objective function?", "answer": "The J = D/(1+H) objective function balances folder density (D) against hierarchy depth (H) in MST folder grouping. The numerator D represents how densely packed items are within folders, while the denominator (1+H) penalizes deeper folder hierarchies. This formula ensures that folders contain meaningful semantic clusters (high density) without requiring excessively nested directory structures (low depth). The optimization process automatically adjusts the partitioning to maximize this objective value using multilevel or bisection clustering methods.", "question_type": "medium", "topics": ["Mindmap", "MST Folder Grouping"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["objective-function", "optimization", "quality-metrics"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/hierarchy_objective.py", "education/book-13-semantic-search/07_density_scoring.md", "education/book-13-semantic-search/08_advanced_federation.md"], "original_answer": "MST folder grouping uses an objective function (J = D/(1+H)) that balances folder density (D) against hierarchy depth (H). This ensures folders are neither too sparse nor too deeply nested. The tool automatically optimizes this balance using multilevel or bisection clustering methods. For technical details on scoring and advanced federation concepts, see the education materials in book-13-semantic-search. See skill_mst_folder_grouping.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_006_q2", "cluster_id": "skill_mst_folder_grouping_006", "question": "How does the tool measure clustering quality?", "answer": "MST folder grouping measures clustering quality using the objective function J = D/(1+H), which balances folder density (D) against hierarchy depth (H). This metric ensures folders contain semantically similar items (high density) without creating unnecessarily deep folder structures. The tool optimizes this balance by testing multiple partitioning strategies using multilevel or bisection clustering methods and selecting the configuration that maximizes the J score.", "question_type": "medium", "topics": ["Mindmap", "MST Folder Grouping"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["objective-function", "optimization", "quality-metrics"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/hierarchy_objective.py", "education/book-13-semantic-search/07_density_scoring.md", "education/book-13-semantic-search/08_advanced_federation.md"], "original_answer": "MST folder grouping uses an objective function (J = D/(1+H)) that balances folder density (D) against hierarchy depth (H). This ensures folders are neither too sparse nor too deeply nested. The tool automatically optimizes this balance using multilevel or bisection clustering methods. For technical details on scoring and advanced federation concepts, see the education materials in book-13-semantic-search. See skill_mst_folder_grouping.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_mst_folder_grouping_006_q3", "cluster_id": "skill_mst_folder_grouping_006", "question": "What's the hierarchy objective?", "answer": "The hierarchy objective in MST folder grouping is the formula J = D/(1+H), which balances folder density (D) against hierarchy depth (H). This objective function ensures that folders are semantically coherent (high density) without becoming too deeply nested (low depth). The optimization automatically finds the best balance between these two factors using multilevel or bisection clustering methods.", "question_type": "medium", "topics": ["Mindmap", "MST Folder Grouping"], "source_file": "by-topic/mindmap/skills-generated.jsonl", "tags": ["objective-function", "optimization", "quality-metrics"], "related_skills": ["skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/hierarchy_objective.py", "education/book-13-semantic-search/07_density_scoring.md", "education/book-13-semantic-search/08_advanced_federation.md"], "original_answer": "MST folder grouping uses an objective function (J = D/(1+H)) that balances folder density (D) against hierarchy depth (H). This ensures folders are neither too sparse nor too deeply nested. The tool automatically optimizes this balance using multilevel or bisection clustering methods. For technical details on scoring and advanced federation concepts, see the education materials in book-13-semantic-search. See skill_mst_folder_grouping.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_accessibility_001_q0", "cluster_id": "skill_accessibility_001", "question": "How do I add accessibility features to my app?", "answer": "To add accessibility features to your app, use the `a11y([label('text'), role(button), hint('description')])` constructor to define accessibility attributes, then call `generate_a11y_attrs(A11y, TARGET, Code)` where TARGET is your platform (vue, react_native, flutter, or swiftui). This generates platform-specific accessibility code: ARIA attributes for Vue, accessibilityLabel/accessibilityRole for React Native, and equivalent props for Flutter and SwiftUI. The approach handles labels, roles, hints, live regions, and keyboard navigation across all platforms.", "question_type": "medium", "topics": ["Quickstart", "Accessibility"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["accessibility", "ARIA", "screen-reader", "cross-platform"], "related_skills": ["skill_accessibility.md"], "related_docs": ["src/unifyweaver/a11y/accessibility.pl", "src/unifyweaver/glue/accessibility_generator.pl"], "original_answer": "Define accessibility attributes using `a11y([label('text'), role(button), hint('description')])` and generate platform-specific code with `generate_a11y_attrs(A11y, vue, Code)` for Vue, React Native, Flutter, or SwiftUI. This creates accessibility labels, roles, and hints that work cross-platform. See skill_accessibility.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_accessibility_001_q1", "cluster_id": "skill_accessibility_001", "question": "How do I make my app accessible to screen readers?", "answer": "To make your app accessible to screen readers, define accessibility attributes using `a11y([label('text'), role(button), hint('description')])` and generate platform-specific code with `generate_a11y_attrs(A11y, Target, Code)` where Target is vue, react_native, flutter, or swiftui. This creates ARIA labels and roles (Vue), accessibilityLabel and accessibilityRole (React Native), or equivalent properties for other platforms. Screen readers will then announce these attributes to users. For complex components, use `aria_spec(component_name, [role(img), label('description'), describedby(element_id)])` to define semantic structure.", "question_type": "medium", "topics": ["Quickstart", "Accessibility"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["accessibility", "ARIA", "screen-reader", "cross-platform"], "related_skills": ["skill_accessibility.md"], "related_docs": ["src/unifyweaver/a11y/accessibility.pl", "src/unifyweaver/glue/accessibility_generator.pl"], "original_answer": "Define accessibility attributes using `a11y([label('text'), role(button), hint('description')])` and generate platform-specific code with `generate_a11y_attrs(A11y, vue, Code)` for Vue, React Native, Flutter, or SwiftUI. This creates accessibility labels, roles, and hints that work cross-platform. See skill_accessibility.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer could be more explicit about screen reader support being the primary outcome. The confidence is slightly lower because the answer mentions 'hint' which maps to accessibilityHint/aria-describedby but doesn't fully explain the screen reader announcement mechanism."}
{"pair_id": "skill_accessibility_001_q2", "cluster_id": "skill_accessibility_001", "question": "How do I add ARIA attributes to my components?", "answer": "Use the `a11y()` term constructor to define accessibility attributes: `a11y([label('text'), role(button), hint('description')])`. Then call `generate_a11y_attrs(A11y, vue, Code)` to generate platform-specific ARIA code. For Vue, this produces `aria-label` and `role` attributes. You can also use `aria_spec(component_name, [role(img), label('text'), describedby(id)])` and generate with `generate_aria_props(component_name, Props)` for more complex ARIA specifications.", "question_type": "medium", "topics": ["Quickstart", "Accessibility"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["accessibility", "ARIA", "screen-reader", "cross-platform"], "related_skills": ["skill_accessibility.md"], "related_docs": ["src/unifyweaver/a11y/accessibility.pl", "src/unifyweaver/glue/accessibility_generator.pl"], "original_answer": "Define accessibility attributes using `a11y([label('text'), role(button), hint('description')])` and generate platform-specific code with `generate_a11y_attrs(A11y, vue, Code)` for Vue, React Native, Flutter, or SwiftUI. This creates accessibility labels, roles, and hints that work cross-platform. See skill_accessibility.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_accessibility_001_q3", "cluster_id": "skill_accessibility_001", "question": "How do I ensure my app is accessible?", "answer": "To ensure your app is accessible, define accessibility attributes using `a11y([label('text'), role(button), hint('description')])` and generate platform-specific code with `generate_a11y_attrs/3`. This produces ARIA attributes for Vue, accessibility labels for React Native, and equivalent accessibility features for Flutter and SwiftUI. Use appropriate roles from the supported list (button, heading, image, checkbox, etc.), provide meaningful labels, add hints for complex interactions, and leverage live regions for dynamic content. Test with screen readers and keyboard navigation to verify cross-platform accessibility.", "question_type": "medium", "topics": ["Quickstart", "Accessibility"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["accessibility", "ARIA", "screen-reader", "cross-platform"], "related_skills": ["skill_accessibility.md"], "related_docs": ["src/unifyweaver/a11y/accessibility.pl", "src/unifyweaver/glue/accessibility_generator.pl"], "original_answer": "Define accessibility attributes using `a11y([label('text'), role(button), hint('description')])` and generate platform-specific code with `generate_a11y_attrs(A11y, vue, Code)` for Vue, React Native, Flutter, or SwiftUI. This creates accessibility labels, roles, and hints that work cross-platform. See skill_accessibility.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "Base answer lacks emphasis on testing/verification which is critical for 'ensuring' accessibility. Answer infers testing best practices not explicitly stated in the base material."}
{"pair_id": "skill_accessibility_002_q0", "cluster_id": "skill_accessibility_002", "question": "How do I implement keyboard navigation for my components?", "answer": "Implement keyboard navigation by using `keyboard_nav(Component, Handlers)` to define keyboard event handlers for your components. Generate the handlers with `generate_keyboard_handler(ComponentType, Handler)`, which creates switch-case logic for arrow keys, Enter, Escape, and Tab. Pre-defined handlers are available for common components like tables, charts, sliders, tabs, and modals. Refer to the accessibility module documentation for implementation details and supported components.", "question_type": "long", "topics": ["Quickstart", "Accessibility"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["keyboard-navigation", "accessibility", "keyboard-handlers", "interaction"], "related_skills": ["skill_accessibility.md"], "related_docs": ["src/unifyweaver/a11y/accessibility.pl", "src/unifyweaver/glue/accessibility_generator.pl"], "original_answer": "Use `keyboard_nav(Component, Handlers)` to define keyboard handlers for components like data tables or charts. Generate keyboard handlers with `generate_keyboard_handler(data_table, Handler)`, which produces switch-case logic for arrow keys, Enter, Escape, and Tab. Pre-defined handlers support navigation for tables, charts, sliders, tabs, and modals. See skill_accessibility.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "Base answer assumes familiarity with the Prolog API and specific function signatures without showing example usage or implementation patterns. The answer would be stronger with a concrete code example demonstrating keyboard_nav usage."}
{"pair_id": "skill_accessibility_002_q1", "cluster_id": "skill_accessibility_002", "question": "How do I add keyboard support to my app?", "answer": "Use `keyboard_nav(Component, Handlers)` to define keyboard event handlers for your components. Call `generate_keyboard_handler(ComponentType, Handler)` to generate keyboard logic that handles arrow keys for navigation, Enter/Escape for actions, and Tab for focus management. Pre-built handlers are available for common components like data tables, charts, sliders, tabs, and modals. Refer to the accessibility module documentation for component-specific keyboard patterns and implementation details.", "question_type": "long", "topics": ["Quickstart", "Accessibility"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["keyboard-navigation", "accessibility", "keyboard-handlers", "interaction"], "related_skills": ["skill_accessibility.md"], "related_docs": ["src/unifyweaver/a11y/accessibility.pl", "src/unifyweaver/glue/accessibility_generator.pl"], "original_answer": "Use `keyboard_nav(Component, Handlers)` to define keyboard handlers for components like data tables or charts. Generate keyboard handlers with `generate_keyboard_handler(data_table, Handler)`, which produces switch-case logic for arrow keys, Enter, Escape, and Tab. Pre-defined handlers support navigation for tables, charts, sliders, tabs, and modals. See skill_accessibility.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_accessibility_002_q2", "cluster_id": "skill_accessibility_002", "question": "How do I make my app navigable with the keyboard?", "answer": "To make your app navigable with the keyboard, use the `keyboard_nav(Component, Handlers)` function to define keyboard handlers for your components. Call `generate_keyboard_handler(component_type, Handler)` to generate switch-case logic that handles arrow keys for navigation, Enter to select/activate, Escape to close, and Tab to move between focusable elements. Pre-built handlers are available for common patterns like data tables, charts, sliders, tabs, and modals. The generated code automatically maps these keyboard events to component actions, ensuring consistent keyboard navigation across your app.", "question_type": "long", "topics": ["Quickstart", "Accessibility"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["keyboard-navigation", "accessibility", "keyboard-handlers", "interaction"], "related_skills": ["skill_accessibility.md"], "related_docs": ["src/unifyweaver/a11y/accessibility.pl", "src/unifyweaver/glue/accessibility_generator.pl"], "original_answer": "Use `keyboard_nav(Component, Handlers)` to define keyboard handlers for components like data tables or charts. Generate keyboard handlers with `generate_keyboard_handler(data_table, Handler)`, which produces switch-case logic for arrow keys, Enter, Escape, and Tab. Pre-defined handlers support navigation for tables, charts, sliders, tabs, and modals. See skill_accessibility.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer assumes the user knows about the skill module system and Prolog-style API. The tailored answer adds more context about what keyboard events are handled and what components support it, but the answer could be more concrete about actual implementation steps or code examples for beginners."}
{"pair_id": "skill_accessibility_002_q3", "cluster_id": "skill_accessibility_002", "question": "How do I handle keyboard events for accessibility?", "answer": "Use `keyboard_nav(Component, Handlers)` to define keyboard event handlers for accessible components. Call `generate_keyboard_handler(ComponentType, Handler)` to generate switch-case logic that handles arrow keys, Enter, Escape, and Tab. Pre-defined handlers are available for tables, charts, sliders, tabs, and modals. Refer to skill_accessibility.md for specific implementation details and role-specific keyboard patterns.", "question_type": "long", "topics": ["Quickstart", "Accessibility"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["keyboard-navigation", "accessibility", "keyboard-handlers", "interaction"], "related_skills": ["skill_accessibility.md"], "related_docs": ["src/unifyweaver/a11y/accessibility.pl", "src/unifyweaver/glue/accessibility_generator.pl"], "original_answer": "Use `keyboard_nav(Component, Handlers)` to define keyboard handlers for components like data tables or charts. Generate keyboard handlers with `generate_keyboard_handler(data_table, Handler)`, which produces switch-case logic for arrow keys, Enter, Escape, and Tab. Pre-defined handlers support navigation for tables, charts, sliders, tabs, and modals. See skill_accessibility.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer mentions 'data_table' and 'Handler' as specific parameters but doesn't clarify what Handler represents or how to structure the Handlers argument. The confidence is moderate because the answer covers the core API but lacks implementation examples that would fully address 'how do I handle' keyboard events."}
{"pair_id": "skill_accessibility_003_q0", "cluster_id": "skill_accessibility_003", "question": "How do I trap focus in modals and manage focus for accessibility?", "answer": "To trap focus in modals, define a focus trap with `focus_trap(modal_dialog, [container_selector('.modal'), initial_focus('.modal-close'), return_focus(true)])` and generate code using `generate_focus_trap_jsx(modal_dialog, JSX)`. This ensures keyboard focus cycles only within the modal and returns to the trigger element when closed. For additional accessibility, use live regions with `generate_live_region_jsx(error_messages, JSX)` to announce modal content to screen readers, and implement skip links with `generate_skip_links_jsx([main, nav, chart], JSX)` if modals contain complex content.", "question_type": "long", "topics": ["Quickstart", "Accessibility"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["focus-management", "focus-trap", "modals", "keyboard-navigation", "skip-links", "live-regions"], "related_skills": ["skill_accessibility.md"], "related_docs": ["src/unifyweaver/a11y/accessibility.pl", "src/unifyweaver/glue/accessibility_generator.pl"], "original_answer": "Define focus traps with `focus_trap(modal_dialog, [container_selector('.modal'), initial_focus('.modal-close'), return_focus(true)])` and generate JSX with `generate_focus_trap_jsx(modal_dialog, JSX)`. For skip links, use `generate_skip_links_jsx([main, nav, chart], JSX)` to let keyboard users jump past navigation. Also use live regions with `generate_live_region_jsx(error_messages, JSX)` for screen reader announcements. See skill_accessibility.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "Base answer mentions skip links as part of focus management, but skip links are primarily for bypassing navigation, not modal focus traps. The connection between skip links and modal focus management is tangential."}
{"pair_id": "skill_accessibility_003_q1", "cluster_id": "skill_accessibility_003", "question": "How do I implement focus traps for modals?", "answer": "Implement focus traps for modals using `focus_trap(modal_dialog, [container_selector('.modal'), initial_focus('.modal-close'), return_focus(true)])`. This defines the trap scope, sets initial keyboard focus, and ensures focus returns when the modal closes. Generate the implementation with `generate_focus_trap_jsx(modal_dialog, JSX)`. This pattern ensures keyboard users cannot tab outside the modal while it's open, and focus management returns properly when dismissed.", "question_type": "long", "topics": ["Quickstart", "Accessibility"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["focus-management", "focus-trap", "modals", "keyboard-navigation", "skip-links", "live-regions"], "related_skills": ["skill_accessibility.md"], "related_docs": ["src/unifyweaver/a11y/accessibility.pl", "src/unifyweaver/glue/accessibility_generator.pl"], "original_answer": "Define focus traps with `focus_trap(modal_dialog, [container_selector('.modal'), initial_focus('.modal-close'), return_focus(true)])` and generate JSX with `generate_focus_trap_jsx(modal_dialog, JSX)`. For skip links, use `generate_skip_links_jsx([main, nav, chart], JSX)` to let keyboard users jump past navigation. Also use live regions with `generate_live_region_jsx(error_messages, JSX)` for screen reader announcements. See skill_accessibility.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_accessibility_003_q2", "cluster_id": "skill_accessibility_003", "question": "How do I manage focus in dialogs?", "answer": "To manage focus in dialogs, use `focus_trap(modal_dialog, [container_selector('.modal'), initial_focus('.modal-close'), return_focus(true)])` to define focus traps that confine keyboard navigation within the dialog and restore focus when closed. Generate the implementation with `generate_focus_trap_jsx(modal_dialog, JSX)`. For additional keyboard support, use `generate_skip_links_jsx([main, nav, chart], JSX)` to let keyboard users navigate efficiently, and implement live regions with `generate_live_region_jsx(error_messages, JSX)` to announce dynamic content to screen reader users.", "question_type": "long", "topics": ["Quickstart", "Accessibility"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["focus-management", "focus-trap", "modals", "keyboard-navigation", "skip-links", "live-regions"], "related_skills": ["skill_accessibility.md"], "related_docs": ["src/unifyweaver/a11y/accessibility.pl", "src/unifyweaver/glue/accessibility_generator.pl"], "original_answer": "Define focus traps with `focus_trap(modal_dialog, [container_selector('.modal'), initial_focus('.modal-close'), return_focus(true)])` and generate JSX with `generate_focus_trap_jsx(modal_dialog, JSX)`. For skip links, use `generate_skip_links_jsx([main, nav, chart], JSX)` to let keyboard users jump past navigation. Also use live regions with `generate_live_region_jsx(error_messages, JSX)` for screen reader announcements. See skill_accessibility.md for details.", "answer_tailored": true, "confidence": 0.75, "confidence_issues": "Base answer includes skip links and live regions which are related but somewhat tangential to the core focus management question. The answer could be more focused solely on focus trapping, initial focus, and return focus mechanisms, making the confidence slightly lower due to mixed concerns."}
{"pair_id": "skill_accessibility_003_q3", "cluster_id": "skill_accessibility_003", "question": "How do I create keyboard-accessible modals?", "answer": "To create keyboard-accessible modals, implement focus traps using `focus_trap(modal_dialog, [container_selector('.modal'), initial_focus('.modal-close'), return_focus(true)])` and generate the implementation with `generate_focus_trap_jsx(modal_dialog, JSX)`. This ensures keyboard focus stays within the modal while active and returns to the trigger element when closed. Additionally, use live regions with `generate_live_region_jsx(error_messages, JSX)` to announce modal content changes to screen reader users. Combine with proper ARIA attributes like `role(dialog)` and `aria_label()` for complete keyboard and screen reader support.", "question_type": "long", "topics": ["Quickstart", "Accessibility"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["focus-management", "focus-trap", "modals", "keyboard-navigation", "skip-links", "live-regions"], "related_skills": ["skill_accessibility.md"], "related_docs": ["src/unifyweaver/a11y/accessibility.pl", "src/unifyweaver/glue/accessibility_generator.pl"], "original_answer": "Define focus traps with `focus_trap(modal_dialog, [container_selector('.modal'), initial_focus('.modal-close'), return_focus(true)])` and generate JSX with `generate_focus_trap_jsx(modal_dialog, JSX)`. For skip links, use `generate_skip_links_jsx([main, nav, chart], JSX)` to let keyboard users jump past navigation. Also use live regions with `generate_live_region_jsx(error_messages, JSX)` for screen reader announcements. See skill_accessibility.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer assumes Prolog-based code generation which may not match all implementation contexts. The answer doesn't explicitly mention ESC key handling for closing modals, which is a common keyboard accessibility expectation. Focus management strategy is clear but could benefit from mentioning testing approaches."}
{"pair_id": "skill_accessibility_001_q0", "cluster_id": "skill_accessibility_001", "question": "How do I add accessibility to my app?", "answer": "To add accessibility to your app, use the accessibility module to define accessible components with ARIA attributes and roles. Wrap components with a11y() containing label, role, and optional hint attributes, then generate platform-specific code:\n\n```prolog\nA11y = a11y([label('Submit'), role(button), hint('Submit form')]),\ngenerate_a11y_attrs(A11y, vue, Code).\n```\n\nThis generates ARIA attributes for Vue (aria-label, role), accessibility props for React Native (accessibilityLabel, accessibilityRole), and equivalent code for Flutter and SwiftUI. Start by identifying interactive elements in your UI, assign appropriate roles (button, link, heading, checkbox, etc.), add descriptive labels, and use hints for additional context. The system compiles your a11y definitions to platform-specific syntax automatically.", "question_type": "medium", "topics": ["Quickstart", "Accessibility"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["accessibility", "a11y", "cross-platform"], "related_skills": ["skill_accessibility.md"], "related_docs": ["src/unifyweaver/a11y/accessibility.pl", "src/unifyweaver/glue/accessibility_generator.pl"], "original_answer": "Use the accessibility module to define accessible components with labels, roles, and hints. Define a11y attributes:\n\n```prolog\nA11y = a11y([label('Submit'), role(button), hint('Submit form')]),\ngenerate_a11y_attrs(A11y, vue, Code).\n```\n\nThe system generates platform-specific code (React Native, Vue, Flutter, SwiftUI). Start by wrapping components with a11y() containing label, role, and optional hint attributes. See skill_accessibility.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_accessibility_001_q1", "cluster_id": "skill_accessibility_001", "question": "How can I make my app accessible?", "answer": "To make your app accessible, use the accessibility module to define a11y attributes for your components. Wrap components with the a11y() constructor containing label, role, and optional hint attributes. For example:\n\n```prolog\nA11y = a11y([label('Submit'), role(button), hint('Submit form')]),\ngenerate_a11y_attrs(A11y, vue, Code).\n```\n\nThis generates platform-specific accessibility code (ARIA for Vue, accessibilityLabel/accessibilityRole for React Native, etc.) across targets including Vue, React Native, Flutter, and SwiftUI. Supported roles include button, heading, image, checkbox, slider, dialog, and others. For live regions, use a11y_live(polite, Term) or a11y_live(assertive, Term) to announce dynamic content changes.", "question_type": "medium", "topics": ["Quickstart", "Accessibility"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["accessibility", "a11y", "cross-platform"], "related_skills": ["skill_accessibility.md"], "related_docs": ["src/unifyweaver/a11y/accessibility.pl", "src/unifyweaver/glue/accessibility_generator.pl"], "original_answer": "Use the accessibility module to define accessible components with labels, roles, and hints. Define a11y attributes:\n\n```prolog\nA11y = a11y([label('Submit'), role(button), hint('Submit form')]),\ngenerate_a11y_attrs(A11y, vue, Code).\n```\n\nThe system generates platform-specific code (React Native, Vue, Flutter, SwiftUI). Start by wrapping components with a11y() containing label, role, and optional hint attributes. See skill_accessibility.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_accessibility_001_q2", "cluster_id": "skill_accessibility_001", "question": "What are the best practices for app accessibility?", "answer": "App accessibility best practices include: (1) Define accessible components using the accessibility module with labels, roles, and hints - wrap components with a11y([label('...'), role(...), hint(...)]) and generate platform-specific code via generate_a11y_attrs(). (2) Use semantic ARIA roles (button, heading, image, checkbox, etc.) appropriate to component function. (3) Ensure keyboard navigation by supporting focus management and keyboard events. (4) Provide descriptive labels and hints for screen reader users. (5) Use live regions (aria-live: polite/assertive) for dynamic content updates. (6) Test across target platforms (React Native, Vue, Flutter, SwiftUI) since the system generates platform-specific accessibility attributes automatically. Start by identifying components that need accessibility, define their a11y attributes, then generate target-specific code.", "question_type": "medium", "topics": ["Quickstart", "Accessibility"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["accessibility", "a11y", "cross-platform"], "related_skills": ["skill_accessibility.md"], "related_docs": ["src/unifyweaver/a11y/accessibility.pl", "src/unifyweaver/glue/accessibility_generator.pl"], "original_answer": "Use the accessibility module to define accessible components with labels, roles, and hints. Define a11y attributes:\n\n```prolog\nA11y = a11y([label('Submit'), role(button), hint('Submit form')]),\ngenerate_a11y_attrs(A11y, vue, Code).\n```\n\nThe system generates platform-specific code (React Native, Vue, Flutter, SwiftUI). Start by wrapping components with a11y() containing label, role, and optional hint attributes. See skill_accessibility.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "Base answer focuses heavily on code generation syntax rather than broader best practices. The question asks for 'best practices' (holistic approach) but answer emphasizes implementation mechanics. Missing discussion of testing, user testing with assistive technologies, or validation. However, the technical guidance provided is accurate and actionable."}
{"pair_id": "skill_accessibility_001_q3", "cluster_id": "skill_accessibility_001", "question": "How do I implement accessibility features?", "answer": "To implement accessibility features, use the accessibility module to define components with a11y() containing label, role, and optional hint attributes. For example: A11y = a11y([label('Submit'), role(button), hint('Submit form')]), then call generate_a11y_attrs(A11y, vue, Code) to generate platform-specific ARIA attributes or accessibility props for React Native, Vue, Flutter, or SwiftUI. Wrap your components with these generated attributes to enable screen reader support, keyboard navigation, and proper semantic meaning across all platforms.", "question_type": "medium", "topics": ["Quickstart", "Accessibility"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["accessibility", "a11y", "cross-platform"], "related_skills": ["skill_accessibility.md"], "related_docs": ["src/unifyweaver/a11y/accessibility.pl", "src/unifyweaver/glue/accessibility_generator.pl"], "original_answer": "Use the accessibility module to define accessible components with labels, roles, and hints. Define a11y attributes:\n\n```prolog\nA11y = a11y([label('Submit'), role(button), hint('Submit form')]),\ngenerate_a11y_attrs(A11y, vue, Code).\n```\n\nThe system generates platform-specific code (React Native, Vue, Flutter, SwiftUI). Start by wrapping components with a11y() containing label, role, and optional hint attributes. See skill_accessibility.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_accessibility_002_q0", "cluster_id": "skill_accessibility_002", "question": "How do I add ARIA attributes to web components?", "answer": "Define ARIA specs for your web components and generate the corresponding attributes:\n\n```prolog\naria_spec(my_chart, [\n    role(img),\n    label(\"Sales chart visualization\"),\n    describedby(chart_description)\n]).\ngenerate_aria_props(my_chart, Props).\n```\n\nThis generates a props object with `role`, `aria-label`, and `aria-describedby` attributes. Supported ARIA attributes include: `role`, `label`, `describedby`, `labelledby`, `controls`, `expanded`, `selected`, `hidden`, `disabled`, `readonly`, and live region modes (polite, assertive, off).", "question_type": "long", "topics": ["Quickstart", "Accessibility"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["ARIA", "web components", "semantic HTML"], "related_skills": ["skill_accessibility.md"], "related_docs": ["src/unifyweaver/a11y/accessibility.pl", "src/unifyweaver/glue/accessibility_generator.pl"], "original_answer": "Define ARIA specs for components and generate props:\n\n```prolog\naria_spec(my_chart, [\n    role(img),\n    label(\"Sales chart visualization\"),\n    describedby(chart_description)\n]).\ngenerate_aria_props(my_chart, Props).\n```\n\nThis generates a props object with role, aria-label, and aria-describedby attributes. Supported ARIA attributes include: role, label, describedby, labelledby, controls, expanded, selected, hidden, disabled, readonly, and live region modes. See skill_accessibility.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "Base answer assumes Prolog/UnifyWeaver framework familiarity. Real-world web developers may expect HTML/JavaScript examples. The answer doesn't explain how the generated props map to actual HTML attributes or how to integrate with standard web component patterns."}
{"pair_id": "skill_accessibility_002_q1", "cluster_id": "skill_accessibility_002", "question": "What ARIA attributes should I use?", "answer": "Use ARIA attributes by defining specs for your components and generating the props. For example:\n\n```prolog\naria_spec(my_chart, [\n    role(img),\n    label(\"Sales chart visualization\"),\n    describedby(chart_description)\n]).\ngenerate_aria_props(my_chart, Props).\n```\n\nThis generates attributes with role, aria-label, and aria-describedby. Supported ARIA attributes include: role, label, describedby, labelledby, controls, expanded, selected, hidden, disabled, readonly, and live region modes (polite, assertive, off).", "question_type": "long", "topics": ["Quickstart", "Accessibility"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["ARIA", "web components", "semantic HTML"], "related_skills": ["skill_accessibility.md"], "related_docs": ["src/unifyweaver/a11y/accessibility.pl", "src/unifyweaver/glue/accessibility_generator.pl"], "original_answer": "Define ARIA specs for components and generate props:\n\n```prolog\naria_spec(my_chart, [\n    role(img),\n    label(\"Sales chart visualization\"),\n    describedby(chart_description)\n]).\ngenerate_aria_props(my_chart, Props).\n```\n\nThis generates a props object with role, aria-label, and aria-describedby attributes. Supported ARIA attributes include: role, label, describedby, labelledby, controls, expanded, selected, hidden, disabled, readonly, and live region modes. See skill_accessibility.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_accessibility_002_q2", "cluster_id": "skill_accessibility_002", "question": "How do I generate ARIA props?", "answer": "To generate ARIA props in UnifyWeaver, define an ARIA spec for your component and call the generator:\n\n```prolog\naria_spec(my_chart, [\n    role(img),\n    label(\"Sales chart visualization\"),\n    describedby(chart_description)\n]).\ngenerate_aria_props(my_chart, Props).\n```\n\nThis generates a props object containing standard ARIA attributes like role, aria-label, and aria-describedby. Supported ARIA attributes include: role, label, describedby, labelledby, controls, expanded, selected, hidden, disabled, readonly, and live region modes (polite, assertive, off).", "question_type": "long", "topics": ["Quickstart", "Accessibility"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["ARIA", "web components", "semantic HTML"], "related_skills": ["skill_accessibility.md"], "related_docs": ["src/unifyweaver/a11y/accessibility.pl", "src/unifyweaver/glue/accessibility_generator.pl"], "original_answer": "Define ARIA specs for components and generate props:\n\n```prolog\naria_spec(my_chart, [\n    role(img),\n    label(\"Sales chart visualization\"),\n    describedby(chart_description)\n]).\ngenerate_aria_props(my_chart, Props).\n```\n\nThis generates a props object with role, aria-label, and aria-describedby attributes. Supported ARIA attributes include: role, label, describedby, labelledby, controls, expanded, selected, hidden, disabled, readonly, and live region modes. See skill_accessibility.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_accessibility_002_q3", "cluster_id": "skill_accessibility_002", "question": "How do I create accessible web components?", "answer": "To create accessible web components, define ARIA specs and generate the corresponding attributes:\n\n```prolog\naria_spec(my_component, [\n    role(button),\n    label(\"Component label\"),\n    describedby(description_id)\n]).\ngenerate_aria_props(my_component, Props).\n```\n\nThis generates ARIA attributes (role, aria-label, aria-describedby) that make your component accessible to screen readers. Key ARIA attributes supported include: role, label, describedby, labelledby, controls, expanded, selected, hidden, disabled, readonly, and live region modes. Additionally implement keyboard navigation with proper focus management and ensure all interactive elements are keyboard accessible.", "question_type": "long", "topics": ["Quickstart", "Accessibility"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["ARIA", "web components", "semantic HTML"], "related_skills": ["skill_accessibility.md"], "related_docs": ["src/unifyweaver/a11y/accessibility.pl", "src/unifyweaver/glue/accessibility_generator.pl"], "original_answer": "Define ARIA specs for components and generate props:\n\n```prolog\naria_spec(my_chart, [\n    role(img),\n    label(\"Sales chart visualization\"),\n    describedby(chart_description)\n]).\ngenerate_aria_props(my_chart, Props).\n```\n\nThis generates a props object with role, aria-label, and aria-describedby attributes. Supported ARIA attributes include: role, label, describedby, labelledby, controls, expanded, selected, hidden, disabled, readonly, and live region modes. See skill_accessibility.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer focuses on Prolog/UnifyWeaver DSL syntax rather than practical web component implementation. The question asks about creating accessible web components generally, which typically involves HTML/Vue/React - the answer should clarify this is for the UnifyWeaver accessibility framework. The confidence is moderate because while the technical content is accurate for the framework, it may not fully address expectations of a general web development audience."}
{"pair_id": "skill_accessibility_003_q0", "cluster_id": "skill_accessibility_003", "question": "How do I add keyboard navigation support?", "answer": "To add keyboard navigation support, use the keyboard_nav/2 and generate_keyboard_handler/2 predicates in accessibility.pl. Define keyboard handlers for your component type (e.g., data_table, interactive_chart, slider, modal), then generate the corresponding event handler code. Pre-defined handlers manage arrow keys, Home/End keys, Enter, Escape, Space, and Tab with automatic preventDefault() calls and focus management built in. For example: keyboard_nav(data_table, Handlers), generate_keyboard_handler(data_table, Handler) will generate a handler that responds to arrow navigation, Home/End jumps, and Enter/Escape/Tab interactions appropriate for that component type.", "question_type": "long", "topics": ["Quickstart", "Accessibility"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["keyboard navigation", "keyboard shortcuts", "focus management"], "related_skills": ["skill_accessibility.md"], "related_docs": ["src/unifyweaver/a11y/accessibility.pl", "src/unifyweaver/glue/accessibility_generator.pl"], "original_answer": "Define keyboard handlers for interactive components:\n\n```prolog\nkeyboard_nav(data_table, Handlers).\ngenerate_keyboard_handler(data_table, Handler).\n```\n\nPre-defined handlers exist for data_table (arrows, Home, End, Enter, Escape, Tab), interactive_chart (arrows, Enter, Escape, Space), slider (arrows, PageUp/Down, Home, End), and modal (Escape, Tab). Each generates event handler code with preventDefault() calls and focus management. See skill_accessibility.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "Base answer references skill_accessibility.md which may not exist or be accessible. Answer assumes developer knows how to integrate generated handlers into their component. No example of actual implementation shown (e.g., how to attach handler to component)."}
{"pair_id": "skill_accessibility_003_q1", "cluster_id": "skill_accessibility_003", "question": "How do I implement keyboard shortcuts?", "answer": "Keyboard shortcuts are implemented by defining keyboard handlers for interactive components. Use `keyboard_nav(component_type, Handlers)` to define handlers and `generate_keyboard_handler(component_type, Handler)` to generate the event handler code. Pre-defined handlers exist for common components: data_table (arrow keys, Home, End, Enter, Escape, Tab), interactive_chart (arrow keys, Enter, Escape, Space), slider (arrow keys, PageUp/Down, Home, End), and modal (Escape, Tab). These handlers automatically generate code with preventDefault() calls and proper focus management. For example: `keyboard_nav(data_table, Handlers), generate_keyboard_handler(data_table, Handler)` generates keyboard navigation for a data table.", "question_type": "long", "topics": ["Quickstart", "Accessibility"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["keyboard navigation", "keyboard shortcuts", "focus management"], "related_skills": ["skill_accessibility.md"], "related_docs": ["src/unifyweaver/a11y/accessibility.pl", "src/unifyweaver/glue/accessibility_generator.pl"], "original_answer": "Define keyboard handlers for interactive components:\n\n```prolog\nkeyboard_nav(data_table, Handlers).\ngenerate_keyboard_handler(data_table, Handler).\n```\n\nPre-defined handlers exist for data_table (arrows, Home, End, Enter, Escape, Tab), interactive_chart (arrows, Enter, Escape, Space), slider (arrows, PageUp/Down, Home, End), and modal (Escape, Tab). Each generates event handler code with preventDefault() calls and focus management. See skill_accessibility.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "Base answer conflates keyboard navigation with keyboard shortcuts. The question asks about 'keyboard shortcuts' (global key combos like Ctrl+S), but the base answer describes keyboard navigation (component-specific arrow key handling). The answer is technically accurate for keyboard navigation but may not fully address user expectations about implementing custom keyboard shortcuts."}
{"pair_id": "skill_accessibility_003_q2", "cluster_id": "skill_accessibility_003", "question": "How do I handle arrow keys and Enter?", "answer": "To handle arrow keys and Enter in your components, use the keyboard navigation module:\n\n```prolog\nkeyboard_nav(component_type, Handlers).\ngenerate_keyboard_handler(component_type, Handler).\n```\n\nPre-defined handlers are available for:\n- **data_table**: Arrow keys (navigate cells), Home/End (jump to edges), Enter (select), Escape (cancel), Tab (move focus)\n- **interactive_chart**: Arrow keys (navigate elements), Enter (activate), Escape (close), Space (toggle)\n- **slider**: Arrow keys (adjust value), PageUp/Down (larger steps), Home/End (min/max)\n- **modal**: Escape (close), Tab (cycle focus)\n\nEach handler automatically includes preventDefault() calls and proper focus management. Reference skill_accessibility.md for complete implementation details and target-specific code generation.", "question_type": "long", "topics": ["Quickstart", "Accessibility"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["keyboard navigation", "keyboard shortcuts", "focus management"], "related_skills": ["skill_accessibility.md"], "related_docs": ["src/unifyweaver/a11y/accessibility.pl", "src/unifyweaver/glue/accessibility_generator.pl"], "original_answer": "Define keyboard handlers for interactive components:\n\n```prolog\nkeyboard_nav(data_table, Handlers).\ngenerate_keyboard_handler(data_table, Handler).\n```\n\nPre-defined handlers exist for data_table (arrows, Home, End, Enter, Escape, Tab), interactive_chart (arrows, Enter, Escape, Space), slider (arrows, PageUp/Down, Home, End), and modal (Escape, Tab). Each generates event handler code with preventDefault() calls and focus management. See skill_accessibility.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "Base answer is vague about what the handlers actually do and doesn't explain the practical difference between components. Prolog syntax may not match user's actual framework (Vue, React, etc.). Missing example of how to actually use generated handlers in component code."}
{"pair_id": "skill_accessibility_003_q3", "cluster_id": "skill_accessibility_003", "question": "How do I support keyboard-only navigation?", "answer": "To support keyboard-only navigation, define keyboard handlers for your interactive components using the accessibility module. Use `keyboard_nav(component_type, Handlers)` to retrieve handlers for your component, then `generate_keyboard_handler(component_type, Handler)` to generate the implementation code. Pre-defined handlers include: data_table (arrow keys, Home, End, Enter, Escape, Tab), interactive_chart (arrow keys, Enter, Escape, Space), slider (arrow keys, PageUp/Down, Home, End), and modal (Escape, Tab). Each handler generates event listener code with preventDefault() calls and focus management automatically. This ensures keyboard users can navigate and interact with all components without a mouse.", "question_type": "long", "topics": ["Quickstart", "Accessibility"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["keyboard navigation", "keyboard shortcuts", "focus management"], "related_skills": ["skill_accessibility.md"], "related_docs": ["src/unifyweaver/a11y/accessibility.pl", "src/unifyweaver/glue/accessibility_generator.pl"], "original_answer": "Define keyboard handlers for interactive components:\n\n```prolog\nkeyboard_nav(data_table, Handlers).\ngenerate_keyboard_handler(data_table, Handler).\n```\n\nPre-defined handlers exist for data_table (arrows, Home, End, Enter, Escape, Tab), interactive_chart (arrows, Enter, Escape, Space), slider (arrows, PageUp/Down, Home, End), and modal (Escape, Tab). Each generates event handler code with preventDefault() calls and focus management. See skill_accessibility.md for details.", "answer_tailored": true, "confidence": 0.75, "confidence_issues": "The base answer lacks concrete example code showing how to implement the handlers in actual Vue/React/Flutter components. Users may need clearer guidance on integrating the generated code into their component templates or JSX. The answer assumes familiarity with the Prolog-based API."}
{"pair_id": "skill_accessibility_004_q0", "cluster_id": "skill_accessibility_004", "question": "How do I implement focus traps for modals?", "answer": "To implement focus traps for modals, define a focus trap configuration specifying the modal container, initial focus element, and behaviors:\n\n```prolog\nfocus_trap(confirmation_modal, [\n    container_selector('#confirmation-modal'),\n    initial_focus('#confirm-button'),\n    return_focus(true),\n    escape_closes(true)\n]).\ngenerate_focus_trap_jsx(confirmation_modal, JSX).\n```\n\nKey options:\n- `container_selector`: CSS selector for the modal element\n- `initial_focus`: Element ID to receive focus when modal opens\n- `return_focus`: Restore focus to previously focused element when modal closes\n- `escape_closes`: Allow Escape key to close the modal\n- `outside_click_closes`: Allow clicking outside modal to close it\n\nFor React, use `generate_focus_trap_hook()` to generate a custom hook that manages focus trap behavior.", "question_type": "long", "topics": ["Quickstart", "Accessibility"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["focus trap", "modal", "focus management"], "related_skills": ["skill_accessibility.md"], "related_docs": ["src/unifyweaver/a11y/accessibility.pl", "src/unifyweaver/glue/accessibility_generator.pl"], "original_answer": "Define focus trap configuration for modals:\n\n```prolog\nfocus_trap(confirmation_modal, [\n    container_selector('#confirmation-modal'),\n    initial_focus('#confirm-button'),\n    return_focus(true),\n    escape_closes(true)\n]).\ngenerate_focus_trap_jsx(confirmation_modal, JSX).\n```\n\nOptions include: container_selector (CSS selector), initial_focus (element to focus on open), return_focus (restore previous focus), escape_closes (Escape key closes), outside_click_closes (click outside closes). Also use generate_focus_trap_hook() for React hooks. See skill_accessibility.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_accessibility_004_q1", "cluster_id": "skill_accessibility_004", "question": "How do I trap focus in a dialog?", "answer": "To trap focus in a dialog, define a focus trap configuration specifying the dialog container, initial focus element, and behavior on close:\n\n```prolog\nfocus_trap(my_dialog, [\n    container_selector('#dialog-id'),\n    initial_focus('#first-focusable-element'),\n    return_focus(true),\n    escape_closes(true)\n]).\ngenerate_focus_trap_jsx(my_dialog, JSX).\n```\n\nKey options:\n- `container_selector`: CSS selector for the dialog element\n- `initial_focus`: Element ID to receive focus when dialog opens\n- `return_focus`: Restore focus to previously focused element when dialog closes\n- `escape_closes`: Allow Escape key to close the dialog\n- `outside_click_closes`: Close when clicking outside the dialog\n\nFor React, use `generate_focus_trap_hook()` to generate a custom hook for managing focus trap behavior.", "question_type": "long", "topics": ["Quickstart", "Accessibility"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["focus trap", "modal", "focus management"], "related_skills": ["skill_accessibility.md"], "related_docs": ["src/unifyweaver/a11y/accessibility.pl", "src/unifyweaver/glue/accessibility_generator.pl"], "original_answer": "Define focus trap configuration for modals:\n\n```prolog\nfocus_trap(confirmation_modal, [\n    container_selector('#confirmation-modal'),\n    initial_focus('#confirm-button'),\n    return_focus(true),\n    escape_closes(true)\n]).\ngenerate_focus_trap_jsx(confirmation_modal, JSX).\n```\n\nOptions include: container_selector (CSS selector), initial_focus (element to focus on open), return_focus (restore previous focus), escape_closes (Escape key closes), outside_click_closes (click outside closes). Also use generate_focus_trap_hook() for React hooks. See skill_accessibility.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_accessibility_004_q2", "cluster_id": "skill_accessibility_004", "question": "How do I prevent focus escape from modals?", "answer": "Prevent focus escape from modals by defining a focus trap configuration:\n\n```prolog\nfocus_trap(my_modal, [\n    container_selector('#modal'),\n    initial_focus('#first-focusable'),\n    return_focus(true),\n    escape_closes(true)\n]).\ngenerate_focus_trap_jsx(my_modal, JSX).\n```\n\nKey options:\n- **container_selector**: CSS selector for modal container\n- **initial_focus**: Element ID to focus when modal opens\n- **return_focus**: Restore focus to previous element when modal closes\n- **escape_closes**: Allow Escape key to close modal\n- **outside_click_closes**: Close modal on click outside\n\nFor React hooks, use `generate_focus_trap_hook()` instead of `generate_focus_trap_jsx()`.", "question_type": "long", "topics": ["Quickstart", "Accessibility"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["focus trap", "modal", "focus management"], "related_skills": ["skill_accessibility.md"], "related_docs": ["src/unifyweaver/a11y/accessibility.pl", "src/unifyweaver/glue/accessibility_generator.pl"], "original_answer": "Define focus trap configuration for modals:\n\n```prolog\nfocus_trap(confirmation_modal, [\n    container_selector('#confirmation-modal'),\n    initial_focus('#confirm-button'),\n    return_focus(true),\n    escape_closes(true)\n]).\ngenerate_focus_trap_jsx(confirmation_modal, JSX).\n```\n\nOptions include: container_selector (CSS selector), initial_focus (element to focus on open), return_focus (restore previous focus), escape_closes (Escape key closes), outside_click_closes (click outside closes). Also use generate_focus_trap_hook() for React hooks. See skill_accessibility.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_accessibility_004_q3", "cluster_id": "skill_accessibility_004", "question": "How do I create accessible modals?", "answer": "To create accessible modals, define a focus trap configuration that manages keyboard navigation and focus management:\n\n```prolog\nfocus_trap(confirmation_modal, [\n    container_selector('#confirmation-modal'),\n    initial_focus('#confirm-button'),\n    return_focus(true),\n    escape_closes(true)\n]).\ngenerate_focus_trap_jsx(confirmation_modal, JSX).\n```\n\nKey configuration options:\n- `container_selector` - CSS selector for the modal element\n- `initial_focus` - Element ID to focus when modal opens\n- `return_focus` - Restore focus to triggering element when closed (set to true)\n- `escape_closes` - Allow Escape key to close the modal\n- `outside_click_closes` - Allow clicking outside modal to close it\n\nFor React, use `generate_focus_trap_hook()` to generate the focus trap hook. This ensures keyboard navigation is trapped within the modal, screen readers announce modal content properly, and focus is managed correctly during open/close transitions.", "question_type": "long", "topics": ["Quickstart", "Accessibility"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["focus trap", "modal", "focus management"], "related_skills": ["skill_accessibility.md"], "related_docs": ["src/unifyweaver/a11y/accessibility.pl", "src/unifyweaver/glue/accessibility_generator.pl"], "original_answer": "Define focus trap configuration for modals:\n\n```prolog\nfocus_trap(confirmation_modal, [\n    container_selector('#confirmation-modal'),\n    initial_focus('#confirm-button'),\n    return_focus(true),\n    escape_closes(true)\n]).\ngenerate_focus_trap_jsx(confirmation_modal, JSX).\n```\n\nOptions include: container_selector (CSS selector), initial_focus (element to focus on open), return_focus (restore previous focus), escape_closes (Escape key closes), outside_click_closes (click outside closes). Also use generate_focus_trap_hook() for React hooks. See skill_accessibility.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_accessibility_005_q0", "cluster_id": "skill_accessibility_005", "question": "How do I make content compatible with screen readers?", "answer": "Use semantic HTML and ARIA attributes to make content compatible with screen readers. For dynamic content updates, use live regions with aria-live attributes set to 'polite' for non-urgent announcements or 'assertive' for urgent alerts. Always include descriptive aria-label or aria-labelledby attributes for interactive elements. Hide purely decorative elements with aria-hidden=\"true\". Provide text alternatives for images using alt text. For complex components, use appropriate ARIA roles (button, heading, navigation, etc.) and ensure all functionality is keyboard accessible. Example: ```prolog\nlive_region(alerts, [aria_live(assertive), role(alert)]).\ngenerate_live_region_jsx(alerts, JSX).\n```\nTest with screen reader software like NVDA, JAWS, or VoiceOver to verify compatibility.", "question_type": "long", "topics": ["Quickstart", "Accessibility"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["screen reader", "live region", "ARIA"], "related_skills": ["skill_accessibility.md"], "related_docs": ["src/unifyweaver/a11y/accessibility.pl", "src/unifyweaver/glue/accessibility_generator.pl"], "original_answer": "Use live regions for screen reader announcements and semantic labels:\n\n```prolog\nlive_region(error_messages, [aria_live(assertive), role(alert)]).\ngenerate_live_region_jsx(error_messages, JSX).\n```\n\nPre-defined regions: chart_updates (polite status), error_messages (assertive alert), loading_status (polite status). Options: aria_live (polite|assertive), aria_atomic (announce entire region), role (status|alert), aria_busy (loading state). Always include descriptive labels and use aria-hidden to hide decorative elements. See skill_accessibility.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "Base answer focuses heavily on live regions but screen reader compatibility encompasses broader patterns (semantic HTML, keyboard navigation, text alternatives) that are equally important. The answer assumes Prolog/JSX context which may not match all user contexts."}
{"pair_id": "skill_accessibility_005_q1", "cluster_id": "skill_accessibility_005", "question": "How do I add screen reader support?", "answer": "To add screen reader support, use live regions for dynamic content announcements and semantic ARIA labels:\n\n```prolog\n% Define a live region for announcements\nlive_region(error_messages, [aria_live(assertive), role(alert)]).\ngenerate_live_region_jsx(error_messages, JSX).\n\n% Add semantic labels to components\na11y([label('Submit'), role(button)]),\ngenerate_a11y_attrs(A11y, vue, Code).\n```\n\nKey patterns:\n- Use `aria_live(assertive)` for urgent updates (errors, alerts)\n- Use `aria_live(polite)` for status messages\n- Add `aria-label` or `aria-describedby` to all interactive elements\n- Use `aria-hidden=\"true\"` for decorative elements\n- Use semantic roles (button, heading, img) instead of generic divs\n\nPre-configured regions: error_messages (assertive alert), loading_status (polite), chart_updates (polite status). Always pair live regions with descriptive text content.", "question_type": "long", "topics": ["Quickstart", "Accessibility"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["screen reader", "live region", "ARIA"], "related_skills": ["skill_accessibility.md"], "related_docs": ["src/unifyweaver/a11y/accessibility.pl", "src/unifyweaver/glue/accessibility_generator.pl"], "original_answer": "Use live regions for screen reader announcements and semantic labels:\n\n```prolog\nlive_region(error_messages, [aria_live(assertive), role(alert)]).\ngenerate_live_region_jsx(error_messages, JSX).\n```\n\nPre-defined regions: chart_updates (polite status), error_messages (assertive alert), loading_status (polite status). Options: aria_live (polite|assertive), aria_atomic (announce entire region), role (status|alert), aria_busy (loading state). Always include descriptive labels and use aria-hidden to hide decorative elements. See skill_accessibility.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer assumes Prolog syntax familiarity; some developers may need clearer mapping to their target platform (Vue, React Native, etc.) before they can implement."}
{"pair_id": "skill_accessibility_005_q2", "cluster_id": "skill_accessibility_005", "question": "How do I create live regions for screen reader announcements?", "answer": "Live regions announce dynamic content changes to screen readers. Use the `aria_live` attribute with `polite` (waits for user pause) or `assertive` (interrupts immediately). Example:\n\n```prolog\nlive_region(error_messages, [aria_live(assertive), role(alert)]).\ngenerate_live_region_jsx(error_messages, JSX).\n```\n\nCommon patterns:\n- Status updates: `aria_live(polite)` with `role(status)`\n- Error alerts: `aria_live(assertive)` with `role(alert)`\n- Form feedback: `aria_live(polite)` with descriptive text\n\nInclude `aria_atomic(true)` to announce the entire region, and wrap dynamic content in the live region element. Always add descriptive labels so screen reader users understand what changed.", "question_type": "long", "topics": ["Quickstart", "Accessibility"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["screen reader", "live region", "ARIA"], "related_skills": ["skill_accessibility.md"], "related_docs": ["src/unifyweaver/a11y/accessibility.pl", "src/unifyweaver/glue/accessibility_generator.pl"], "original_answer": "Use live regions for screen reader announcements and semantic labels:\n\n```prolog\nlive_region(error_messages, [aria_live(assertive), role(alert)]).\ngenerate_live_region_jsx(error_messages, JSX).\n```\n\nPre-defined regions: chart_updates (polite status), error_messages (assertive alert), loading_status (polite status). Options: aria_live (polite|assertive), aria_atomic (announce entire region), role (status|alert), aria_busy (loading state). Always include descriptive labels and use aria-hidden to hide decorative elements. See skill_accessibility.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "Base answer is somewhat verbose and could be more direct. The answer addresses the core question but mixes technical details with guidance that could be clearer. Missing explicit mention of common use cases like form validation or dynamic list updates."}
{"pair_id": "skill_accessibility_005_q3", "cluster_id": "skill_accessibility_005", "question": "How do I make dynamic content accessible?", "answer": "Use live regions to announce dynamic content changes to screen readers. Live regions automatically notify users of updates without requiring focus changes.\n\nFor error messages and alerts, use assertive live regions:\n```prolog\nlive_region(error_messages, [aria_live(assertive), role(alert)]).\ngenerate_live_region_jsx(error_messages, JSX).\n```\n\nFor status updates and less urgent changes, use polite live regions:\n```prolog\nlive_region(chart_updates, [aria_live(polite), role(status)]).\n```\n\nKey options:\n- `aria_live(assertive|polite)` - How urgently to announce changes\n- `aria_atomic(true)` - Announce entire region or just changes\n- `role(status|alert)` - Semantic role for the region\n- `aria_busy(true)` - Indicate loading state\n- `aria_label()` - Descriptive label for the region\n\nAlways include descriptive labels so users understand what content updated, and use `aria-hidden` to hide decorative elements.", "question_type": "long", "topics": ["Quickstart", "Accessibility"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["screen reader", "live region", "ARIA"], "related_skills": ["skill_accessibility.md"], "related_docs": ["src/unifyweaver/a11y/accessibility.pl", "src/unifyweaver/glue/accessibility_generator.pl"], "original_answer": "Use live regions for screen reader announcements and semantic labels:\n\n```prolog\nlive_region(error_messages, [aria_live(assertive), role(alert)]).\ngenerate_live_region_jsx(error_messages, JSX).\n```\n\nPre-defined regions: chart_updates (polite status), error_messages (assertive alert), loading_status (polite status). Options: aria_live (polite|assertive), aria_atomic (announce entire region), role (status|alert), aria_busy (loading state). Always include descriptive labels and use aria-hidden to hide decorative elements. See skill_accessibility.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer assumes Prolog/logic programming context which may not apply to all users. Answer simplified to focus on the core pattern (live regions) while maintaining technical accuracy."}
{"pair_id": "skill_accessibility_006_q0", "cluster_id": "skill_accessibility_006", "question": "How do I add skip links for keyboard navigation?", "answer": "Generate skip links to let keyboard users jump to content sections:\n\n```prolog\ngenerate_skip_links_jsx([main, nav, chart], JSX).\n```\n\nThis creates anchor elements that are visually hidden but accessible to keyboard users. Pre-defined skip links include: main (#main-content), nav (#navigation), chart (#chart-container), and controls (#control-panel). Pair these with id attributes on target sections to enable efficient keyboard navigation. The generated skip links appear at the top of the page and allow users to bypass repetitive content.", "question_type": "long", "topics": ["Quickstart", "Accessibility"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["skip links", "keyboard navigation", "user experience"], "related_skills": ["skill_accessibility.md"], "related_docs": ["src/unifyweaver/a11y/accessibility.pl", "src/unifyweaver/glue/accessibility_generator.pl"], "original_answer": "Generate skip links to let keyboard users jump to content:\n\n```prolog\ngenerate_skip_links_jsx([main, nav, chart], JSX).\n```\n\nPre-defined skip links: main (#main-content), nav (#navigation), chart (#chart-container), controls (#control-panel). This generates anchor elements that are visually hidden but accessible to keyboard users. Combined with proper id attributes on target sections, skip links improve keyboard navigation efficiency. See skill_accessibility.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "Answer assumes the user is working with a Prolog-based system and React/JSX. Real-world implementation details about CSS hiding, keyboard focus order, and exact HTML structure could be more explicit. The base answer references 'skill_accessibility.md' which may not be accessible in all contexts."}
{"pair_id": "skill_accessibility_006_q1", "cluster_id": "skill_accessibility_006", "question": "How do I let keyboard users skip navigation?", "answer": "Generate skip links to let keyboard users jump directly to main content sections:\n\n```prolog\ngenerate_skip_links_jsx([main, nav, chart], JSX).\n```\n\nThis creates visually hidden anchor elements that keyboard users can access (typically via Tab at page load). Pre-defined targets include main (#main-content), nav (#navigation), chart (#chart-container), and controls (#control-panel). Pair skip links with proper id attributes on target sections to enable efficient keyboard navigation. See skill_accessibility.md for implementation details.", "question_type": "long", "topics": ["Quickstart", "Accessibility"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["skip links", "keyboard navigation", "user experience"], "related_skills": ["skill_accessibility.md"], "related_docs": ["src/unifyweaver/a11y/accessibility.pl", "src/unifyweaver/glue/accessibility_generator.pl"], "original_answer": "Generate skip links to let keyboard users jump to content:\n\n```prolog\ngenerate_skip_links_jsx([main, nav, chart], JSX).\n```\n\nPre-defined skip links: main (#main-content), nav (#navigation), chart (#chart-container), controls (#control-panel). This generates anchor elements that are visually hidden but accessible to keyboard users. Combined with proper id attributes on target sections, skip links improve keyboard navigation efficiency. See skill_accessibility.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "Answer assumes JSX/React context but question doesn't specify platform. Could mention keyboard activation pattern (Tab key) more explicitly."}
{"pair_id": "skill_accessibility_006_q2", "cluster_id": "skill_accessibility_006", "question": "What are skip links?", "answer": "Skip links are hidden anchor elements that allow keyboard users to jump directly to main content sections, bypassing repetitive navigation. They're typically placed at the top of a page and link to key areas like main content, navigation, and controls. In the UnifyWeaver accessibility system, you can generate them with `generate_skip_links_jsx([main, nav, chart], JSX)`, which creates invisible-to-sighted-users but screen-reader-accessible links that improve keyboard navigation efficiency. Each skip link targets a corresponding id attribute on its section (e.g., #main-content for the main section).", "question_type": "long", "topics": ["Quickstart", "Accessibility"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["skip links", "keyboard navigation", "user experience"], "related_skills": ["skill_accessibility.md"], "related_docs": ["src/unifyweaver/a11y/accessibility.pl", "src/unifyweaver/glue/accessibility_generator.pl"], "original_answer": "Generate skip links to let keyboard users jump to content:\n\n```prolog\ngenerate_skip_links_jsx([main, nav, chart], JSX).\n```\n\nPre-defined skip links: main (#main-content), nav (#navigation), chart (#chart-container), controls (#control-panel). This generates anchor elements that are visually hidden but accessible to keyboard users. Combined with proper id attributes on target sections, skip links improve keyboard navigation efficiency. See skill_accessibility.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_accessibility_006_q3", "cluster_id": "skill_accessibility_006", "question": "How do I implement skip to main content?", "answer": "Implement skip to main content links using the accessibility module:\n\n```prolog\ngenerate_skip_links_jsx([main, nav, chart], JSX).\n```\n\nThis generates visually hidden anchor elements that keyboard users can access immediately upon page load. The module provides pre-defined skip link targets: main (#main-content), nav (#navigation), chart (#chart-container), and controls (#control-panel). Ensure corresponding id attributes exist on your target sections (e.g., id=\"main-content\" on your main content area). When activated, these links focus the target section, allowing keyboard and screen reader users to bypass repetitive navigation elements and jump directly to primary content.", "question_type": "long", "topics": ["Quickstart", "Accessibility"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["skip links", "keyboard navigation", "user experience"], "related_skills": ["skill_accessibility.md"], "related_docs": ["src/unifyweaver/a11y/accessibility.pl", "src/unifyweaver/glue/accessibility_generator.pl"], "original_answer": "Generate skip links to let keyboard users jump to content:\n\n```prolog\ngenerate_skip_links_jsx([main, nav, chart], JSX).\n```\n\nPre-defined skip links: main (#main-content), nav (#navigation), chart (#chart-container), controls (#control-panel). This generates anchor elements that are visually hidden but accessible to keyboard users. Combined with proper id attributes on target sections, skip links improve keyboard navigation efficiency. See skill_accessibility.md for details.", "answer_tailored": true, "confidence": 0.75, "confidence_issues": "The base answer doesn't explain implementation steps like adding id attributes to target elements or how to make links 'visually hidden but accessible', which are critical for actually implementing skip links. The answer assumes familiarity with the generate_skip_links_jsx function without detailing the output format or integration steps."}
{"pair_id": "skill_aggregation_patterns_001_q0", "cluster_id": "skill_aggregation_patterns_001", "question": "How do I combine search scores from multiple sources?", "answer": "Use fuzzy logic score blending to combine multiple ranking signals. Call `blend_scores(Weight, Score1, Score2, Combined)` where Weight (0.0-1.0) controls the relative influence of each source. For multiple sources, use `f_and([S1, S2, S3], Min)` to find the intersection (minimum score) or `f_or([S1, S2, S3], Max)` to find the union (maximum score). This approach works across semantic search, keyword matching, and other ranking paradigms. See skill_aggregation_patterns.md for implementation details and examples.", "question_type": "medium", "topics": ["Quickstart", "Aggregation Patterns"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["fuzzy-logic", "scoring", "search"], "related_skills": ["skill_aggregation_patterns.md", "skill_fuzzy_search.md"], "related_docs": ["src/unifyweaver/fuzzy/fuzzy.pl"], "original_answer": "Use fuzzy logic score blending to combine multiple ranking signals. Call `blend_scores(Weight, Score1, Score2, Combined)` where Weight (0.0-1.0) controls the influence of each score. For multiple scores, use `f_and([S1, S2, S3], Min)` for intersection logic or `f_or([S1, S2, S3], Max)` for union logic. See skill_aggregation_patterns.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_aggregation_patterns_001_q1", "cluster_id": "skill_aggregation_patterns_001", "question": "How do I blend multiple ranking signals?", "answer": "To blend multiple ranking signals, use `blend_scores(Weight, Score1, Score2, Combined)` where Weight (0.0-1.0) controls the proportion of each score in the final result. For combining more than two scores, use `f_and([S1, S2, S3], Min)` to find the minimum (intersection logic) or `f_or([S1, S2, S3], Max)` to find the maximum (union logic). This fuzzy logic approach lets you create weighted combinations of ranking signals from different sources, such as semantic and keyword scores.", "question_type": "medium", "topics": ["Quickstart", "Aggregation Patterns"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["fuzzy-logic", "scoring", "search"], "related_skills": ["skill_aggregation_patterns.md", "skill_fuzzy_search.md"], "related_docs": ["src/unifyweaver/fuzzy/fuzzy.pl"], "original_answer": "Use fuzzy logic score blending to combine multiple ranking signals. Call `blend_scores(Weight, Score1, Score2, Combined)` where Weight (0.0-1.0) controls the influence of each score. For multiple scores, use `f_and([S1, S2, S3], Min)` for intersection logic or `f_or([S1, S2, S3], Max)` for union logic. See skill_aggregation_patterns.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "Base answer references 'skill_aggregation_patterns.md' but the actual skill document name in context is 'skill: Aggregation Patterns'. The explanation of Weight semantics could be clearer\u2014it's not entirely explicit whether Weight represents the proportion for Score1 vs Score2, or if both scores are equally weighted. The answer assumes familiarity with fuzzy logic terminology that may not be universal."}
{"pair_id": "skill_aggregation_patterns_001_q2", "cluster_id": "skill_aggregation_patterns_001", "question": "How do I merge scores from semantic and keyword search?", "answer": "To merge scores from semantic and keyword search, use `blend_scores(Weight, SemanticScore, KeywordScore, Combined)` where Weight (0.0-1.0) controls the relative influence of each score. A weight of 0.7 gives 70% influence to the first score and 30% to the second. For combining more than two scores, use `f_and([S1, S2, S3], Min)` to take the minimum score (intersection logic) or `f_or([S1, S2, S3], Max)` to take the maximum score (union logic). This approach is part of the fuzzy search aggregation pattern described in skill_fuzzy_search.md.", "question_type": "medium", "topics": ["Quickstart", "Aggregation Patterns"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["fuzzy-logic", "scoring", "search"], "related_skills": ["skill_aggregation_patterns.md", "skill_fuzzy_search.md"], "related_docs": ["src/unifyweaver/fuzzy/fuzzy.pl"], "original_answer": "Use fuzzy logic score blending to combine multiple ranking signals. Call `blend_scores(Weight, Score1, Score2, Combined)` where Weight (0.0-1.0) controls the influence of each score. For multiple scores, use `f_and([S1, S2, S3], Min)` for intersection logic or `f_or([S1, S2, S3], Max)` for union logic. See skill_aggregation_patterns.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_aggregation_patterns_002_q0", "cluster_id": "skill_aggregation_patterns_002", "question": "How do I reduce a stream of data to a single summary value?", "answer": "Use `aggregate_all(Op, Goal, Result)` to reduce a stream to a single summary value. The Op parameter specifies the reduction operation: `count` for total items, `sum(V)` to add values, `min(V)` or `max(V)` for extremes, `avg(V)` for average, or `set(V)`/`bag(V)` for collections. For example, `aggregate_all(sum(Price), order(_, _, Price), Total)` sums all order prices into a single Total. This compiles to efficient runtime code in Go, Python, Rust, or C#.", "question_type": "medium", "topics": ["Quickstart", "Aggregation Patterns"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["streaming", "aggregation", "operators"], "related_skills": ["skill_aggregation_patterns.md", "skill_stream_aggregation.md"], "related_docs": ["src/unifyweaver/targets/go_target.pl", "docs/BINDING_MATRIX.md"], "original_answer": "Use `aggregate_all(Op, Goal, Result)` where Op can be `count`, `sum(V)`, `min(V)`, `max(V)`, `avg(V)`, `set(V)`, or `bag(V)`. For example: `aggregate_all(sum(Price), order(_, _, Price), Total)` sums all order prices. This generates efficient runtime code for Go, Python, Rust, or C#. See skill_aggregation_patterns.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_aggregation_patterns_002_q1", "cluster_id": "skill_aggregation_patterns_002", "question": "How do I aggregate data from a stream?", "answer": "Use `aggregate_all(Op, Goal, Result)` to reduce stream data to a summary value. Op can be `count`, `sum(V)`, `min(V)`, `max(V)`, `avg(V)`, `set(V)`, or `bag(V)`. For example: `aggregate_all(sum(Price), order(_, _, Price), Total)` accumulates all order prices into a single Total. This compiles to efficient procedural code in Go, Python, Rust, or C# that processes data streams at runtime.", "question_type": "medium", "topics": ["Quickstart", "Aggregation Patterns"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["streaming", "aggregation", "operators"], "related_skills": ["skill_aggregation_patterns.md", "skill_stream_aggregation.md"], "related_docs": ["src/unifyweaver/targets/go_target.pl", "docs/BINDING_MATRIX.md"], "original_answer": "Use `aggregate_all(Op, Goal, Result)` where Op can be `count`, `sum(V)`, `min(V)`, `max(V)`, `avg(V)`, `set(V)`, or `bag(V)`. For example: `aggregate_all(sum(Price), order(_, _, Price), Total)` sums all order prices. This generates efficient runtime code for Go, Python, Rust, or C#. See skill_aggregation_patterns.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_aggregation_patterns_002_q2", "cluster_id": "skill_aggregation_patterns_002", "question": "How do I sum or count values in a data stream?", "answer": "Use `aggregate_all(Op, Goal, Result)` in Prolog to sum or count values in a data stream. The Op parameter supports operations like `count`, `sum(V)`, `min(V)`, `max(V)`, `avg(V)`, `set(V)`, or `bag(V)`. For example, `aggregate_all(sum(Price), order(_, _, Price), Total)` sums all order prices into Total. This compiles to efficient runtime code in Go, Python, Rust, or C# depending on your target language. Use stream aggregation when processing data streams with custom logic in embedded databases like SQLite, BBolt, Redb, or LiteDB.", "question_type": "medium", "topics": ["Quickstart", "Aggregation Patterns"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["streaming", "aggregation", "operators"], "related_skills": ["skill_aggregation_patterns.md", "skill_stream_aggregation.md"], "related_docs": ["src/unifyweaver/targets/go_target.pl", "docs/BINDING_MATRIX.md"], "original_answer": "Use `aggregate_all(Op, Goal, Result)` where Op can be `count`, `sum(V)`, `min(V)`, `max(V)`, `avg(V)`, `set(V)`, or `bag(V)`. For example: `aggregate_all(sum(Price), order(_, _, Price), Total)` sums all order prices. This generates efficient runtime code for Go, Python, Rust, or C#. See skill_aggregation_patterns.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_aggregation_patterns_003_q0", "cluster_id": "skill_aggregation_patterns_003", "question": "How do I group data by category and get counts for each group?", "answer": "To group data by category and get counts for each group, use SQL aggregation. Define a Prolog predicate with `aggregate_all(count, ...)` that groups by category: `count_by_category(Category, Count) :- product(_, Category, _), aggregate_all(count, product(_, Category, _), Count)`. Compile this to SQL using `compile_predicate_to_sql(count_by_category/2, [dialect(postgres)], SQL)`, which generates `SELECT category, COUNT(*) FROM products GROUP BY category`. This works for SQL targets like PostgreSQL, MySQL, or SQLite.", "question_type": "medium", "topics": ["Quickstart", "Aggregation Patterns"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["SQL", "grouping", "aggregation"], "related_skills": ["skill_aggregation_patterns.md", "skill_sql_target.md", "skill_query_patterns.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl", "docs/BINDING_MATRIX.md"], "original_answer": "Use SQL aggregation by compiling Prolog predicates with `aggregate_all`. Define a fact-based predicate, then compile to SQL: `compile_predicate_to_sql(my_pred/2, [dialect(postgres)], SQL)`. For example, `count_by_category(Category, Count) :- product(_, Category, _), aggregate_all(count, product(_, Category, _), Count)` generates `SELECT category, COUNT(*) FROM products GROUP BY category`. See skill_aggregation_patterns.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer assumes knowledge of Prolog compilation workflow and doesn't mention stream-based aggregation as an alternative for non-SQL targets. Also doesn't clarify that the actual compilation syntax may vary depending on the specific system being used."}
{"pair_id": "skill_aggregation_patterns_003_q1", "cluster_id": "skill_aggregation_patterns_003", "question": "How do I use GROUP BY in my queries?", "answer": "To use GROUP BY in your queries, define a Prolog predicate with `aggregate_all` that specifies what to group by and what aggregation function to apply. For example: `count_by_category(Category, Count) :- product(_, Category, _), aggregate_all(count, product(_, Category, _), Count)`. Then compile it to SQL using `compile_predicate_to_sql(count_by_category/2, [dialect(postgres)], SQL)`, which generates `SELECT category, COUNT(*) FROM products GROUP BY category`. The `aggregate_all` functor handles the grouping logic automatically based on the free variables in your predicate.", "question_type": "medium", "topics": ["Quickstart", "Aggregation Patterns"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["SQL", "grouping", "aggregation"], "related_skills": ["skill_aggregation_patterns.md", "skill_sql_target.md", "skill_query_patterns.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl", "docs/BINDING_MATRIX.md"], "original_answer": "Use SQL aggregation by compiling Prolog predicates with `aggregate_all`. Define a fact-based predicate, then compile to SQL: `compile_predicate_to_sql(my_pred/2, [dialect(postgres)], SQL)`. For example, `count_by_category(Category, Count) :- product(_, Category, _), aggregate_all(count, product(_, Category, _), Count)` generates `SELECT category, COUNT(*) FROM products GROUP BY category`. See skill_aggregation_patterns.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_aggregation_patterns_003_q2", "cluster_id": "skill_aggregation_patterns_003", "question": "How do I count items by category?", "answer": "To count items by category, use SQL aggregation with Prolog's `aggregate_all`. Define a predicate like `count_by_category(Category, Count) :- product(_, Category, _), aggregate_all(count, product(_, Category, _), Count)`, then compile it to SQL using `compile_predicate_to_sql(count_by_category/2, [dialect(postgres)], SQL)`. This generates `SELECT category, COUNT(*) FROM products GROUP BY category`. The skill also supports stream-based aggregation for embedded databases (BBolt, Redb, LiteDB) if you need runtime aggregation instead of pure SQL.", "question_type": "medium", "topics": ["Quickstart", "Aggregation Patterns"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["SQL", "grouping", "aggregation"], "related_skills": ["skill_aggregation_patterns.md", "skill_sql_target.md", "skill_query_patterns.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl", "docs/BINDING_MATRIX.md"], "original_answer": "Use SQL aggregation by compiling Prolog predicates with `aggregate_all`. Define a fact-based predicate, then compile to SQL: `compile_predicate_to_sql(my_pred/2, [dialect(postgres)], SQL)`. For example, `count_by_category(Category, Count) :- product(_, Category, _), aggregate_all(count, product(_, Category, _), Count)` generates `SELECT category, COUNT(*) FROM products GROUP BY category`. See skill_aggregation_patterns.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_aggregation_patterns_004_q0", "cluster_id": "skill_aggregation_patterns_004", "question": "Should I use SQL generation or runtime aggregation for my data?", "answer": "Choose SQL generation (SQL Target) when you need pure SQL output, have an external database like PostgreSQL or MySQL, or require complex joins across many tables. Choose runtime aggregation (Stream Aggregation) when building self-contained applications, working with local storage in Go/Python/Rust/C#, or processing data streams. For local transactional storage, use embedded databases: SQLite for Python, BBolt for Go, Redb for Rust, or LiteDB for C#. For combining multiple ranking signals with different scales, use Fuzzy Logic aggregation. The choice depends on whether your database is external or embedded, and whether you need SQL generation or runtime processing.", "question_type": "medium", "topics": ["Quickstart", "Aggregation Patterns"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["strategy", "database", "performance"], "related_skills": ["skill_aggregation_patterns.md", "skill_sql_target.md", "skill_stream_aggregation.md"], "related_docs": ["docs/BINDING_MATRIX.md", "education/book-10-sql-target/"], "original_answer": "Use SQL Target when you need pure SQL output, have an external database (PostgreSQL, MySQL), or require complex joins. Use Stream Aggregation for self-contained applications, fast local storage, or processing in Go, Python, Rust, C#. Use Embedded Databases like SQLite, BBolt (Go), Redb (Rust), or LiteDB (C#) for local, transactional storage. Use Fuzzy Logic when combining multiple ranking signals with different scales. See skill_aggregation_patterns.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_aggregation_patterns_004_q1", "cluster_id": "skill_aggregation_patterns_004", "question": "When do I use SQL vs stream aggregation?", "answer": "Use SQL Target when you need pure SQL output, have an external database (PostgreSQL, MySQL), or require complex joins across tables. Use Stream Aggregation when you're building self-contained applications, need fast local storage with embedded databases (SQLite, BBolt, Redb, LiteDB), or processing data streams in Go, Python, Rust, or C#. Choose based on your deployment model: SQL Target for external databases and query generation, Stream Aggregation for embedded databases and runtime aggregation with custom logic.", "question_type": "medium", "topics": ["Quickstart", "Aggregation Patterns"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["strategy", "database", "performance"], "related_skills": ["skill_aggregation_patterns.md", "skill_sql_target.md", "skill_stream_aggregation.md"], "related_docs": ["docs/BINDING_MATRIX.md", "education/book-10-sql-target/"], "original_answer": "Use SQL Target when you need pure SQL output, have an external database (PostgreSQL, MySQL), or require complex joins. Use Stream Aggregation for self-contained applications, fast local storage, or processing in Go, Python, Rust, C#. Use Embedded Databases like SQLite, BBolt (Go), Redb (Rust), or LiteDB (C#) for local, transactional storage. Use Fuzzy Logic when combining multiple ranking signals with different scales. See skill_aggregation_patterns.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_aggregation_patterns_004_q2", "cluster_id": "skill_aggregation_patterns_004", "question": "How do I choose between SQL and embedded databases?", "answer": "Choose SQL Target when you need pure SQL output, have an external database (PostgreSQL, MySQL), or require complex joins across tables. Choose Stream Aggregation and embedded databases (SQLite for Python, BBolt for Go, Redb for Rust, LiteDB for C#) when building self-contained applications that need fast local storage and transactional guarantees. Choose Fuzzy Logic when combining multiple ranking signals with different scales for search systems.", "question_type": "medium", "topics": ["Quickstart", "Aggregation Patterns"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["strategy", "database", "performance"], "related_skills": ["skill_aggregation_patterns.md", "skill_sql_target.md", "skill_stream_aggregation.md"], "related_docs": ["docs/BINDING_MATRIX.md", "education/book-10-sql-target/"], "original_answer": "Use SQL Target when you need pure SQL output, have an external database (PostgreSQL, MySQL), or require complex joins. Use Stream Aggregation for self-contained applications, fast local storage, or processing in Go, Python, Rust, C#. Use Embedded Databases like SQLite, BBolt (Go), Redb (Rust), or LiteDB (C#) for local, transactional storage. Use Fuzzy Logic when combining multiple ranking signals with different scales. See skill_aggregation_patterns.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_aggregation_patterns_005_q0", "cluster_id": "skill_aggregation_patterns_005", "question": "How do I query an embedded database from generated code?", "answer": "To query an embedded database from generated code, use Stream Aggregation with `aggregate_all` operators that compile to procedural code. Each target language has a supported embedded database: Python uses SQLite, Go uses BBolt, Rust uses Redb, and C# uses LiteDB. Write Prolog rules using `aggregate_all` for operations like counting, summing, or filtering, and they'll compile to native loops and queries in your target language. For example, `aggregate_all(sum(Price), order(_, _, Price), Total)` compiles to a loop that sums prices. Choose your database based on needs: SQLite for Python semantic search, BBolt for Go key-value storage, Redb for Rust transactions, or LiteDB for C# type-safe documents.", "question_type": "long", "topics": ["Quickstart", "Aggregation Patterns"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["embedded-db", "KV-store", "targets"], "related_skills": ["skill_aggregation_patterns.md", "skill_stream_aggregation.md"], "related_docs": ["docs/BINDING_MATRIX.md", "src/unifyweaver/targets/go_target.pl"], "original_answer": "Each target language supports different embedded databases: Python uses SQLite, Go uses BBolt, Rust uses Redb, and C# uses LiteDB. Use Stream Aggregation with `aggregate_all` operators to process embedded data. For type-safe document storage, C# LiteDB is ideal; for pure Rust transactions, use Redb; for fast file-based KV storage, use BBolt. Queries compile to procedural code that reads from the embedded database. See skill_aggregation_patterns.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_aggregation_patterns_005_q1", "cluster_id": "skill_aggregation_patterns_005", "question": "How do I use SQLite in my generated code?", "answer": "To use SQLite in your generated code, use Stream Aggregation with `aggregate_all` operators to process embedded data. Python is the primary target language that directly supports SQLite - queries compile to procedural code that reads from and writes to the SQLite database. Use `aggregate_all` operators in your Prolog rules to define aggregations that will compile to Python code interacting with SQLite. For other languages: Go uses BBolt, Rust uses Redb, and C# uses LiteDB as their embedded database alternatives. See skill_stream_aggregation.md for code examples.", "question_type": "long", "topics": ["Quickstart", "Aggregation Patterns"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["embedded-db", "KV-store", "targets"], "related_skills": ["skill_aggregation_patterns.md", "skill_stream_aggregation.md"], "related_docs": ["docs/BINDING_MATRIX.md", "src/unifyweaver/targets/go_target.pl"], "original_answer": "Each target language supports different embedded databases: Python uses SQLite, Go uses BBolt, Rust uses Redb, and C# uses LiteDB. Use Stream Aggregation with `aggregate_all` operators to process embedded data. For type-safe document storage, C# LiteDB is ideal; for pure Rust transactions, use Redb; for fast file-based KV storage, use BBolt. Queries compile to procedural code that reads from the embedded database. See skill_aggregation_patterns.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "The base answer conflates SQL Target (which generates pure SQL) with Stream Aggregation (which generates procedural code). The question asks specifically about using SQLite in generated code, which implies Stream Aggregation, not SQL Target. The answer could be clearer about Python being the primary language with SQLite support."}
{"pair_id": "skill_aggregation_patterns_005_q2", "cluster_id": "skill_aggregation_patterns_005", "question": "How do I work with embedded KV stores?", "answer": "Each target language supports different embedded KV stores: Go uses BBolt for fast file-based key-value storage, Rust uses Redb for pure Rust transactions, Python uses SQLite, and C# uses LiteDB for document storage. Use Stream Aggregation with `aggregate_all` operators to process data from these embedded databases. Your queries compile to procedural code that reads directly from the embedded store without requiring an external database connection.", "question_type": "long", "topics": ["Quickstart", "Aggregation Patterns"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["embedded-db", "KV-store", "targets"], "related_skills": ["skill_aggregation_patterns.md", "skill_stream_aggregation.md"], "related_docs": ["docs/BINDING_MATRIX.md", "src/unifyweaver/targets/go_target.pl"], "original_answer": "Each target language supports different embedded databases: Python uses SQLite, Go uses BBolt, Rust uses Redb, and C# uses LiteDB. Use Stream Aggregation with `aggregate_all` operators to process embedded data. For type-safe document storage, C# LiteDB is ideal; for pure Rust transactions, use Redb; for fast file-based KV storage, use BBolt. Queries compile to procedural code that reads from the embedded database. See skill_aggregation_patterns.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_aggregation_patterns_006_q0", "cluster_id": "skill_aggregation_patterns_006", "question": "How do I implement complex GROUP BY queries with HAVING clauses?", "answer": "Use SQL Target for complex GROUP BY with HAVING queries. Define your aggregation in Prolog using `aggregate_all` predicates, then compile with `compile_predicate_to_sql(my_pred/2, [dialect(postgres)], SQL)` to generate proper GROUP BY and HAVING clauses automatically. This approach works best for external databases like PostgreSQL, MySQL, and SQLite. The SQL Target handles the translation from Prolog aggregation logic to SQL, avoiding manual query construction and ensuring correct clause generation for complex filtering conditions.", "question_type": "long", "topics": ["Quickstart", "Aggregation Patterns"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["SQL", "GROUP-BY", "HAVING"], "related_skills": ["skill_aggregation_patterns.md", "skill_sql_target.md", "skill_query_patterns.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl", "education/book-10-sql-target/", "docs/BINDING_MATRIX.md"], "original_answer": "Use SQL Target for complex GROUP BY with HAVING. Define your aggregation in Prolog using `aggregate_all`, then compile with `compile_predicate_to_sql(my_pred/2, [dialect(postgres)], SQL)`. The SQL Target generates proper GROUP BY and HAVING clauses automatically. This approach is best for external databases (PostgreSQL, MySQL, SQLite) and complex joins across many tables. See skill_aggregation_patterns.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_aggregation_patterns_006_q1", "cluster_id": "skill_aggregation_patterns_006", "question": "How do I filter grouped results?", "answer": "Use SQL Target with HAVING clauses to filter grouped results. Define your aggregation in Prolog with `aggregate_all`, then compile using `compile_predicate_to_sql(my_pred/2, [dialect(postgres)], SQL)`. The SQL Target automatically generates GROUP BY and HAVING clauses that filter aggregated groups based on your conditions. This approach works best for external databases like PostgreSQL, MySQL, and SQLite. For example, to filter groups with count greater than 5, add a HAVING condition in your Prolog predicate before compilation.", "question_type": "long", "topics": ["Quickstart", "Aggregation Patterns"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["SQL", "GROUP-BY", "HAVING"], "related_skills": ["skill_aggregation_patterns.md", "skill_sql_target.md", "skill_query_patterns.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl", "education/book-10-sql-target/", "docs/BINDING_MATRIX.md"], "original_answer": "Use SQL Target for complex GROUP BY with HAVING. Define your aggregation in Prolog using `aggregate_all`, then compile with `compile_predicate_to_sql(my_pred/2, [dialect(postgres)], SQL)`. The SQL Target generates proper GROUP BY and HAVING clauses automatically. This approach is best for external databases (PostgreSQL, MySQL, SQLite) and complex joins across many tables. See skill_aggregation_patterns.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "The base answer mentions HAVING clauses but doesn't provide a concrete example of how to actually write the HAVING condition in Prolog or the resulting SQL. The answer assumes familiarity with the compilation process but could be more explicit about the filtering mechanism itself."}
{"pair_id": "skill_aggregation_patterns_006_q2", "cluster_id": "skill_aggregation_patterns_006", "question": "How do I add conditions to aggregated data?", "answer": "To add conditions to aggregated data, use the HAVING clause in SQL Target. Define your aggregation in Prolog with `aggregate_all`, then compile using `compile_predicate_to_sql(my_pred/2, [dialect(postgres)], SQL)`. The HAVING clause filters groups based on aggregate functions (e.g., `HAVING COUNT(*) > 5`), while WHERE filters individual rows before aggregation. For external databases like PostgreSQL, MySQL, or SQLite, SQL Target automatically generates proper GROUP BY with HAVING. For runtime aggregation in Go, Python, or Rust, apply conditional logic after accumulating values in stream aggregation.", "question_type": "long", "topics": ["Quickstart", "Aggregation Patterns"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["SQL", "GROUP-BY", "HAVING"], "related_skills": ["skill_aggregation_patterns.md", "skill_sql_target.md", "skill_query_patterns.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl", "education/book-10-sql-target/", "docs/BINDING_MATRIX.md"], "original_answer": "Use SQL Target for complex GROUP BY with HAVING. Define your aggregation in Prolog using `aggregate_all`, then compile with `compile_predicate_to_sql(my_pred/2, [dialect(postgres)], SQL)`. The SQL Target generates proper GROUP BY and HAVING clauses automatically. This approach is best for external databases (PostgreSQL, MySQL, SQLite) and complex joins across many tables. See skill_aggregation_patterns.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "Base answer mentions HAVING but doesn't clearly distinguish HAVING (post-aggregation) from WHERE (pre-aggregation), which is critical for answering 'how to add conditions to aggregated data'. The tailored answer addresses this but requires inference not explicitly stated in the base answer."}
{"pair_id": "skill_answer_tailoring_001_q0", "cluster_id": "skill_answer_tailoring_001", "question": "How do I create variations of my Q&A answers for training data?", "answer": "To create variations of Q&A answers for training data, use `python scripts/generate_tailored_answers.py --input <jsonl_dir>`. This reads (question, base_answer) pairs and generates reworded answers that directly address each question while maintaining semantic equivalence. Output includes `answer_tailored: true` and preserves original in `original_answer`.", "question_type": "medium", "topics": ["Quickstart", "Answer Tailoring"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["training-data", "augmentation", "automation"], "related_skills": ["skill_answer_tailoring.md", "skill_qa_generation.md", "skill_synthetic_data.md"], "related_docs": ["scripts/generate_tailored_answers.py", "scripts/expand_clusters_to_pairs.py"], "original_answer": "Use `python scripts/generate_tailored_answers.py --input training-data/expanded` to automatically reword your Q&A pairs. The tool generates semantically equivalent answers with natural variation in phrasing while preserving technical content. Results are saved with `answer_tailored: true` flag and the original answer preserved. See skill_answer_tailoring.md for details.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_answer_tailoring_001_q1", "cluster_id": "skill_answer_tailoring_001", "question": "How can I reword answers to add diversity to my training dataset?", "answer": "To add diversity to your training dataset through answer rewording, use the answer tailoring script: `python scripts/generate_tailored_answers.py --input training-data/expanded`. This tool automatically rewrites your Q&A pairs to create natural variation in phrasing while maintaining semantic equivalence and directly addressing each question. Each output preserves the original answer and marks the pair with `answer_tailored: true`, enabling you to generate diverse training data from a single base answer without losing semantic meaning.", "question_type": "medium", "topics": ["Quickstart", "Answer Tailoring"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["training-data", "augmentation", "automation"], "related_skills": ["skill_answer_tailoring.md", "skill_qa_generation.md", "skill_synthetic_data.md"], "related_docs": ["scripts/generate_tailored_answers.py", "scripts/expand_clusters_to_pairs.py"], "original_answer": "Use `python scripts/generate_tailored_answers.py --input training-data/expanded` to automatically reword your Q&A pairs. The tool generates semantically equivalent answers with natural variation in phrasing while preserving technical content. Results are saved with `answer_tailored: true` flag and the original answer preserved. See skill_answer_tailoring.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_answer_tailoring_001_q2", "cluster_id": "skill_answer_tailoring_001", "question": "Can I automatically generate different versions of the same answer?", "answer": "For training data diversity, use the answer tailoring script: `python scripts/generate_tailored_answers.py --input training-data/expanded`. Each base answer gets reworded to directly address its specific question with natural variation. Use `--provider gemini` or `--model haiku` for bulk processing, `--model sonnet` for quality-sensitive data.", "question_type": "medium", "topics": ["Quickstart", "Answer Tailoring"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["training-data", "augmentation", "automation"], "related_skills": ["skill_answer_tailoring.md", "skill_qa_generation.md", "skill_synthetic_data.md"], "related_docs": ["scripts/generate_tailored_answers.py", "scripts/expand_clusters_to_pairs.py"], "original_answer": "Use `python scripts/generate_tailored_answers.py --input training-data/expanded` to automatically reword your Q&A pairs. The tool generates semantically equivalent answers with natural variation in phrasing while preserving technical content. Results are saved with `answer_tailored: true` flag and the original answer preserved. See skill_answer_tailoring.md for details.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_answer_tailoring_002_q0", "cluster_id": "skill_answer_tailoring_002", "question": "How do I process a single Q&A file instead of a whole directory?", "answer": "Choose LLM provider with `--provider claude` or `--provider gemini`. Claude haiku is fast and low-cost for bulk processing. Sonnet offers better quality at medium cost. Gemini flash is similar to haiku. For quality-sensitive data, use `--model sonnet` or `--model opus`.", "question_type": "long", "topics": ["Quickstart", "Answer Tailoring"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["file-processing", "command-options"], "related_skills": ["skill_answer_tailoring.md"], "related_docs": ["scripts/generate_tailored_answers.py"], "original_answer": "Use the `--file` option: `python scripts/generate_tailored_answers.py --file training-data/expanded/mindmap/pairs.jsonl`. This processes only the specified JSONL file instead of all files in a directory. See skill_answer_tailoring.md for details.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_answer_tailoring_002_q1", "cluster_id": "skill_answer_tailoring_002", "question": "Can I tailor answers in just one JSONL file?", "answer": "For answer rewriting, use `--model haiku` (Claude) or `--model gemini-2.5-flash-preview` (Gemini) for bulk processing. Use `--model sonnet` for quality-sensitive data, `--model opus` for best quality. Set with `python scripts/generate_tailored_answers.py --model <name>`.", "question_type": "long", "topics": ["Quickstart", "Answer Tailoring"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["file-processing", "command-options"], "related_skills": ["skill_answer_tailoring.md"], "related_docs": ["scripts/generate_tailored_answers.py"], "original_answer": "Use the `--file` option: `python scripts/generate_tailored_answers.py --file training-data/expanded/mindmap/pairs.jsonl`. This processes only the specified JSONL file instead of all files in a directory. See skill_answer_tailoring.md for details.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_answer_tailoring_002_q2", "cluster_id": "skill_answer_tailoring_002", "question": "What command runs answer tailoring on a specific file?", "answer": "Claude haiku and Gemini flash are similarly fast for answer tailoring. Gemini may have longer timeouts. For speed: use `--provider gemini --model gemini-2.5-flash-preview` or `--provider claude --model haiku`. Both support `--delay` to control rate limiting.", "question_type": "long", "topics": ["Quickstart", "Answer Tailoring"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["file-processing", "command-options"], "related_skills": ["skill_answer_tailoring.md"], "related_docs": ["scripts/generate_tailored_answers.py"], "original_answer": "Use the `--file` option: `python scripts/generate_tailored_answers.py --file training-data/expanded/mindmap/pairs.jsonl`. This processes only the specified JSONL file instead of all files in a directory. See skill_answer_tailoring.md for details.", "answer_tailored": true, "confidence": 0.85, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_answer_tailoring_003_q0", "cluster_id": "skill_answer_tailoring_003", "question": "Which LLM model should I use for tailoring answers?", "answer": "For tailoring answers, use Claude Haiku for fast, cost-efficient bulk processing, or Claude Sonnet if quality is your priority. Gemini Flash is also a good option for speed and cost efficiency. You can switch models with the `--provider` and `--model` flags. Choose Haiku for rapid iteration, Sonnet for better quality, and Opus only if you need the highest quality and can afford the cost.", "question_type": "medium", "topics": ["Quickstart", "Answer Tailoring"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["models", "providers", "configuration"], "related_skills": ["skill_answer_tailoring.md"], "related_docs": ["scripts/generate_tailored_answers.py"], "original_answer": "For bulk processing, use Claude haiku or Gemini flash for speed and cost efficiency. For quality-sensitive data, use Claude sonnet. Switch models with `--provider gemini --model gemini-2.5-flash-preview`. Claude haiku is fast and good quality, Sonnet offers better quality at medium cost, and Opus provides best quality at high cost. See skill_answer_tailoring.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_answer_tailoring_003_q1", "cluster_id": "skill_answer_tailoring_003", "question": "What's the best model for answer variation generation?", "answer": "For bulk processing, Claude haiku or Gemini flash offer the best speed/cost balance: `--provider claude --model haiku` or `--provider gemini --model gemini-2.5-flash-preview`. Use `--batch-size 10 --delay 0.5` to avoid rate limits while maintaining throughput.", "question_type": "medium", "topics": ["Quickstart", "Answer Tailoring"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["models", "providers", "configuration"], "related_skills": ["skill_answer_tailoring.md"], "related_docs": ["scripts/generate_tailored_answers.py"], "original_answer": "For bulk processing, use Claude haiku or Gemini flash for speed and cost efficiency. For quality-sensitive data, use Claude sonnet. Switch models with `--provider gemini --model gemini-2.5-flash-preview`. Claude haiku is fast and good quality, Sonnet offers better quality at medium cost, and Opus provides best quality at high cost. See skill_answer_tailoring.md for details.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_answer_tailoring_003_q2", "cluster_id": "skill_answer_tailoring_003", "question": "Should I use Claude or Gemini for rewriting answers?", "answer": "Process thousands of Q&A pairs safely with: `python scripts/generate_tailored_answers.py --input <dir> --batch-size 5 --delay 1.0`. The script saves progress after each batch and skips already-processed pairs automatically. Reduce batch size and increase delay if hitting limits.", "question_type": "medium", "topics": ["Quickstart", "Answer Tailoring"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["models", "providers", "configuration"], "related_skills": ["skill_answer_tailoring.md"], "related_docs": ["scripts/generate_tailored_answers.py"], "original_answer": "For bulk processing, use Claude haiku or Gemini flash for speed and cost efficiency. For quality-sensitive data, use Claude sonnet. Switch models with `--provider gemini --model gemini-2.5-flash-preview`. Claude haiku is fast and good quality, Sonnet offers better quality at medium cost, and Opus provides best quality at high cost. See skill_answer_tailoring.md for details.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_answer_tailoring_004_q0", "cluster_id": "skill_answer_tailoring_004", "question": "How do I handle rate limiting when tailoring large datasets?", "answer": "Handle rate limiting by adjusting batch size and delay: `python scripts/generate_tailored_answers.py --batch-size 5 --delay 2.0`. Smaller batches with longer delays reduce API pressure. The script saves progress after each batch, so you can safely restart if needed.", "question_type": "long", "topics": ["Quickstart", "Answer Tailoring"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["rate-limiting", "troubleshooting", "performance"], "related_skills": ["skill_answer_tailoring.md"], "related_docs": ["scripts/generate_tailored_answers.py"], "original_answer": "Adjust batch size and delay between calls. Use `--batch-size 5 --delay 1.0` for rate-limit safety or increase delay to 2.0 seconds. You can also reduce batch size further if needed. This slows processing but prevents hitting API limits. See skill_answer_tailoring.md for details.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_answer_tailoring_004_q1", "cluster_id": "skill_answer_tailoring_004", "question": "My answer tailoring is hitting rate limits. What should I do?", "answer": "If hitting rate limits, increase delay and reduce batch size: `--batch-size 5 --delay 2.0`. The script automatically skips already-processed pairs, so you can restart safely. Progress is saved after each batch completion.", "question_type": "long", "topics": ["Quickstart", "Answer Tailoring"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["rate-limiting", "troubleshooting", "performance"], "related_skills": ["skill_answer_tailoring.md"], "related_docs": ["scripts/generate_tailored_answers.py"], "original_answer": "Adjust batch size and delay between calls. Use `--batch-size 5 --delay 1.0` for rate-limit safety or increase delay to 2.0 seconds. You can also reduce batch size further if needed. This slows processing but prevents hitting API limits. See skill_answer_tailoring.md for details.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_answer_tailoring_004_q2", "cluster_id": "skill_answer_tailoring_004", "question": "How can I slow down the API calls to avoid getting blocked?", "answer": "Slow down API calls with the `--delay` option: `python scripts/generate_tailored_answers.py --delay 2.0` for 2-second delays between calls. Combine with smaller batches: `--batch-size 5 --delay 1.5` for safe bulk processing.", "question_type": "long", "topics": ["Quickstart", "Answer Tailoring"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["rate-limiting", "troubleshooting", "performance"], "related_skills": ["skill_answer_tailoring.md"], "related_docs": ["scripts/generate_tailored_answers.py"], "original_answer": "Adjust batch size and delay between calls. Use `--batch-size 5 --delay 1.0` for rate-limit safety or increase delay to 2.0 seconds. You can also reduce batch size further if needed. This slows processing but prevents hitting API limits. See skill_answer_tailoring.md for details.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_answer_tailoring_005_q0", "cluster_id": "skill_answer_tailoring_005", "question": "How do I resume an interrupted answer tailoring run?", "answer": "Resume an interrupted run by executing the same command again. The script checks the output file for already-processed pairs (those with `answer_tailored: true`) and skips them. Progress saves after each batch, so minimal work is lost on interruption.", "question_type": "long", "topics": ["Quickstart", "Answer Tailoring"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["resumable-processing", "error-recovery"], "related_skills": ["skill_answer_tailoring.md"], "related_docs": ["scripts/generate_tailored_answers.py"], "original_answer": "Simply run the same command again. The tool automatically skips pairs already marked with `answer_tailored: true`. To reprocess everything from scratch, use `--no-skip` flag: `python scripts/generate_tailored_answers.py --input training-data/expanded --no-skip`. See skill_answer_tailoring.md for details.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_answer_tailoring_005_q1", "cluster_id": "skill_answer_tailoring_005", "question": "Can I continue where I left off if the script stops?", "answer": "Yes, you can continue where you left off. Just re-run the same command - the script checks output for processed pair_ids and skips them. Progress saves after each batch, so you lose at most one batch of work on interruption.", "question_type": "long", "topics": ["Quickstart", "Answer Tailoring"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["resumable-processing", "error-recovery"], "related_skills": ["skill_answer_tailoring.md"], "related_docs": ["scripts/generate_tailored_answers.py"], "original_answer": "Simply run the same command again. The tool automatically skips pairs already marked with `answer_tailored: true`. To reprocess everything from scratch, use `--no-skip` flag: `python scripts/generate_tailored_answers.py --input training-data/expanded --no-skip`. See skill_answer_tailoring.md for details.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_answer_tailoring_005_q2", "cluster_id": "skill_answer_tailoring_005", "question": "How do I avoid reprocessing already tailored answers?", "answer": "The script automatically skips already-tailored answers by checking for `pair_id` entries with `answer_tailored: true` in the output file. Re-run the same command to process only new/failed pairs. Use `--no-skip` to force reprocessing everything.", "question_type": "long", "topics": ["Quickstart", "Answer Tailoring"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["resumable-processing", "error-recovery"], "related_skills": ["skill_answer_tailoring.md"], "related_docs": ["scripts/generate_tailored_answers.py"], "original_answer": "Simply run the same command again. The tool automatically skips pairs already marked with `answer_tailored: true`. To reprocess everything from scratch, use `--no-skip` flag: `python scripts/generate_tailored_answers.py --input training-data/expanded --no-skip`. See skill_answer_tailoring.md for details.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_answer_tailoring_006_q0", "cluster_id": "skill_answer_tailoring_006", "question": "What happens to my original answers when I tailor them?", "answer": "Original answers are preserved in the `original_answer` field. The output JSONL includes both the new tailored answer in `answer` and the original in `original_answer`, plus `answer_tailored: true` to indicate successful processing.", "question_type": "medium", "topics": ["Quickstart", "Answer Tailoring"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["data-preservation", "output-format"], "related_skills": ["skill_answer_tailoring.md"], "related_docs": ["scripts/generate_tailored_answers.py"], "original_answer": "Original answers are preserved in the `original_answer` field. The output JSONL includes the new tailored answer, the original answer, and `answer_tailored: true` flag. This lets you maintain both versions for comparison or fallback. See skill_answer_tailoring.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_answer_tailoring_006_q1", "cluster_id": "skill_answer_tailoring_006", "question": "Do I lose my original answers when generating variations?", "answer": "No, original answers are never lost. The script preserves them in the `original_answer` field while writing the new tailored version to `answer`. Each record also gets `answer_tailored: true` to indicate it was processed.", "question_type": "medium", "topics": ["Quickstart", "Answer Tailoring"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["data-preservation", "output-format"], "related_skills": ["skill_answer_tailoring.md"], "related_docs": ["scripts/generate_tailored_answers.py"], "original_answer": "Original answers are preserved in the `original_answer` field. The output JSONL includes the new tailored answer, the original answer, and `answer_tailored: true` flag. This lets you maintain both versions for comparison or fallback. See skill_answer_tailoring.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_answer_tailoring_006_q2", "cluster_id": "skill_answer_tailoring_006", "question": "How are answers stored after tailoring?", "answer": "tailored answer here", "question_type": "medium", "topics": ["Quickstart", "Answer Tailoring"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["data-preservation", "output-format"], "related_skills": ["skill_answer_tailoring.md"], "related_docs": ["scripts/generate_tailored_answers.py"], "original_answer": "Original answers are preserved in the `original_answer` field. The output JSONL includes the new tailored answer, the original answer, and `answer_tailored: true` flag. This lets you maintain both versions for comparison or fallback. See skill_answer_tailoring.md for details.", "answer_tailored": true, "confidence": 0.85, "confidence_issues": null}
{"pair_id": "skill_app_generation_001_q0", "cluster_id": "skill_app_generation_001", "question": "How can I generate a complete frontend app from a Prolog specification?", "answer": "Use the `generate_complete_project/4` predicate with an app specification. Define your app structure including navigation, screens, and options, then specify your target framework (Vue, React Native, Flutter, or SwiftUI) and output directory. Example:\n```prolog\n?- generate_complete_project(\n       app(myapp, [\n           navigation(tabs, [\n               screen(home, 'HomeView', []),\n               screen(profile, 'ProfileView', [])\n           ], [])\n       ]),\n       [frontend-vue],\n       'OUTPUT_DIR',\n       Result\n   ).\n```\nThis generates a complete frontend project scaffolding. Multiple frontend targets are supported: `frontend-vue` for Vue 3, `frontend-react_native` for React Native, `frontend-flutter` for Flutter, and `frontend-swiftui` for SwiftUI. You can also combine frontend targets with backend targets like `[frontend-vue, backend-fastapi]`. See skill_app_generation.md for additional features like theming, authentication, and data binding.", "question_type": "medium", "topics": ["Quickstart", "App Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["app-generation", "frontend", "scaffolding", "declarative"], "related_skills": ["skill_app_generation.md"], "related_docs": ["src/unifyweaver/glue/app_generator.pl", "education/other-books/book-gui-generation/02_app_generation.md"], "original_answer": "Use the `generate_complete_project/4` predicate with an app specification. Define your app structure including navigation, screens, and options, then specify your target framework (Vue, React Native, Flutter, or SwiftUI) and output directory. Example:\n```prolog\n?- generate_complete_project(\n       app(myapp, [\n           navigation(tabs, [\n               screen(home, 'HomeView', []),\n               screen(profile, 'ProfileView', [])\n           ], [])\n       ]),\n       [frontend-vue],\n       'OUTPUT_DIR',\n       Result\n   ).\n```\nSee skill_app_generation.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_app_generation_001_q1", "cluster_id": "skill_app_generation_001", "question": "Can I create a Vue or React app using Prolog?", "answer": "Yes, you can create Vue or React apps using Prolog with the `generate_complete_project/4` predicate. Define your app structure with navigation and screens, specify your target framework (`frontend-vue` for Vue 3 or `frontend-react_native` for React Native), and provide an output directory. Example for Vue:\n\n```prolog\n?- generate_complete_project(\n       app(myapp, [\n           navigation(tabs, [\n               screen(home, 'HomeView', []),\n               screen(profile, 'ProfileView', [])\n           ], [])\n       ]),\n       [frontend-vue],\n       'OUTPUT_DIR',\n       Result\n   ).\n```\n\nFor React Native, use `[frontend-react_native]` instead. See skill_app_generation.md for full documentation.", "question_type": "medium", "topics": ["Quickstart", "App Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["app-generation", "frontend", "scaffolding", "declarative"], "related_skills": ["skill_app_generation.md"], "related_docs": ["src/unifyweaver/glue/app_generator.pl", "education/other-books/book-gui-generation/02_app_generation.md"], "original_answer": "Use the `generate_complete_project/4` predicate with an app specification. Define your app structure including navigation, screens, and options, then specify your target framework (Vue, React Native, Flutter, or SwiftUI) and output directory. Example:\n```prolog\n?- generate_complete_project(\n       app(myapp, [\n           navigation(tabs, [\n               screen(home, 'HomeView', []),\n               screen(profile, 'ProfileView', [])\n           ], [])\n       ]),\n       [frontend-vue],\n       'OUTPUT_DIR',\n       Result\n   ).\n```\nSee skill_app_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_app_generation_001_q2", "cluster_id": "skill_app_generation_001", "question": "What's the quickest way to scaffold a frontend project?", "answer": "Use `generate_complete_project/4` with an app specification. The quickest approach: define your app name, navigation structure (tabs/drawer/stack), screens, choose your target framework (frontend-vue, frontend-react_native, frontend-flutter, or frontend-swiftui), and output directory. Example for Vue: `?- generate_complete_project(app(myapp, [navigation(tabs, [screen(home, 'HomeView', []), screen(profile, 'ProfileView', [])], [])]), [frontend-vue], 'OUTPUT_DIR', Result).` This generates a complete scaffolded project with routing and basic structure ready to customize.", "question_type": "medium", "topics": ["Quickstart", "App Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["app-generation", "frontend", "scaffolding", "declarative"], "related_skills": ["skill_app_generation.md"], "related_docs": ["src/unifyweaver/glue/app_generator.pl", "education/other-books/book-gui-generation/02_app_generation.md"], "original_answer": "Use the `generate_complete_project/4` predicate with an app specification. Define your app structure including navigation, screens, and options, then specify your target framework (Vue, React Native, Flutter, or SwiftUI) and output directory. Example:\n```prolog\n?- generate_complete_project(\n       app(myapp, [\n           navigation(tabs, [\n               screen(home, 'HomeView', []),\n               screen(profile, 'ProfileView', [])\n           ], [])\n       ]),\n       [frontend-vue],\n       'OUTPUT_DIR',\n       Result\n   ).\n```\nSee skill_app_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_app_generation_001_q3", "cluster_id": "skill_app_generation_001", "question": "How do I generate an app declaratively?", "answer": "To generate an app declaratively, use the `generate_complete_project/4` predicate with an app specification. Define your app structure with navigation (tabs, drawer, or stack), screens, and options. Then specify your target framework (frontend-vue, frontend-react_native, frontend-flutter, or frontend-swiftui) and output directory. Example for a Vue 3 app with tab navigation:\n\n```prolog\n?- generate_complete_project(\n       app(myapp, [\n           navigation(tabs, [\n               screen(home, 'HomeView', []),\n               screen(profile, 'ProfileView', [])\n           ], [])\n       ]),\n       [frontend-vue],\n       'OUTPUT_DIR',\n       Result\n   ).\n```\n\nYou can also generate with multiple targets including backends (e.g., [frontend-vue, backend-fastapi]). For more details on theming, authentication, and data binding options, see skill_app_generation.md.", "question_type": "medium", "topics": ["Quickstart", "App Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["app-generation", "frontend", "scaffolding", "declarative"], "related_skills": ["skill_app_generation.md"], "related_docs": ["src/unifyweaver/glue/app_generator.pl", "education/other-books/book-gui-generation/02_app_generation.md"], "original_answer": "Use the `generate_complete_project/4` predicate with an app specification. Define your app structure including navigation, screens, and options, then specify your target framework (Vue, React Native, Flutter, or SwiftUI) and output directory. Example:\n```prolog\n?- generate_complete_project(\n       app(myapp, [\n           navigation(tabs, [\n               screen(home, 'HomeView', []),\n               screen(profile, 'ProfileView', [])\n           ], [])\n       ]),\n       [frontend-vue],\n       'OUTPUT_DIR',\n       Result\n   ).\n```\nSee skill_app_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_app_generation_002_q0", "cluster_id": "skill_app_generation_002", "question": "What frontend frameworks can I generate apps with?", "answer": "UnifyWeaver supports four frontend frameworks for app generation: Vue 3 (web apps via frontend-vue), React Native (mobile apps via frontend-react_native), Flutter (cross-platform via frontend-flutter), and SwiftUI (iOS/macOS via frontend-swiftui). Specify your target framework in the targets list when calling generate_complete_project/4.", "question_type": "medium", "topics": ["Quickstart", "App Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["frameworks", "frontend-targets", "app-generation"], "related_skills": ["skill_app_generation.md"], "related_docs": ["education/other-books/book-gui-generation/01_introduction.md"], "original_answer": "UnifyWeaver supports four frontend targets:\n- **frontend-vue**: Vue 3 + Vite + TypeScript for web apps\n- **frontend-react_native**: React Native + Expo for mobile apps\n- **frontend-flutter**: Flutter + Dart for cross-platform development\n- **frontend-swiftui**: SwiftUI for iOS and macOS apps\n\nSpecify your target framework in the targets list when calling `generate_complete_project/4`. See skill_app_generation.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_app_generation_002_q1", "cluster_id": "skill_app_generation_002", "question": "Which mobile and web frameworks are supported?", "answer": "UnifyWeaver supports four frontend frameworks: Vue 3 + Vite + TypeScript (frontend-vue) for web apps, React Native + Expo (frontend-react_native) for mobile, Flutter + Dart (frontend-flutter) for cross-platform mobile, and SwiftUI (frontend-swiftui) for iOS/macOS. Specify your target in the targets list when calling generate_complete_project/4.", "question_type": "medium", "topics": ["Quickstart", "App Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["frameworks", "frontend-targets", "app-generation"], "related_skills": ["skill_app_generation.md"], "related_docs": ["education/other-books/book-gui-generation/01_introduction.md"], "original_answer": "UnifyWeaver supports four frontend targets:\n- **frontend-vue**: Vue 3 + Vite + TypeScript for web apps\n- **frontend-react_native**: React Native + Expo for mobile apps\n- **frontend-flutter**: Flutter + Dart for cross-platform development\n- **frontend-swiftui**: SwiftUI for iOS and macOS apps\n\nSpecify your target framework in the targets list when calling `generate_complete_project/4`. See skill_app_generation.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_app_generation_002_q2", "cluster_id": "skill_app_generation_002", "question": "Can I generate Flutter or SwiftUI apps?", "answer": "Yes, UnifyWeaver supports generating both Flutter and SwiftUI apps. Use `frontend-flutter` for cross-platform development with Flutter + Dart, or `frontend-swiftui` for iOS and macOS apps. Specify your target in the targets list when calling `generate_complete_project/4`. Example: `generate_complete_project(app(myapp, [...]), [frontend-flutter], 'OUTPUT_DIR', Result)` for Flutter or replace `frontend-flutter` with `frontend-swiftui` for native Apple platforms.", "question_type": "medium", "topics": ["Quickstart", "App Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["frameworks", "frontend-targets", "app-generation"], "related_skills": ["skill_app_generation.md"], "related_docs": ["education/other-books/book-gui-generation/01_introduction.md"], "original_answer": "UnifyWeaver supports four frontend targets:\n- **frontend-vue**: Vue 3 + Vite + TypeScript for web apps\n- **frontend-react_native**: React Native + Expo for mobile apps\n- **frontend-flutter**: Flutter + Dart for cross-platform development\n- **frontend-swiftui**: SwiftUI for iOS and macOS apps\n\nSpecify your target framework in the targets list when calling `generate_complete_project/4`. See skill_app_generation.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_app_generation_002_q3", "cluster_id": "skill_app_generation_002", "question": "What are all the available frontend targets?", "answer": "UnifyWeaver supports four frontend targets for app generation:\n\n- **frontend-vue**: Vue 3 + Vite + TypeScript for web applications\n- **frontend-react_native**: React Native + Expo for mobile applications\n- **frontend-flutter**: Flutter + Dart for cross-platform development\n- **frontend-swiftui**: SwiftUI for iOS and macOS applications\n\nSpecify your desired target in the targets list when calling `generate_complete_project/4`. For example: `generate_complete_project(app(...), [frontend-vue], OutputDir, Result)`.", "question_type": "medium", "topics": ["Quickstart", "App Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["frameworks", "frontend-targets", "app-generation"], "related_skills": ["skill_app_generation.md"], "related_docs": ["education/other-books/book-gui-generation/01_introduction.md"], "original_answer": "UnifyWeaver supports four frontend targets:\n- **frontend-vue**: Vue 3 + Vite + TypeScript for web apps\n- **frontend-react_native**: React Native + Expo for mobile apps\n- **frontend-flutter**: Flutter + Dart for cross-platform development\n- **frontend-swiftui**: SwiftUI for iOS and macOS apps\n\nSpecify your target framework in the targets list when calling `generate_complete_project/4`. See skill_app_generation.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_app_generation_003_q0", "cluster_id": "skill_app_generation_003", "question": "How do I add theming and authentication to a generated app?", "answer": "To add theming and authentication to a generated app, include both `theme()` and `auth()` options in your app specification:\n\n```prolog\napp(myapp, [\n    navigation(tabs, [\n        screen(home, 'HomeView', []),\n        screen(profile, 'ProfileView', [])\n    ], []),\n    theme(default, [dark_mode(true)]),\n    auth([...])\n])\n```\n\nUse `theme(ThemeName, ThemeOptions)` to configure colors and dark mode support. For `auth(AuthOptions)`, refer to skill_webapp_security.md for specific authentication configuration options like login methods and route guards.", "question_type": "long", "topics": ["Quickstart", "App Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["theming", "authentication", "security", "customization"], "related_skills": ["skill_app_generation.md", "skill_webapp_security.md"], "related_docs": ["education/other-books/book-gui-generation/08_theming.md"], "original_answer": "Include theme and auth options in your app specification. Use `theme(ThemeName, ThemeOptions)` for colors and dark mode support, and `auth(AuthOptions)` for authentication and route guards.\n```prolog\napp(myapp, [\n    navigation(tabs, [...], []),\n    theme(default, [dark_mode(true)]),\n    auth([...])\n])\n```\nFor authentication details, see skill_webapp_security.md. See skill_app_generation.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_app_generation_003_q1", "cluster_id": "skill_app_generation_003", "question": "Can I add dark mode and login to my app?", "answer": "Yes, you can add both dark mode and login to your app. Include `theme(default, [dark_mode(true)])` for dark mode support and `auth([...])` for authentication with route guards in your app specification:\n\n```prolog\napp(myapp, [\n    navigation(tabs, [...], []),\n    theme(default, [dark_mode(true)]),\n    auth([...])\n])\n```\n\nFor specific authentication configuration options, refer to skill_webapp_security.md. For the complete app generation process, see skill_app_generation.md.", "question_type": "long", "topics": ["Quickstart", "App Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["theming", "authentication", "security", "customization"], "related_skills": ["skill_app_generation.md", "skill_webapp_security.md"], "related_docs": ["education/other-books/book-gui-generation/08_theming.md"], "original_answer": "Include theme and auth options in your app specification. Use `theme(ThemeName, ThemeOptions)` for colors and dark mode support, and `auth(AuthOptions)` for authentication and route guards.\n```prolog\napp(myapp, [\n    navigation(tabs, [...], []),\n    theme(default, [dark_mode(true)]),\n    auth([...])\n])\n```\nFor authentication details, see skill_webapp_security.md. See skill_app_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_app_generation_003_q2", "cluster_id": "skill_app_generation_003", "question": "How do I implement authentication in generated apps?", "answer": "To implement authentication in generated apps, include the `auth(AuthOptions)` parameter in your app specification. Use `theme(ThemeName, ThemeOptions)` for UI theming if needed. Example:\n\n```prolog\napp(myapp, [\n    navigation(tabs, [...], []),\n    theme(default, [dark_mode(true)]),\n    auth([...])  % Add authentication options here\n])\n```\n\nThen call `generate_complete_project/4` with your app specification and target frontend (e.g., `[frontend-vue]`). For detailed authentication configuration options and route guards, refer to `skill_webapp_security.md`.", "question_type": "long", "topics": ["Quickstart", "App Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["theming", "authentication", "security", "customization"], "related_skills": ["skill_app_generation.md", "skill_webapp_security.md"], "related_docs": ["education/other-books/book-gui-generation/08_theming.md"], "original_answer": "Include theme and auth options in your app specification. Use `theme(ThemeName, ThemeOptions)` for colors and dark mode support, and `auth(AuthOptions)` for authentication and route guards.\n```prolog\napp(myapp, [\n    navigation(tabs, [...], []),\n    theme(default, [dark_mode(true)]),\n    auth([...])\n])\n```\nFor authentication details, see skill_webapp_security.md. See skill_app_generation.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "The base answer mentions auth options but doesn't specify what those options are or how to configure them. The skill document references `skill_webapp_security.md` for details but that content is truncated/not provided, making it difficult to give a complete answer about what authentication parameters to actually use."}
{"pair_id": "skill_app_generation_003_q3", "cluster_id": "skill_app_generation_003", "question": "What customization options are available?", "answer": "UnifyWeaver's app generator offers several customization options within the app specification. You can customize the theme using `theme(ThemeName, ThemeOptions)` to control colors and enable dark mode support. For authentication, use `auth(AuthOptions)` to add login functionality and route guards. You can also customize navigation structure (tabs, drawer, or stack) and individual screen options. For authentication details, refer to skill_webapp_security.md. The app specification uses Prolog syntax: `app(myapp, [navigation(Type, Screens, []), theme(default, [dark_mode(true)]), auth([...])])`. Additional customization features include data binding for reactive state and layout options (grid, flexbox). See skill_app_generation.md for complete details on all available options.", "question_type": "long", "topics": ["Quickstart", "App Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["theming", "authentication", "security", "customization"], "related_skills": ["skill_app_generation.md", "skill_webapp_security.md"], "related_docs": ["education/other-books/book-gui-generation/08_theming.md"], "original_answer": "Include theme and auth options in your app specification. Use `theme(ThemeName, ThemeOptions)` for colors and dark mode support, and `auth(AuthOptions)` for authentication and route guards.\n```prolog\napp(myapp, [\n    navigation(tabs, [...], []),\n    theme(default, [dark_mode(true)]),\n    auth([...])\n])\n```\nFor authentication details, see skill_webapp_security.md. See skill_app_generation.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer mentions theme and auth options clearly but is somewhat brief. The tailored answer expands on navigation types and layout customization mentioned in the skill document but not explicitly in the base answer. Confidence is moderate because the question asks broadly about 'customization options' and while the answer covers major areas (theme, auth, navigation, data binding, layout), the skill document is truncated and may contain additional options not visible."}
{"pair_id": "skill_app_generation_004_q0", "cluster_id": "skill_app_generation_004", "question": "Can I generate an app with both frontend and backend?", "answer": "Yes, you can generate full-stack applications by specifying both a frontend and backend target in the targets list. Use `generate_complete_project/4` with multiple targets like `[frontend-vue, backend-fastapi]`. This generates both frontend and backend boilerplate in your output directory. Available frontend targets include `frontend-vue`, `frontend-react_native`, `frontend-flutter`, and `frontend-swiftui`. Backend targets like `backend-fastapi` are also supported.", "question_type": "long", "topics": ["Quickstart", "App Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["full-stack", "backend", "scaffolding"], "related_skills": ["skill_app_generation.md"], "related_docs": ["education/other-books/book-gui-generation/02_app_generation.md"], "original_answer": "Yes, you can generate full-stack applications by specifying multiple targets in the targets list. Include both a frontend target and backend target:\n```prolog\n?- generate_complete_project(\n       app(myapp, [...]),\n       [frontend-vue, backend-fastapi],\n       'OUTPUT_DIR',\n       Result\n   ).\n```\nThis generates both your frontend and backend boilerplate in the output directory. See skill_app_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_app_generation_004_q1", "cluster_id": "skill_app_generation_004", "question": "How do I create a full-stack app with Prolog?", "answer": "You can create a full-stack app with Prolog by specifying both frontend and backend targets in the `generate_complete_project/4` predicate. For example, to generate a Vue.js frontend with a FastAPI backend:\n\n```prolog\n?- generate_complete_project(\n       app(myapp, [\n           navigation(tabs, [\n               screen(home, 'HomeView', []),\n               screen(profile, 'ProfileView', [])\n           ], [])\n       ]),\n       [frontend-vue, backend-fastapi],\n       '/path/to/output',\n       Result\n   ).\n```\n\nThis generates complete boilerplate for both your frontend (Vue 3 + Vite + TypeScript) and backend (FastAPI) in the specified output directory. You can mix any frontend target (vue, react_native, flutter, swiftui) with backend options like fastapi. See skill_app_generation.md for additional framework combinations and detailed configuration options.", "question_type": "long", "topics": ["Quickstart", "App Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["full-stack", "backend", "scaffolding"], "related_skills": ["skill_app_generation.md"], "related_docs": ["education/other-books/book-gui-generation/02_app_generation.md"], "original_answer": "Yes, you can generate full-stack applications by specifying multiple targets in the targets list. Include both a frontend target and backend target:\n```prolog\n?- generate_complete_project(\n       app(myapp, [...]),\n       [frontend-vue, backend-fastapi],\n       'OUTPUT_DIR',\n       Result\n   ).\n```\nThis generates both your frontend and backend boilerplate in the output directory. See skill_app_generation.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_app_generation_004_q2", "cluster_id": "skill_app_generation_004", "question": "Can I scaffold both Vue and FastAPI together?", "answer": "Yes, you can scaffold both Vue and FastAPI together by specifying both targets in the `generate_complete_project` call. Include `frontend-vue` and `backend-fastapi` in the targets list:\n\n```prolog\n?- generate_complete_project(\n       app(myapp, [...]),\n       [frontend-vue, backend-fastapi],\n       'OUTPUT_DIR',\n       Result\n   ).\n```\n\nThis generates both your Vue 3 frontend and FastAPI backend boilerplate in a single operation.", "question_type": "long", "topics": ["Quickstart", "App Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["full-stack", "backend", "scaffolding"], "related_skills": ["skill_app_generation.md"], "related_docs": ["education/other-books/book-gui-generation/02_app_generation.md"], "original_answer": "Yes, you can generate full-stack applications by specifying multiple targets in the targets list. Include both a frontend target and backend target:\n```prolog\n?- generate_complete_project(\n       app(myapp, [...]),\n       [frontend-vue, backend-fastapi],\n       'OUTPUT_DIR',\n       Result\n   ).\n```\nThis generates both your frontend and backend boilerplate in the output directory. See skill_app_generation.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_app_generation_005_q0", "cluster_id": "skill_app_generation_005", "question": "What navigation patterns are supported for app layouts?", "answer": "UnifyWeaver supports three navigation patterns for app layouts: **tabs** for tab-based navigation at the bottom or top of the screen, **drawer** for side menu navigation, and **stack** for hierarchical screen navigation. You define navigation using the `navigation(Type, Screens, Options)` structure where Type is one of these three options and Screens contains `screen(id, 'ComponentName', ScreenOptions)` terms. This approach works across all supported frontend targets including Vue 3, React Native, Flutter, and SwiftUI.", "question_type": "long", "topics": ["Quickstart", "App Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["navigation", "layout", "screens", "ui-structure"], "related_skills": ["skill_app_generation.md"], "related_docs": ["education/other-books/book-gui-generation/04_layout_system.md"], "original_answer": "UnifyWeaver supports three navigation types: **tabs** for tab-based navigation, **drawer** for side menu navigation, and **stack** for stack-based navigation. Define your navigation with screens:\n```prolog\nnavigation(Type, Screens, Options)\n```\nWhere Type is one of `tabs`, `drawer`, or `stack`, and Screens is a list of `screen(id, 'ComponentName', ScreenOptions)` terms. See skill_app_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_app_generation_005_q1", "cluster_id": "skill_app_generation_005", "question": "How do I structure screens in a generated app?", "answer": "Structure screens in a generated app using the navigation specification. Define your navigation with a type (tabs, drawer, or stack) and a list of screens:\n\n```prolog\nnavigation(Type, Screens, Options)\n```\n\nEach screen is defined as:\n```prolog\nscreen(id, 'ComponentName', ScreenOptions)\n```\n\nWhere:\n- `Type` is one of: `tabs` (tab-based), `drawer` (side menu), or `stack` (stack-based)\n- `id` is a unique identifier for the screen\n- `'ComponentName'` is the name of the Vue/React/Flutter component to render\n- `ScreenOptions` contains screen-specific configuration\n\nExample:\n```prolog\nnavigation(tabs, [\n    screen(home, 'HomeView', []),\n    screen(profile, 'ProfileView', [])\n], [])\n```", "question_type": "long", "topics": ["Quickstart", "App Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["navigation", "layout", "screens", "ui-structure"], "related_skills": ["skill_app_generation.md"], "related_docs": ["education/other-books/book-gui-generation/04_layout_system.md"], "original_answer": "UnifyWeaver supports three navigation types: **tabs** for tab-based navigation, **drawer** for side menu navigation, and **stack** for stack-based navigation. Define your navigation with screens:\n```prolog\nnavigation(Type, Screens, Options)\n```\nWhere Type is one of `tabs`, `drawer`, or `stack`, and Screens is a list of `screen(id, 'ComponentName', ScreenOptions)` terms. See skill_app_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_app_generation_005_q2", "cluster_id": "skill_app_generation_005", "question": "Can I create tab-based or drawer navigation?", "answer": "Yes, UnifyWeaver supports tab-based and drawer navigation. Use the `navigation/3` predicate with `tabs` for tab-based navigation or `drawer` for side menu navigation:\n\n```prolog\nnavigation(tabs, [\n    screen(home, 'HomeView', []),\n    screen(settings, 'SettingsView', [])\n], [])\n```\n\nOr for drawer navigation:\n\n```prolog\nnavigation(drawer, [\n    screen(home, 'HomeView', []),\n    screen(profile, 'ProfileView', [])\n], [])\n```\n\nInclude this in your app specification passed to `generate_complete_project/4`.", "question_type": "long", "topics": ["Quickstart", "App Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["navigation", "layout", "screens", "ui-structure"], "related_skills": ["skill_app_generation.md"], "related_docs": ["education/other-books/book-gui-generation/04_layout_system.md"], "original_answer": "UnifyWeaver supports three navigation types: **tabs** for tab-based navigation, **drawer** for side menu navigation, and **stack** for stack-based navigation. Define your navigation with screens:\n```prolog\nnavigation(Type, Screens, Options)\n```\nWhere Type is one of `tabs`, `drawer`, or `stack`, and Screens is a list of `screen(id, 'ComponentName', ScreenOptions)` terms. See skill_app_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_app_generation_005_q3", "cluster_id": "skill_app_generation_005", "question": "What layout options are available?", "answer": "Layout options in UnifyWeaver include CSS Grid and Flexbox via the `layout/2` predicate. Define layouts in your app specification. Navigation layouts include tabs, drawer, and stack. See `skill_layout_system.md` and `skill_gui_design.md` for detailed layout configuration.", "question_type": "long", "topics": ["Quickstart", "App Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["navigation", "layout", "screens", "ui-structure"], "related_skills": ["skill_app_generation.md"], "related_docs": ["education/other-books/book-gui-generation/04_layout_system.md"], "original_answer": "UnifyWeaver supports three navigation types: **tabs** for tab-based navigation, **drawer** for side menu navigation, and **stack** for stack-based navigation. Define your navigation with screens:\n```prolog\nnavigation(Type, Screens, Options)\n```\nWhere Type is one of `tabs`, `drawer`, or `stack`, and Screens is a list of `screen(id, 'ComponentName', ScreenOptions)` terms. See skill_app_generation.md for details.", "answer_tailored": true, "confidence": 0.8, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_app_generation_006_q0", "cluster_id": "skill_app_generation_006", "question": "Where can I learn more about building advanced UI features in generated apps?", "answer": "UnifyWeaver provides comprehensive guides for building advanced UI features in the education section. For data binding and reactive state management, see `education/other-books/book-gui-generation/05_data_binding.md`. For responsive design with breakpoints and media queries, refer to `education/other-books/book-gui-generation/07_responsive_design.md`. Accessibility features including ARIA and keyboard navigation are covered in `education/other-books/book-gui-generation/06_accessibility.md`. Layout systems using CSS Grid and Flexbox are documented in `education/other-books/book-gui-generation/04_layout_system.md`. Start with `education/other-books/book-gui-generation/01_introduction.md` for an overview, then consult skill_app_generation.md for Prolog-based generation details.", "question_type": "medium", "topics": ["Quickstart", "App Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["learning", "advanced-features", "documentation", "ui-patterns"], "related_skills": ["skill_app_generation.md"], "related_docs": ["education/other-books/book-gui-generation/01_introduction.md", "education/other-books/book-gui-generation/05_data_binding.md", "education/other-books/book-gui-generation/06_accessibility.md", "education/other-books/book-gui-generation/07_responsive_design.md"], "original_answer": "UnifyWeaver includes comprehensive guides in the education section:\n- **Data binding**: Learn reactive state management in `book-gui-generation/05_data_binding.md`\n- **Responsive design**: Breakpoints and media queries in `book-gui-generation/07_responsive_design.md`\n- **Accessibility**: ARIA and keyboard navigation in `book-gui-generation/06_accessibility.md`\n- **Layouts**: CSS Grid and Flexbox in `book-gui-generation/04_layout_system.md`\n\nStart with `book-gui-generation/01_introduction.md` for an overview. See skill_app_generation.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_app_generation_006_q1", "cluster_id": "skill_app_generation_006", "question": "How do I handle state and data binding?", "answer": "UnifyWeaver handles state and data binding through reactive state management. For comprehensive guidance, see `education/other-books/book-gui-generation/05_data_binding.md` which covers how to implement reactive state in generated apps. You can also reference `skill_app_generation.md` for Prolog-based data binding specifications using the `data_binding([...])` option in your app configuration. For integration with specific frameworks (Vue, React Native, Flutter), see the framework-specific sections in the app generation skill documentation.", "question_type": "medium", "topics": ["Quickstart", "App Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["learning", "advanced-features", "documentation", "ui-patterns"], "related_skills": ["skill_app_generation.md"], "related_docs": ["education/other-books/book-gui-generation/01_introduction.md", "education/other-books/book-gui-generation/05_data_binding.md", "education/other-books/book-gui-generation/06_accessibility.md", "education/other-books/book-gui-generation/07_responsive_design.md"], "original_answer": "UnifyWeaver includes comprehensive guides in the education section:\n- **Data binding**: Learn reactive state management in `book-gui-generation/05_data_binding.md`\n- **Responsive design**: Breakpoints and media queries in `book-gui-generation/07_responsive_design.md`\n- **Accessibility**: ARIA and keyboard navigation in `book-gui-generation/06_accessibility.md`\n- **Layouts**: CSS Grid and Flexbox in `book-gui-generation/04_layout_system.md`\n\nStart with `book-gui-generation/01_introduction.md` for an overview. See skill_app_generation.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "The base answer doesn't clearly explain the mechanism for data binding in UnifyWeaver - whether it uses Vue's reactivity, React hooks, Flutter state management, etc. The answer assumes the education materials exist as specified but cannot verify their current contents from the skill document alone."}
{"pair_id": "skill_app_generation_006_q2", "cluster_id": "skill_app_generation_006", "question": "Where's the documentation for responsive design?", "answer": "Responsive design documentation is located in `education/other-books/book-gui-generation/07_responsive_design.md`. This guide covers breakpoints and media queries for building responsive UnifyWeaver applications. For layout foundations, see `book-gui-generation/04_layout_system.md` which covers CSS Grid and Flexbox.", "question_type": "medium", "topics": ["Quickstart", "App Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["learning", "advanced-features", "documentation", "ui-patterns"], "related_skills": ["skill_app_generation.md"], "related_docs": ["education/other-books/book-gui-generation/01_introduction.md", "education/other-books/book-gui-generation/05_data_binding.md", "education/other-books/book-gui-generation/06_accessibility.md", "education/other-books/book-gui-generation/07_responsive_design.md"], "original_answer": "UnifyWeaver includes comprehensive guides in the education section:\n- **Data binding**: Learn reactive state management in `book-gui-generation/05_data_binding.md`\n- **Responsive design**: Breakpoints and media queries in `book-gui-generation/07_responsive_design.md`\n- **Accessibility**: ARIA and keyboard navigation in `book-gui-generation/06_accessibility.md`\n- **Layouts**: CSS Grid and Flexbox in `book-gui-generation/04_layout_system.md`\n\nStart with `book-gui-generation/01_introduction.md` for an overview. See skill_app_generation.md for details.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null}
{"pair_id": "skill_app_generation_006_q3", "cluster_id": "skill_app_generation_006", "question": "How do I make accessible apps?", "answer": "To make accessible apps with UnifyWeaver, use the accessibility guide in `education/other-books/book-gui-generation/06_accessibility.md`, which covers ARIA attributes and keyboard navigation. Additionally, ensure responsive design using media queries from `book-gui-generation/07_responsive_design.md` and implement proper data binding for state management in `book-gui-generation/05_data_binding.md`. Start with `book-gui-generation/01_introduction.md` for context, then reference skill_app_generation.md for generating accessible applications.", "question_type": "medium", "topics": ["Quickstart", "App Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["learning", "advanced-features", "documentation", "ui-patterns"], "related_skills": ["skill_app_generation.md"], "related_docs": ["education/other-books/book-gui-generation/01_introduction.md", "education/other-books/book-gui-generation/05_data_binding.md", "education/other-books/book-gui-generation/06_accessibility.md", "education/other-books/book-gui-generation/07_responsive_design.md"], "original_answer": "UnifyWeaver includes comprehensive guides in the education section:\n- **Data binding**: Learn reactive state management in `book-gui-generation/05_data_binding.md`\n- **Responsive design**: Breakpoints and media queries in `book-gui-generation/07_responsive_design.md`\n- **Accessibility**: ARIA and keyboard navigation in `book-gui-generation/06_accessibility.md`\n- **Layouts**: CSS Grid and Flexbox in `book-gui-generation/04_layout_system.md`\n\nStart with `book-gui-generation/01_introduction.md` for an overview. See skill_app_generation.md for details.", "answer_tailored": true, "confidence": 0.75, "confidence_issues": "The base answer provides file references but lacks specific implementation examples or accessibility best practices (contrast, semantic HTML, focus management). The answer assumes files exist and are relevant but doesn't verify their actual content or depth of accessibility coverage."}
{"pair_id": "skill_authentication_001_q0", "cluster_id": "skill_authentication_001", "question": "How do I add user authentication to my app?", "answer": "To add user authentication to your app, use the auth_backends module to configure authentication with three key components: (1) Choose a backend for user storage (mock for development, text_file for simple setup, or sqlite/postgresql/mongodb/ldap/oauth2 for production); (2) Select a password hashing algorithm (bcrypt recommended for security, or sha256/plain); (3) Specify a token type (jwt for stateless tokens). Define your app with auth configuration and generate the auth server. Example: `app(my_app, [auth([backend(text_file), password_hash(bcrypt), token_type(jwt), users_file('users.txt')])])` followed by `generate_auth_server(app(my_app, [...]), node, Files)`.", "question_type": "medium", "topics": ["Quickstart", "Authentication"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["authentication", "user-management", "security"], "related_skills": ["skill_authentication.md", "skill_infrastructure.md", "skill_deployment.md", "skill_networking.md", "skill_frontend_security.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "Configure authentication using the auth_backends module. Define an app with auth configuration specifying the backend (mock, text_file, sqlite, postgresql, mongodb, ldap, or oauth2), password hash algorithm (plain, bcrypt, sha256, argon2), and token type (jwt or session). Example:\n\n```prolog\napp(my_app, [auth([backend(text_file), password_hash(bcrypt), token_type(jwt), users_file('users.txt')])]).\ngenerate_auth_server(app(my_app, [...]), node, Files).\n```\n\nSee skill_authentication.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_authentication_001_q1", "cluster_id": "skill_authentication_001", "question": "How do I set up login for my application?", "answer": "To set up login for your application, configure authentication using the auth_backends module. Define your app with auth settings specifying: a backend (mock for development, text_file for simple storage, or database/LDAP/OAuth2 for production), a password hashing algorithm (bcrypt for security, or plain for development), and a token type (jwt for stateless tokens or session for server-side sessions). Example: app(my_app, [auth([backend(text_file), password_hash(bcrypt), token_type(jwt), users_file('users.txt'), session_duration(86400)])]), then generate_auth_server(app(my_app, [...]), node, Files). Reference skill_authentication.md for full details on backends, hashing algorithms, and configuration options.", "question_type": "medium", "topics": ["Quickstart", "Authentication"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["authentication", "user-management", "security"], "related_skills": ["skill_authentication.md", "skill_infrastructure.md", "skill_deployment.md", "skill_networking.md", "skill_frontend_security.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "Configure authentication using the auth_backends module. Define an app with auth configuration specifying the backend (mock, text_file, sqlite, postgresql, mongodb, ldap, or oauth2), password hash algorithm (plain, bcrypt, sha256, argon2), and token type (jwt or session). Example:\n\n```prolog\napp(my_app, [auth([backend(text_file), password_hash(bcrypt), token_type(jwt), users_file('users.txt')])]).\ngenerate_auth_server(app(my_app, [...]), node, Files).\n```\n\nSee skill_authentication.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_authentication_001_q2", "cluster_id": "skill_authentication_001", "question": "How can I add user login and registration?", "answer": "To add user login and registration, configure authentication using the auth_backends module. Set up an app with auth configuration specifying: a backend (text_file for simple file storage, sqlite/postgresql for databases, or oauth2 for social login), a password hash algorithm (bcrypt for high security, sha256 for medium), and a token type (jwt for stateless tokens). Example:\n\n```prolog\napp(my_app, [\n    auth([\n        backend(text_file),\n        password_hash(bcrypt),\n        token_type(jwt),\n        users_file('users.txt'),\n        session_duration(86400)\n    ])\n]).\ngenerate_auth_server(app(my_app, [...]), node, Files).\n```\n\nThis generates login and registration endpoints. For production, use postgresql or mongodb instead of text_file. See skill_authentication.md for backend and algorithm options.", "question_type": "medium", "topics": ["Quickstart", "Authentication"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["authentication", "user-management", "security"], "related_skills": ["skill_authentication.md", "skill_infrastructure.md", "skill_deployment.md", "skill_networking.md", "skill_frontend_security.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "Configure authentication using the auth_backends module. Define an app with auth configuration specifying the backend (mock, text_file, sqlite, postgresql, mongodb, ldap, or oauth2), password hash algorithm (plain, bcrypt, sha256, argon2), and token type (jwt or session). Example:\n\n```prolog\napp(my_app, [auth([backend(text_file), password_hash(bcrypt), token_type(jwt), users_file('users.txt')])]).\ngenerate_auth_server(app(my_app, [...]), node, Files).\n```\n\nSee skill_authentication.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "Base answer focuses on configuration syntax but doesn't explicitly mention that generate_auth_server creates the actual login/registration endpoints. The connection between config and endpoint generation could be clearer for users unfamiliar with the system."}
{"pair_id": "skill_authentication_001_q3", "cluster_id": "skill_authentication_001", "question": "What's the best way to handle user authentication?", "answer": "The best way to handle user authentication is to use the auth_backends module to configure authentication declaratively. Choose an appropriate backend for your storage needs (mock for development, text_file for simple deployments, or postgresql/mongodb for production scalability), select a password hashing algorithm (bcrypt for good security, argon2 for very high security), and specify a token type (jwt for stateless tokens). Configure your app with these settings and generate an auth server. Example: `app(my_app, [auth([backend(text_file), password_hash(bcrypt), token_type(jwt), users_file('users.txt')])])` followed by `generate_auth_server(app(my_app, [...]), node, Files)`. See skill_authentication.md for backend-specific requirements and capabilities.", "question_type": "medium", "topics": ["Quickstart", "Authentication"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["authentication", "user-management", "security"], "related_skills": ["skill_authentication.md", "skill_infrastructure.md", "skill_deployment.md", "skill_networking.md", "skill_frontend_security.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "Configure authentication using the auth_backends module. Define an app with auth configuration specifying the backend (mock, text_file, sqlite, postgresql, mongodb, ldap, or oauth2), password hash algorithm (plain, bcrypt, sha256, argon2), and token type (jwt or session). Example:\n\n```prolog\napp(my_app, [auth([backend(text_file), password_hash(bcrypt), token_type(jwt), users_file('users.txt')])]).\ngenerate_auth_server(app(my_app, [...]), node, Files).\n```\n\nSee skill_authentication.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_authentication_002_q0", "cluster_id": "skill_authentication_002", "question": "Which storage backends are available for user data?", "answer": "Multiple storage backends are available for user data: mock (development/testing only), text_file (simple text file storage, implemented), text_file_encrypted (encrypted text file, proposed), sqlite (queryable database, portable), postgresql (scalable, concurrent), mongodb (flexible schema, document store), ldap (enterprise directory/Active Directory), and oauth2 (social login providers). Use `backend_available(text_file)` to check if a backend is implemented, and `backend_capabilities(mongodb, Caps)` to query specific backend capabilities. For simple setups, use text_file; for scalability, choose postgresql or mongodb; for enterprise environments, consider ldap or oauth2 integration.", "question_type": "long", "topics": ["Quickstart", "Authentication", "Backends"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["backends", "storage", "authentication"], "related_skills": ["skill_authentication.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "Multiple backends are available: mock (development only), text_file (simple, implemented), text_file_encrypted (proposed), sqlite (queryable, portable), postgresql (scalable, concurrent), mongodb (flexible schema), ldap (enterprise directory), and oauth2 (social login). Use `backend_available(text_file)` to check availability and `backend_capabilities(mongodb, Caps)` to get backend capabilities. Choose text_file for simple setups, postgresql/mongodb for scalability, and ldap/oauth2 for enterprise integration.\n\nSee skill_authentication.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_authentication_002_q1", "cluster_id": "skill_authentication_002", "question": "What are my options for storing user credentials?", "answer": "You have several storage backend options for user credentials: text_file (simple file-based storage, implemented), text_file_encrypted (encrypted file storage, proposed), sqlite (queryable relational database, portable), postgresql (scalable relational database with concurrency support), mongodb (flexible document-based storage), ldap (enterprise directory integration), oauth2 (delegated authentication via social providers), and mock (development/testing only). For simple setups, use text_file. For scalability and concurrent access, choose postgresql or mongodb. For enterprise environments, consider ldap or oauth2. Use `backend_available(backend_name)` to check if a backend is implemented, or `backend_capabilities(backend_name, Caps)` to see what features each backend supports.", "question_type": "long", "topics": ["Quickstart", "Authentication", "Backends"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["backends", "storage", "authentication"], "related_skills": ["skill_authentication.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "Multiple backends are available: mock (development only), text_file (simple, implemented), text_file_encrypted (proposed), sqlite (queryable, portable), postgresql (scalable, concurrent), mongodb (flexible schema), ldap (enterprise directory), and oauth2 (social login). Use `backend_available(text_file)` to check availability and `backend_capabilities(mongodb, Caps)` to get backend capabilities. Choose text_file for simple setups, postgresql/mongodb for scalability, and ldap/oauth2 for enterprise integration.\n\nSee skill_authentication.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_authentication_002_q2", "cluster_id": "skill_authentication_002", "question": "Can I use a database for user storage?", "answer": "Yes, multiple database backends are available for user storage: SQLite (queryable, portable, lightweight), PostgreSQL (scalable, concurrent, enterprise-grade), and MongoDB (flexible schema, document-oriented). Use `backend_available(sqlite)` or `backend_available(postgresql)` to check availability, and `backend_capabilities(postgresql, Caps)` to review specific capabilities. For simple applications, SQLite is a good choice; for larger deployments, PostgreSQL or MongoDB provide better scalability.", "question_type": "long", "topics": ["Quickstart", "Authentication", "Backends"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["backends", "storage", "authentication"], "related_skills": ["skill_authentication.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "Multiple backends are available: mock (development only), text_file (simple, implemented), text_file_encrypted (proposed), sqlite (queryable, portable), postgresql (scalable, concurrent), mongodb (flexible schema), ldap (enterprise directory), and oauth2 (social login). Use `backend_available(text_file)` to check availability and `backend_capabilities(mongodb, Caps)` to get backend capabilities. Choose text_file for simple setups, postgresql/mongodb for scalability, and ldap/oauth2 for enterprise integration.\n\nSee skill_authentication.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_authentication_002_q3", "cluster_id": "skill_authentication_002", "question": "What's the difference between file and database backends?", "answer": "File backends like text_file store user credentials in a text file\u2014simple to set up and portable, but not queryable or scalable. Database backends like sqlite, postgresql, and mongodb store credentials in databases, offering queryable data, transactions, and scalability. Use text_file for simple development setups, sqlite for portable single-file databases, and postgresql/mongodb for production systems requiring concurrent access and scalability. Check availability with `backend_available(text_file)` and capabilities with `backend_capabilities(mongodb, Caps)`.", "question_type": "long", "topics": ["Quickstart", "Authentication", "Backends"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["backends", "storage", "authentication"], "related_skills": ["skill_authentication.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "Multiple backends are available: mock (development only), text_file (simple, implemented), text_file_encrypted (proposed), sqlite (queryable, portable), postgresql (scalable, concurrent), mongodb (flexible schema), ldap (enterprise directory), and oauth2 (social login). Use `backend_available(text_file)` to check availability and `backend_capabilities(mongodb, Caps)` to get backend capabilities. Choose text_file for simple setups, postgresql/mongodb for scalability, and ldap/oauth2 for enterprise integration.\n\nSee skill_authentication.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_authentication_003_q0", "cluster_id": "skill_authentication_003", "question": "What password hashing algorithms should I use?", "answer": "For password hashing, use bcrypt for production environments as it provides high security and is implemented. For development, plain is acceptable. SHA256 offers medium security. Argon2 and scrypt provide very high security but are proposed features not yet implemented. Configure your choice in the auth config with `password_hash(bcrypt)`. You can verify algorithm availability with `hash_available(bcrypt)` or inspect properties with `hash_algorithm(argon2, Props)`.", "question_type": "medium", "topics": ["Quickstart", "Authentication", "Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["password-hashing", "security", "encryption"], "related_skills": ["skill_authentication.md", "skill_frontend_security.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "Use bcrypt for high security (implemented and recommended for production). For development, plain is acceptable. sha256 provides medium security (implemented). argon2 and scrypt offer very high security but are proposed features. Specify the algorithm in auth config: `password_hash(bcrypt)`. Query available algorithms with `hash_available(bcrypt)` or get detailed properties with `hash_algorithm(argon2, Props)`.\n\nSee skill_authentication.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_authentication_003_q1", "cluster_id": "skill_authentication_003", "question": "How do I secure passwords in my app?", "answer": "To secure passwords in your app, use bcrypt for high security in production environments\u2014it's the recommended, implemented algorithm. For development only, plain is acceptable. sha256 provides medium security if needed. Very high security options argon2 and scrypt are proposed features. Configure password hashing in your auth backend: `password_hash(bcrypt)`. Verify algorithm availability with `hash_available(bcrypt)` or get detailed properties using `hash_algorithm(argon2, Props)`. Refer to skill_authentication.md for complete details.", "question_type": "medium", "topics": ["Quickstart", "Authentication", "Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["password-hashing", "security", "encryption"], "related_skills": ["skill_authentication.md", "skill_frontend_security.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "Use bcrypt for high security (implemented and recommended for production). For development, plain is acceptable. sha256 provides medium security (implemented). argon2 and scrypt offer very high security but are proposed features. Specify the algorithm in auth config: `password_hash(bcrypt)`. Query available algorithms with `hash_available(bcrypt)` or get detailed properties with `hash_algorithm(argon2, Props)`.\n\nSee skill_authentication.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_authentication_003_q2", "cluster_id": "skill_authentication_003", "question": "What's the most secure password hashing method?", "answer": "For the most secure password hashing method, use argon2 (very high security) if available in your environment, as it's specifically designed for password hashing with strong resistance to GPU attacks. If argon2 isn't available, bcrypt (high security, implemented) is the recommended production standard and can be configured with `password_hash(bcrypt)` in your auth config. Scrypt offers similarly high security but is proposed. Avoid sha256 (medium security) and plain text (no security) for production use. Query available algorithms with `hash_available(algorithm_name)` or get detailed properties with `hash_algorithm(argon2, Props)`.", "question_type": "medium", "topics": ["Quickstart", "Authentication", "Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["password-hashing", "security", "encryption"], "related_skills": ["skill_authentication.md", "skill_frontend_security.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "Use bcrypt for high security (implemented and recommended for production). For development, plain is acceptable. sha256 provides medium security (implemented). argon2 and scrypt offer very high security but are proposed features. Specify the algorithm in auth config: `password_hash(bcrypt)`. Query available algorithms with `hash_available(bcrypt)` or get detailed properties with `hash_algorithm(argon2, Props)`.\n\nSee skill_authentication.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_authentication_003_q3", "cluster_id": "skill_authentication_003", "question": "Which hashing algorithm should I choose for production?", "answer": "For production, use bcrypt for high security\u2014it's implemented and recommended. If you need even stronger security, argon2 and scrypt offer very high security but are currently proposed features. sha256 provides medium security if bcrypt isn't available. Configure it with `password_hash(bcrypt)` in your auth config, and verify availability with `hash_available(bcrypt)`.", "question_type": "medium", "topics": ["Quickstart", "Authentication", "Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["password-hashing", "security", "encryption"], "related_skills": ["skill_authentication.md", "skill_frontend_security.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "Use bcrypt for high security (implemented and recommended for production). For development, plain is acceptable. sha256 provides medium security (implemented). argon2 and scrypt offer very high security but are proposed features. Specify the algorithm in auth config: `password_hash(bcrypt)`. Query available algorithms with `hash_available(bcrypt)` or get detailed properties with `hash_algorithm(argon2, Props)`.\n\nSee skill_authentication.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_authentication_004_q0", "cluster_id": "skill_authentication_004", "question": "What token types should I use for authentication?", "answer": "For authentication, you have three token type options: JWT (JSON Web Token) for stateless authentication in distributed systems and APIs, Sessions for simpler server-side authentication with cookies, and API keys for static authentication. JWT is currently implemented and recommended for most applications. Configure your choice with `token_type(jwt)` in your auth config, and set session duration with `session_duration(86400)` for a 24-hour default. Query token properties with `token_type(jwt, Props)` to get detailed specifications for your chosen type.", "question_type": "long", "topics": ["Quickstart", "Authentication", "Tokens"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["tokens", "jwt", "sessions", "authentication"], "related_skills": ["skill_authentication.md", "skill_networking.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "JWT (JSON Web Token) is stateless, implemented, and recommended for most applications. Sessions use server-side storage with cookies (proposed). API keys provide static authentication (proposed). Specify token type with `token_type(jwt)` in auth config. Query properties with `token_type(jwt, Props)`. JWT works well for distributed systems and APIs, while sessions are simpler for traditional web apps. Set session duration with `session_duration(86400)` (default: 24 hours).\n\nSee skill_authentication.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_authentication_004_q1", "cluster_id": "skill_authentication_004", "question": "Should I use JWT or sessions?", "answer": "JWT is stateless and implemented, making it ideal for distributed systems and APIs. Sessions use server-side storage with cookies and are simpler for traditional web apps, but are still proposed. For most modern applications, JWT is recommended. Configure with `token_type(jwt)` in your auth config. Query token properties with `token_type(jwt, Props)`. Set session duration with `session_duration(86400)` if using sessions (default: 24 hours).", "question_type": "long", "topics": ["Quickstart", "Authentication", "Tokens"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["tokens", "jwt", "sessions", "authentication"], "related_skills": ["skill_authentication.md", "skill_networking.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "JWT (JSON Web Token) is stateless, implemented, and recommended for most applications. Sessions use server-side storage with cookies (proposed). API keys provide static authentication (proposed). Specify token type with `token_type(jwt)` in auth config. Query properties with `token_type(jwt, Props)`. JWT works well for distributed systems and APIs, while sessions are simpler for traditional web apps. Set session duration with `session_duration(86400)` (default: 24 hours).\n\nSee skill_authentication.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_authentication_004_q2", "cluster_id": "skill_authentication_004", "question": "What's the difference between JWT and session tokens?", "answer": "JWT (JSON Web Token) is stateless and implemented, making it ideal for distributed systems and APIs where the server doesn't need to maintain session state. Sessions, which are proposed, use server-side storage with cookies and are simpler for traditional web apps. JWT tokens are self-contained and can be verified without database lookups, while sessions require the server to store and retrieve user data. Configure with `token_type(jwt)` or `token_type(session)` in auth config, and set session duration with `session_duration(86400)` (default: 24 hours).", "question_type": "long", "topics": ["Quickstart", "Authentication", "Tokens"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["tokens", "jwt", "sessions", "authentication"], "related_skills": ["skill_authentication.md", "skill_networking.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "JWT (JSON Web Token) is stateless, implemented, and recommended for most applications. Sessions use server-side storage with cookies (proposed). API keys provide static authentication (proposed). Specify token type with `token_type(jwt)` in auth config. Query properties with `token_type(jwt, Props)`. JWT works well for distributed systems and APIs, while sessions are simpler for traditional web apps. Set session duration with `session_duration(86400)` (default: 24 hours).\n\nSee skill_authentication.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "Session tokens are marked 'proposed' in the skill document, so implementation details may be incomplete or subject to change."}
{"pair_id": "skill_authentication_004_q3", "cluster_id": "skill_authentication_004", "question": "How do I choose between stateless and stateful tokens?", "answer": "JWT (stateless) is implemented and recommended for distributed systems and APIs because it doesn't require server storage. Sessions (stateful, server-side with cookies) are simpler for traditional web apps but require persistent storage. Use `token_type(jwt)` for stateless authentication or `token_type(session)` for stateful. Configure session duration with `session_duration(86400)` (24 hours default). Query token properties with `token_type(Type, Props)` to understand trade-offs before choosing.", "question_type": "long", "topics": ["Quickstart", "Authentication", "Tokens"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["tokens", "jwt", "sessions", "authentication"], "related_skills": ["skill_authentication.md", "skill_networking.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "JWT (JSON Web Token) is stateless, implemented, and recommended for most applications. Sessions use server-side storage with cookies (proposed). API keys provide static authentication (proposed). Specify token type with `token_type(jwt)` in auth config. Query properties with `token_type(jwt, Props)`. JWT works well for distributed systems and APIs, while sessions are simpler for traditional web apps. Set session duration with `session_duration(86400)` (default: 24 hours).\n\nSee skill_authentication.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_authentication_005_q0", "cluster_id": "skill_authentication_005", "question": "How do I set up authentication for development vs production?", "answer": "For development, use the mock backend with plain password hashing: `app(dev_app, [auth([backend(mock), password_hash(plain), token_type(jwt)])])`. This provides quick setup with built-in test users (admin@test.com/admin123, shell@test.com/shell123, user@test.com/user123) for testing without persistence. For production, use the text_file backend with bcrypt hashing and a short session duration: `app(prod_app, [auth([backend(text_file), password_hash(bcrypt), token_type(jwt), users_file('/secure/users.txt'), session_duration(3600)])])`. For enterprise deployments requiring centralized authentication, use LDAP: `app(enterprise_app, [auth([backend(ldap), token_type(jwt), ldap_server(...), ldap_base_dn(...)])])`. The key differences are backend choice (mock for dev, file/database for production, LDAP for enterprise), password hashing security (plain for dev, bcrypt for production), and session duration (longer for dev, shorter for production).", "question_type": "medium", "topics": ["Quickstart", "Authentication", "Configuration"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["configuration", "development", "production", "deployment"], "related_skills": ["skill_authentication.md", "skill_deployment.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "For development, use mock backend with plain password hashing: `app(dev_app, [auth([backend(mock), password_hash(plain), token_type(jwt)])])`. For production, use text_file backend with bcrypt and shorter session duration: `app(prod_app, [auth([backend(text_file), password_hash(bcrypt), token_type(jwt), users_file('/secure/users.txt'), session_duration(3600)])])`. For enterprise, consider LDAP: `app(enterprise_app, [auth([backend(ldap), token_type(jwt), ldap_server(...), ldap_base_dn(...)])])`. The mock backend includes test users: admin@test.com/admin123, shell@test.com/shell123, user@test.com/user123.\n\nSee skill_authentication.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_authentication_005_q1", "cluster_id": "skill_authentication_005", "question": "What configuration should I use for testing?", "answer": "For testing, use the mock backend with plain password hashing: `app(test_app, [auth([backend(mock), password_hash(plain), token_type(jwt)])])`. The mock backend is designed for development and testing, provides fast setup with no persistence requirements, and includes built-in test users: admin@test.com/admin123, shell@test.com/shell123, and user@test.com/user123. This allows you to test authentication flows without external dependencies or database setup.", "question_type": "medium", "topics": ["Quickstart", "Authentication", "Configuration"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["configuration", "development", "production", "deployment"], "related_skills": ["skill_authentication.md", "skill_deployment.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "For development, use mock backend with plain password hashing: `app(dev_app, [auth([backend(mock), password_hash(plain), token_type(jwt)])])`. For production, use text_file backend with bcrypt and shorter session duration: `app(prod_app, [auth([backend(text_file), password_hash(bcrypt), token_type(jwt), users_file('/secure/users.txt'), session_duration(3600)])])`. For enterprise, consider LDAP: `app(enterprise_app, [auth([backend(ldap), token_type(jwt), ldap_server(...), ldap_base_dn(...)])])`. The mock backend includes test users: admin@test.com/admin123, shell@test.com/shell123, user@test.com/user123.\n\nSee skill_authentication.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_authentication_005_q2", "cluster_id": "skill_authentication_005", "question": "How do I configure different auth settings for environments?", "answer": "Configure environment-specific auth by creating separate app declarations for each environment. For development, use the mock backend with plain password hashing for fast iteration: `app(dev_app, [auth([backend(mock), password_hash(plain), token_type(jwt)])])`. For production, use text_file backend with bcrypt hashing and a secure users file path: `app(prod_app, [auth([backend(text_file), password_hash(bcrypt), token_type(jwt), users_file('/secure/users.txt'), session_duration(3600)])])`. For enterprise deployments, configure LDAP for centralized authentication: `app(enterprise_app, [auth([backend(ldap), token_type(jwt), ldap_server(...), ldap_base_dn(...)])])`. Each environment's auth configuration can be loaded conditionally based on deployment context.", "question_type": "medium", "topics": ["Quickstart", "Authentication", "Configuration"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["configuration", "development", "production", "deployment"], "related_skills": ["skill_authentication.md", "skill_deployment.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "For development, use mock backend with plain password hashing: `app(dev_app, [auth([backend(mock), password_hash(plain), token_type(jwt)])])`. For production, use text_file backend with bcrypt and shorter session duration: `app(prod_app, [auth([backend(text_file), password_hash(bcrypt), token_type(jwt), users_file('/secure/users.txt'), session_duration(3600)])])`. For enterprise, consider LDAP: `app(enterprise_app, [auth([backend(ldap), token_type(jwt), ldap_server(...), ldap_base_dn(...)])])`. The mock backend includes test users: admin@test.com/admin123, shell@test.com/shell123, user@test.com/user123.\n\nSee skill_authentication.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer provides good environment-specific examples but doesn't explain the mechanism for conditionally loading different configs per environment (e.g., via environment variables or config files), which is important for actually implementing multi-environment setups."}
{"pair_id": "skill_authentication_005_q3", "cluster_id": "skill_authentication_005", "question": "What are best practices for dev and prod auth setup?", "answer": "For development, use mock backend with plain password hashing: `app(dev_app, [auth([backend(mock), password_hash(plain), token_type(jwt)])])`. For production, use text_file backend with bcrypt and shorter session duration: `app(prod_app, [auth([backend(text_file), password_hash(bcrypt), token_type(jwt), users_file('/secure/users.txt'), session_duration(3600)])])`. For enterprise deployments, consider LDAP: `app(enterprise_app, [auth([backend(ldap), token_type(jwt), ldap_server(...), ldap_base_dn(...)])])`. Development includes test users: admin@test.com/admin123, shell@test.com/shell123, user@test.com/user123. Key differences: dev prioritizes speed with mock backend and plain hashing; prod uses persistent file storage with bcrypt and restricted session duration; enterprise uses centralized LDAP authentication.", "question_type": "medium", "topics": ["Quickstart", "Authentication", "Configuration"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["configuration", "development", "production", "deployment"], "related_skills": ["skill_authentication.md", "skill_deployment.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "For development, use mock backend with plain password hashing: `app(dev_app, [auth([backend(mock), password_hash(plain), token_type(jwt)])])`. For production, use text_file backend with bcrypt and shorter session duration: `app(prod_app, [auth([backend(text_file), password_hash(bcrypt), token_type(jwt), users_file('/secure/users.txt'), session_duration(3600)])])`. For enterprise, consider LDAP: `app(enterprise_app, [auth([backend(ldap), token_type(jwt), ldap_server(...), ldap_base_dn(...)])])`. The mock backend includes test users: admin@test.com/admin123, shell@test.com/shell123, user@test.com/user123.\n\nSee skill_authentication.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "Base answer mixes backend selection with session duration strategy. Enterprise section assumes LDAP without acknowledging other production options (PostgreSQL, MongoDB). Doesn't explain why these specific choices (bcrypt over argon2, file over SQLite) are best practices. Missing details on session management differences between dev/prod."}
{"pair_id": "skill_authentication_006_q0", "cluster_id": "skill_authentication_006", "question": "How do I generate and manage user authentication server?", "answer": "To generate and manage a user authentication server, use `generate_auth_server(AppSpec, Target, Files)` with target 'node' to create a Node.js/Express server. This generates auth-config.json and auth-server.cjs with core functions: authenticate(username, password), register(username, password, roles, permissions), loadUsers(), hashPassword(password), and verifyPassword(password, storedHash). Configure authentication in your app specification with backend (e.g., text_file, sqlite, postgresql), password_hash algorithm (bcrypt, sha256), and token_type (jwt, session). Format users file as `username:password_hash:roles:permissions`. Use `generate_default_users(AppSpec, Content)` to create initial users, and extract configuration with `app_auth_config(AppSpec, AuthConfig)`, `app_auth_backend(AppSpec, Backend)`, or `app_auth_token_type(AppSpec, TokenType)` for programmatic access to auth settings.", "question_type": "long", "topics": ["Quickstart", "Authentication", "Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["code-generation", "server", "node.js", "users-file"], "related_skills": ["skill_authentication.md", "skill_networking.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "Use `generate_auth_server(AppSpec, Target, Files)` with target 'node' to generate Node.js/Express server. This creates auth-config.json and auth-server.cjs with functions: authenticate(username, password), register(username, password, roles, permissions), loadUsers(), hashPassword(password), verifyPassword(password, storedHash). Format users file as `username:password_hash:roles:permissions`. Generate default users with `generate_default_users(AppSpec, Content)`. Extract config with `app_auth_config(AppSpec, AuthConfig)`, `app_auth_backend(AppSpec, Backend)`, or `app_auth_token_type(AppSpec, TokenType)`.\n\nSee skill_authentication.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_authentication_006_q1", "cluster_id": "skill_authentication_006", "question": "How do I create an auth server for Node.js?", "answer": "To create an auth server for Node.js, use `generate_auth_server(AppSpec, node, Files)` where AppSpec contains your app configuration with auth settings. This generates auth-config.json and auth-server.cjs with authentication functions: authenticate(username, password), register(username, password, roles, permissions), loadUsers(), hashPassword(password), and verifyPassword(password, storedHash). Configure your app with a backend (e.g., text_file), password hashing algorithm (e.g., bcrypt), and token type (e.g., jwt). Format your users file as `username:password_hash:roles:permissions`. You can extract specific auth configuration using `app_auth_config()`, `app_auth_backend()`, or `app_auth_token_type()` predicates.", "question_type": "long", "topics": ["Quickstart", "Authentication", "Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["code-generation", "server", "node.js", "users-file"], "related_skills": ["skill_authentication.md", "skill_networking.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "Use `generate_auth_server(AppSpec, Target, Files)` with target 'node' to generate Node.js/Express server. This creates auth-config.json and auth-server.cjs with functions: authenticate(username, password), register(username, password, roles, permissions), loadUsers(), hashPassword(password), verifyPassword(password, storedHash). Format users file as `username:password_hash:roles:permissions`. Generate default users with `generate_default_users(AppSpec, Content)`. Extract config with `app_auth_config(AppSpec, AuthConfig)`, `app_auth_backend(AppSpec, Backend)`, or `app_auth_token_type(AppSpec, TokenType)`.\n\nSee skill_authentication.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer includes some implementation details (like hashPassword, verifyPassword function signatures) that may vary depending on the specific version or configuration. The answer assumes the user wants a Prolog-based generation approach rather than direct Node.js setup, which might not match all user expectations."}
{"pair_id": "skill_authentication_006_q2", "cluster_id": "skill_authentication_006", "question": "How do I format the users file?", "answer": "The users file should be formatted as `username:password_hash:roles:permissions` where each line contains a user entry. The password_hash should be the hashed version of the password (using your configured hashing algorithm like bcrypt). You can generate a default users file with `generate_default_users(AppSpec, Content)`. When using the text_file backend, this file is specified via the `users_file('users.txt')` configuration parameter.", "question_type": "long", "topics": ["Quickstart", "Authentication", "Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["code-generation", "server", "node.js", "users-file"], "related_skills": ["skill_authentication.md", "skill_networking.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "Use `generate_auth_server(AppSpec, Target, Files)` with target 'node' to generate Node.js/Express server. This creates auth-config.json and auth-server.cjs with functions: authenticate(username, password), register(username, password, roles, permissions), loadUsers(), hashPassword(password), verifyPassword(password, storedHash). Format users file as `username:password_hash:roles:permissions`. Generate default users with `generate_default_users(AppSpec, Content)`. Extract config with `app_auth_config(AppSpec, AuthConfig)`, `app_auth_backend(AppSpec, Backend)`, or `app_auth_token_type(AppSpec, TokenType)`.\n\nSee skill_authentication.md for details.", "answer_tailored": true, "confidence": 0.75, "confidence_issues": "Base answer provides format but lacks clarity on whether roles/permissions are comma-separated or pipe-separated; doesn't specify file encoding or line endings; no example of actual formatted content shown."}
{"pair_id": "skill_authentication_006_q3", "cluster_id": "skill_authentication_006", "question": "What functions does the generated auth server provide?", "answer": "The generated auth server provides the following functions: authenticate(username, password) for user login, register(username, password, roles, permissions) for user registration, loadUsers() to load user data from storage, hashPassword(password) to hash passwords using the configured algorithm, and verifyPassword(password, storedHash) to verify passwords against stored hashes. These functions are created in auth-server.cjs when using generate_auth_server(AppSpec, 'node', Files) with Node.js/Express as the target.", "question_type": "long", "topics": ["Quickstart", "Authentication", "Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["code-generation", "server", "node.js", "users-file"], "related_skills": ["skill_authentication.md", "skill_networking.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "Use `generate_auth_server(AppSpec, Target, Files)` with target 'node' to generate Node.js/Express server. This creates auth-config.json and auth-server.cjs with functions: authenticate(username, password), register(username, password, roles, permissions), loadUsers(), hashPassword(password), verifyPassword(password, storedHash). Format users file as `username:password_hash:roles:permissions`. Generate default users with `generate_default_users(AppSpec, Content)`. Extract config with `app_auth_config(AppSpec, AuthConfig)`, `app_auth_backend(AppSpec, Backend)`, or `app_auth_token_type(AppSpec, TokenType)`.\n\nSee skill_authentication.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer mentions these functions but also includes tangential information about file formats and config extraction. The confidence is moderate because the answer clearly lists the functions, but the base answer doesn't explicitly state what each function does or their signatures, which would be helpful for understanding their exact purpose."}
{"pair_id": "skill_browser_python_001_q0", "cluster_id": "skill_browser_python_001", "question": "How can I run Python code directly in the browser without a server?", "answer": "You can use Pyodide, which compiles CPython to WebAssembly, allowing you to run Python directly in the browser without a server. Pyodide supports full Python 3 with libraries like NumPy, pandas, SciPy, and matplotlib.\n\nTo get started, compile a Python module:\n\n```prolog\ncompile_pyodide_module(analysis, [\n    packages([numpy, pandas]),\n    exports([analyze, transform])\n], PythonCode).\n```\n\nThen generate an HTML page:\n\n```prolog\ngenerate_pyodide_html('Data Analysis', [\n    packages([numpy]),\n    python_module(PythonCode)\n], HTML).\n```\n\nEverything runs in the browser sandbox with no server needed. Your code executes via WebAssembly with full access to scientific computing libraries.", "question_type": "medium", "topics": ["Quickstart", "Browser Python (Pyodide)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["browser", "python", "pyodide", "webassembly", "client-side"], "related_skills": ["skill_browser_python.md"], "related_docs": ["src/unifyweaver/targets/python_pyodide_target.pl", "src/unifyweaver/targets/python_target.pl"], "original_answer": "You can use Pyodide, which compiles Python to WebAssembly for browser execution. Compile a Python module with NumPy/pandas support:\n\n```prolog\ncompile_pyodide_module(analysis, [\n    packages([numpy, pandas]),\n    exports([analyze, transform])\n], PythonCode).\n```\n\nThen generate an HTML page to run it:\n\n```prolog\ngenerate_pyodide_html('Data Analysis', [\n    packages([numpy]),\n    python_module(PythonCode)\n], HTML).\n```\n\nNo server required\u2014everything runs in the browser sandbox. See skill_browser_python.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_browser_python_001_q1", "cluster_id": "skill_browser_python_001", "question": "Can I execute Python in the browser?", "answer": "Yes, you can execute Python in the browser using Pyodide, which compiles Python to WebAssembly. This allows you to run full Python 3 with libraries like NumPy, pandas, and SciPy directly in the browser without a server. You can compile a Python module using: `compile_pyodide_module(analysis, [packages([numpy, pandas]), exports([analyze, transform])], PythonCode)` and generate an HTML page with `generate_pyodide_html('Data Analysis', [packages([numpy]), python_module(PythonCode)], HTML)`. Everything executes in the browser sandbox for security.", "question_type": "medium", "topics": ["Quickstart", "Browser Python (Pyodide)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["browser", "python", "pyodide", "webassembly", "client-side"], "related_skills": ["skill_browser_python.md"], "related_docs": ["src/unifyweaver/targets/python_pyodide_target.pl", "src/unifyweaver/targets/python_target.pl"], "original_answer": "You can use Pyodide, which compiles Python to WebAssembly for browser execution. Compile a Python module with NumPy/pandas support:\n\n```prolog\ncompile_pyodide_module(analysis, [\n    packages([numpy, pandas]),\n    exports([analyze, transform])\n], PythonCode).\n```\n\nThen generate an HTML page to run it:\n\n```prolog\ngenerate_pyodide_html('Data Analysis', [\n    packages([numpy]),\n    python_module(PythonCode)\n], HTML).\n```\n\nNo server required\u2014everything runs in the browser sandbox. See skill_browser_python.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_browser_python_001_q2", "cluster_id": "skill_browser_python_001", "question": "Is it possible to run Python client-side?", "answer": "Yes, you can run Python client-side using Pyodide, which compiles Python to WebAssembly for execution directly in the browser. This enables full Python 3 with libraries like NumPy, SciPy, and pandas\u2014no server required. Use compile_pyodide_module() to create a Python module and generate_pyodide_html() to create a browser page. Everything runs in the browser sandbox for security.", "question_type": "medium", "topics": ["Quickstart", "Browser Python (Pyodide)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["browser", "python", "pyodide", "webassembly", "client-side"], "related_skills": ["skill_browser_python.md"], "related_docs": ["src/unifyweaver/targets/python_pyodide_target.pl", "src/unifyweaver/targets/python_target.pl"], "original_answer": "You can use Pyodide, which compiles Python to WebAssembly for browser execution. Compile a Python module with NumPy/pandas support:\n\n```prolog\ncompile_pyodide_module(analysis, [\n    packages([numpy, pandas]),\n    exports([analyze, transform])\n], PythonCode).\n```\n\nThen generate an HTML page to run it:\n\n```prolog\ngenerate_pyodide_html('Data Analysis', [\n    packages([numpy]),\n    python_module(PythonCode)\n], HTML).\n```\n\nNo server required\u2014everything runs in the browser sandbox. See skill_browser_python.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_browser_python_001_q3", "cluster_id": "skill_browser_python_001", "question": "How do I use Python in a web application?", "answer": "You can use Pyodide to run Python directly in the browser via WebAssembly. Compile a Python module with required packages like NumPy or pandas, then generate an HTML page to run it. This approach requires no server\u2014everything executes in the browser sandbox. For example:\n\n```prolog\ncompile_pyodide_module(analysis, [\n    packages([numpy, pandas]),\n    exports([analyze, transform])\n], PythonCode).\n\ngenerate_pyodide_html('Data Analysis', [\n    packages([numpy]),\n    python_module(PythonCode)\n], HTML).\n```\n\nPyodide supports NumPy, SciPy, pandas, matplotlib, scikit-learn, and other scientific packages. See skill_browser_python.md for complete integration details.", "question_type": "medium", "topics": ["Quickstart", "Browser Python (Pyodide)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["browser", "python", "pyodide", "webassembly", "client-side"], "related_skills": ["skill_browser_python.md"], "related_docs": ["src/unifyweaver/targets/python_pyodide_target.pl", "src/unifyweaver/targets/python_target.pl"], "original_answer": "You can use Pyodide, which compiles Python to WebAssembly for browser execution. Compile a Python module with NumPy/pandas support:\n\n```prolog\ncompile_pyodide_module(analysis, [\n    packages([numpy, pandas]),\n    exports([analyze, transform])\n], PythonCode).\n```\n\nThen generate an HTML page to run it:\n\n```prolog\ngenerate_pyodide_html('Data Analysis', [\n    packages([numpy]),\n    python_module(PythonCode)\n], HTML).\n```\n\nNo server required\u2014everything runs in the browser sandbox. See skill_browser_python.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_browser_python_002_q0", "cluster_id": "skill_browser_python_002", "question": "How do I use NumPy or pandas for data analysis in a web browser?", "answer": "To use NumPy or pandas for data analysis in a web browser, use Pyodide, which compiles Python to WebAssembly. Create a data processing module with: `compile_pyodide_module(processor, [packages([pandas, numpy]), exports([load_data, process, summarize])], Code).` This generates browser-based Python code that runs client-side without a server. Pyodide supports NumPy, pandas, SciPy, scikit-learn, matplotlib, and other scientific libraries. The compiled module exposes functions through JavaScript interop for seamless integration with web applications.", "question_type": "medium", "topics": ["Quickstart", "Browser Python (Pyodide)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["numpy", "pandas", "data-analysis", "browser", "pyodide"], "related_skills": ["skill_browser_python.md"], "related_docs": ["src/unifyweaver/targets/python_pyodide_target.pl"], "original_answer": "Pyodide supports NumPy, pandas, SciPy, scikit-learn, matplotlib, and more. To create a data processing module:\n\n```prolog\ncompile_pyodide_module(processor, [\n    packages([pandas, numpy]),\n    exports([load_data, process, summarize])\n], Code).\n```\n\nThe compiled module exposes functions via JavaScript interop. Available packages include numpy, scipy, pandas, matplotlib, scikit_learn, sympy, networkx, pillow, opencv_python, and statsmodels. See skill_browser_python.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_browser_python_002_q1", "cluster_id": "skill_browser_python_002", "question": "Can I run NumPy in the browser?", "answer": "Yes, you can run NumPy in the browser using Pyodide, which compiles CPython to WebAssembly. Pyodide provides full access to NumPy along with other scientific packages like SciPy, pandas, and matplotlib. To use NumPy in a browser application, you can compile a Pyodide module that includes NumPy as a dependency:\n\n```prolog\ncompile_pyodide_module(analysis, [\n    packages([numpy]),\n    exports([analyze])\n], Code).\n```\n\nThis generates Python code that runs directly in the browser with WebAssembly, allowing you to perform NumPy operations without a server.", "question_type": "medium", "topics": ["Quickstart", "Browser Python (Pyodide)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["numpy", "pandas", "data-analysis", "browser", "pyodide"], "related_skills": ["skill_browser_python.md"], "related_docs": ["src/unifyweaver/targets/python_pyodide_target.pl"], "original_answer": "Pyodide supports NumPy, pandas, SciPy, scikit-learn, matplotlib, and more. To create a data processing module:\n\n```prolog\ncompile_pyodide_module(processor, [\n    packages([pandas, numpy]),\n    exports([load_data, process, summarize])\n], Code).\n```\n\nThe compiled module exposes functions via JavaScript interop. Available packages include numpy, scipy, pandas, matplotlib, scikit_learn, sympy, networkx, pillow, opencv_python, and statsmodels. See skill_browser_python.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_browser_python_002_q2", "cluster_id": "skill_browser_python_002", "question": "Does Pyodide support pandas?", "answer": "Yes, Pyodide supports pandas. You can use pandas for client-side data processing by including it in the packages list when compiling a Pyodide module. For example: compile_pyodide_module(processor, [packages([pandas, numpy]), exports([load_data, process])], Code). Pandas is one of the available packages in Pyodide, along with NumPy, SciPy, matplotlib, and others.", "question_type": "medium", "topics": ["Quickstart", "Browser Python (Pyodide)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["numpy", "pandas", "data-analysis", "browser", "pyodide"], "related_skills": ["skill_browser_python.md"], "related_docs": ["src/unifyweaver/targets/python_pyodide_target.pl"], "original_answer": "Pyodide supports NumPy, pandas, SciPy, scikit-learn, matplotlib, and more. To create a data processing module:\n\n```prolog\ncompile_pyodide_module(processor, [\n    packages([pandas, numpy]),\n    exports([load_data, process, summarize])\n], Code).\n```\n\nThe compiled module exposes functions via JavaScript interop. Available packages include numpy, scipy, pandas, matplotlib, scikit_learn, sympy, networkx, pillow, opencv_python, and statsmodels. See skill_browser_python.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_browser_python_002_q3", "cluster_id": "skill_browser_python_002", "question": "What data science libraries work in the browser?", "answer": "Pyodide enables full data science libraries to run directly in the browser via WebAssembly. Supported libraries include NumPy, pandas, SciPy, scikit-learn, matplotlib, sympy, networkx, pillow, opencv_python, and statsmodels. You can create a browser-based data processing module using: compile_pyodide_module(processor, [packages([pandas, numpy]), exports([load_data, process])], Code). This compiles Python functions that run client-side without a server, leveraging the browser sandbox for security.", "question_type": "medium", "topics": ["Quickstart", "Browser Python (Pyodide)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["numpy", "pandas", "data-analysis", "browser", "pyodide"], "related_skills": ["skill_browser_python.md"], "related_docs": ["src/unifyweaver/targets/python_pyodide_target.pl"], "original_answer": "Pyodide supports NumPy, pandas, SciPy, scikit-learn, matplotlib, and more. To create a data processing module:\n\n```prolog\ncompile_pyodide_module(processor, [\n    packages([pandas, numpy]),\n    exports([load_data, process, summarize])\n], Code).\n```\n\nThe compiled module exposes functions via JavaScript interop. Available packages include numpy, scipy, pandas, matplotlib, scikit_learn, sympy, networkx, pillow, opencv_python, and statsmodels. See skill_browser_python.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_browser_python_003_q0", "cluster_id": "skill_browser_python_003", "question": "How do I create interactive charts or visualizations using Python in the browser?", "answer": "To create interactive charts or visualizations using Python in the browser, use Pyodide to compile Python visualization functions to WebAssembly. First, compile a visualization module with matplotlib and numpy packages, exporting your plotting functions:\n\n```prolog\ncompile_pyodide_module(viz, [\n    packages([numpy, matplotlib]),\n    exports([plot_histogram, plot_scatter])\n], PythonCode).\n```\n\nThen generate an HTML page that integrates the Python module with the browser:\n\n```prolog\ngenerate_pyodide_html('Interactive Visualization', [\n    packages([numpy, matplotlib]),\n    python_module(PythonCode),\n    chart(true)\n], HTML).\n```\n\nThis allows your Python functions to run directly in the browser via WebAssembly without a server. Your matplotlib-based visualizations will be interactive and can respond to user input. The chart(true) option enables Chart.js integration for additional interactive charting capabilities.", "question_type": "medium", "topics": ["Quickstart", "Browser Python (Pyodide)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["visualization", "charts", "matplotlib", "pyodide", "browser"], "related_skills": ["skill_browser_python.md"], "related_docs": ["src/unifyweaver/targets/python_pyodide_target.pl"], "original_answer": "Create a visualization module and generate an HTML page with Chart.js:\n\n```prolog\ncompile_pyodide_module(viz, [\n    packages([numpy, matplotlib]),\n    exports([plot_histogram, plot_scatter])\n], PythonCode).\n\ngenerate_pyodide_html('Interactive Visualization', [\n    packages([numpy]),\n    python_module(PythonCode),\n    chart(true)\n], HTML).\n```\n\nYour Python functions can generate charts and interact with the page. Matplotlib is supported, and Chart.js integration is available. See skill_browser_python.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "The base answer mentions Chart.js integration but provides limited detail on how it works with matplotlib or how users actually interact with the visualizations. The confidence is moderate because the answer covers the core approach but lacks specifics about interactive features and user interaction patterns."}
{"pair_id": "skill_browser_python_003_q1", "cluster_id": "skill_browser_python_003", "question": "Can I visualize data with Python in the browser?", "answer": "Yes, you can visualize data with Python in the browser using Pyodide. Create a visualization module with matplotlib and compile it to run in the browser:\n\n```prolog\ncompile_pyodide_module(viz, [\n    packages([numpy, matplotlib]),\n    exports([plot_histogram, plot_scatter])\n], PythonCode).\n\ngenerate_pyodide_html('Interactive Visualization', [\n    packages([numpy]),\n    python_module(PythonCode),\n    chart(true)\n], HTML).\n```\n\nYour Python functions run entirely in the browser via WebAssembly. Matplotlib is supported for static plots, and Chart.js integration is available for interactive charts. No server required.", "question_type": "medium", "topics": ["Quickstart", "Browser Python (Pyodide)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["visualization", "charts", "matplotlib", "pyodide", "browser"], "related_skills": ["skill_browser_python.md"], "related_docs": ["src/unifyweaver/targets/python_pyodide_target.pl"], "original_answer": "Create a visualization module and generate an HTML page with Chart.js:\n\n```prolog\ncompile_pyodide_module(viz, [\n    packages([numpy, matplotlib]),\n    exports([plot_histogram, plot_scatter])\n], PythonCode).\n\ngenerate_pyodide_html('Interactive Visualization', [\n    packages([numpy]),\n    python_module(PythonCode),\n    chart(true)\n], HTML).\n```\n\nYour Python functions can generate charts and interact with the page. Matplotlib is supported, and Chart.js integration is available. See skill_browser_python.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "Base answer mentions Chart.js integration but provides limited detail on how to actually use it. The prolog syntax is provided but practical JavaScript/Python integration examples are missing."}
{"pair_id": "skill_browser_python_003_q2", "cluster_id": "skill_browser_python_003", "question": "How do I make interactive plots without a server?", "answer": "Use Pyodide to run Python with matplotlib directly in the browser. Create a visualization module with your plotting functions and generate an HTML page:\n\n```prolog\ncompile_pyodide_module(viz, [\n    packages([numpy, matplotlib]),\n    exports([plot_histogram, plot_scatter])\n], PythonCode).\n\ngenerate_pyodide_html('Interactive Visualization', [\n    packages([numpy, matplotlib]),\n    python_module(PythonCode)\n], HTML).\n```\n\nYour Python functions run entirely in the browser via WebAssembly\u2014no server needed. Matplotlib generates interactive plots client-side, and you can integrate with JavaScript for additional interactivity.", "question_type": "medium", "topics": ["Quickstart", "Browser Python (Pyodide)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["visualization", "charts", "matplotlib", "pyodide", "browser"], "related_skills": ["skill_browser_python.md"], "related_docs": ["src/unifyweaver/targets/python_pyodide_target.pl"], "original_answer": "Create a visualization module and generate an HTML page with Chart.js:\n\n```prolog\ncompile_pyodide_module(viz, [\n    packages([numpy, matplotlib]),\n    exports([plot_histogram, plot_scatter])\n], PythonCode).\n\ngenerate_pyodide_html('Interactive Visualization', [\n    packages([numpy]),\n    python_module(PythonCode),\n    chart(true)\n], HTML).\n```\n\nYour Python functions can generate charts and interact with the page. Matplotlib is supported, and Chart.js integration is available. See skill_browser_python.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "Base answer mentions Chart.js integration but the skill document shows matplotlib as the primary charting tool. The confidence is moderate because the answer works but could be more specific about matplotlib's interactive capabilities in Pyodide or clarify when to use matplotlib vs other options."}
{"pair_id": "skill_browser_python_003_q3", "cluster_id": "skill_browser_python_003", "question": "Does the browser Python support matplotlib?", "answer": "Yes, browser Python via Pyodide supports matplotlib. You can use matplotlib in your browser Python code by including it in the packages list when compiling a Pyodide module. For example: `compile_pyodide_module(viz, [packages([numpy, matplotlib]), exports([plot_histogram])], PythonCode)`. The generated module runs entirely in the browser via WebAssembly, allowing you to create and display matplotlib visualizations without a server.", "question_type": "medium", "topics": ["Quickstart", "Browser Python (Pyodide)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["visualization", "charts", "matplotlib", "pyodide", "browser"], "related_skills": ["skill_browser_python.md"], "related_docs": ["src/unifyweaver/targets/python_pyodide_target.pl"], "original_answer": "Create a visualization module and generate an HTML page with Chart.js:\n\n```prolog\ncompile_pyodide_module(viz, [\n    packages([numpy, matplotlib]),\n    exports([plot_histogram, plot_scatter])\n], PythonCode).\n\ngenerate_pyodide_html('Interactive Visualization', [\n    packages([numpy]),\n    python_module(PythonCode),\n    chart(true)\n], HTML).\n```\n\nYour Python functions can generate charts and interact with the page. Matplotlib is supported, and Chart.js integration is available. See skill_browser_python.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_browser_python_004_q0", "cluster_id": "skill_browser_python_004", "question": "How do I call Python functions from JavaScript in the browser?", "answer": "To call Python functions from JavaScript in the browser, export your Python functions when compiling with Pyodide:\n\n```prolog\ncompile_pyodide_module(processor, [\n    packages([numpy]),\n    exports([analyze, transform])\n], Code).\n```\n\nThen use the PyodideRunner class to invoke them from JavaScript:\n\n```javascript\nconst pyodide = new PyodideRunner();\nawait pyodide.init();\nconst result = await pyodide.callFunction(pythonCode, 'analyze', arg1, arg2);\n```\n\nGenerate the JavaScript loader with:\n\n```prolog\ngenerate_pyodide_loader([packages([numpy])], JSCode).\n```\n\nThis creates a class that manages Pyodide initialization and provides methods to call your exported Python functions directly from JavaScript with full NumPy/pandas support running in the browser via WebAssembly.", "question_type": "long", "topics": ["Quickstart", "Browser Python (Pyodide)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["javascript", "interop", "python-js", "pyodide", "function-calls"], "related_skills": ["skill_browser_python.md"], "related_docs": ["src/unifyweaver/targets/python_pyodide_target.pl"], "original_answer": "Export Python functions when compiling your module:\n\n```prolog\ncompile_pyodide_module(processor, [\n    packages([numpy]),\n    exports([analyze, transform])\n], Code).\n```\n\nUse the PyodideRunner to call functions from JavaScript:\n\n```javascript\nconst pyodide = new PyodideRunner();\nawait pyodide.callFunction(pythonCode, 'analyze', arg1, arg2);\n```\n\nGenerate a loader with:\n\n```prolog\ngenerate_pyodide_loader([packages([numpy])], JSCode).\n```\n\nThis creates a class for managing Pyodide initialization and calling Python functions. See skill_browser_python.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer references 'skill_browser_python.md' which is not shown in the provided skill document. The PyodideRunner API usage pattern (init, callFunction methods) is demonstrated but not formally documented in the provided reference material, creating slight ambiguity about exact API signatures."}
{"pair_id": "skill_browser_python_004_q1", "cluster_id": "skill_browser_python_004", "question": "Can I integrate Python functions with JavaScript?", "answer": "Yes, you can integrate Python functions with JavaScript using Pyodide. When compiling your module, export the Python functions you want to access from JavaScript:\n\n```prolog\ncompile_pyodide_module(processor, [\n    packages([numpy]),\n    exports([analyze, transform])\n], Code).\n```\n\nThen use the PyodideRunner class to call these functions from JavaScript:\n\n```javascript\nconst pyodide = new PyodideRunner();\nawait pyodide.callFunction(pythonCode, 'analyze', arg1, arg2);\n```\n\nThe exported functions become available in a JavaScript registry and can be called with arguments. Generate the loader using `generate_pyodide_loader/2` to set up the Pyodide environment and manage initialization.", "question_type": "long", "topics": ["Quickstart", "Browser Python (Pyodide)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["javascript", "interop", "python-js", "pyodide", "function-calls"], "related_skills": ["skill_browser_python.md"], "related_docs": ["src/unifyweaver/targets/python_pyodide_target.pl"], "original_answer": "Export Python functions when compiling your module:\n\n```prolog\ncompile_pyodide_module(processor, [\n    packages([numpy]),\n    exports([analyze, transform])\n], Code).\n```\n\nUse the PyodideRunner to call functions from JavaScript:\n\n```javascript\nconst pyodide = new PyodideRunner();\nawait pyodide.callFunction(pythonCode, 'analyze', arg1, arg2);\n```\n\nGenerate a loader with:\n\n```prolog\ngenerate_pyodide_loader([packages([numpy])], JSCode).\n```\n\nThis creates a class for managing Pyodide initialization and calling Python functions. See skill_browser_python.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_browser_python_004_q2", "cluster_id": "skill_browser_python_004", "question": "How do I invoke Python code from JS?", "answer": "To invoke Python code from JavaScript, export your Python functions when compiling the Pyodide module using the `exports` option:\n\n```prolog\ncompile_pyodide_module(processor, [\n    packages([numpy]),\n    exports([analyze, transform])\n], Code).\n```\n\nThen use the PyodideRunner class to call the exported functions from JavaScript:\n\n```javascript\nconst pyodide = new PyodideRunner();\nawait pyodide.init();\nconst result = await pyodide.callFunction('analyze', arg1, arg2);\n```\n\nThe `exports` list specifies which Python functions are accessible from JavaScript. The PyodideRunner handles Pyodide initialization and provides `callFunction()` to invoke any exported Python function by name with arguments.", "question_type": "long", "topics": ["Quickstart", "Browser Python (Pyodide)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["javascript", "interop", "python-js", "pyodide", "function-calls"], "related_skills": ["skill_browser_python.md"], "related_docs": ["src/unifyweaver/targets/python_pyodide_target.pl"], "original_answer": "Export Python functions when compiling your module:\n\n```prolog\ncompile_pyodide_module(processor, [\n    packages([numpy]),\n    exports([analyze, transform])\n], Code).\n```\n\nUse the PyodideRunner to call functions from JavaScript:\n\n```javascript\nconst pyodide = new PyodideRunner();\nawait pyodide.callFunction(pythonCode, 'analyze', arg1, arg2);\n```\n\nGenerate a loader with:\n\n```prolog\ngenerate_pyodide_loader([packages([numpy])], JSCode).\n```\n\nThis creates a class for managing Pyodide initialization and calling Python functions. See skill_browser_python.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_browser_python_004_q3", "cluster_id": "skill_browser_python_004", "question": "How do I make Python functions accessible to JavaScript?", "answer": "To make Python functions accessible to JavaScript, export them when compiling your Pyodide module using the `exports` option:\n\n```prolog\ncompile_pyodide_module(processor, [\n    packages([numpy]),\n    exports([analyze, transform])\n], Code).\n```\n\nThis generates a Python module with an EXPORTS registry. Then use PyodideRunner in JavaScript to call these functions:\n\n```javascript\nconst pyodide = new PyodideRunner();\nawait pyodide.init();\nconst result = await pyodide.callFunction('analyze', arg1, arg2);\n```\n\nAlternatively, generate a loader to handle initialization:\n\n```prolog\ngenerate_pyodide_loader([packages([numpy])], JSCode).\n```\n\nThe exported functions are accessible via the EXPORTS dictionary in the compiled module, allowing seamless JavaScript-Python interoperability.", "question_type": "long", "topics": ["Quickstart", "Browser Python (Pyodide)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["javascript", "interop", "python-js", "pyodide", "function-calls"], "related_skills": ["skill_browser_python.md"], "related_docs": ["src/unifyweaver/targets/python_pyodide_target.pl"], "original_answer": "Export Python functions when compiling your module:\n\n```prolog\ncompile_pyodide_module(processor, [\n    packages([numpy]),\n    exports([analyze, transform])\n], Code).\n```\n\nUse the PyodideRunner to call functions from JavaScript:\n\n```javascript\nconst pyodide = new PyodideRunner();\nawait pyodide.callFunction(pythonCode, 'analyze', arg1, arg2);\n```\n\nGenerate a loader with:\n\n```prolog\ngenerate_pyodide_loader([packages([numpy])], JSCode).\n```\n\nThis creates a class for managing Pyodide initialization and calling Python functions. See skill_browser_python.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_browser_python_005_q0", "cluster_id": "skill_browser_python_005", "question": "How do I prevent Python computations from blocking my web page?", "answer": "Use Web Workers to run Python computations in a background thread, preventing UI blocking. Compile your Python module with Pyodide, then generate a worker script that runs independently from your main thread.\n\nExample:\n```prolog\ncompile_pyodide_module(compute, [\n    packages([numpy, scipy]),\n    exports([fft, optimize, integrate])\n], ComputeCode).\n\ngenerate_pyodide_worker([packages([numpy, scipy])], WorkerCode).\n```\n\nIn your main thread, communicate with the worker:\n```javascript\nconst worker = new Worker('pyodide-worker.js');\nworker.postMessage({id: 1, code: 'import numpy as np; result = np.array([1,2,3]).tolist()'});\nworker.onmessage = (event) => console.log('Result:', event.data.data);\n```\n\nThis offloads CPU-intensive Python tasks to a separate thread, keeping your web page responsive during heavy computations.", "question_type": "long", "topics": ["Quickstart", "Browser Python (Pyodide)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["web-worker", "background-execution", "performance", "async", "pyodide"], "related_skills": ["skill_browser_python.md"], "related_docs": ["src/unifyweaver/targets/python_pyodide_target.pl"], "original_answer": "Use Web Workers to run Python in a background thread:\n\n```prolog\ncompile_pyodide_module(compute, [\n    packages([numpy, scipy]),\n    exports([fft, optimize, integrate])\n], ComputeCode).\n\ngenerate_pyodide_worker([packages([numpy, scipy])], WorkerCode).\n```\n\nThen communicate with the worker from your main thread:\n\n```javascript\nconst worker = new Worker('pyodide-worker.js');\nworker.postMessage({id: 1, code: 'import numpy as np; np.array([1,2,3]).tolist()'});\nworker.onmessage = (event) => console.log('Result:', event.data.data);\n```\n\nThis prevents UI blocking during CPU-intensive tasks. See skill_browser_python.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer mentions 'generate_pyodide_worker' function but this is not documented in the skill document provided. The approach is correct (Web Workers + Pyodide), but the specific API reference may not be accurate. The core concept directly addresses the question, but confidence is reduced due to undocumented API usage."}
{"pair_id": "skill_browser_python_005_q1", "cluster_id": "skill_browser_python_005", "question": "Can I run heavy Python calculations without freezing the UI?", "answer": "Yes, use Web Workers to run Python calculations in background threads. Compile your Pyodide module with `compile_pyodide_module/3`, then spawn it in a dedicated worker:\n\n```prolog\ncompile_pyodide_module(compute, [\n    packages([numpy, scipy]),\n    exports([fft, optimize, integrate])\n], ComputeCode).\n\ngenerate_pyodide_worker([packages([numpy, scipy])], WorkerCode).\n```\n\nCommunicate from your main thread:\n\n```javascript\nconst worker = new Worker('pyodide-worker.js');\nworker.postMessage({id: 1, func: 'fft', args: [arrayData]});\nworker.onmessage = (event) => {\n  console.log('Result:', event.data);\n  // UI remains responsive\n};\n```\n\nThis offloads CPU-intensive NumPy/SciPy operations to a background thread, keeping your UI responsive during heavy calculations.", "question_type": "long", "topics": ["Quickstart", "Browser Python (Pyodide)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["web-worker", "background-execution", "performance", "async", "pyodide"], "related_skills": ["skill_browser_python.md"], "related_docs": ["src/unifyweaver/targets/python_pyodide_target.pl"], "original_answer": "Use Web Workers to run Python in a background thread:\n\n```prolog\ncompile_pyodide_module(compute, [\n    packages([numpy, scipy]),\n    exports([fft, optimize, integrate])\n], ComputeCode).\n\ngenerate_pyodide_worker([packages([numpy, scipy])], WorkerCode).\n```\n\nThen communicate with the worker from your main thread:\n\n```javascript\nconst worker = new Worker('pyodide-worker.js');\nworker.postMessage({id: 1, code: 'import numpy as np; np.array([1,2,3]).tolist()'});\nworker.onmessage = (event) => console.log('Result:', event.data.data);\n```\n\nThis prevents UI blocking during CPU-intensive tasks. See skill_browser_python.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer references `generate_pyodide_worker/2` which isn't documented in the skill document itself. The answer is technically sound but the exact API may differ from actual implementation. The tailored version assumes standard Web Worker patterns which are widely supported."}
{"pair_id": "skill_browser_python_005_q2", "cluster_id": "skill_browser_python_005", "question": "How do I execute Python in a background thread?", "answer": "To execute Python in a background thread using Pyodide, use Web Workers. First, compile your Python module with the necessary packages:\n\n```prolog\ncompile_pyodide_module(compute, [\n    packages([numpy, scipy]),\n    exports([fft, optimize, integrate])\n], ComputeCode).\n\ngenerate_pyodide_worker([packages([numpy, scipy])], WorkerCode).\n```\n\nThen create a worker file and communicate from your main thread:\n\n```javascript\nconst worker = new Worker('pyodide-worker.js');\nworker.postMessage({id: 1, code: 'import numpy as np; np.array([1,2,3]).tolist()'});\nworker.onmessage = (event) => console.log('Result:', event.data.data);\n```\n\nWeb Workers run Python in a separate thread, preventing UI blocking during CPU-intensive NumPy/SciPy computations. The worker communicates results back to the main thread via message passing.", "question_type": "long", "topics": ["Quickstart", "Browser Python (Pyodide)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["web-worker", "background-execution", "performance", "async", "pyodide"], "related_skills": ["skill_browser_python.md"], "related_docs": ["src/unifyweaver/targets/python_pyodide_target.pl"], "original_answer": "Use Web Workers to run Python in a background thread:\n\n```prolog\ncompile_pyodide_module(compute, [\n    packages([numpy, scipy]),\n    exports([fft, optimize, integrate])\n], ComputeCode).\n\ngenerate_pyodide_worker([packages([numpy, scipy])], WorkerCode).\n```\n\nThen communicate with the worker from your main thread:\n\n```javascript\nconst worker = new Worker('pyodide-worker.js');\nworker.postMessage({id: 1, code: 'import numpy as np; np.array([1,2,3]).tolist()'});\nworker.onmessage = (event) => console.log('Result:', event.data.data);\n```\n\nThis prevents UI blocking during CPU-intensive tasks. See skill_browser_python.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer directly addresses the question with appropriate Prolog compilation functions and JavaScript Web Worker patterns. However, confidence is reduced because: (1) the skill document doesn't fully detail Web Worker-specific implementation details or threading guarantees, and (2) there's no mention of potential limitations (e.g., shared memory constraints, serialization overhead) that users should know about when using Web Workers with Python."}
{"pair_id": "skill_browser_python_005_q3", "cluster_id": "skill_browser_python_005", "question": "What is a Web Worker and how does it help with Python?", "answer": "A Web Worker is a background thread that runs JavaScript separately from the main UI thread. When combined with Pyodide (Python via WebAssembly), it prevents the browser UI from freezing during CPU-intensive Python computations.\n\nTo use Python in a Web Worker:\n\n1. Compile your Python code as a Pyodide module with the packages you need:\n```prolog\ncompile_pyodide_module(compute, [\n    packages([numpy, scipy]),\n    exports([fft, optimize, integrate])\n], ComputeCode).\n```\n\n2. Generate a worker file that runs this Python code:\n```prolog\ngenerate_pyodide_worker([packages([numpy, scipy])], WorkerCode).\n```\n\n3. Create and communicate with the worker from the main thread:\n```javascript\nconst worker = new Worker('pyodide-worker.js');\nworker.postMessage({id: 1, code: 'import numpy as np; np.array([1,2,3]).tolist()'});\nworker.onmessage = (event) => console.log('Result:', event.data.data);\n```\n\nThis approach keeps your UI responsive while Pyodide executes heavy numerical operations (NumPy, SciPy) in the background.", "question_type": "long", "topics": ["Quickstart", "Browser Python (Pyodide)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["web-worker", "background-execution", "performance", "async", "pyodide"], "related_skills": ["skill_browser_python.md"], "related_docs": ["src/unifyweaver/targets/python_pyodide_target.pl"], "original_answer": "Use Web Workers to run Python in a background thread:\n\n```prolog\ncompile_pyodide_module(compute, [\n    packages([numpy, scipy]),\n    exports([fft, optimize, integrate])\n], ComputeCode).\n\ngenerate_pyodide_worker([packages([numpy, scipy])], WorkerCode).\n```\n\nThen communicate with the worker from your main thread:\n\n```javascript\nconst worker = new Worker('pyodide-worker.js');\nworker.postMessage({id: 1, code: 'import numpy as np; np.array([1,2,3]).tolist()'});\nworker.onmessage = (event) => console.log('Result:', event.data.data);\n```\n\nThis prevents UI blocking during CPU-intensive tasks. See skill_browser_python.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer mentions 'Web Worker' but doesn't clearly explain what it is before diving into implementation. The tailored answer adds a definition, but the skill document itself doesn't have detailed Web Worker documentation, only references to generating workers. The confidence is moderate because the implementation details are clear, but the conceptual explanation of Web Workers themselves isn't comprehensively covered in the source material."}
{"pair_id": "skill_browser_python_006_q0", "cluster_id": "skill_browser_python_006", "question": "What are the performance characteristics of running Python in the browser?", "answer": "Performance characteristics of Pyodide:\n\n**Initial Load:** ~10-15 seconds (cached afterward). Mitigation: show loading indicators, pre-load during idle time, use Web Workers.\n\n**Memory:** ~2GB limit on 64-bit browsers. For large datasets, consider chunking your data.\n\n**Speed:** NumPy runs at ~60-80% of native Python speed. Fast for vectorized operations, but use Web Workers for CPU-intensive tasks.\n\n**Tip:** Display a loading indicator during initialization and cache Pyodide for faster subsequent loads.", "question_type": "medium", "topics": ["Quickstart", "Browser Python (Pyodide)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["performance", "optimization", "memory", "speed", "pyodide"], "related_skills": ["skill_browser_python.md"], "related_docs": ["src/unifyweaver/targets/python_pyodide_target.pl"], "original_answer": "Performance characteristics of Pyodide:\n\n**Initial Load:** ~10-15 seconds (cached afterward). Mitigation: show loading indicators, pre-load during idle time, use Web Workers.\n\n**Memory:** ~2GB limit on 64-bit browsers. For large datasets, consider chunking your data.\n\n**Speed:** NumPy runs at ~60-80% of native Python speed. Fast for vectorized operations, but use Web Workers for CPU-intensive tasks.\n\n**Tip:** Display a loading indicator during initialization and cache Pyodide for faster subsequent loads. See skill_browser_python.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_browser_python_006_q1", "cluster_id": "skill_browser_python_006", "question": "How fast is Pyodide compared to native Python?", "answer": "Pyodide runs NumPy at approximately 60-80% of native Python speed. Initial load takes 10-15 seconds (cached afterward), with ~2GB memory limit on 64-bit browsers. Vectorized operations are fast, but CPU-intensive tasks benefit from Web Workers. For performance-critical applications, consider chunking large datasets and pre-loading Pyodide during idle time.", "question_type": "medium", "topics": ["Quickstart", "Browser Python (Pyodide)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["performance", "optimization", "memory", "speed", "pyodide"], "related_skills": ["skill_browser_python.md"], "related_docs": ["src/unifyweaver/targets/python_pyodide_target.pl"], "original_answer": "Performance characteristics of Pyodide:\n\n**Initial Load:** ~10-15 seconds (cached afterward). Mitigation: show loading indicators, pre-load during idle time, use Web Workers.\n\n**Memory:** ~2GB limit on 64-bit browsers. For large datasets, consider chunking your data.\n\n**Speed:** NumPy runs at ~60-80% of native Python speed. Fast for vectorized operations, but use Web Workers for CPU-intensive tasks.\n\n**Tip:** Display a loading indicator during initialization and cache Pyodide for faster subsequent loads. See skill_browser_python.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_browser_python_006_q2", "cluster_id": "skill_browser_python_006", "question": "How much memory does browser Python use?", "answer": "Browser Python (Pyodide) running in 64-bit browsers has approximately a 2GB memory limit. For applications exceeding this, consider chunking your data into smaller portions or using Web Workers to manage memory more efficiently. The initial Pyodide runtime itself adds some overhead, but the exact memory footprint depends on which packages you load (NumPy, pandas, etc.). For memory-intensive operations, pre-allocate data structures and release variables when no longer needed.", "question_type": "medium", "topics": ["Quickstart", "Browser Python (Pyodide)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["performance", "optimization", "memory", "speed", "pyodide"], "related_skills": ["skill_browser_python.md"], "related_docs": ["src/unifyweaver/targets/python_pyodide_target.pl"], "original_answer": "Performance characteristics of Pyodide:\n\n**Initial Load:** ~10-15 seconds (cached afterward). Mitigation: show loading indicators, pre-load during idle time, use Web Workers.\n\n**Memory:** ~2GB limit on 64-bit browsers. For large datasets, consider chunking your data.\n\n**Speed:** NumPy runs at ~60-80% of native Python speed. Fast for vectorized operations, but use Web Workers for CPU-intensive tasks.\n\n**Tip:** Display a loading indicator during initialization and cache Pyodide for faster subsequent loads. See skill_browser_python.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "The base answer provides the 2GB limit but doesn't clarify if this is Pyodide-specific or a general browser constraint, nor does it detail memory overhead of specific packages. The answer makes reasonable inferences about optimization strategies but these aren't explicitly covered in the base answer."}
{"pair_id": "skill_browser_python_006_q3", "cluster_id": "skill_browser_python_006", "question": "What is the startup time for Pyodide?", "answer": "Pyodide's startup time is approximately 10-15 seconds for the initial load. This includes downloading and initializing the WebAssembly runtime and Python environment. Subsequent loads are significantly faster due to browser caching. To optimize startup, you can: display a loading indicator during initialization, pre-load Pyodide during idle time, or use Web Workers to load it in the background without blocking the UI.", "question_type": "medium", "topics": ["Quickstart", "Browser Python (Pyodide)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["performance", "optimization", "memory", "speed", "pyodide"], "related_skills": ["skill_browser_python.md"], "related_docs": ["src/unifyweaver/targets/python_pyodide_target.pl"], "original_answer": "Performance characteristics of Pyodide:\n\n**Initial Load:** ~10-15 seconds (cached afterward). Mitigation: show loading indicators, pre-load during idle time, use Web Workers.\n\n**Memory:** ~2GB limit on 64-bit browsers. For large datasets, consider chunking your data.\n\n**Speed:** NumPy runs at ~60-80% of native Python speed. Fast for vectorized operations, but use Web Workers for CPU-intensive tasks.\n\n**Tip:** Display a loading indicator during initialization and cache Pyodide for faster subsequent loads. See skill_browser_python.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_component_library_001_q0", "cluster_id": "skill_component_library_001", "question": "How do I create a modal dialog for confirming user actions?", "answer": "Use the `modal/3` predicate with type `confirm` to create a confirmation dialog. Specify the title, message, and set `dismissable(false)` to prevent accidental dismissal:\n\n```prolog\nmodal(confirm, [\n    title('Delete Item?'),\n    message('This cannot be undone.'),\n    dismissable(false)\n], Spec).\n```\n\nThen generate platform-specific code using `generate_component(Spec, Framework, Code)` where Framework is one of: `react_native`, `vue`, `flutter`, or `swiftui`. You can also add an `onClose/1` callback to handle the user's response.", "question_type": "medium", "topics": ["Quickstart", "Component Library"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["modal", "dialog", "ui-component"], "related_skills": ["skill_component_library.md", "skill_gui_design.md"], "related_docs": ["src/unifyweaver/components/component_library.pl"], "original_answer": "Use the `modal/3` predicate with type `confirm`. Set the title, message, and dismissable option:\n```prolog\nmodal(confirm, [\n    title('Delete Item?'),\n    message('This cannot be undone.'),\n    dismissable(false)\n], Spec).\n```\nThen generate code for your target framework with `generate_component(Spec, react_native, Code)`. Supported targets: react_native, vue, flutter, swiftui. See skill_component_library.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_component_library_001_q1", "cluster_id": "skill_component_library_001", "question": "How do I build a confirmation popup?", "answer": "Use the `modal/3` predicate with type `confirm` to build a confirmation popup. Set the title, message, and dismissable option:\n\n```prolog\nmodal(confirm, [\n    title('Delete Item?'),\n    message('This cannot be undone.'),\n    dismissable(false)\n], Spec).\n```\n\nThen generate platform-specific code using `generate_component(Spec, TargetFramework, Code)`. Supported frameworks: react_native, vue, flutter, swiftui.", "question_type": "medium", "topics": ["Quickstart", "Component Library"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["modal", "dialog", "ui-component"], "related_skills": ["skill_component_library.md", "skill_gui_design.md"], "related_docs": ["src/unifyweaver/components/component_library.pl"], "original_answer": "Use the `modal/3` predicate with type `confirm`. Set the title, message, and dismissable option:\n```prolog\nmodal(confirm, [\n    title('Delete Item?'),\n    message('This cannot be undone.'),\n    dismissable(false)\n], Spec).\n```\nThen generate code for your target framework with `generate_component(Spec, react_native, Code)`. Supported targets: react_native, vue, flutter, swiftui. See skill_component_library.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_component_library_001_q2", "cluster_id": "skill_component_library_001", "question": "What's the best way to show an alert dialog?", "answer": "Use the `alert_dialog/3` predicate to show an alert dialog. Specify the title, message, and confirmation options:\n\n```prolog\nalert_dialog('Delete Item?', [\n    message('This cannot be undone.'),\n    confirmText('Delete'),\n    onConfirm(handle_delete)\n], Spec).\n```\n\nThen generate code for your target framework: `generate_component(Spec, react_native, Code)`. Supported targets: react_native, vue, flutter, swiftui.", "question_type": "medium", "topics": ["Quickstart", "Component Library"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["modal", "dialog", "ui-component"], "related_skills": ["skill_component_library.md", "skill_gui_design.md"], "related_docs": ["src/unifyweaver/components/component_library.pl"], "original_answer": "Use the `modal/3` predicate with type `confirm`. Set the title, message, and dismissable option:\n```prolog\nmodal(confirm, [\n    title('Delete Item?'),\n    message('This cannot be undone.'),\n    dismissable(false)\n], Spec).\n```\nThen generate code for your target framework with `generate_component(Spec, react_native, Code)`. Supported targets: react_native, vue, flutter, swiftui. See skill_component_library.md for details.", "answer_tailored": true, "confidence": 0.75, "confidence_issues": "The base answer recommends `modal/3` with type `confirm`, but the skill document has a dedicated `alert_dialog/3` predicate which is more semantically appropriate for alert dialogs. The base answer is not incorrect but uses a less specific component."}
{"pair_id": "skill_component_library_002_q0", "cluster_id": "skill_component_library_002", "question": "How do I show success/error notifications to users?", "answer": "Use the `toast/3` predicate to show notifications:\n\n```prolog\ntoast('Item saved!', [type(success), duration(3000)], Spec).\ntoast('Network error', [type(error), position(top)], Spec).\n```\n\nSupported types: `success`, `error`, `warning`, `info`. After creating the spec, generate framework-specific code with `generate_component(Spec, Target, Code)` where Target is your framework (e.g., react_native, flutter). Duration is in milliseconds, and position can be `top`, `bottom`, or `center`.", "question_type": "medium", "topics": ["Quickstart", "Component Library"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["toast", "notification", "feedback"], "related_skills": ["skill_component_library.md", "skill_gui_design.md"], "related_docs": ["src/unifyweaver/components/component_library.pl"], "original_answer": "Use the `toast/3` predicate with the message and options:\n```prolog\ntoast('Item saved!', [type(success), duration(3000)], Spec).\ntoast('Network error', [type(error), position(top)], Spec).\n```\nSupported types: info, success, warning, error. Position options: top, bottom, center. Generate code with `generate_component(Spec, Target, Code)` for your framework. See skill_component_library.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_component_library_002_q1", "cluster_id": "skill_component_library_002", "question": "How do I display toast messages?", "answer": "Use the `toast/3` predicate to display toast notifications. Call `toast('Your message', [type(Type), duration(Ms), position(Pos)], Spec)` where type is one of: info, success, warning, error; duration is milliseconds (default 3000); and position is top, bottom, or center (default bottom). Then generate platform-specific code with `generate_component(Spec, TargetFramework, Code)`. Example: `toast('Item saved!', [type(success), duration(2000)], Spec), generate_component(Spec, react_native, Code)` generates a React Native toast component.", "question_type": "medium", "topics": ["Quickstart", "Component Library"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["toast", "notification", "feedback"], "related_skills": ["skill_component_library.md", "skill_gui_design.md"], "related_docs": ["src/unifyweaver/components/component_library.pl"], "original_answer": "Use the `toast/3` predicate with the message and options:\n```prolog\ntoast('Item saved!', [type(success), duration(3000)], Spec).\ntoast('Network error', [type(error), position(top)], Spec).\n```\nSupported types: info, success, warning, error. Position options: top, bottom, center. Generate code with `generate_component(Spec, Target, Code)` for your framework. See skill_component_library.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_component_library_002_q2", "cluster_id": "skill_component_library_002", "question": "What's the easiest way to show feedback notifications?", "answer": "Use the `toast/3` predicate for quick feedback notifications. It's the simplest approach:\n\n```prolog\ntoast('Item saved!', [type(success), duration(3000)], Spec),\ngenerate_component(Spec, react_native, Code).\n```\n\nToast supports four types: `success`, `error`, `warning`, and `info`. You can customize the display duration (in milliseconds), position (`top`, `bottom`, or `center`), and even add action buttons. For more persistent notifications, use `snackbar/3` or `banner/3` instead.", "question_type": "medium", "topics": ["Quickstart", "Component Library"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["toast", "notification", "feedback"], "related_skills": ["skill_component_library.md", "skill_gui_design.md"], "related_docs": ["src/unifyweaver/components/component_library.pl"], "original_answer": "Use the `toast/3` predicate with the message and options:\n```prolog\ntoast('Item saved!', [type(success), duration(3000)], Spec).\ntoast('Network error', [type(error), position(top)], Spec).\n```\nSupported types: info, success, warning, error. Position options: top, bottom, center. Generate code with `generate_component(Spec, Target, Code)` for your framework. See skill_component_library.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_component_library_003_q0", "cluster_id": "skill_component_library_003", "question": "How do I create reusable UI cards or list items?", "answer": "Use `card/3` for reusable content containers and `list_item/3` for list entries. `card/3` creates styled containers with optional title, subtitle, image, and elevation properties. `list_item/3` creates list row components with leading icons/avatars, text content, and tap handlers. Both generate platform-specific code for Vue, React Native, Flutter, and SwiftUI:\n\n```prolog\ncard(body_content, [\n    title('Article Title'),\n    subtitle('By Author'),\n    image('https://example.com/image.jpg'),\n    elevated(true)\n], Spec).\n\nlist_item(content, [\n    leading(icon_avatar),\n    subtitle('Description'),\n    onPress(handle_tap)\n], Spec).\n```\n\nGenerate platform-specific code with `generate_component(Spec, Platform, Code)` where Platform is `react_native`, `flutter`, `vue`, or `swiftui`.", "question_type": "medium", "topics": ["Quickstart", "Component Library"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["card", "list-item", "content-component"], "related_skills": ["skill_component_library.md", "skill_layout_system.md"], "related_docs": ["src/unifyweaver/components/component_library.pl"], "original_answer": "Use `card/3` for content containers or `list_item/3` for list entries:\n```prolog\ncard(body_content, [\n    title('Article Title'),\n    subtitle('By Author'),\n    image('https://example.com/image.jpg'),\n    elevated(true)\n], Spec).\n\nlist_item(content, [\n    leading(icon_avatar),\n    subtitle('Description'),\n    onPress(handle_tap)\n], Spec).\n```\nBoth support platform-specific code generation. See skill_component_library.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "Base answer references 'skill_component_library.md' but the skill document provided shows 'src/unifyweaver/components/component_library' module. The exact signature and available options for card/3 and list_item/3 are not fully detailed in the provided skill document excerpt, only modal, alert_dialog, toast, and snackbar are shown in detail."}
{"pair_id": "skill_component_library_003_q1", "cluster_id": "skill_component_library_003", "question": "How do I structure card components?", "answer": "To structure card components, use `card/3` with content and options. Basic structure:\n\n```prolog\ncard(body_content, [\n    title('Card Title'),\n    subtitle('Subtitle text'),\n    image('url_to_image'),\n    elevated(true)\n], Spec).\n```\n\nFor list-style cards, use `list_item/3`:\n\n```prolog\nlist_item(content, [\n    leading(icon_or_avatar),\n    subtitle('Item description'),\n    onPress(handler)\n], Spec).\n```\n\nBoth components generate platform-specific code for Vue, React Native, Flutter, and SwiftUI. Pass the resulting Spec to `generate_component/3` with your target platform.", "question_type": "medium", "topics": ["Quickstart", "Component Library"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["card", "list-item", "content-component"], "related_skills": ["skill_component_library.md", "skill_layout_system.md"], "related_docs": ["src/unifyweaver/components/component_library.pl"], "original_answer": "Use `card/3` for content containers or `list_item/3` for list entries:\n```prolog\ncard(body_content, [\n    title('Article Title'),\n    subtitle('By Author'),\n    image('https://example.com/image.jpg'),\n    elevated(true)\n], Spec).\n\nlist_item(content, [\n    leading(icon_avatar),\n    subtitle('Description'),\n    onPress(handle_tap)\n], Spec).\n```\nBoth support platform-specific code generation. See skill_component_library.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_component_library_003_q2", "cluster_id": "skill_component_library_003", "question": "What's the pattern for list item components?", "answer": "Use `list_item/3` for list entries. Basic syntax: `list_item(content, [leading(icon_avatar), subtitle('Description'), onPress(handle_tap)], Spec)`. Key options include `leading(Element)` for prefix content, `title(T)` for main text, `subtitle(S)` for secondary text, `trailing(Element)` for suffix content, and `onPress(Callback)` for tap handlers. For grouped lists with headers, combine with `card/3` containers. Both components support platform-specific code generation across Vue, React Native, Flutter, and SwiftUI.", "question_type": "medium", "topics": ["Quickstart", "Component Library"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["card", "list-item", "content-component"], "related_skills": ["skill_component_library.md", "skill_layout_system.md"], "related_docs": ["src/unifyweaver/components/component_library.pl"], "original_answer": "Use `card/3` for content containers or `list_item/3` for list entries:\n```prolog\ncard(body_content, [\n    title('Article Title'),\n    subtitle('By Author'),\n    image('https://example.com/image.jpg'),\n    elevated(true)\n], Spec).\n\nlist_item(content, [\n    leading(icon_avatar),\n    subtitle('Description'),\n    onPress(handle_tap)\n], Spec).\n```\nBoth support platform-specific code generation. See skill_component_library.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "Base answer mentions list_item/3 but doesn't fully detail all available options. Documentation appears truncated, limiting confidence in completeness of option list. Answer infers standard list patterns but cannot verify all supported parameters without full documentation."}
{"pair_id": "skill_component_library_004_q0", "cluster_id": "skill_component_library_004", "question": "How do I generate code for different platforms like React Native and Flutter?", "answer": "Use `generate_component/3` to generate platform-specific code by specifying the target framework as the second argument:\n\n```prolog\ngenerate_component(Spec, react_native, Code).\ngenerate_component(Spec, vue, Code).\ngenerate_component(Spec, flutter, Code).\ngenerate_component(Spec, swiftui, Code).\n```\n\nAlternatively, use target-specific generators like `generate_vue_component(Spec, Code)`. Each component automatically adapts to the platform's native patterns and conventions.", "question_type": "medium", "topics": ["Quickstart", "Component Library"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["code-generation", "cross-platform", "multi-framework"], "related_skills": ["skill_component_library.md"], "related_docs": ["src/unifyweaver/components/component_library.pl"], "original_answer": "Use `generate_component/3` to generate code for any supported target framework:\n```prolog\ngenerate_component(Spec, react_native, Code).\ngenerate_component(Spec, vue, Code).\ngenerate_component(Spec, flutter, Code).\ngenerate_component(Spec, swiftui, Code).\n```\nOr use target-specific generators like `generate_vue_component(Spec, Code)`. Each component adapts to the platform's native patterns and conventions. See skill_component_library.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_component_library_004_q1", "cluster_id": "skill_component_library_004", "question": "How do I target multiple mobile frameworks?", "answer": "Use `generate_component/3` to generate code for multiple mobile frameworks. Pass the same Spec to different framework targets:\n\n```prolog\ngenerate_component(Spec, react_native, Code1).\ngenerate_component(Spec, flutter, Code2).\ngenerate_component(Spec, swiftui, Code3).\n```\n\nEach call adapts the component to that platform's native patterns. Alternatively, use framework-specific generators like `generate_react_native_component(Spec, Code)`. The Component Library handles cross-platform conversion automatically.", "question_type": "medium", "topics": ["Quickstart", "Component Library"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["code-generation", "cross-platform", "multi-framework"], "related_skills": ["skill_component_library.md"], "related_docs": ["src/unifyweaver/components/component_library.pl"], "original_answer": "Use `generate_component/3` to generate code for any supported target framework:\n```prolog\ngenerate_component(Spec, react_native, Code).\ngenerate_component(Spec, vue, Code).\ngenerate_component(Spec, flutter, Code).\ngenerate_component(Spec, swiftui, Code).\n```\nOr use target-specific generators like `generate_vue_component(Spec, Code)`. Each component adapts to the platform's native patterns and conventions. See skill_component_library.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_component_library_004_q2", "cluster_id": "skill_component_library_004", "question": "Can I generate Vue and SwiftUI code?", "answer": "Yes, you can generate both Vue and SwiftUI code using the component library. Use `generate_component/3` with the appropriate target framework: `generate_component(Spec, vue, Code)` for Vue components and `generate_component(Spec, swiftui, Code)` for SwiftUI components. Alternatively, use the target-specific generators like `generate_vue_component(Spec, Code)` for Vue. Each generated component adapts to the platform's native patterns and conventions.", "question_type": "medium", "topics": ["Quickstart", "Component Library"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["code-generation", "cross-platform", "multi-framework"], "related_skills": ["skill_component_library.md"], "related_docs": ["src/unifyweaver/components/component_library.pl"], "original_answer": "Use `generate_component/3` to generate code for any supported target framework:\n```prolog\ngenerate_component(Spec, react_native, Code).\ngenerate_component(Spec, vue, Code).\ngenerate_component(Spec, flutter, Code).\ngenerate_component(Spec, swiftui, Code).\n```\nOr use target-specific generators like `generate_vue_component(Spec, Code)`. Each component adapts to the platform's native patterns and conventions. See skill_component_library.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_component_library_005_q0", "cluster_id": "skill_component_library_005", "question": "How do I add visual feedback like loading spinners or progress bars?", "answer": "Use progress components for visual feedback. Spinner for loading indicators: `spinner([size(medium), color(primary)], Spec)` supports small/medium/large sizes. Progress bar for linear progress: `progress_bar(75, [max(100), showLabel(true), color(primary)], Spec)` displays percentage. Progress circle for circular progress: `progress_circle(60, [size(48), showValue(true), color(primary)], Spec)` shows completion visually. Generate platform-specific code with `generate_component(Spec, Target, Code)` where Target is react_native, vue, flutter, or swiftui.", "question_type": "medium", "topics": ["Quickstart", "Component Library"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["progress", "spinner", "loading-state"], "related_skills": ["skill_component_library.md"], "related_docs": ["src/unifyweaver/components/component_library.pl"], "original_answer": "Use progress components for visual feedback:\n```prolog\nspinner([size(medium), color(primary)], Spec).\nprogress_bar(75, [max(100), showLabel(true), color(primary)], Spec).\nprogress_circle(60, [size(48), showValue(true), color(primary)], Spec).\n```\nSpinner supports small/medium/large sizes. Progress bar and circle show percentage completion. Generate platform-specific code with `generate_component(Spec, Target, Code)`. See skill_component_library.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_component_library_005_q1", "cluster_id": "skill_component_library_005", "question": "How do I show loading states?", "answer": "Use progress components to display loading states. Use `spinner([size(medium), color(primary)], Spec)` for indeterminate loading, `progress_bar(75, [max(100), showLabel(true), color(primary)], Spec)` for determinate progress with percentage, or `progress_circle(60, [size(48), showValue(true), color(primary)], Spec)` for circular progress. Spinners support small/medium/large sizes. Generate platform-specific code with `generate_component(Spec, Target, Code)` where Target is react_native, vue, flutter, or swiftui.", "question_type": "medium", "topics": ["Quickstart", "Component Library"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["progress", "spinner", "loading-state"], "related_skills": ["skill_component_library.md"], "related_docs": ["src/unifyweaver/components/component_library.pl"], "original_answer": "Use progress components for visual feedback:\n```prolog\nspinner([size(medium), color(primary)], Spec).\nprogress_bar(75, [max(100), showLabel(true), color(primary)], Spec).\nprogress_circle(60, [size(48), showValue(true), color(primary)], Spec).\n```\nSpinner supports small/medium/large sizes. Progress bar and circle show percentage completion. Generate platform-specific code with `generate_component(Spec, Target, Code)`. See skill_component_library.md for details.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null}
{"pair_id": "skill_component_library_005_q2", "cluster_id": "skill_component_library_005", "question": "How do I display progress to users?", "answer": "Use progress components to display user progress:\n\n```prolog\nspinner([size(medium), color(primary)], Spec).\nprogress_bar(75, [max(100), showLabel(true), color(primary)], Spec).\nprogress_circle(60, [size(48), showValue(true), color(primary)], Spec).\n```\n\nChoose based on your needs:\n- **Spinner**: Indeterminate loading state (small/medium/large sizes)\n- **Progress bar**: Show percentage completion with optional label\n- **Progress circle**: Circular percentage display with optional value indicator\n\nGenerate platform-specific code using `generate_component(Spec, Target, Code)` where Target is `react_native`, `vue`, `flutter`, or `swiftui`.", "question_type": "medium", "topics": ["Quickstart", "Component Library"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["progress", "spinner", "loading-state"], "related_skills": ["skill_component_library.md"], "related_docs": ["src/unifyweaver/components/component_library.pl"], "original_answer": "Use progress components for visual feedback:\n```prolog\nspinner([size(medium), color(primary)], Spec).\nprogress_bar(75, [max(100), showLabel(true), color(primary)], Spec).\nprogress_circle(60, [size(48), showValue(true), color(primary)], Spec).\n```\nSpinner supports small/medium/large sizes. Progress bar and circle show percentage completion. Generate platform-specific code with `generate_component(Spec, Target, Code)`. See skill_component_library.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_component_library_006_q0", "cluster_id": "skill_component_library_006", "question": "How do I create interactive input components like search bars and ratings?", "answer": "Use input components to create interactive search bars and ratings:\n\n```prolog\nsearch_bar([placeholder('Search...'), showCancel(true), autoFocus(false)], Spec),\ngenerate_component(Spec, react_native, Code).\n\nrating(4, [max(5), allowHalf(true), onChange(handle_change)], Spec),\ngenerate_component(Spec, vue, Code).\n```\n\nSearch bars support options like placeholder text, cancel button, and auto-focus. Rating components let you set max value, allow half-star ratings, and handle change events. Both generate native code for react_native, vue, flutter, or swiftui. For more input options (stepper, slider), see the skill documentation.", "question_type": "medium", "topics": ["Quickstart", "Component Library"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["input", "search", "rating", "slider"], "related_skills": ["skill_component_library.md"], "related_docs": ["src/unifyweaver/components/component_library.pl"], "original_answer": "Use input components for user interactions:\n```prolog\nsearch_bar([placeholder('Search...'), showCancel(true), autoFocus(false)], Spec).\nrating(4, [max(5), allowHalf(true), onChange(handle_change)], Spec).\nstepper(5, [min(0), max(99), step(1), onChange(handle_change)], Spec).\nslider_input(50, [min(0), max(100), showValue(true)], Spec).\n```\nEach component generates native code for react_native, vue, flutter, or swiftui targets. See skill_component_library.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_component_library_006_q1", "cluster_id": "skill_component_library_006", "question": "How do I build a search interface?", "answer": "To build a search interface, use the search_bar component with your desired options:\n\n```prolog\nsearch_bar([placeholder('Search...'), showCancel(true), autoFocus(false)], Spec),\ngenerate_component(Spec, react_native, Code).\n```\n\nYou can combine this with other input components for filtering:\n- slider_input for range filtering\n- rating for quality/relevance filtering\n- stepper for quantity/limit controls\n\nEach component generates native code for react_native, vue, flutter, or swiftui targets. The search_bar component supports placeholder text, cancel button visibility, and auto-focus settings. See skill_component_library.md for complete API documentation and additional input components.", "question_type": "medium", "topics": ["Quickstart", "Component Library"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["input", "search", "rating", "slider"], "related_skills": ["skill_component_library.md"], "related_docs": ["src/unifyweaver/components/component_library.pl"], "original_answer": "Use input components for user interactions:\n```prolog\nsearch_bar([placeholder('Search...'), showCancel(true), autoFocus(false)], Spec).\nrating(4, [max(5), allowHalf(true), onChange(handle_change)], Spec).\nstepper(5, [min(0), max(99), step(1), onChange(handle_change)], Spec).\nslider_input(50, [min(0), max(100), showValue(true)], Spec).\n```\nEach component generates native code for react_native, vue, flutter, or swiftui targets. See skill_component_library.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "The base answer covers search_bar but doesn't fully explain how to build a complete search interface (results display, filtering logic, form composition). The base answer mixes search_bar with other input components (rating, stepper, slider_input) that support filtering but doesn't clearly explain search interface architecture or how these components work together for search."}
{"pair_id": "skill_component_library_006_q2", "cluster_id": "skill_component_library_006", "question": "How do I add a rating or star input?", "answer": "Use the `rating/3` component for star input:\n\n```prolog\nrating(InitialValue, Options, Spec).\n```\n\nCommon options:\n- `max(N)` - maximum rating value (default: 5)\n- `allowHalf(true|false)` - enable half-star ratings (default: false)\n- `onChange(Callback)` - handler for rating changes\n- `readOnly(true|false)` - disable user interaction\n- `size(Size)` - star size\n\nExample:\n```prolog\nrating(4, [max(5), allowHalf(true), onChange(handle_rating_change)], Spec),\ngenerate_component(Spec, react_native, Code).\n```\n\nThe component generates native code for Vue, React Native, Flutter, and SwiftUI targets.", "question_type": "medium", "topics": ["Quickstart", "Component Library"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["input", "search", "rating", "slider"], "related_skills": ["skill_component_library.md"], "related_docs": ["src/unifyweaver/components/component_library.pl"], "original_answer": "Use input components for user interactions:\n```prolog\nsearch_bar([placeholder('Search...'), showCancel(true), autoFocus(false)], Spec).\nrating(4, [max(5), allowHalf(true), onChange(handle_change)], Spec).\nstepper(5, [min(0), max(99), step(1), onChange(handle_change)], Spec).\nslider_input(50, [min(0), max(100), showValue(true)], Spec).\n```\nEach component generates native code for react_native, vue, flutter, or swiftui targets. See skill_component_library.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_data_binding_001_q0", "cluster_id": "skill_data_binding_001", "question": "How do I connect Prolog data to React components so they update in real-time?", "answer": "To connect Prolog data to React components with real-time updates, use the data binding generator. First, define your data source using `data_source(Name, [predicate(P/A), fields([...]), primary_key(K), refresh_interval(Ms), ...])`. The `refresh_interval` parameter enables polling for real-time synchronization. Next, create a binding with `binding(Component, Source, [x_axis(...), y_axis(...), ...])` to map your Prolog fields to React component props. Finally, generate the React hook with `generate_binding_hook(Component, HookCode)`. This creates a custom hook that automatically fetches data at your specified interval, manages state, and re-renders your component whenever the underlying Prolog data changes.", "question_type": "medium", "topics": ["Quickstart", "Data Binding"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["data-binding", "react", "prolog", "reactive"], "related_skills": ["skill_data_binding.md"], "related_docs": ["src/unifyweaver/glue/data_binding_generator.pl"], "original_answer": "Use the data binding generator to create hooks that sync Prolog data with React. Define a data source with `data_source(Name, [predicate(P/A), fields([...]), ...])`, then create a binding with `binding(Component, Source, [x_axis(...), y_axis(...), ...])`. Finally, generate the React hook with `generate_binding_hook(Component, HookCode)`. This creates a custom hook that fetches and manages your data. See skill_data_binding.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_data_binding_001_q1", "cluster_id": "skill_data_binding_001", "question": "How do I bind Prolog predicates to React UI?", "answer": "To bind Prolog predicates to React UI, use the data binding generator. First, define a data source that references your Prolog predicate: `data_source(name, [predicate(your_predicate/arity), fields([field1, field2, ...]), primary_key(id)])`. Then create a binding that maps the source to your React component: `binding(component_name, source_name, [x_axis(field), y_axis(field), ...])`. Finally, generate the React hook with `generate_binding_hook(component_name, HookCode)`. This produces a custom hook that automatically fetches, updates, and manages your Prolog data with reactive UI synchronization.", "question_type": "medium", "topics": ["Quickstart", "Data Binding"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["data-binding", "react", "prolog", "reactive"], "related_skills": ["skill_data_binding.md"], "related_docs": ["src/unifyweaver/glue/data_binding_generator.pl"], "original_answer": "Use the data binding generator to create hooks that sync Prolog data with React. Define a data source with `data_source(Name, [predicate(P/A), fields([...]), ...])`, then create a binding with `binding(Component, Source, [x_axis(...), y_axis(...), ...])`. Finally, generate the React hook with `generate_binding_hook(Component, HookCode)`. This creates a custom hook that fetches and manages your data. See skill_data_binding.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_data_binding_001_q2", "cluster_id": "skill_data_binding_001", "question": "How do I make React components reactive to Prolog data changes?", "answer": "Make React components reactive to Prolog data changes by using the data binding generator. First, define a data source with `data_source(Name, [predicate(P/A), fields([...]), refresh_interval(Ms), ...])` to specify your Prolog data and polling behavior. Then create a binding with `binding(Component, Source, [x_axis(...), y_axis(...), ...])` to map Prolog fields to UI elements. Finally, generate the React hook with `generate_binding_hook(Component, HookCode)`. This creates a custom hook that automatically fetches data at the specified interval and updates your component whenever the underlying Prolog data changes. For real-time two-way synchronization, configure WebSocket sync in your binding configuration.", "question_type": "medium", "topics": ["Quickstart", "Data Binding"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["data-binding", "react", "prolog", "reactive"], "related_skills": ["skill_data_binding.md"], "related_docs": ["src/unifyweaver/glue/data_binding_generator.pl"], "original_answer": "Use the data binding generator to create hooks that sync Prolog data with React. Define a data source with `data_source(Name, [predicate(P/A), fields([...]), ...])`, then create a binding with `binding(Component, Source, [x_axis(...), y_axis(...), ...])`. Finally, generate the React hook with `generate_binding_hook(Component, HookCode)`. This creates a custom hook that fetches and manages your data. See skill_data_binding.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_data_binding_002_q0", "cluster_id": "skill_data_binding_002", "question": "How do I create a chart that displays data from Prolog?", "answer": "To create a chart displaying Prolog data, define a data source with `data_source(Name, [predicate(P/A), fields([...]), ...])`, then create a binding with `binding(ChartName, SourceName, [x_axis(Field), y_axis(Field), series(Field)])`. For example: `data_source(sales, [predicate(sales_record/4), fields([date, product, quantity, amount])])` and `binding(sales_chart, sales, [x_axis(date), y_axis(amount), series(product)])`. Finally, generate the React hook with `generate_binding_hook(sales_chart, HookCode)` to handle data fetching and chart updates automatically.", "question_type": "medium", "topics": ["Quickstart", "Data Binding"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["data-binding", "charts", "visualization"], "related_skills": ["skill_data_binding.md"], "related_docs": ["src/unifyweaver/glue/data_binding_generator.pl"], "original_answer": "Define your data source and then create a binding specifying the chart axes. For example: `data_source(sales, [predicate(sales_record/4), fields([date, product, quantity, amount])])` and `binding(line_chart, sales, [x_axis(date), y_axis(amount), series(product)])`. Then generate the hook with `generate_binding_hook(line_chart, HookCode)`. The generated hook handles fetching and updating chart data automatically. See skill_data_binding.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_data_binding_002_q1", "cluster_id": "skill_data_binding_002", "question": "How do I bind a Prolog data source to a chart?", "answer": "To bind a Prolog data source to a chart, define your data source with `data_source(Name, [predicate(P/A), fields([...]),...])`, then create a binding with `binding(ComponentName, SourceName, [x_axis(Field), y_axis(Field), series(Field)])`. For example: `data_source(sales, [predicate(sales_record/4), fields([date, product, quantity, amount])])` and `binding(line_chart, sales, [x_axis(date), y_axis(amount), series(product)])`. Finally, generate the React hook with `generate_binding_hook(line_chart, HookCode)`, which automatically handles data fetching and updates.", "question_type": "medium", "topics": ["Quickstart", "Data Binding"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["data-binding", "charts", "visualization"], "related_skills": ["skill_data_binding.md"], "related_docs": ["src/unifyweaver/glue/data_binding_generator.pl"], "original_answer": "Define your data source and then create a binding specifying the chart axes. For example: `data_source(sales, [predicate(sales_record/4), fields([date, product, quantity, amount])])` and `binding(line_chart, sales, [x_axis(date), y_axis(amount), series(product)])`. Then generate the hook with `generate_binding_hook(line_chart, HookCode)`. The generated hook handles fetching and updating chart data automatically. See skill_data_binding.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_data_binding_002_q2", "cluster_id": "skill_data_binding_002", "question": "What's the easiest way to visualize Prolog data in React?", "answer": "The easiest way is to define a data source for your Prolog predicates, then create a binding that maps your data to chart axes. For example: `data_source(sales, [predicate(sales_record/4), fields([date, product, quantity, amount])])` defines your data, and `binding(line_chart, sales, [x_axis(date), y_axis(amount), series(product)])` maps it to a chart. Finally, `generate_binding_hook(line_chart, HookCode)` generates a React hook that automatically handles data fetching and updates. This approach works for various visualization types including line charts, bar charts, and network graphs.", "question_type": "medium", "topics": ["Quickstart", "Data Binding"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["data-binding", "charts", "visualization"], "related_skills": ["skill_data_binding.md"], "related_docs": ["src/unifyweaver/glue/data_binding_generator.pl"], "original_answer": "Define your data source and then create a binding specifying the chart axes. For example: `data_source(sales, [predicate(sales_record/4), fields([date, product, quantity, amount])])` and `binding(line_chart, sales, [x_axis(date), y_axis(amount), series(product)])`. Then generate the hook with `generate_binding_hook(line_chart, HookCode)`. The generated hook handles fetching and updating chart data automatically. See skill_data_binding.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_data_binding_003_q0", "cluster_id": "skill_data_binding_003", "question": "How do I create an editable data table that updates Prolog when data changes?", "answer": "Create an editable data table by defining a two-way binding with the `two_way_binding/3` predicate. Specify your data source, list the columns to display, mark which columns are editable, and provide an `on_edit` handler to process updates back to Prolog:\n\n```prolog\ntwo_way_binding(data_table, sales, [\n    columns([date, product, quantity, amount]),\n    editable([quantity, amount]),\n    on_edit(update_record)\n]).\n```\n\nThen generate the React hook for displaying and editing:\n\n```prolog\ngenerate_binding_hook(data_table, HookCode).\n```\n\nAnd generate the mutation handler to process edits back to Prolog:\n\n```prolog\ngenerate_mutation_handler(sales, MutationCode).\n```\n\nThe hook provides real-time reactivity while the mutation handler ensures changes sync back to your Prolog data source.", "question_type": "medium", "topics": ["Quickstart", "Data Binding"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["data-binding", "two-way-binding", "forms", "mutations"], "related_skills": ["skill_data_binding.md"], "related_docs": ["src/unifyweaver/glue/data_binding_generator.pl"], "original_answer": "Use two-way binding to enable editing. Define your data source, then create a two-way binding: `two_way_binding(data_table, sales, [columns([date, product, quantity]), editable([quantity, amount]), on_edit(update_record)])`. Generate both the binding hook with `generate_binding_hook(data_table, HookCode)` and the mutation handler with `generate_mutation_handler(sales, MutationCode)`. This provides both data fetching and update capabilities. See skill_data_binding.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer assumes familiarity with the two-way binding syntax and doesn't explain the connection between the three components (data source, binding definition, and handlers). The tailored version clarifies this relationship but relies on correct predicate signatures that aren't fully verified in the skill document excerpt provided."}
{"pair_id": "skill_data_binding_003_q1", "cluster_id": "skill_data_binding_003", "question": "How do I make a two-way binding between a table and Prolog data?", "answer": "To create a two-way binding between a table and Prolog data, define your data source with `data_source(table_name, [predicate(P/A), fields([...]), primary_key(K)])`, then establish the binding with `two_way_binding(table_component, table_name, [columns([field1, field2, ...]), editable([editable_fields]), on_edit(update_handler)])`. Generate the React hook using `generate_binding_hook(table_component, HookCode)` to handle data fetching and state management, and create the mutation handler with `generate_mutation_handler(table_name, MutationCode)` to process user edits back to Prolog. This combines reactive UI updates with form write-back capabilities.", "question_type": "medium", "topics": ["Quickstart", "Data Binding"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["data-binding", "two-way-binding", "forms", "mutations"], "related_skills": ["skill_data_binding.md"], "related_docs": ["src/unifyweaver/glue/data_binding_generator.pl"], "original_answer": "Use two-way binding to enable editing. Define your data source, then create a two-way binding: `two_way_binding(data_table, sales, [columns([date, product, quantity]), editable([quantity, amount]), on_edit(update_record)])`. Generate both the binding hook with `generate_binding_hook(data_table, HookCode)` and the mutation handler with `generate_mutation_handler(sales, MutationCode)`. This provides both data fetching and update capabilities. See skill_data_binding.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer assumes familiarity with the framework's mutation handler generation. Real usage might require additional configuration for conflict resolution or transaction handling that isn't explicitly mentioned."}
{"pair_id": "skill_data_binding_003_q2", "cluster_id": "skill_data_binding_003", "question": "How do I build a form that syncs with Prolog?", "answer": "To build a form that syncs with Prolog, use two-way binding. First, define your data source with `data_source(form_name, [predicate(your_pred/arity), fields([field_list]), primary_key(id)])`. Then create a two-way binding: `two_way_binding(form_component, form_name, [columns([field_names]), editable([field_names]), on_edit(update_record)])`. Generate the React hook with `generate_binding_hook(form_component, HookCode)` for data fetching and the mutation handler with `generate_mutation_handler(form_name, MutationCode)` for handling form submissions and updates. This enables real-time bidirectional synchronization between your Prolog data and React form inputs.", "question_type": "medium", "topics": ["Quickstart", "Data Binding"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["data-binding", "two-way-binding", "forms", "mutations"], "related_skills": ["skill_data_binding.md"], "related_docs": ["src/unifyweaver/glue/data_binding_generator.pl"], "original_answer": "Use two-way binding to enable editing. Define your data source, then create a two-way binding: `two_way_binding(data_table, sales, [columns([date, product, quantity]), editable([quantity, amount]), on_edit(update_record)])`. Generate both the binding hook with `generate_binding_hook(data_table, HookCode)` and the mutation handler with `generate_mutation_handler(sales, MutationCode)`. This provides both data fetching and update capabilities. See skill_data_binding.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer assumes the reader knows the full two-way binding syntax. The tailored version adds the data source definition step which is necessary for complete implementation but wasn't explicitly in the base answer."}
{"pair_id": "skill_data_binding_004_q0", "cluster_id": "skill_data_binding_004", "question": "How do I get real-time updates when Prolog data changes using WebSocket?", "answer": "To get real-time updates when Prolog data changes using WebSocket, use `generate_websocket_sync(Source, SyncCode)` after defining your data source and binding. This generates a React hook (e.g., `useSalesSync`) that automatically maintains a WebSocket connection to your server. The hook handles connection lifecycle management, auto-reconnect on failure, and listens for real-time events: sync (full data refresh), insert (new records), update (record changes), and delete (record removal). Your UI components connected to this hook will reactively update whenever the underlying Prolog data changes on the server.", "question_type": "medium", "topics": ["Quickstart", "Data Binding"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["data-binding", "websocket", "real-time", "sync"], "related_skills": ["skill_data_binding.md"], "related_docs": ["src/unifyweaver/glue/data_binding_generator.pl"], "original_answer": "Generate WebSocket synchronization for real-time updates. First set up your data source and binding normally, then call `generate_websocket_sync(Source, SyncCode)` to generate a hook that maintains a WebSocket connection. The generated `useSalesSync` hook handles connection management, auto-reconnect, and real-time events (sync, insert, update, delete). This keeps your UI automatically synchronized with server changes. See skill_data_binding.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "Base answer could be more explicit about which events are supported (sync, insert, update, delete) and the automatic nature of UI updates. Minor clarification added to improve directness."}
{"pair_id": "skill_data_binding_004_q1", "cluster_id": "skill_data_binding_004", "question": "How do I set up live data synchronization?", "answer": "To set up live data synchronization, first define your data source with `data_source(Name, Options)` and create a binding with `binding(Component, Source, Mapping)`. Then generate WebSocket synchronization by calling `generate_websocket_sync(Source, SyncCode)`. This produces a React hook (e.g., `useSalesSync`) that automatically manages the WebSocket connection, handles reconnection, and syncs real-time events (insert, update, delete, sync) to keep your UI reactively updated with server changes.", "question_type": "medium", "topics": ["Quickstart", "Data Binding"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["data-binding", "websocket", "real-time", "sync"], "related_skills": ["skill_data_binding.md"], "related_docs": ["src/unifyweaver/glue/data_binding_generator.pl"], "original_answer": "Generate WebSocket synchronization for real-time updates. First set up your data source and binding normally, then call `generate_websocket_sync(Source, SyncCode)` to generate a hook that maintains a WebSocket connection. The generated `useSalesSync` hook handles connection management, auto-reconnect, and real-time events (sync, insert, update, delete). This keeps your UI automatically synchronized with server changes. See skill_data_binding.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_data_binding_004_q2", "cluster_id": "skill_data_binding_004", "question": "How do I subscribe to Prolog data changes?", "answer": "To subscribe to Prolog data changes, use `generate_websocket_sync(Source, SyncCode)` to create a WebSocket-based hook. This generated hook automatically maintains a connection, handles reconnection, and listens for real-time events (sync, insert, update, delete) from the server. The hook keeps your React component synchronized with Prolog data changes without manual polling. Set up your data source and binding first, then generate the sync hook to enable reactive updates.", "question_type": "medium", "topics": ["Quickstart", "Data Binding"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["data-binding", "websocket", "real-time", "sync"], "related_skills": ["skill_data_binding.md"], "related_docs": ["src/unifyweaver/glue/data_binding_generator.pl"], "original_answer": "Generate WebSocket synchronization for real-time updates. First set up your data source and binding normally, then call `generate_websocket_sync(Source, SyncCode)` to generate a hook that maintains a WebSocket connection. The generated `useSalesSync` hook handles connection management, auto-reconnect, and real-time events (sync, insert, update, delete). This keeps your UI automatically synchronized with server changes. See skill_data_binding.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_data_binding_005_q0", "cluster_id": "skill_data_binding_005", "question": "How do I aggregate or filter Prolog data before binding it to a chart?", "answer": "Create a computed source using `computed_source/2` to apply aggregations, filtering, or joins before binding to your chart. For aggregation, specify a base source with `computation(aggregate)`, `group_by([field])`, and `aggregations([sum(...), count(...), etc])`. For filtering, use `computation(filter)` with `filter_predicate(condition)`. For joins across multiple sources, use `computation(join)` with `join_on(key_field)` and `join_type(inner/left/outer)`. Once your computed source is defined, bind it to your chart component using `binding(chart_name, computed_source_name, [mapping_options])` and generate the React hook as normal. Computed sources handle all data transformations server-side before sending to React.", "question_type": "long", "topics": ["Quickstart", "Data Binding"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["data-binding", "computed-sources", "aggregation", "filtering"], "related_skills": ["skill_data_binding.md"], "related_docs": ["src/unifyweaver/glue/data_binding_generator.pl"], "original_answer": "Create a computed source to apply aggregations, filtering, or joins. For aggregation: `computed_source(sales_summary, [base_source(sales), computation(aggregate), group_by([product]), aggregations([sum(amount, total_sales), count(_, sale_count)])])`. For filtering: `computed_source(high_value, [base_source(sales), computation(filter), filter_predicate(amount > 1000)])`. Then bind and generate hooks as normal. Computed sources automatically handle grouping, aggregation, filtering, and joins. See skill_data_binding.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_data_binding_005_q1", "cluster_id": "skill_data_binding_005", "question": "How do I group data or apply transformations in data binding?", "answer": "To group data or apply transformations, use `computed_source` to create derived data from your base source. For grouping and aggregation: `computed_source(sales_summary, [base_source(sales), computation(aggregate), group_by([product]), aggregations([sum(amount, total_sales), count(_, sale_count)])])`. For filtering transformations: `computed_source(high_value, [base_source(sales), computation(filter), filter_predicate(amount > 1000)])`. For joins across multiple sources: `computed_source(product_sales, [sources([products, sales]), computation(join), join_on(product_id), join_type(inner)])`. Once your computed source is defined, bind it to your component and generate hooks normally. Computed sources handle all grouping, aggregation, filtering, and join operations automatically.", "question_type": "long", "topics": ["Quickstart", "Data Binding"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["data-binding", "computed-sources", "aggregation", "filtering"], "related_skills": ["skill_data_binding.md"], "related_docs": ["src/unifyweaver/glue/data_binding_generator.pl"], "original_answer": "Create a computed source to apply aggregations, filtering, or joins. For aggregation: `computed_source(sales_summary, [base_source(sales), computation(aggregate), group_by([product]), aggregations([sum(amount, total_sales), count(_, sale_count)])])`. For filtering: `computed_source(high_value, [base_source(sales), computation(filter), filter_predicate(amount > 1000)])`. Then bind and generate hooks as normal. Computed sources automatically handle grouping, aggregation, filtering, and joins. See skill_data_binding.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_data_binding_005_q2", "cluster_id": "skill_data_binding_005", "question": "How do I create computed data sources?", "answer": "Create a computed source using `computed_source/2` to derive data from transformations. For aggregation, use `computed_source(name, [base_source(SourceName), computation(aggregate), group_by([Field]), aggregations([sum(field, alias), count(_, alias)])])`. For filtering, use `computed_source(name, [base_source(SourceName), computation(filter), filter_predicate(Condition)])`. For joins across multiple sources, use `computed_source(name, [sources([Source1, Source2]), computation(join), join_on(KeyField), join_type(inner)])`. After defining the computed source, bind it to UI components and generate hooks normally\u2014the computed source handles grouping, aggregation, filtering, and joins automatically.", "question_type": "long", "topics": ["Quickstart", "Data Binding"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["data-binding", "computed-sources", "aggregation", "filtering"], "related_skills": ["skill_data_binding.md"], "related_docs": ["src/unifyweaver/glue/data_binding_generator.pl"], "original_answer": "Create a computed source to apply aggregations, filtering, or joins. For aggregation: `computed_source(sales_summary, [base_source(sales), computation(aggregate), group_by([product]), aggregations([sum(amount, total_sales), count(_, sale_count)])])`. For filtering: `computed_source(high_value, [base_source(sales), computation(filter), filter_predicate(amount > 1000)])`. Then bind and generate hooks as normal. Computed sources automatically handle grouping, aggregation, filtering, and joins. See skill_data_binding.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_data_binding_006_q0", "cluster_id": "skill_data_binding_006", "question": "What TypeScript types are generated for my data bindings?", "answer": "TypeScript types for data bindings are automatically generated based on field naming conventions: `*id`, `*name`, `*label` fields become `string` types; `*count`, `*amount`, `*value` become `number`; `*date`, `*time`, `*timestamp` become `Date | string`; and `is_*`, `has_*`, `*enabled` become `boolean`. Use `generate_binding_types(Source, TypesCode)` to generate complete type definitions for your data source. If you need custom types for specific fields, override them with `infer_field_type(field_name, 'CustomType')`. This provides full TypeScript support in your React components bound to Prolog data sources.", "question_type": "long", "topics": ["Quickstart", "Data Binding"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["data-binding", "typescript", "types", "type-inference"], "related_skills": ["skill_data_binding.md"], "related_docs": ["src/unifyweaver/glue/data_binding_generator.pl"], "original_answer": "The generator automatically infers TypeScript types based on field naming conventions: `*id`, `*name`, `*label` \u2192 `string`; `*count`, `*amount`, `*value` \u2192 `number`; `*date`, `*time`, `*timestamp` \u2192 `Date | string`; `is_*`, `has_*`, `*enabled` \u2192 `boolean`. Generate type definitions with `generate_binding_types(Source, TypesCode)`. Override field types with `infer_field_type(my_field, 'CustomType')` if needed. This ensures full TypeScript support in your React components. See skill_data_binding.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer mentions `generate_binding_types/2` and `infer_field_type/2` predicates but the skill document doesn't show their exact usage signatures or examples, making confidence moderate rather than high. The core information about type inference rules is clear and directly addresses the question."}
{"pair_id": "skill_data_binding_006_q1", "cluster_id": "skill_data_binding_006", "question": "How do I get TypeScript type safety for bound data?", "answer": "TypeScript type safety for bound data is achieved through automatic type inference based on field naming conventions. The system infers types as follows: fields ending in `id`, `name`, or `label` become `string`; fields ending in `count`, `amount`, or `value` become `number`; fields ending in `date`, `time`, or `timestamp` become `Date | string`; and fields starting with `is_`, `has_`, or ending in `enabled` become `boolean`. Generate type definitions using `generate_binding_types(Source, TypesCode)`. For non-standard fields, override the inferred type with `infer_field_type(field_name, 'YourCustomType')`. This generates fully typed React components with complete TypeScript support.", "question_type": "long", "topics": ["Quickstart", "Data Binding"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["data-binding", "typescript", "types", "type-inference"], "related_skills": ["skill_data_binding.md"], "related_docs": ["src/unifyweaver/glue/data_binding_generator.pl"], "original_answer": "The generator automatically infers TypeScript types based on field naming conventions: `*id`, `*name`, `*label` \u2192 `string`; `*count`, `*amount`, `*value` \u2192 `number`; `*date`, `*time`, `*timestamp` \u2192 `Date | string`; `is_*`, `has_*`, `*enabled` \u2192 `boolean`. Generate type definitions with `generate_binding_types(Source, TypesCode)`. Override field types with `infer_field_type(my_field, 'CustomType')` if needed. This ensures full TypeScript support in your React components. See skill_data_binding.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer references 'skill_data_binding.md' for details, but the specific location and availability of this documentation is unclear from the skill document provided. The answer assumes field naming conventions are consistently followed, which may not always be the case in practice."}
{"pair_id": "skill_data_binding_006_q2", "cluster_id": "skill_data_binding_006", "question": "How are data fields typed in generated hooks?", "answer": "Data fields in generated hooks are automatically typed based on field naming conventions: fields ending in `id`, `name`, or `label` become `string` type; fields ending in `count`, `amount`, or `value` become `number`; fields ending in `date`, `time`, or `timestamp` become `Date | string`; and fields starting with `is_`, `has_`, or ending in `enabled` become `boolean`. You can generate complete type definitions using `generate_binding_types(Source, TypesCode)`, or override specific field types with `infer_field_type(field_name, 'CustomType')` for custom type assignments.", "question_type": "long", "topics": ["Quickstart", "Data Binding"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["data-binding", "typescript", "types", "type-inference"], "related_skills": ["skill_data_binding.md"], "related_docs": ["src/unifyweaver/glue/data_binding_generator.pl"], "original_answer": "The generator automatically infers TypeScript types based on field naming conventions: `*id`, `*name`, `*label` \u2192 `string`; `*count`, `*amount`, `*value` \u2192 `number`; `*date`, `*time`, `*timestamp` \u2192 `Date | string`; `is_*`, `has_*`, `*enabled` \u2192 `boolean`. Generate type definitions with `generate_binding_types(Source, TypesCode)`. Override field types with `infer_field_type(my_field, 'CustomType')` if needed. This ensures full TypeScript support in your React components. See skill_data_binding.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer references 'skill_data_binding.md' which may not exist or be accessible. The answer assumes the naming convention system is the primary typing mechanism without clarifying if other typing systems exist in the codebase."}
{"pair_id": "skill_data_sources_001_q0", "cluster_id": "skill_data_sources_001", "question": "How do I read JSON or JSONL data files in my Prolog code?", "answer": "To read JSON or JSONL data files in Prolog, use the `source/2` directive with `json` format and specify your file path using `json_file/1`. For JSONL files (newline-delimited JSON), add `record_format(jsonl)`. Specify which fields to extract with `columns/1` using dot notation for nested paths or array indices. Example:\n\n```prolog\n:- source(json, events, [\n    json_file('data/events.jsonl'),\n    record_format(jsonl),\n    columns(['event.type', 'event.timestamp'])\n]).\n\n?- events(Type, Timestamp).\n```\n\nFor plain JSON files (not newline-delimited), omit `record_format(jsonl)`. You can also use JSONPath expressions in columns for more complex selectors, or use `return_object(true)` to get full JSON objects instead of projected columns.", "question_type": "medium", "topics": ["Quickstart", "Data Sources (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["json", "jsonl", "data-loading", "prolog"], "related_skills": ["skill_data_sources.md", "skill_json_sources.md"], "related_docs": ["docs/playbooks/parsing/README.md", "src/unifyweaver/sources/json_source.pl"], "original_answer": "Use the `source/2` directive with `json` format and specify your file path. For JSONL files (newline-delimited), add `record_format(jsonl)`. Example:\n```prolog\n:- source(json, events, [\n    json_file('data/events.jsonl'),\n    record_format(jsonl),\n    columns(['event.type', 'event.timestamp'])\n]).\n?- events(Type, Timestamp).\n```\nSee skill_data_sources.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_data_sources_001_q1", "cluster_id": "skill_data_sources_001", "question": "How can I load data from JSON files?", "answer": "To load data from JSON files in Prolog, use the `source/2` directive with `json` format and specify your file path using `json_file/1`. For standard JSON files, use basic column projection with dot notation. For JSONL files (newline-delimited JSON), add `record_format(jsonl)`. Example:\n\n```prolog\n:- source(json, events, [\n    json_file('data/events.jsonl'),\n    record_format(jsonl),\n    columns(['event.type', 'event.timestamp'])\n]).\n?- events(Type, Timestamp).\n```\n\nFor JSON files without JSONL format, simply omit the `record_format/1` argument. You can also use JSONPath selectors for complex nested structures, or return full objects with `return_object(true)`. See skill_data_sources.md for advanced options like schema definitions and null handling policies.", "question_type": "medium", "topics": ["Quickstart", "Data Sources (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["json", "jsonl", "data-loading", "prolog"], "related_skills": ["skill_data_sources.md", "skill_json_sources.md"], "related_docs": ["docs/playbooks/parsing/README.md", "src/unifyweaver/sources/json_source.pl"], "original_answer": "Use the `source/2` directive with `json` format and specify your file path. For JSONL files (newline-delimited), add `record_format(jsonl)`. Example:\n```prolog\n:- source(json, events, [\n    json_file('data/events.jsonl'),\n    record_format(jsonl),\n    columns(['event.type', 'event.timestamp'])\n]).\n?- events(Type, Timestamp).\n```\nSee skill_data_sources.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_data_sources_001_q2", "cluster_id": "skill_data_sources_001", "question": "What's the best way to handle JSONL streams?", "answer": "For JSONL streams, use the `source/2` directive with `json` format and set `record_format(jsonl)` to parse newline-delimited JSON. Specify your JSONL file path and optionally add column projection or null handling policies:\n\n```prolog\n:- source(json, events, [\n    json_file('data/events.jsonl'),\n    record_format(jsonl),\n    columns(['event.type', 'event.timestamp']),\n    null_policy(skip)  % optional: skip, default('N/A'), or fail\n]).\n\n?- events(Type, Timestamp).\n```\n\nFor typed records with schema, add a schema definition. For full JSON objects instead of projected columns, use `return_object(true)`.", "question_type": "medium", "topics": ["Quickstart", "Data Sources (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["json", "jsonl", "data-loading", "prolog"], "related_skills": ["skill_data_sources.md", "skill_json_sources.md"], "related_docs": ["docs/playbooks/parsing/README.md", "src/unifyweaver/sources/json_source.pl"], "original_answer": "Use the `source/2` directive with `json` format and specify your file path. For JSONL files (newline-delimited), add `record_format(jsonl)`. Example:\n```prolog\n:- source(json, events, [\n    json_file('data/events.jsonl'),\n    record_format(jsonl),\n    columns(['event.type', 'event.timestamp'])\n]).\n?- events(Type, Timestamp).\n```\nSee skill_data_sources.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_data_sources_002_q0", "cluster_id": "skill_data_sources_002", "question": "How do I extract specific fields from nested JSON objects?", "answer": "Use dot notation for simple nested paths like `'order.customer.name'` or array access like `'items[0].total'`. For complex queries, use JSONPath selectors like `jsonpath('$.users[*].profile.email')` or recursive descent with `jsonpath('$..address.city')`. Define your JSON source with column projection:\n\n```prolog\n:- source(json, orders, [\n    json_file('data/orders.json'),\n    columns(['order.id', 'order.customer.name', 'items[0].total'])\n]).\n```\n\nFor typed nested records, use the schema option with nested record definitions. Alternatively, use `return_object(true)` to get the full JSON object and extract fields programmatically.", "question_type": "medium", "topics": ["Quickstart", "Data Sources (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["jsonpath", "column-projection", "nested-data", "query"], "related_skills": ["skill_data_sources.md", "skill_json_sources.md"], "related_docs": ["src/unifyweaver/sources/json_source.pl"], "original_answer": "Use dot notation for simple paths or JSONPath for complex queries. Dot notation example: `'order.customer.name'`. JSONPath example: `jsonpath('$.users[*].profile.email')`. For nested records with custom types:\n```prolog\n:- source(json, orders, [\n    json_file('data/orders.json'),\n    columns(['order.id', 'items[0].total'])\n]).\n```\nSee skill_data_sources.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_data_sources_002_q1", "cluster_id": "skill_data_sources_002", "question": "Can I use JSONPath to query nested data?", "answer": "Yes, you can use JSONPath to query nested data in Prolog. Use `jsonpath()` with selectors like `jsonpath('$.users[*].profile.email')` for accessing nested properties and arrays. JSONPath supports dot notation (`.property`), bracket notation (`['property']`), array indices (`[0]`, `[*]`), and recursive descent (`..property`). For simpler nested paths, you can also use dot notation directly: `'order.customer.name'` or array access: `'items[0].total'`. Define your source with column projection using either format:\n\n```prolog\n:- source(json, data, [\n    json_file('data/file.json'),\n    columns([\n        jsonpath('$.users[*].profile.email'),\n        'order.customer.name',\n        'items[0].total'\n    ])\n]).\n```", "question_type": "medium", "topics": ["Quickstart", "Data Sources (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["jsonpath", "column-projection", "nested-data", "query"], "related_skills": ["skill_data_sources.md", "skill_json_sources.md"], "related_docs": ["src/unifyweaver/sources/json_source.pl"], "original_answer": "Use dot notation for simple paths or JSONPath for complex queries. Dot notation example: `'order.customer.name'`. JSONPath example: `jsonpath('$.users[*].profile.email')`. For nested records with custom types:\n```prolog\n:- source(json, orders, [\n    json_file('data/orders.json'),\n    columns(['order.id', 'items[0].total'])\n]).\n```\nSee skill_data_sources.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_data_sources_002_q2", "cluster_id": "skill_data_sources_002", "question": "How do I project columns from complex JSON?", "answer": "To project columns from complex JSON, use dot notation for simple nested paths or JSONPath for complex queries. Dot notation example: `'order.customer.name'` or `'items[0].total'`. JSONPath example: `jsonpath('$.users[*].profile.email')` for array traversal or `jsonpath('$..address.city')` for recursive descent. Declare the source with column projection:\n```prolog\n:- source(json, orders, [\n    json_file('data/orders.json'),\n    columns(['order.id', 'items[0].total'])\n]).\n```\nFor full objects instead of projections, use `return_object(true)` with `arity(1)`.", "question_type": "medium", "topics": ["Quickstart", "Data Sources (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["jsonpath", "column-projection", "nested-data", "query"], "related_skills": ["skill_data_sources.md", "skill_json_sources.md"], "related_docs": ["src/unifyweaver/sources/json_source.pl"], "original_answer": "Use dot notation for simple paths or JSONPath for complex queries. Dot notation example: `'order.customer.name'`. JSONPath example: `jsonpath('$.users[*].profile.email')`. For nested records with custom types:\n```prolog\n:- source(json, orders, [\n    json_file('data/orders.json'),\n    columns(['order.id', 'items[0].total'])\n]).\n```\nSee skill_data_sources.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_data_sources_003_q0", "cluster_id": "skill_data_sources_003", "question": "What should I do when JSON fields might be null or missing?", "answer": "Use the `null_policy/1` option to control how null or missing JSON fields are handled. Three options are available:\n\n- `null_policy(skip)` - Skip entire rows containing null values\n- `null_policy(fail)` - Throw an error when null values are encountered\n- `null_policy(default('value'))` - Replace null values with a specified default value\n\nExample for handling sparse data:\n```prolog\n:- source(json, sparse_data, [\n    json_file('data/sparse.jsonl'),\n    record_format(jsonl),\n    columns(['required_field', 'optional_field']),\n    null_policy(default('N/A'))\n]).\n```\n\nChoose the policy based on your needs: skip rows if nulls indicate incomplete records, fail if nulls are errors, or use defaults for graceful degradation with missing optional fields.", "question_type": "medium", "topics": ["Quickstart", "Data Sources (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["null-handling", "validation", "data-quality"], "related_skills": ["skill_data_sources.md"], "related_docs": ["src/unifyweaver/sources/json_source.pl"], "original_answer": "Use the `null_policy/1` option to control null handling. Options are:\n- `null_policy(skip)` - skip rows with null values\n- `null_policy(fail)` - throw error on null\n- `null_policy(default('value'))` - substitute default value\n\nExample:\n```prolog\n:- source(json, sparse_data, [\n    json_file('data/sparse.jsonl'),\n    record_format(jsonl),\n    columns(['required_field', 'optional_field']),\n    null_policy(default('N/A'))\n]).\n```\nSee skill_data_sources.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_data_sources_003_q1", "cluster_id": "skill_data_sources_003", "question": "How do I handle missing values in my data?", "answer": "Use the `null_policy/1` option to control how missing values are handled in your JSON/JSONL data sources:\n\n- `null_policy(skip)` - Skip rows that contain null values\n- `null_policy(fail)` - Throw an error when null values are encountered\n- `null_policy(default('value'))` - Replace null values with a default value\n\nExample:\n```prolog\n:- source(json, sparse_data, [\n    json_file('data/sparse.jsonl'),\n    record_format(jsonl),\n    columns(['required_field', 'optional_field']),\n    null_policy(default('N/A'))\n]).\n```\n\nChoose the policy based on your needs: use `skip` to exclude incomplete records, `fail` to catch data quality issues, or `default()` to fill in missing values.", "question_type": "medium", "topics": ["Quickstart", "Data Sources (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["null-handling", "validation", "data-quality"], "related_skills": ["skill_data_sources.md"], "related_docs": ["src/unifyweaver/sources/json_source.pl"], "original_answer": "Use the `null_policy/1` option to control null handling. Options are:\n- `null_policy(skip)` - skip rows with null values\n- `null_policy(fail)` - throw error on null\n- `null_policy(default('value'))` - substitute default value\n\nExample:\n```prolog\n:- source(json, sparse_data, [\n    json_file('data/sparse.jsonl'),\n    record_format(jsonl),\n    columns(['required_field', 'optional_field']),\n    null_policy(default('N/A'))\n]).\n```\nSee skill_data_sources.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_data_sources_003_q2", "cluster_id": "skill_data_sources_003", "question": "Can I skip rows with incomplete data?", "answer": "Yes, you can skip rows with incomplete data using the `null_policy(skip)` option in your JSON source declaration. This will automatically filter out any rows containing null values in your specified columns.\n\nExample:\n```prolog\n:- source(json, sparse_data, [\n    json_file('data/sparse.jsonl'),\n    record_format(jsonl),\n    columns(['required_field', 'optional_field']),\n    null_policy(skip)\n]).\n```\n\nAlternatively, you can use `null_policy(default('value'))` to substitute a default value instead of skipping the row entirely, or `null_policy(fail)` to throw an error when nulls are encountered.", "question_type": "medium", "topics": ["Quickstart", "Data Sources (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["null-handling", "validation", "data-quality"], "related_skills": ["skill_data_sources.md"], "related_docs": ["src/unifyweaver/sources/json_source.pl"], "original_answer": "Use the `null_policy/1` option to control null handling. Options are:\n- `null_policy(skip)` - skip rows with null values\n- `null_policy(fail)` - throw error on null\n- `null_policy(default('value'))` - substitute default value\n\nExample:\n```prolog\n:- source(json, sparse_data, [\n    json_file('data/sparse.jsonl'),\n    record_format(jsonl),\n    columns(['required_field', 'optional_field']),\n    null_policy(default('N/A'))\n]).\n```\nSee skill_data_sources.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_data_sources_004_q0", "cluster_id": "skill_data_sources_004", "question": "How do I extract code blocks or structured records from Markdown files?", "answer": "Use the `extract_records.pl` Perl script to extract structured records from Markdown files. For code blocks only, use: `perl scripts/utils/extract_records.pl -f content -q \"pattern\" file.md`. For structured records as JSON metadata, use: `perl scripts/utils/extract_records.pl -f json -q \"pattern\" file.md`. You can filter by file type across multiple files with: `perl scripts/utils/extract_records.pl --file-filter \"file_type=UnifyWeaver Example Library\" docs/`. The `-q` parameter specifies the search pattern to locate records within Markdown files.", "question_type": "medium", "topics": ["Quickstart", "Data Sources (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["markdown", "record-extraction", "documentation"], "related_skills": ["skill_data_sources.md", "skill_extract_records.md"], "related_docs": ["scripts/utils/extract_records.pl", "docs/playbooks/parsing/README.md"], "original_answer": "Use the `extract_records.pl` Perl script to extract records. Extract content (code only) with: `perl scripts/utils/extract_records.pl -f content -q \"pattern\" file.md`. Extract as JSON metadata: `perl scripts/utils/extract_records.pl -f json -q \"pattern\" file.md`. Filter by file type: `perl scripts/utils/extract_records.pl --file-filter \"file_type=UnifyWeaver Example Library\" docs/`. See skill_data_sources.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer is slightly vague about what constitutes 'structured records' and could benefit from clarifying that this script searches for patterns within Markdown and extracts matching blocks. The skill document excerpt is truncated, so some implementation details may be missing."}
{"pair_id": "skill_data_sources_004_q1", "cluster_id": "skill_data_sources_004", "question": "Can I pull script content from documentation?", "answer": "Yes, you can extract script content from documentation using the `extract_records.pl` Perl script. Use the `-f content` flag to extract code only: `perl scripts/utils/extract_records.pl -f content -q \"pattern\" file.md`. For example, to extract UnifyWeaver execution examples: `perl scripts/utils/extract_records.pl -f content -q \"unifyweaver.execution.xml_data_source\" playbooks/examples_library/xml_examples.md > tmp/script.sh`. You can also use `-f json` to extract records with metadata, or `--file-filter` to filter by file type across directories.", "question_type": "medium", "topics": ["Quickstart", "Data Sources (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["markdown", "record-extraction", "documentation"], "related_skills": ["skill_data_sources.md", "skill_extract_records.md"], "related_docs": ["scripts/utils/extract_records.pl", "docs/playbooks/parsing/README.md"], "original_answer": "Use the `extract_records.pl` Perl script to extract records. Extract content (code only) with: `perl scripts/utils/extract_records.pl -f content -q \"pattern\" file.md`. Extract as JSON metadata: `perl scripts/utils/extract_records.pl -f json -q \"pattern\" file.md`. Filter by file type: `perl scripts/utils/extract_records.pl --file-filter \"file_type=UnifyWeaver Example Library\" docs/`. See skill_data_sources.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_data_sources_004_q2", "cluster_id": "skill_data_sources_004", "question": "How do I extract examples from Markdown?", "answer": "Use the `extract_records.pl` Perl script located in `scripts/utils/`. To extract content (code snippets) from Markdown, run: `perl scripts/utils/extract_records.pl -f content -q \"pattern\" file.md`. To extract records as JSON metadata, use: `perl scripts/utils/extract_records.pl -f json -q \"pattern\" file.md`. You can also filter by file type across multiple files: `perl scripts/utils/extract_records.pl --file-filter \"file_type=UnifyWeaver Example Library\" docs/`. The `-q` flag specifies a pattern to match (e.g., skill names or example types), and `-f` specifies the output format (content or json).", "question_type": "medium", "topics": ["Quickstart", "Data Sources (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["markdown", "record-extraction", "documentation"], "related_skills": ["skill_data_sources.md", "skill_extract_records.md"], "related_docs": ["scripts/utils/extract_records.pl", "docs/playbooks/parsing/README.md"], "original_answer": "Use the `extract_records.pl` Perl script to extract records. Extract content (code only) with: `perl scripts/utils/extract_records.pl -f content -q \"pattern\" file.md`. Extract as JSON metadata: `perl scripts/utils/extract_records.pl -f json -q \"pattern\" file.md`. Filter by file type: `perl scripts/utils/extract_records.pl --file-filter \"file_type=UnifyWeaver Example Library\" docs/`. See skill_data_sources.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_data_sources_005_q0", "cluster_id": "skill_data_sources_005", "question": "How do I define typed records with specific schemas?", "answer": "To define typed records with specific schemas, use the `schema/1` option with field definitions and specify the record type using `record_type/1`. Example:\n\n```prolog\n:- source(json, products, [\n    json_file('data/products.json'),\n    schema([\n        field(id, 'id', string),\n        field(name, 'name', string),\n        field(price, 'price', double)\n    ]),\n    record_type('ProductRecord')\n]).\n?- products(Record).\n```\n\nThis returns typed ProductRecord objects with the specified fields. For nested records, use `record(TypeName, [field(...)])` within schema field definitions to create hierarchical record structures.", "question_type": "long", "topics": ["Quickstart", "Data Sources (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["schema", "typed-records", "validation"], "related_skills": ["skill_data_sources.md", "skill_json_sources.md"], "related_docs": ["src/unifyweaver/sources/json_source.pl"], "original_answer": "Use the `schema/1` option to define fields with types and the `record_type/1` to name your record. Example:\n```prolog\n:- source(json, products, [\n    json_file('data/products.json'),\n    schema([\n        field(id, 'id', string),\n        field(name, 'name', string),\n        field(price, 'price', double)\n    ]),\n    record_type('ProductRecord')\n]).\n?- products(Record).\n```\nFor nested records, use `record(TypeName, [field(...)])` within schema fields. See skill_data_sources.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_data_sources_005_q1", "cluster_id": "skill_data_sources_005", "question": "Can I enforce data types when loading JSON?", "answer": "Yes, you can enforce data types when loading JSON using the `schema/1` option. Define a schema with typed fields using the `field(name, jsonpath, type)` syntax, and optionally specify a `record_type/1` to name your record structure. Example:\n\n```prolog\n:- source(json, products, [\n    json_file('data/products.json'),\n    schema([\n        field(id, 'id', string),\n        field(name, 'name', string),\n        field(price, 'price', double)\n    ]),\n    record_type('ProductRecord')\n]).\n?- products(Record).\n```\n\nFor nested structures, use `record(TypeName, [field(...)])` within schema fields to enforce types on nested objects.", "question_type": "long", "topics": ["Quickstart", "Data Sources (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["schema", "typed-records", "validation"], "related_skills": ["skill_data_sources.md", "skill_json_sources.md"], "related_docs": ["src/unifyweaver/sources/json_source.pl"], "original_answer": "Use the `schema/1` option to define fields with types and the `record_type/1` to name your record. Example:\n```prolog\n:- source(json, products, [\n    json_file('data/products.json'),\n    schema([\n        field(id, 'id', string),\n        field(name, 'name', string),\n        field(price, 'price', double)\n    ]),\n    record_type('ProductRecord')\n]).\n?- products(Record).\n```\nFor nested records, use `record(TypeName, [field(...)])` within schema fields. See skill_data_sources.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_data_sources_005_q2", "cluster_id": "skill_data_sources_005", "question": "How do I create custom record types?", "answer": "Use the `schema/1` option with `field/3` declarations and the `record_type/1` option to define custom record types. Each field specifies a Prolog name, JSON path, and type (string, double, int, etc.). For nested records, use `record(TypeName, [field(...)])` within a field definition. Example:\n\n```prolog\n:- source(json, products, [\n    json_file('data/products.json'),\n    schema([\n        field(id, 'id', string),\n        field(name, 'name', string),\n        field(price, 'price', double)\n    ]),\n    record_type('ProductRecord')\n]).\n?- products(Record).\n```\n\nThis creates a ProductRecord type with three fields (id, name, price) mapped from the JSON structure.", "question_type": "long", "topics": ["Quickstart", "Data Sources (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["schema", "typed-records", "validation"], "related_skills": ["skill_data_sources.md", "skill_json_sources.md"], "related_docs": ["src/unifyweaver/sources/json_source.pl"], "original_answer": "Use the `schema/1` option to define fields with types and the `record_type/1` to name your record. Example:\n```prolog\n:- source(json, products, [\n    json_file('data/products.json'),\n    schema([\n        field(id, 'id', string),\n        field(name, 'name', string),\n        field(price, 'price', double)\n    ]),\n    record_type('ProductRecord')\n]).\n?- products(Record).\n```\nFor nested records, use `record(TypeName, [field(...)])` within schema fields. See skill_data_sources.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_data_sources_006_q0", "cluster_id": "skill_data_sources_006", "question": "How do I get the full JSON object instead of projecting individual columns?", "answer": "To get the full JSON object instead of projecting individual columns, use `return_object(true)` with `arity(1)` and a `type_hint/1` specifying the object type:\n\n```prolog\n:- source(json, raw_products, [\n    json_file('data/products.json'),\n    arity(1),\n    return_object(true),\n    type_hint('System.Text.Json.Nodes.JsonObject, System.Text.Json')\n]).\n?- raw_products(JsonObject).\n```\n\nThis returns the complete JSON object as a single parameter rather than projecting specific columns. The `type_hint` must specify the appropriate JSON object type for your system.", "question_type": "long", "topics": ["Quickstart", "Data Sources (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["return-object", "raw-json", "type-hint"], "related_skills": ["skill_data_sources.md", "skill_json_sources.md"], "related_docs": ["src/unifyweaver/sources/json_source.pl"], "original_answer": "Use `return_object(true)` with a `type_hint/1` specifying the object type, and set `arity(1)`. Example:\n```prolog\n:- source(json, raw_products, [\n    json_file('data/products.json'),\n    arity(1),\n    return_object(true),\n    type_hint('System.Text.Json.Nodes.JsonObject, System.Text.Json')\n]).\n?- raw_products(JsonObject).\n```\nNote: `return_object(true)` requires arity=1 and a type hint. See skill_data_sources.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_data_sources_006_q1", "cluster_id": "skill_data_sources_006", "question": "Can I return raw JSON objects?", "answer": "Yes, you can return raw JSON objects using `return_object(true)` with three requirements: set `arity(1)` to indicate a single-argument predicate, provide a `type_hint/1` specifying the object type (e.g., `'System.Text.Json.Nodes.JsonObject, System.Text.Json'`), and omit the `columns/1` directive. Example:\n\n```prolog\n:- source(json, raw_products, [\n    json_file('data/products.json'),\n    arity(1),\n    return_object(true),\n    type_hint('System.Text.Json.Nodes.JsonObject, System.Text.Json')\n]).\n?- raw_products(JsonObject).\n```\n\nThis returns the full JSON object for each record rather than projected columns.", "question_type": "long", "topics": ["Quickstart", "Data Sources (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["return-object", "raw-json", "type-hint"], "related_skills": ["skill_data_sources.md", "skill_json_sources.md"], "related_docs": ["src/unifyweaver/sources/json_source.pl"], "original_answer": "Use `return_object(true)` with a `type_hint/1` specifying the object type, and set `arity(1)`. Example:\n```prolog\n:- source(json, raw_products, [\n    json_file('data/products.json'),\n    arity(1),\n    return_object(true),\n    type_hint('System.Text.Json.Nodes.JsonObject, System.Text.Json')\n]).\n?- raw_products(JsonObject).\n```\nNote: `return_object(true)` requires arity=1 and a type hint. See skill_data_sources.md for details.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null}
{"pair_id": "skill_data_sources_006_q2", "cluster_id": "skill_data_sources_006", "question": "How do I get complete records without column selection?", "answer": "To get complete records without column selection, use `return_object(true)` with `arity(1)` and a `type_hint`. Example:\n\n```prolog\n:- source(json, raw_products, [\n    json_file('data/products.json'),\n    arity(1),\n    return_object(true),\n    type_hint('System.Text.Json.Nodes.JsonObject, System.Text.Json')\n]).\n?- raw_products(JsonObject).\n```\n\nThis returns the entire JSON object for each record instead of projected columns. The `type_hint` specifies that each result is a JsonObject from System.Text.Json.", "question_type": "long", "topics": ["Quickstart", "Data Sources (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["return-object", "raw-json", "type-hint"], "related_skills": ["skill_data_sources.md", "skill_json_sources.md"], "related_docs": ["src/unifyweaver/sources/json_source.pl"], "original_answer": "Use `return_object(true)` with a `type_hint/1` specifying the object type, and set `arity(1)`. Example:\n```prolog\n:- source(json, raw_products, [\n    json_file('data/products.json'),\n    arity(1),\n    return_object(true),\n    type_hint('System.Text.Json.Nodes.JsonObject, System.Text.Json')\n]).\n?- raw_products(JsonObject).\n```\nNote: `return_object(true)` requires arity=1 and a type hint. See skill_data_sources.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_data_tools_001_q0", "cluster_id": "skill_data_tools_001", "question": "How do I process and query data in UnifyWeaver?", "answer": "UnifyWeaver provides comprehensive data processing tools including SQL generation for multiple databases (SQLite, PostgreSQL, MySQL), runtime stream aggregation across Go/C#/Perl/Ruby, fuzzy search with score blending, and JSON/JSONL source handling. To query data: (1) declare your source with `source(json, name, [json_file('path'), columns(['field.paths'])])`, (2) define aggregation patterns using GROUP BY, window functions, or runtime operators like `count`, `sum`, `avg`, `min`, `max`, and (3) generate target code. UnifyWeaver unifies these patterns\u2014SQL grouping, stream accumulation, and fuzzy score blending\u2014all reducing many values to fewer values while preserving meaningful information. See skill_data_tools.md and skill_query_patterns.md for detailed patterns and code generation examples.", "question_type": "medium", "topics": ["Quickstart", "Data Tools (Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["data-processing", "query", "aggregation", "beginner"], "related_skills": ["skill_query_patterns.md", "skill_data_sources.md", "skill_data_tools.md"], "related_docs": ["docs/BINDING_MATRIX.md", "src/unifyweaver/targets/sql_target.pl"], "original_answer": "UnifyWeaver provides comprehensive data processing tools including SQL generation for multiple databases, runtime stream aggregation, fuzzy search capabilities, and JSON/JSONL source handling. Start by declaring your data source, define aggregation patterns (GROUP BY, window functions), and generate target code. For example: `source(json, orders, [json_file('data/orders.json'), columns(['order.customer.name', 'items[0].total'])])`. See skill_data_tools.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_data_tools_001_q1", "cluster_id": "skill_data_tools_001", "question": "What tools are available for data processing?", "answer": "UnifyWeaver provides comprehensive data processing tools including SQL generation (SQLite, PostgreSQL, MySQL), runtime stream aggregation for Go/C#/Perl/Ruby, fuzzy search with score blending, and JSON/JSONL source handling. Declare your data source using `source(json, name, [json_file('path'), columns(['field.names'])])`, then define aggregation patterns with GROUP BY or window functions, and generate target code. See skill_data_tools.md for complete documentation.", "question_type": "medium", "topics": ["Quickstart", "Data Tools (Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["data-processing", "query", "aggregation", "beginner"], "related_skills": ["skill_query_patterns.md", "skill_data_sources.md", "skill_data_tools.md"], "related_docs": ["docs/BINDING_MATRIX.md", "src/unifyweaver/targets/sql_target.pl"], "original_answer": "UnifyWeaver provides comprehensive data processing tools including SQL generation for multiple databases, runtime stream aggregation, fuzzy search capabilities, and JSON/JSONL source handling. Start by declaring your data source, define aggregation patterns (GROUP BY, window functions), and generate target code. For example: `source(json, orders, [json_file('data/orders.json'), columns(['order.customer.name', 'items[0].total'])])`. See skill_data_tools.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "Base answer is comprehensive but somewhat verbose for a direct question about 'available tools.' The tailored version condensed this while preserving the key tool categories and practical example. Confidence slightly reduced because the question could also seek a simpler tool inventory without implementation details."}
{"pair_id": "skill_data_tools_001_q2", "cluster_id": "skill_data_tools_001", "question": "How do I work with data sources?", "answer": "UnifyWeaver provides comprehensive data processing tools for working with data sources. Start by declaring your data source using the source/3 predicate with your format (json, csv, etc.) and file path. For example: `source(json, orders, [json_file('data/orders.json'), columns(['order.customer.name', 'items[0].total'])])`. Once declared, you can define aggregation patterns using SQL generation (GROUP BY, window functions for PostgreSQL), runtime stream aggregation (Go, C#, Perl, Ruby), or fuzzy search capabilities. The system then generates target code in your chosen language. See skill_data_tools.md for comprehensive details on source configuration and skill_sql_target.md for database-specific patterns.", "question_type": "medium", "topics": ["Quickstart", "Data Tools (Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["data-processing", "query", "aggregation", "beginner"], "related_skills": ["skill_query_patterns.md", "skill_data_sources.md", "skill_data_tools.md"], "related_docs": ["docs/BINDING_MATRIX.md", "src/unifyweaver/targets/sql_target.pl"], "original_answer": "UnifyWeaver provides comprehensive data processing tools including SQL generation for multiple databases, runtime stream aggregation, fuzzy search capabilities, and JSON/JSONL source handling. Start by declaring your data source, define aggregation patterns (GROUP BY, window functions), and generate target code. For example: `source(json, orders, [json_file('data/orders.json'), columns(['order.customer.name', 'items[0].total'])])`. See skill_data_tools.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "The base answer provides good technical depth but assumes familiarity with the source/3 predicate syntax. The question 'how do I work with data sources?' is broad and could include connection strings, authentication, schema mapping, or data validation\u2014topics not addressed in the base answer. The answer focuses heavily on aggregation patterns rather than the full lifecycle of source declaration, connection, and basic querying."}
{"pair_id": "skill_data_tools_002_q0", "cluster_id": "skill_data_tools_002", "question": "How do I train and run machine learning models?", "answer": "You can train federated models using `python3 scripts/train_pearltrees_federated.py reports/data.jsonl models/federated.pkl --model nomic-ai/nomic-embed-text-v1.5`. Run inference with `python3 scripts/infer_pearltrees_federated.py --model models/federated.pkl --query 'your query'`. Choose embedding models based on your needs: nomic-embed-text-v1.5 for semantic search quality, all-MiniLM-L6-v2 for lightweight/fast deployment, BERT/ModernBERT for entropy computation. Optimize hierarchies using `python3 scripts/mindmap/hierarchy_objective.py --tree hierarchy.json --embeddings embeddings.npy` to compute the J = D/(1+H) objective.", "question_type": "medium", "topics": ["Quickstart", "Data Tools (Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["machine-learning", "embeddings", "training", "inference", "semantic-search"], "related_skills": ["skill_ml_tools.md", "skill_embedding_models.md", "skill_train_model.md", "skill_semantic_inference.md", "skill_data_tools.md"], "related_docs": ["education/book-13-semantic-search/", "education/book-14-ai-training/", "scripts/train_pearltrees_federated.py", "tools/density_explorer/"], "original_answer": "You can train federated models using `python3 scripts/train_pearltrees_federated.py reports/data.jsonl models/federated.pkl --model nomic-ai/nomic-embed-text-v1.5`. Run inference with `python3 scripts/infer_pearltrees_federated.py --model models/federated.pkl --query 'your query'`. Supported embedding models include nomic, MiniLM, BERT, and ModernBERT. Optimize hierarchies using `python3 scripts/mindmap/hierarchy_objective.py --tree hierarchy.json --embeddings embeddings.npy` to compute the J = D/(1+H) objective. See skill_data_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_data_tools_002_q1", "cluster_id": "skill_data_tools_002", "question": "How do I use embeddings for semantic search?", "answer": "Use embeddings for semantic search by: (1) choosing an embedding model like nomic-embed-text-v1.5 for Q&A search or all-MiniLM-L6-v2 for lightweight deployments, (2) training a federated model with `python3 scripts/train_pearltrees_federated.py reports/data.jsonl models/federated.pkl --model nomic-ai/nomic-embed-text-v1.5`, and (3) running inference with `python3 scripts/infer_pearltrees_federated.py --model models/federated.pkl --query 'your query' --top-k 5`. The embedding model converts your query into a vector, which is projected and compared against indexed document embeddings to rank results by semantic similarity. Optimize your hierarchy structure using `python3 scripts/mindmap/hierarchy_objective.py --tree hierarchy.json --embeddings embeddings.npy` to improve search quality.", "question_type": "medium", "topics": ["Quickstart", "Data Tools (Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["machine-learning", "embeddings", "training", "inference", "semantic-search"], "related_skills": ["skill_ml_tools.md", "skill_embedding_models.md", "skill_train_model.md", "skill_semantic_inference.md", "skill_data_tools.md"], "related_docs": ["education/book-13-semantic-search/", "education/book-14-ai-training/", "scripts/train_pearltrees_federated.py", "tools/density_explorer/"], "original_answer": "You can train federated models using `python3 scripts/train_pearltrees_federated.py reports/data.jsonl models/federated.pkl --model nomic-ai/nomic-embed-text-v1.5`. Run inference with `python3 scripts/infer_pearltrees_federated.py --model models/federated.pkl --query 'your query'`. Supported embedding models include nomic, MiniLM, BERT, and ModernBERT. Optimize hierarchies using `python3 scripts/mindmap/hierarchy_objective.py --tree hierarchy.json --embeddings embeddings.npy` to compute the J = D/(1+H) objective. See skill_data_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_data_tools_002_q2", "cluster_id": "skill_data_tools_002", "question": "Can I train models on my data?", "answer": "Yes, you can train models on your data using the federated training script. Run `python3 scripts/train_pearltrees_federated.py reports/data.jsonl models/federated.pkl --model nomic-ai/nomic-embed-text-v1.5` to train a model on your dataset. You can choose from embedding models like nomic-embed-text-v1.5 (best for semantic search), all-MiniLM-L6-v2 (fast and lightweight), BERT, or ModernBERT. After training, use `python3 scripts/infer_pearltrees_federated.py --model models/federated.pkl --query 'your query'` to run inference. The training uses Procrustes projection and MST clustering to optimize your data hierarchy.", "question_type": "medium", "topics": ["Quickstart", "Data Tools (Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["machine-learning", "embeddings", "training", "inference", "semantic-search"], "related_skills": ["skill_ml_tools.md", "skill_embedding_models.md", "skill_train_model.md", "skill_semantic_inference.md", "skill_data_tools.md"], "related_docs": ["education/book-13-semantic-search/", "education/book-14-ai-training/", "scripts/train_pearltrees_federated.py", "tools/density_explorer/"], "original_answer": "You can train federated models using `python3 scripts/train_pearltrees_federated.py reports/data.jsonl models/federated.pkl --model nomic-ai/nomic-embed-text-v1.5`. Run inference with `python3 scripts/infer_pearltrees_federated.py --model models/federated.pkl --query 'your query'`. Supported embedding models include nomic, MiniLM, BERT, and ModernBERT. Optimize hierarchies using `python3 scripts/mindmap/hierarchy_objective.py --tree hierarchy.json --embeddings embeddings.npy` to compute the J = D/(1+H) objective. See skill_data_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_data_tools_003_q0", "cluster_id": "skill_data_tools_003", "question": "How do I generate synthetic Q&A training data?", "answer": "To generate synthetic Q&A training data, use `python training-data/scripts/generate_qa_from_skills.py --all --model haiku` to generate Q&A pairs from skills and documentation. Then reword the answers using `python scripts/generate_tailored_answers.py --input training-data/expanded`. For Pearltrees-specific training data, use `python scripts/generate_pearl_dataset.py --rdf data/export.rdf --output reports/targets.jsonl`. Finally, expand the generated Q&A clusters into individual pairs and generate embeddings for model training.", "question_type": "medium", "topics": ["Quickstart", "Data Tools (Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["synthetic-data", "qa-generation", "training-data", "documentation"], "related_skills": ["skill_synthetic_data.md", "skill_qa_generation.md", "skill_answer_tailoring.md", "skill_pearl_dataset.md", "skill_data_tools.md"], "related_docs": ["training-data/scripts/generate_qa_from_skills.py", "scripts/generate_tailored_answers.py", "scripts/generate_pearl_dataset.py"], "original_answer": "Generate Q&A from skills and documentation using `python training-data/scripts/generate_qa_from_skills.py --all --model haiku`. Reword answers using `python scripts/generate_tailored_answers.py --input training-data/expanded`. For Pearltrees data, use `python scripts/generate_pearl_dataset.py --rdf data/export.rdf --output reports/targets.jsonl`. Expand generated Q&A clusters to individual pairs, then generate embeddings for model training. See skill_data_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_data_tools_003_q1", "cluster_id": "skill_data_tools_003", "question": "Can I create training data from my documentation?", "answer": "Yes, you can create training data from your documentation using UnifyWeaver's synthetic data tools. Use `python training-data/scripts/generate_qa_from_skills.py --all --model haiku` to generate Q&A pairs from skills and documentation files. Then reword the answers using `python scripts/generate_tailored_answers.py --input training-data/expanded`. For Pearltrees data specifically, use `python scripts/generate_pearl_dataset.py --rdf data/export.rdf --output reports/targets.jsonl`. The generated Q&A pairs can be expanded to individual training pairs and used to generate embeddings for model training.", "question_type": "medium", "topics": ["Quickstart", "Data Tools (Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["synthetic-data", "qa-generation", "training-data", "documentation"], "related_skills": ["skill_synthetic_data.md", "skill_qa_generation.md", "skill_answer_tailoring.md", "skill_pearl_dataset.md", "skill_data_tools.md"], "related_docs": ["training-data/scripts/generate_qa_from_skills.py", "scripts/generate_tailored_answers.py", "scripts/generate_pearl_dataset.py"], "original_answer": "Generate Q&A from skills and documentation using `python training-data/scripts/generate_qa_from_skills.py --all --model haiku`. Reword answers using `python scripts/generate_tailored_answers.py --input training-data/expanded`. For Pearltrees data, use `python scripts/generate_pearl_dataset.py --rdf data/export.rdf --output reports/targets.jsonl`. Expand generated Q&A clusters to individual pairs, then generate embeddings for model training. See skill_data_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_data_tools_003_q2", "cluster_id": "skill_data_tools_003", "question": "How do I generate AI training datasets?", "answer": "Generate AI training datasets using Python scripts: (1) Generate Q&A pairs from skills with `python training-data/scripts/generate_qa_from_skills.py --all --model haiku`, (2) Reword answers using `python scripts/generate_tailored_answers.py --input training-data/expanded`, (3) For Pearltrees datasets, use `python scripts/generate_pearl_dataset.py --rdf data/export.rdf --output reports/targets.jsonl`, (4) Expand Q&A clusters into individual pairs and generate embeddings for training. See skill_data_tools.md for the complete synthetic data pipeline and LLM provider options.", "question_type": "medium", "topics": ["Quickstart", "Data Tools (Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["synthetic-data", "qa-generation", "training-data", "documentation"], "related_skills": ["skill_synthetic_data.md", "skill_qa_generation.md", "skill_answer_tailoring.md", "skill_pearl_dataset.md", "skill_data_tools.md"], "related_docs": ["training-data/scripts/generate_qa_from_skills.py", "scripts/generate_tailored_answers.py", "scripts/generate_pearl_dataset.py"], "original_answer": "Generate Q&A from skills and documentation using `python training-data/scripts/generate_qa_from_skills.py --all --model haiku`. Reword answers using `python scripts/generate_tailored_answers.py --input training-data/expanded`. For Pearltrees data, use `python scripts/generate_pearl_dataset.py --rdf data/export.rdf --output reports/targets.jsonl`. Expand generated Q&A clusters to individual pairs, then generate embeddings for model training. See skill_data_tools.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_data_tools_004_q0", "cluster_id": "skill_data_tools_004", "question": "How do I combine multiple scoring methods like semantic and keyword search?", "answer": "Use fuzzy score blending to combine semantic and keyword scores. Load the fuzzy module with `:- use_module('src/unifyweaver/fuzzy/fuzzy').` then call `blend_scores(Weight, SemanticScores, KeywordScores, Combined)` where Weight is a decimal between 0.0-1.0 representing the semantic score proportion (e.g., 0.7 for 70% semantic, 30% keyword). Supported fusion methods include Reciprocal Rank Fusion (RRF), multiplication, and weighted blending.", "question_type": "long", "topics": ["Quickstart", "Data Tools (Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["fuzzy-logic", "score-fusion", "search", "advanced"], "related_skills": ["skill_query_patterns.md", "skill_fuzzy_search.md", "skill_aggregation_patterns.md", "skill_data_tools.md"], "related_docs": ["src/unifyweaver/fuzzy/", "docs/BINDING_MATRIX.md"], "original_answer": "Use fuzzy score blending to combine semantic and keyword scores. Load the fuzzy module with `:- use_module('src/unifyweaver/fuzzy/fuzzy').` then call `blend_scores(0.7, SemanticScores, KeywordScores, Combined)` where 0.7 is the weight for semantic scores. Supported fusion methods include Reciprocal Rank Fusion (RRF), multiplication, and weighted blending. Apply window functions like RANK, LAG, LEAD for advanced aggregation patterns. See skill_data_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_data_tools_004_q1", "cluster_id": "skill_data_tools_004", "question": "How do I blend different search scores?", "answer": "Use fuzzy score blending to combine semantic and keyword scores. Load the fuzzy module with `:- use_module('src/unifyweaver/fuzzy/fuzzy').` then call `blend_scores(Weight, SemanticScores, KeywordScores, Combined)` where Weight (0.0-1.0) controls the balance between the two score sets. For example, `blend_scores(0.7, SemanticScores, KeywordScores, Combined)` weights semantic scores at 70% and keyword scores at 30%. UnifyWeaver also supports additional fusion methods including Reciprocal Rank Fusion (RRF) and multiplication-based blending for different use cases.", "question_type": "long", "topics": ["Quickstart", "Data Tools (Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["fuzzy-logic", "score-fusion", "search", "advanced"], "related_skills": ["skill_query_patterns.md", "skill_fuzzy_search.md", "skill_aggregation_patterns.md", "skill_data_tools.md"], "related_docs": ["src/unifyweaver/fuzzy/", "docs/BINDING_MATRIX.md"], "original_answer": "Use fuzzy score blending to combine semantic and keyword scores. Load the fuzzy module with `:- use_module('src/unifyweaver/fuzzy/fuzzy').` then call `blend_scores(0.7, SemanticScores, KeywordScores, Combined)` where 0.7 is the weight for semantic scores. Supported fusion methods include Reciprocal Rank Fusion (RRF), multiplication, and weighted blending. Apply window functions like RANK, LAG, LEAD for advanced aggregation patterns. See skill_data_tools.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_data_tools_004_q2", "cluster_id": "skill_data_tools_004", "question": "Can I use fuzzy logic for scoring?", "answer": "Yes, you can use fuzzy logic for scoring. Use the fuzzy module with `:- use_module('src/unifyweaver/fuzzy/fuzzy').` and call `blend_scores(0.7, SemanticScores, KeywordScores, Combined)` to combine semantic and keyword scores, where 0.7 is the semantic weight. Supported fusion methods include Reciprocal Rank Fusion (RRF), multiplication, and weighted blending. This allows you to merge multiple relevance signals into a single combined score.", "question_type": "long", "topics": ["Quickstart", "Data Tools (Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["fuzzy-logic", "score-fusion", "search", "advanced"], "related_skills": ["skill_query_patterns.md", "skill_fuzzy_search.md", "skill_aggregation_patterns.md", "skill_data_tools.md"], "related_docs": ["src/unifyweaver/fuzzy/", "docs/BINDING_MATRIX.md"], "original_answer": "Use fuzzy score blending to combine semantic and keyword scores. Load the fuzzy module with `:- use_module('src/unifyweaver/fuzzy/fuzzy').` then call `blend_scores(0.7, SemanticScores, KeywordScores, Combined)` where 0.7 is the weight for semantic scores. Supported fusion methods include Reciprocal Rank Fusion (RRF), multiplication, and weighted blending. Apply window functions like RANK, LAG, LEAD for advanced aggregation patterns. See skill_data_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_data_tools_005_q0", "cluster_id": "skill_data_tools_005", "question": "How do I extract structured data from markdown files?", "answer": "Extract structured data from markdown files using the perl utility `perl scripts/utils/extract_records.pl -f json -q 'pattern' path/to/file.md`. Use the `-f` flag to specify output format (json, csv, content, etc.) and `-q` flag to provide an optional query pattern to filter records. For example, to extract content matching a pattern: `perl scripts/utils/extract_records.pl -f content -q 'pattern' file.md`. The extracted records can then be used with the data sources module for further processing in Prolog queries.", "question_type": "long", "topics": ["Quickstart", "Data Tools (Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["data-extraction", "markdown", "structured-data", "json"], "related_skills": ["skill_data_sources.md", "skill_extract_records.md", "skill_json_sources.md", "skill_data_tools.md"], "related_docs": ["scripts/utils/extract_records.pl", "src/unifyweaver/targets/sql_target.pl"], "original_answer": "Extract records from markdown using the perl utility: `perl scripts/utils/extract_records.pl -f json -q 'pattern' path/to/file.md`. Specify output format with `-f` (json/csv/etc) and optional query pattern with `-q`. This integrates with the data sources module for structured data extraction. For JSON/JSONL sources, declare them with `source(json, name, [json_file('path'), columns(['field.subfield']), record_format(jsonl), null_policy(skip)])`. See skill_data_tools.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer mixes markdown extraction with JSON/JSONL source declaration, which are separate concerns. The tailored answer focuses on the extraction tool but doesn't fully explain what 'pattern' should be or show complete usage examples with different output formats."}
{"pair_id": "skill_data_tools_005_q1", "cluster_id": "skill_data_tools_005", "question": "Can I parse records from documentation?", "answer": "Yes, you can parse records from documentation using the `extract_records.pl` perl utility. Run `perl scripts/utils/extract_records.pl -f json -q 'pattern' path/to/file.md` to extract records from markdown files. Use the `-f` flag to specify output format (json, csv, etc.) and `-q` for optional pattern matching. The extracted records can then be integrated with the data sources module for structured data handling.", "question_type": "long", "topics": ["Quickstart", "Data Tools (Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["data-extraction", "markdown", "structured-data", "json"], "related_skills": ["skill_data_sources.md", "skill_extract_records.md", "skill_json_sources.md", "skill_data_tools.md"], "related_docs": ["scripts/utils/extract_records.pl", "src/unifyweaver/targets/sql_target.pl"], "original_answer": "Extract records from markdown using the perl utility: `perl scripts/utils/extract_records.pl -f json -q 'pattern' path/to/file.md`. Specify output format with `-f` (json/csv/etc) and optional query pattern with `-q`. This integrates with the data sources module for structured data extraction. For JSON/JSONL sources, declare them with `source(json, name, [json_file('path'), columns(['field.subfield']), record_format(jsonl), null_policy(skip)])`. See skill_data_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_data_tools_005_q2", "cluster_id": "skill_data_tools_005", "question": "How do I convert markdown to JSON?", "answer": "To convert markdown to JSON, use the perl utility: `perl scripts/utils/extract_records.pl -f json -q 'pattern' path/to/file.md`. The `-f json` flag specifies JSON output format, and `-q` optionally filters records by pattern. For example, to extract all records matching a pattern from a markdown file and output as JSON: `perl scripts/utils/extract_records.pl -f json -q 'unifyweaver.execution.xml_data_source' playbooks/examples_library/xml_examples.md`. The extracted records can then be used as a JSON data source by declaring it with the source/2 predicate and referencing the output file.", "question_type": "long", "topics": ["Quickstart", "Data Tools (Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["data-extraction", "markdown", "structured-data", "json"], "related_skills": ["skill_data_sources.md", "skill_extract_records.md", "skill_json_sources.md", "skill_data_tools.md"], "related_docs": ["scripts/utils/extract_records.pl", "src/unifyweaver/targets/sql_target.pl"], "original_answer": "Extract records from markdown using the perl utility: `perl scripts/utils/extract_records.pl -f json -q 'pattern' path/to/file.md`. Specify output format with `-f` (json/csv/etc) and optional query pattern with `-q`. This integrates with the data sources module for structured data extraction. For JSON/JSONL sources, declare them with `source(json, name, [json_file('path'), columns(['field.subfield']), record_format(jsonl), null_policy(skip)])`. See skill_data_tools.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer conflates markdown-to-JSON conversion with data source declaration. While the perl script does convert markdown to JSON, the answer includes unrelated information about source/2 predicates that don't directly address the conversion question. The command examples are accurate, but the explanation could be more focused on the conversion process itself."}
{"pair_id": "skill_data_tools_006_q0", "cluster_id": "skill_data_tools_006", "question": "How do I generate SQL for different databases?", "answer": "Use the SQL target module by loading `:- use_module('src/unifyweaver/targets/sql_target').` Then call `compile_predicate_to_sql(my_pred/2, [dialect(postgres)], SQL)` to generate SQL for your target database. Supported dialects include postgres, mysql, and sqlite. Each dialect generates appropriately optimized SQL with support for views, CTEs, recursive queries, and window functions.", "question_type": "long", "topics": ["Quickstart", "Data Tools (Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sql", "query-generation", "database", "advanced"], "related_skills": ["skill_query_patterns.md", "skill_sql_target.md", "skill_stream_aggregation.md", "skill_data_tools.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl", "docs/BINDING_MATRIX.md"], "original_answer": "Use the SQL target module to compile predicates to SQL across multiple databases. Load with `:- use_module('src/unifyweaver/targets/sql_target').` then call `compile_predicate_to_sql(my_pred/2, [dialect(postgres)], SQL)` to generate PostgreSQL queries. Supported dialects include postgres, mysql, and sqlite. Supports views, CTEs, recursive queries, and window functions. Stream aggregation for Go, C#, Perl, Ruby targets uses `aggregate_all(count, item(_), Count)` or `aggregate_all(sum(Price), order(_, Price), Region, Total)` patterns. See skill_data_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_data_tools_006_q1", "cluster_id": "skill_data_tools_006", "question": "Can I compile queries to SQL?", "answer": "Yes, you can compile queries to SQL using the SQL target module. Load it with `:- use_module('src/unifyweaver/targets/sql_target').` then call `compile_predicate_to_sql(my_pred/2, [dialect(postgres)], SQL)` to generate SQL queries. Supported dialects include postgres, mysql, and sqlite. This supports views, CTEs, recursive queries, and window functions for SQL generation.", "question_type": "long", "topics": ["Quickstart", "Data Tools (Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sql", "query-generation", "database", "advanced"], "related_skills": ["skill_query_patterns.md", "skill_sql_target.md", "skill_stream_aggregation.md", "skill_data_tools.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl", "docs/BINDING_MATRIX.md"], "original_answer": "Use the SQL target module to compile predicates to SQL across multiple databases. Load with `:- use_module('src/unifyweaver/targets/sql_target').` then call `compile_predicate_to_sql(my_pred/2, [dialect(postgres)], SQL)` to generate PostgreSQL queries. Supported dialects include postgres, mysql, and sqlite. Supports views, CTEs, recursive queries, and window functions. Stream aggregation for Go, C#, Perl, Ruby targets uses `aggregate_all(count, item(_), Count)` or `aggregate_all(sum(Price), order(_, Price), Region, Total)` patterns. See skill_data_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_data_tools_006_q2", "cluster_id": "skill_data_tools_006", "question": "How do I target PostgreSQL, MySQL, or SQLite?", "answer": "Use the SQL target module to compile predicates to SQL across multiple databases. Load with `:- use_module('src/unifyweaver/targets/sql_target').` then call `compile_predicate_to_sql(my_pred/2, [dialect(postgres)], SQL)` to generate queries. Supported dialects are postgres, mysql, and sqlite. The module supports views, CTEs, recursive queries, and window functions across all three database systems.", "question_type": "long", "topics": ["Quickstart", "Data Tools (Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sql", "query-generation", "database", "advanced"], "related_skills": ["skill_query_patterns.md", "skill_sql_target.md", "skill_stream_aggregation.md", "skill_data_tools.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl", "docs/BINDING_MATRIX.md"], "original_answer": "Use the SQL target module to compile predicates to SQL across multiple databases. Load with `:- use_module('src/unifyweaver/targets/sql_target').` then call `compile_predicate_to_sql(my_pred/2, [dialect(postgres)], SQL)` to generate PostgreSQL queries. Supported dialects include postgres, mysql, and sqlite. Supports views, CTEs, recursive queries, and window functions. Stream aggregation for Go, C#, Perl, Ruby targets uses `aggregate_all(count, item(_), Count)` or `aggregate_all(sum(Price), order(_, Price), Region, Total)` patterns. See skill_data_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_deployment_001_q0", "cluster_id": "skill_deployment_001", "question": "How do I deploy my service to a remote server?", "answer": "To deploy your service to a remote server, declare your service using `declare_service(name, [host('server.example.com'), port(8080), target(python), entry_point('main.py'), lifecycle(persistent)])`, then call `deploy_service(name, Result)`. For SSH-based deployment, use `generate_ssh_deploy(Service, Options, Script)` to generate deployment scripts. For multi-host deployment, use `declare_service_hosts(my_api, ['host1.example.com', 'host2.example.com'])` followed by `deploy_to_all_hosts(my_api, Results)`. You can also use `deploy_with_rollback(my_api, Result)` for automatic rollback support.", "question_type": "medium", "topics": ["Quickstart", "Deployment"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["deployment", "ssh", "service-declaration", "lifecycle"], "related_skills": ["skill_deployment.md", "skill_infrastructure.md", "skill_authentication.md", "skill_networking.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "Declare your service with `declare_service(name, [host(...), port(...), target(...), entry_point(...), lifecycle(...)])`, then deploy using `deploy_service(name, Result)`. For SSH deployment, use `generate_ssh_deploy(Service, Options, Script)` to generate deployment scripts. Service lifecycle types include persistent (always running), transient (stops after idle), on_demand (starts on request), and pipeline_bound (lives for pipeline duration). See skill_deployment.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_deployment_001_q1", "cluster_id": "skill_deployment_001", "question": "What's the process for deploying an application?", "answer": "To deploy an application, first declare your service using `declare_service(name, [host(...), port(...), target(...), entry_point(...), lifecycle(...)])` with configuration options for your target platform. Then execute `deploy_service(name, Result)` to deploy. For SSH deployments, generate scripts with `generate_ssh_deploy(Service, Options, Script)`. Choose a lifecycle type based on your needs: persistent for always-running services, transient for idle-timeout services, on_demand for request-triggered services, or pipeline_bound for pipeline-duration services. For Docker, use `generate_dockerfile(Service, Options, Dockerfile)` and `build_docker_image()`. For Kubernetes, declare config with `declare_k8s_config()` and generate manifests with `generate_k8s_deployment()`. For multi-host deployment, use `deploy_to_all_hosts()` with rollback support via `deploy_with_rollback()`.", "question_type": "medium", "topics": ["Quickstart", "Deployment"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["deployment", "ssh", "service-declaration", "lifecycle"], "related_skills": ["skill_deployment.md", "skill_infrastructure.md", "skill_authentication.md", "skill_networking.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "Declare your service with `declare_service(name, [host(...), port(...), target(...), entry_point(...), lifecycle(...)])`, then deploy using `deploy_service(name, Result)`. For SSH deployment, use `generate_ssh_deploy(Service, Options, Script)` to generate deployment scripts. Service lifecycle types include persistent (always running), transient (stops after idle), on_demand (starts on request), and pipeline_bound (lives for pipeline duration). See skill_deployment.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_deployment_001_q2", "cluster_id": "skill_deployment_001", "question": "How do I set up automated deployment?", "answer": "To set up automated deployment, declare your service using `declare_service(name, [host(...), port(...), target(...), entry_point(...), lifecycle(...)])` with appropriate options. Then use `deploy_service(name, Result)` to deploy. For SSH-based automation, generate deployment scripts with `generate_ssh_deploy(Service, Options, Script)`. Choose a lifecycle type: persistent (always running), transient (stops after idle timeout), on_demand (starts on request), or pipeline_bound (lives for pipeline duration). For containerized automation, use Docker with `generate_dockerfile(Service, Options, Dockerfile)` and `build_docker_image()`, or Kubernetes with `declare_k8s_config()` and `generate_k8s_deployment()`. Multi-host deployment is supported via `declare_service_hosts()` and `deploy_to_all_hosts()`, with rollback capability through `deploy_with_rollback()`.", "question_type": "medium", "topics": ["Quickstart", "Deployment"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["deployment", "ssh", "service-declaration", "lifecycle"], "related_skills": ["skill_deployment.md", "skill_infrastructure.md", "skill_authentication.md", "skill_networking.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "Declare your service with `declare_service(name, [host(...), port(...), target(...), entry_point(...), lifecycle(...)])`, then deploy using `deploy_service(name, Result)`. For SSH deployment, use `generate_ssh_deploy(Service, Options, Script)` to generate deployment scripts. Service lifecycle types include persistent (always running), transient (stops after idle), on_demand (starts on request), and pipeline_bound (lives for pipeline duration). See skill_deployment.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_deployment_002_q0", "cluster_id": "skill_deployment_002", "question": "How do I create Docker containers for my application?", "answer": "To create Docker containers for your application, first declare your service using `declare_service(my_api, [target(python), entry_point('main.py'), ...])`. Then generate a Dockerfile with `generate_dockerfile(Service, Options, Dockerfile)` and optionally a `.dockerignore` file with `generate_dockerignore(Service, Options, Content)`. Build the image using `build_docker_image(my_api, [tag('v1.0')], Result)` and push it to a registry with `push_docker_image(my_api, [registry(my_registry)], Result)`. For applications with multiple containers, use `declare_compose_config(...)` and `generate_docker_compose(...)` to manage them together with Docker Compose.", "question_type": "medium", "topics": ["Quickstart", "Deployment"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["docker", "containerization", "build", "registry"], "related_skills": ["skill_deployment.md", "skill_infrastructure.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "Use `generate_dockerfile(Service, Options, Dockerfile)` to create a Dockerfile. You can also generate `.dockerignore` with `generate_dockerignore(Service, Options, Content)`. Build images using `build_docker_image(my_api, [tag('v1.0')], Result)` and push to a registry with `push_docker_image(my_api, [registry(my_registry)], Result)`. For multi-service setups, declare and generate Docker Compose configs with `declare_compose_config(...)` and `generate_docker_compose(...)`. See skill_deployment.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_deployment_002_q1", "cluster_id": "skill_deployment_002", "question": "How do I generate a Dockerfile?", "answer": "To generate a Dockerfile, use the `generate_dockerfile(Service, Options, Dockerfile)` predicate. First declare your service with `declare_service(Name, Options)` specifying the target language (python, go, rust), entry point, and other configuration. Then call `generate_dockerfile(my_api, [], Dockerfile)` to create the Dockerfile. You can also generate a `.dockerignore` file using `generate_dockerignore(Service, Options, Content)` to exclude unnecessary files from the Docker build context.", "question_type": "medium", "topics": ["Quickstart", "Deployment"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["docker", "containerization", "build", "registry"], "related_skills": ["skill_deployment.md", "skill_infrastructure.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "Use `generate_dockerfile(Service, Options, Dockerfile)` to create a Dockerfile. You can also generate `.dockerignore` with `generate_dockerignore(Service, Options, Content)`. Build images using `build_docker_image(my_api, [tag('v1.0')], Result)` and push to a registry with `push_docker_image(my_api, [registry(my_registry)], Result)`. For multi-service setups, declare and generate Docker Compose configs with `declare_compose_config(...)` and `generate_docker_compose(...)`. See skill_deployment.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_deployment_002_q2", "cluster_id": "skill_deployment_002", "question": "How do I containerize my service?", "answer": "To containerize your service, use `generate_dockerfile(Service, Options, Dockerfile)` to create a Dockerfile for your application. You can also generate a `.dockerignore` file with `generate_dockerignore(Service, Options, Content)` to exclude unnecessary files. Once you have your Dockerfile, build the container image using `build_docker_image(my_api, [tag('v1.0')], Result)` and push it to a registry with `push_docker_image(my_api, [registry(my_registry)], Result)`. For projects with multiple services, use `declare_compose_config(...)` and `generate_docker_compose(...)` to generate Docker Compose configuration.", "question_type": "medium", "topics": ["Quickstart", "Deployment"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["docker", "containerization", "build", "registry"], "related_skills": ["skill_deployment.md", "skill_infrastructure.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "Use `generate_dockerfile(Service, Options, Dockerfile)` to create a Dockerfile. You can also generate `.dockerignore` with `generate_dockerignore(Service, Options, Content)`. Build images using `build_docker_image(my_api, [tag('v1.0')], Result)` and push to a registry with `push_docker_image(my_api, [registry(my_registry)], Result)`. For multi-service setups, declare and generate Docker Compose configs with `declare_compose_config(...)` and `generate_docker_compose(...)`. See skill_deployment.md for details.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null}
{"pair_id": "skill_deployment_002_q3", "cluster_id": "skill_deployment_002", "question": "Can I build and push Docker images?", "answer": "Yes. Use `build_docker_image(my_api, [tag('v1.0')], Result)` to build Docker images and `push_docker_image(my_api, [registry(my_registry)], Result)` to push them to a registry. First, generate a Dockerfile with `generate_dockerfile(Service, Options, Dockerfile)`. For multi-service deployments, you can also declare and generate Docker Compose configs with `declare_compose_config(...)` and `generate_docker_compose(...)`.", "question_type": "medium", "topics": ["Quickstart", "Deployment"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["docker", "containerization", "build", "registry"], "related_skills": ["skill_deployment.md", "skill_infrastructure.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "Use `generate_dockerfile(Service, Options, Dockerfile)` to create a Dockerfile. You can also generate `.dockerignore` with `generate_dockerignore(Service, Options, Content)`. Build images using `build_docker_image(my_api, [tag('v1.0')], Result)` and push to a registry with `push_docker_image(my_api, [registry(my_registry)], Result)`. For multi-service setups, declare and generate Docker Compose configs with `declare_compose_config(...)` and `generate_docker_compose(...)`. See skill_deployment.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_deployment_003_q0", "cluster_id": "skill_deployment_003", "question": "How do I deploy to Kubernetes?", "answer": "To deploy to Kubernetes, first declare your K8s config using `declare_k8s_config(my_api, [replicas(3), namespace(production), image('myregistry/myapi:latest'), ports([8080]), resources([requests([cpu('100m'), memory('128Mi')]), limits([cpu('500m'), memory('512Mi')])])])`. Then generate the required manifests: `generate_k8s_deployment(my_api, [], Manifest)` for the deployment, `generate_k8s_service(my_api, [], ServiceManifest)` for the service, `generate_k8s_configmap(my_api, [], ConfigMap)` for configuration, and `generate_k8s_ingress(my_api, [], IngressManifest)` for ingress routing. Finally, deploy with `deploy_to_k8s(my_api, Options, Result)`. You can scale deployments with `scale_k8s_deployment(my_api, 5, Options, Result)` and check status with `rollout_status(my_api, Options, Status)`.", "question_type": "medium", "topics": ["Quickstart", "Deployment"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["kubernetes", "k8s", "manifests", "helm", "scaling"], "related_skills": ["skill_deployment.md", "skill_infrastructure.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "Declare K8s config with `declare_k8s_config(my_api, [replicas(3), namespace(...), image(...), ports(...), resources(...)])`. Generate manifests using `generate_k8s_deployment(...)`, `generate_k8s_service(...)`, `generate_k8s_configmap(...)`, and `generate_k8s_ingress(...)`. Deploy with `deploy_to_k8s(my_api, Options, Result)`, scale with `scale_k8s_deployment(my_api, 5, Options, Result)`, and check status with `rollout_status(my_api, Options, Status)`. You can also generate Helm charts with `generate_helm_chart(...)`. See skill_deployment.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_deployment_003_q1", "cluster_id": "skill_deployment_003", "question": "How do I set up Kubernetes manifests?", "answer": "To set up Kubernetes manifests, first declare your K8s configuration using `declare_k8s_config(my_api, [replicas(3), namespace(production), image('myregistry/myapi:latest'), ports([8080]), resources([requests([cpu('100m'), memory('128Mi')]), limits([cpu('500m'), memory('512Mi')])])])`. Then generate the required manifests: use `generate_k8s_deployment(my_api, [], Manifest)` for the Deployment, `generate_k8s_service(my_api, [], ServiceManifest)` for the Service, `generate_k8s_configmap(my_api, [...], ConfigMap)` for configuration, and `generate_k8s_ingress(my_api, [...], IngressManifest)` for ingress routing. Once your manifests are ready, deploy them to your cluster using `deploy_to_k8s(my_api, Options, Result)`. You can also generate complete Helm charts with `generate_helm_chart(...)` for more advanced deployments.", "question_type": "medium", "topics": ["Quickstart", "Deployment"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["kubernetes", "k8s", "manifests", "helm", "scaling"], "related_skills": ["skill_deployment.md", "skill_infrastructure.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "Declare K8s config with `declare_k8s_config(my_api, [replicas(3), namespace(...), image(...), ports(...), resources(...)])`. Generate manifests using `generate_k8s_deployment(...)`, `generate_k8s_service(...)`, `generate_k8s_configmap(...)`, and `generate_k8s_ingress(...)`. Deploy with `deploy_to_k8s(my_api, Options, Result)`, scale with `scale_k8s_deployment(my_api, 5, Options, Result)`, and check status with `rollout_status(my_api, Options, Status)`. You can also generate Helm charts with `generate_helm_chart(...)`. See skill_deployment.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_deployment_003_q2", "cluster_id": "skill_deployment_003", "question": "Can I generate Helm charts?", "answer": "Yes, you can generate Helm charts using the `generate_helm_chart(...)` function. First, declare your Kubernetes configuration with `declare_k8s_config(my_api, [replicas(3), namespace(...), image(...), ports(...), resources(...)])`. Then generate the Helm chart using `generate_helm_chart(my_api, Options, HelmChart)`. This creates a complete Helm chart structure that can be customized and deployed.", "question_type": "medium", "topics": ["Quickstart", "Deployment"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["kubernetes", "k8s", "manifests", "helm", "scaling"], "related_skills": ["skill_deployment.md", "skill_infrastructure.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "Declare K8s config with `declare_k8s_config(my_api, [replicas(3), namespace(...), image(...), ports(...), resources(...)])`. Generate manifests using `generate_k8s_deployment(...)`, `generate_k8s_service(...)`, `generate_k8s_configmap(...)`, and `generate_k8s_ingress(...)`. Deploy with `deploy_to_k8s(my_api, Options, Result)`, scale with `scale_k8s_deployment(my_api, 5, Options, Result)`, and check status with `rollout_status(my_api, Options, Status)`. You can also generate Helm charts with `generate_helm_chart(...)`. See skill_deployment.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "The base answer mentions Helm chart generation but provides minimal detail about the function signature, parameters, or what the generated output contains. The truncation of the skill document means we cannot verify the exact API or see examples of Helm chart generation."}
{"pair_id": "skill_deployment_003_q3", "cluster_id": "skill_deployment_003", "question": "How do I scale services in Kubernetes?", "answer": "To scale services in Kubernetes, use the `scale_k8s_deployment(my_api, ReplicaCount, Options, Result)` predicate to adjust the number of replicas. First declare your K8s config with `declare_k8s_config(my_api, [replicas(N), ...])` and deploy with `deploy_to_k8s(my_api, Options, Result)`. Then scale by calling `scale_k8s_deployment(my_api, 5, [], Result)` to set your desired replica count. Monitor scaling progress with `rollout_status(my_api, Options, Status)` to verify the deployment has reached the target state.", "question_type": "medium", "topics": ["Quickstart", "Deployment"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["kubernetes", "k8s", "manifests", "helm", "scaling"], "related_skills": ["skill_deployment.md", "skill_infrastructure.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "Declare K8s config with `declare_k8s_config(my_api, [replicas(3), namespace(...), image(...), ports(...), resources(...)])`. Generate manifests using `generate_k8s_deployment(...)`, `generate_k8s_service(...)`, `generate_k8s_configmap(...)`, and `generate_k8s_ingress(...)`. Deploy with `deploy_to_k8s(my_api, Options, Result)`, scale with `scale_k8s_deployment(my_api, 5, Options, Result)`, and check status with `rollout_status(my_api, Options, Status)`. You can also generate Helm charts with `generate_helm_chart(...)`. See skill_deployment.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_deployment_004_q0", "cluster_id": "skill_deployment_004", "question": "How do I deploy serverless functions to AWS Lambda, Google Cloud, or Azure?", "answer": "To deploy serverless functions, use cloud-specific configurations: For AWS Lambda, declare `declare_lambda_config(my_func, [runtime(python39), handler('main.handler'), memory(256), timeout(30)])` and generate with `generate_lambda_function(...)` or `generate_sam_template(...)`; optionally add API Gateway with `declare_api_gateway(...)`. For Google Cloud Functions, use `declare_gcf_config(...)` and `generate_gcf_deploy(...)`; for Azure Functions, use `declare_azure_func_config(...)` and `generate_azure_func_deploy(...)`.", "question_type": "medium", "topics": ["Quickstart", "Deployment"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["serverless", "lambda", "cloud-functions", "aws", "gcp", "azure"], "related_skills": ["skill_deployment.md", "skill_infrastructure.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "For AWS Lambda, declare config with `declare_lambda_config(my_func, [runtime(python39), handler('main.handler'), memory(256), timeout(30)])` and generate with `generate_lambda_function(...)`, `generate_lambda_deploy(...)`, or `generate_sam_template(...)`.\nFor Google Cloud Functions, use `declare_gcf_config(...)` and `generate_gcf_deploy(...)`.\nFor Azure Functions, use `declare_azure_func_config(...)` and `generate_azure_func_deploy(...)`.\nCreate API Gateway integration with `declare_api_gateway(...)` and `generate_api_gateway_config(...)`. See skill_deployment.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_deployment_004_q1", "cluster_id": "skill_deployment_004", "question": "How do I deploy cloud functions?", "answer": "To deploy cloud functions, use the appropriate platform's configuration. For AWS Lambda, declare config with `declare_lambda_config(my_func, [runtime(python39), handler('main.handler'), memory(256), timeout(30)])` and generate with `generate_lambda_function(...)` or `generate_sam_template(...)`. For Google Cloud Functions, use `declare_gcf_config(...)` and `generate_gcf_deploy(...)`. For Azure Functions, use `declare_azure_func_config(...)` and `generate_azure_func_deploy(...)`. Optionally integrate with API Gateway using `declare_api_gateway(...)` and `generate_api_gateway_config(...)`.", "question_type": "medium", "topics": ["Quickstart", "Deployment"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["serverless", "lambda", "cloud-functions", "aws", "gcp", "azure"], "related_skills": ["skill_deployment.md", "skill_infrastructure.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "For AWS Lambda, declare config with `declare_lambda_config(my_func, [runtime(python39), handler('main.handler'), memory(256), timeout(30)])` and generate with `generate_lambda_function(...)`, `generate_lambda_deploy(...)`, or `generate_sam_template(...)`.\nFor Google Cloud Functions, use `declare_gcf_config(...)` and `generate_gcf_deploy(...)`.\nFor Azure Functions, use `declare_azure_func_config(...)` and `generate_azure_func_deploy(...)`.\nCreate API Gateway integration with `declare_api_gateway(...)` and `generate_api_gateway_config(...)`. See skill_deployment.md for details.", "answer_tailored": true, "confidence": 0.75, "confidence_issues": "Base answer references 'skill_deployment.md for details' which is external documentation not provided. Answer assumes user knows which cloud platform they're targeting. Exact parameter syntax and available options for each platform config not fully specified."}
{"pair_id": "skill_deployment_004_q2", "cluster_id": "skill_deployment_004", "question": "Can I generate Lambda deployment packages?", "answer": "Yes, you can generate Lambda deployment packages using the deployment skill. Declare your Lambda function with `declare_lambda_config(my_func, [runtime(python39), handler('main.handler'), memory(256), timeout(30)])`, then generate the deployment package with `generate_lambda_function(...)` or `generate_lambda_deploy(...)`. You can also use `generate_sam_template(...)` to create AWS SAM templates for infrastructure-as-code deployment. For Google Cloud Functions, use `declare_gcf_config(...)` and `generate_gcf_deploy(...)`. For Azure Functions, use `declare_azure_func_config(...)` and `generate_azure_func_deploy(...)`.", "question_type": "medium", "topics": ["Quickstart", "Deployment"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["serverless", "lambda", "cloud-functions", "aws", "gcp", "azure"], "related_skills": ["skill_deployment.md", "skill_infrastructure.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "For AWS Lambda, declare config with `declare_lambda_config(my_func, [runtime(python39), handler('main.handler'), memory(256), timeout(30)])` and generate with `generate_lambda_function(...)`, `generate_lambda_deploy(...)`, or `generate_sam_template(...)`.\nFor Google Cloud Functions, use `declare_gcf_config(...)` and `generate_gcf_deploy(...)`.\nFor Azure Functions, use `declare_azure_func_config(...)` and `generate_azure_func_deploy(...)`.\nCreate API Gateway integration with `declare_api_gateway(...)` and `generate_api_gateway_config(...)`. See skill_deployment.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_deployment_004_q3", "cluster_id": "skill_deployment_004", "question": "How do I set up cloud function handlers?", "answer": "To set up cloud function handlers, declare configuration for your cloud provider: AWS Lambda uses `declare_lambda_config(my_func, [runtime(python39), handler('main.handler'), memory(256), timeout(30)])` then generate with `generate_lambda_function(...)` or `generate_sam_template(...)`; Google Cloud Functions uses `declare_gcf_config(...)` with `generate_gcf_deploy(...)`; Azure Functions uses `declare_azure_func_config(...)` with `generate_azure_func_deploy(...)`. Optionally integrate with API Gateway using `declare_api_gateway(...)` and `generate_api_gateway_config(...)`.", "question_type": "medium", "topics": ["Quickstart", "Deployment"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["serverless", "lambda", "cloud-functions", "aws", "gcp", "azure"], "related_skills": ["skill_deployment.md", "skill_infrastructure.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "For AWS Lambda, declare config with `declare_lambda_config(my_func, [runtime(python39), handler('main.handler'), memory(256), timeout(30)])` and generate with `generate_lambda_function(...)`, `generate_lambda_deploy(...)`, or `generate_sam_template(...)`.\nFor Google Cloud Functions, use `declare_gcf_config(...)` and `generate_gcf_deploy(...)`.\nFor Azure Functions, use `declare_azure_func_config(...)` and `generate_azure_func_deploy(...)`.\nCreate API Gateway integration with `declare_api_gateway(...)` and `generate_api_gateway_config(...)`. See skill_deployment.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_deployment_005_q0", "cluster_id": "skill_deployment_005", "question": "How do I manage secrets and credentials in my deployed services?", "answer": "To manage secrets and credentials in deployed services, declare them using `declare_service_secrets(my_api, [secret(db_password, vault, 'secret/data/db'), secret(api_key, aws, 'prod/api-key')])`. UnifyWeaver supports multiple secret backends: HashiCorp Vault (via `declare_vault_config` and `generate_vault_read`), AWS Secrets Manager (`generate_aws_secret_read`), Azure Key Vault (`generate_azure_secret_read`), and GCP Secret Manager (`generate_gcp_secret_read`). Generate environment variable scripts with `generate_secret_env_script(...)`, Kubernetes secrets with `generate_k8s_secret(...)`, or external secrets integrations with `generate_k8s_external_secret(...)` for cloud-native deployments.", "question_type": "medium", "topics": ["Quickstart", "Deployment"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["secrets", "vault", "security", "credentials", "key-management"], "related_skills": ["skill_deployment.md", "skill_infrastructure.md", "skill_authentication.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "Declare service secrets with `declare_service_secrets(my_api, [secret(db_password, vault, 'secret/data/db'), secret(api_key, aws, 'prod/api-key')])`. Support includes HashiCorp Vault (`declare_vault_config...`, `generate_vault_read...`), AWS Secrets Manager (`generate_aws_secret_read...`), Azure Key Vault (`generate_azure_secret_read...`), and GCP Secret Manager (`generate_gcp_secret_read...`).\nGenerate environment scripts with `generate_secret_env_script(...)`, Kubernetes secrets with `generate_k8s_secret(...)`, or external secrets with `generate_k8s_external_secret(...)`. See skill_deployment.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_deployment_005_q1", "cluster_id": "skill_deployment_005", "question": "How do I handle sensitive configuration?", "answer": "Use `declare_service_secrets(my_api, [secret(db_password, vault, 'secret/data/db'), secret(api_key, aws, 'prod/api-key')])` to declare service secrets. UnifyWeaver supports multiple secret backends: HashiCorp Vault, AWS Secrets Manager, Azure Key Vault, and GCP Secret Manager. Generate environment scripts with `generate_secret_env_script(...)`, Kubernetes secrets with `generate_k8s_secret(...)`, or external secrets operators with `generate_k8s_external_secret(...)`. Choose the backend that matches your infrastructure.", "question_type": "medium", "topics": ["Quickstart", "Deployment"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["secrets", "vault", "security", "credentials", "key-management"], "related_skills": ["skill_deployment.md", "skill_infrastructure.md", "skill_authentication.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "Declare service secrets with `declare_service_secrets(my_api, [secret(db_password, vault, 'secret/data/db'), secret(api_key, aws, 'prod/api-key')])`. Support includes HashiCorp Vault (`declare_vault_config...`, `generate_vault_read...`), AWS Secrets Manager (`generate_aws_secret_read...`), Azure Key Vault (`generate_azure_secret_read...`), and GCP Secret Manager (`generate_gcp_secret_read...`).\nGenerate environment scripts with `generate_secret_env_script(...)`, Kubernetes secrets with `generate_k8s_secret(...)`, or external secrets with `generate_k8s_external_secret(...)`. See skill_deployment.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_deployment_005_q2", "cluster_id": "skill_deployment_005", "question": "Can I integrate with Vault or cloud secret managers?", "answer": "Yes, UnifyWeaver's deployment system supports integration with Vault and cloud secret managers. Declare service secrets using `declare_service_secrets(my_api, [secret(db_password, vault, 'secret/data/db'), secret(api_key, aws, 'prod/api-key')])`. Supported backends include HashiCorp Vault, AWS Secrets Manager, Azure Key Vault, and GCP Secret Manager. Generate environment scripts with `generate_secret_env_script(...)`, Kubernetes secrets with `generate_k8s_secret(...)`, or external secrets with `generate_k8s_external_secret(...)` for seamless integration.", "question_type": "medium", "topics": ["Quickstart", "Deployment"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["secrets", "vault", "security", "credentials", "key-management"], "related_skills": ["skill_deployment.md", "skill_infrastructure.md", "skill_authentication.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "Declare service secrets with `declare_service_secrets(my_api, [secret(db_password, vault, 'secret/data/db'), secret(api_key, aws, 'prod/api-key')])`. Support includes HashiCorp Vault (`declare_vault_config...`, `generate_vault_read...`), AWS Secrets Manager (`generate_aws_secret_read...`), Azure Key Vault (`generate_azure_secret_read...`), and GCP Secret Manager (`generate_gcp_secret_read...`).\nGenerate environment scripts with `generate_secret_env_script(...)`, Kubernetes secrets with `generate_k8s_secret(...)`, or external secrets with `generate_k8s_external_secret(...)`. See skill_deployment.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_deployment_005_q3", "cluster_id": "skill_deployment_005", "question": "How do I bind secrets to services?", "answer": "To bind secrets to services, declare them using `declare_service_secrets(my_api, [secret(db_password, vault, 'secret/data/db'), secret(api_key, aws, 'prod/api-key')])`. Choose your secrets backend: HashiCorp Vault with `declare_vault_config(...)` and `generate_vault_read(...)`, AWS Secrets Manager with `generate_aws_secret_read(...)`, Azure Key Vault with `generate_azure_secret_read(...)`, or GCP Secret Manager with `generate_gcp_secret_read(...)`. Generate environment variables using `generate_secret_env_script(...)`, Kubernetes secrets with `generate_k8s_secret(...)`, or external secrets with `generate_k8s_external_secret(...)`.", "question_type": "medium", "topics": ["Quickstart", "Deployment"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["secrets", "vault", "security", "credentials", "key-management"], "related_skills": ["skill_deployment.md", "skill_infrastructure.md", "skill_authentication.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "Declare service secrets with `declare_service_secrets(my_api, [secret(db_password, vault, 'secret/data/db'), secret(api_key, aws, 'prod/api-key')])`. Support includes HashiCorp Vault (`declare_vault_config...`, `generate_vault_read...`), AWS Secrets Manager (`generate_aws_secret_read...`), Azure Key Vault (`generate_azure_secret_read...`), and GCP Secret Manager (`generate_gcp_secret_read...`).\nGenerate environment scripts with `generate_secret_env_script(...)`, Kubernetes secrets with `generate_k8s_secret(...)`, or external secrets with `generate_k8s_external_secret(...)`. See skill_deployment.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_deployment_006_q0", "cluster_id": "skill_deployment_006", "question": "How do I deploy services across multiple regions with failover?", "answer": "To deploy services across multiple regions with failover: (1) Declare regions using `declare_region(region_name, [provider(aws), zone('region-code'), endpoints(...)])` for each target region. (2) Assign regions to your service with `declare_service_regions(my_api, [primary(us_west), secondary([us_east, eu_west])])` to specify primary and backup regions. (3) Configure failover policy with `declare_failover_policy(my_api, [strategy(health_based), health_check_interval(30), failover_threshold(3)])` to define health checking and failure thresholds. (4) Deploy to all regions using `deploy_to_all_regions(my_api, [], Results)` or deploy to specific regions with `deploy_to_region(my_api, region_name, [], Result)`. (5) Manage traffic routing between regions with `declare_traffic_policy(...)` and generate DNS configurations for automatic failover using `generate_route53_config(...)` for AWS or `generate_cloudflare_config(...)` for Cloudflare.", "question_type": "medium", "topics": ["Quickstart", "Deployment"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["multi-region", "failover", "high-availability", "traffic-management", "disaster-recovery"], "related_skills": ["skill_deployment.md", "skill_infrastructure.md", "skill_networking.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "Declare regions with `declare_region(us_west, [provider(aws), zone('us-west-2'), endpoints(...)])` and assign to service with `declare_service_regions(my_api, [primary(us_west), secondary([us_east, eu_west])])`.\nConfigure failover with `declare_failover_policy(my_api, [strategy(health_based), health_check_interval(30), failover_threshold(3)])`.\nDeploy using `deploy_to_region(my_api, us_west, [], Result)` or `deploy_to_all_regions(my_api, [], Results)`. Manage traffic with `declare_traffic_policy(...)` and generate DNS configs with `generate_route53_config(...)` or `generate_cloudflare_config(...)`. See skill_deployment.md for details.", "answer_tailored": true, "confidence": 0.75, "confidence_issues": "The base answer references skill_deployment.md details that aren't shown in the provided skill document excerpt (appears truncated). The answer covers core multi-region deployment concepts but lacks specifics on traffic policy syntax and DNS configuration examples that would strengthen confidence in implementation details."}
{"pair_id": "skill_deployment_006_q1", "cluster_id": "skill_deployment_006", "question": "How do I set up multi-region deployment?", "answer": "To set up multi-region deployment, declare regions using `declare_region(region_name, [provider(aws), zone('region-zone'), endpoints(...)])` and assign them to your service with `declare_service_regions(service_name, [primary(primary_region), secondary([secondary_region1, secondary_region2])])`. Configure failover behavior with `declare_failover_policy(service_name, [strategy(health_based), health_check_interval(30), failover_threshold(3)])`. Deploy to all regions using `deploy_to_all_regions(service_name, [], Results)` or to a specific region with `deploy_to_region(service_name, region_name, [], Result)`. Finally, manage traffic routing across regions with `declare_traffic_policy(...)` and generate DNS configurations using `generate_route53_config(...)` for AWS or `generate_cloudflare_config(...)` for other providers.", "question_type": "medium", "topics": ["Quickstart", "Deployment"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["multi-region", "failover", "high-availability", "traffic-management", "disaster-recovery"], "related_skills": ["skill_deployment.md", "skill_infrastructure.md", "skill_networking.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "Declare regions with `declare_region(us_west, [provider(aws), zone('us-west-2'), endpoints(...)])` and assign to service with `declare_service_regions(my_api, [primary(us_west), secondary([us_east, eu_west])])`.\nConfigure failover with `declare_failover_policy(my_api, [strategy(health_based), health_check_interval(30), failover_threshold(3)])`.\nDeploy using `deploy_to_region(my_api, us_west, [], Result)` or `deploy_to_all_regions(my_api, [], Results)`. Manage traffic with `declare_traffic_policy(...)` and generate DNS configs with `generate_route53_config(...)` or `generate_cloudflare_config(...)`. See skill_deployment.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_deployment_006_q2", "cluster_id": "skill_deployment_006", "question": "Can I configure failover policies?", "answer": "Yes, you can configure failover policies using `declare_failover_policy(my_api, [strategy(health_based), health_check_interval(30), failover_threshold(3)])`. First, declare regions with `declare_region(us_west, [provider(aws), zone('us-west-2'), endpoints(...)])` and assign them to your service with `declare_service_regions(my_api, [primary(us_west), secondary([us_east, eu_west])])`. The failover policy supports health-based strategies with configurable health check intervals and failover thresholds. Deploy across regions using `deploy_to_all_regions(my_api, [], Results)` and manage traffic routing with `declare_traffic_policy(...)` for DNS-based failover management.", "question_type": "medium", "topics": ["Quickstart", "Deployment"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["multi-region", "failover", "high-availability", "traffic-management", "disaster-recovery"], "related_skills": ["skill_deployment.md", "skill_infrastructure.md", "skill_networking.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "Declare regions with `declare_region(us_west, [provider(aws), zone('us-west-2'), endpoints(...)])` and assign to service with `declare_service_regions(my_api, [primary(us_west), secondary([us_east, eu_west])])`.\nConfigure failover with `declare_failover_policy(my_api, [strategy(health_based), health_check_interval(30), failover_threshold(3)])`.\nDeploy using `deploy_to_region(my_api, us_west, [], Result)` or `deploy_to_all_regions(my_api, [], Results)`. Manage traffic with `declare_traffic_policy(...)` and generate DNS configs with `generate_route53_config(...)` or `generate_cloudflare_config(...)`. See skill_deployment.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "Answer assumes health_based is the only or primary strategy; skill document content is truncated so other strategy options may exist. Confidence reduced due to incomplete documentation reference."}
{"pair_id": "skill_deployment_006_q3", "cluster_id": "skill_deployment_006", "question": "How do I manage traffic across regions?", "answer": "To manage traffic across regions, declare regions with `declare_region(region_name, [provider(aws), zone('zone-id'), endpoints(...)])`. Assign regions to your service using `declare_service_regions(my_api, [primary(us_west), secondary([us_east, eu_west])])`. Configure failover behavior with `declare_failover_policy(my_api, [strategy(health_based), health_check_interval(30), failover_threshold(3)])`. Deploy across regions with `deploy_to_all_regions(my_api, [], Results)`. Finally, manage traffic routing with `declare_traffic_policy(...)` and generate DNS configurations using `generate_route53_config(...)` for AWS or `generate_cloudflare_config(...)` for Cloudflare.", "question_type": "medium", "topics": ["Quickstart", "Deployment"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["multi-region", "failover", "high-availability", "traffic-management", "disaster-recovery"], "related_skills": ["skill_deployment.md", "skill_infrastructure.md", "skill_networking.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "Declare regions with `declare_region(us_west, [provider(aws), zone('us-west-2'), endpoints(...)])` and assign to service with `declare_service_regions(my_api, [primary(us_west), secondary([us_east, eu_west])])`.\nConfigure failover with `declare_failover_policy(my_api, [strategy(health_based), health_check_interval(30), failover_threshold(3)])`.\nDeploy using `deploy_to_region(my_api, us_west, [], Result)` or `deploy_to_all_regions(my_api, [], Results)`. Manage traffic with `declare_traffic_policy(...)` and generate DNS configs with `generate_route53_config(...)` or `generate_cloudflare_config(...)`. See skill_deployment.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_embedding_models_001_q0", "cluster_id": "skill_embedding_models_001", "question": "Which embedding model should I use for Q&A mapping?", "answer": "Use nomic-embed-text-v1.5 for Q&A mapping. It produces well-separated embeddings for queries vs documents with asymmetric prefixes (`search_query:`, `search_document:`) that help Procrustes projection learn cleaner mappings. It offers +6.7% recall improvement over MiniLM, 768 dimensions, 8192 token context window, and works well on modern mobile devices. Load it with: `model = SentenceTransformer('nomic-ai/nomic-embed-text-v1.5', trust_remote_code=True)`. Encode queries with the `search_query:` prefix and documents with `search_document:` prefix to leverage its asymmetric design.", "question_type": "medium", "topics": ["Quickstart", "Embedding Model Selection"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["embeddings", "semantic-search", "nomic"], "related_skills": ["skill_embedding_models.md"], "related_docs": ["sandbox/docs/proposals/SEARCH_METHODS_COMPARISON.md", "docs/proposals/MINIMAL_TRANSFORMATION_PROJECTION.md"], "original_answer": "Use nomic-embed-text-v1.5 for Q&A mapping. It produces well-separated embeddings for queries vs documents with asymmetric prefixes (`search_query:`, `search_document:`) that help Procrustes projection learn cleaner mappings. Performance: +6.7% recall improvement over MiniLM.\n\n```python\nfrom sentence_transformers import SentenceTransformer\nmodel = SentenceTransformer('nomic-ai/nomic-embed-text-v1.5', trust_remote_code=True)\nquery_emb = model.encode(\"search_query: How do I authenticate?\")\ndoc_emb = model.encode(\"search_document: Authentication requires valid credentials...\")\n```\n\nSee skill_embedding_models.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_embedding_models_001_q1", "cluster_id": "skill_embedding_models_001", "question": "What's the best embedding model for semantic search?", "answer": "Use nomic-embed-text-v1.5 for semantic search. It produces well-separated embeddings for queries vs documents with asymmetric prefixes (`search_query:`, `search_document:`) that help Procrustes projection learn cleaner mappings. It supports 8192 token context, works on mobile devices, and delivers +6.7% recall improvement over MiniLM. For lightweight deployments, use all-MiniLM-L6-v2 instead (384 dims, very fast, ~0.1-0.2 GB RAM).", "question_type": "medium", "topics": ["Quickstart", "Embedding Model Selection"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["embeddings", "semantic-search", "nomic"], "related_skills": ["skill_embedding_models.md"], "related_docs": ["sandbox/docs/proposals/SEARCH_METHODS_COMPARISON.md", "docs/proposals/MINIMAL_TRANSFORMATION_PROJECTION.md"], "original_answer": "Use nomic-embed-text-v1.5 for Q&A mapping. It produces well-separated embeddings for queries vs documents with asymmetric prefixes (`search_query:`, `search_document:`) that help Procrustes projection learn cleaner mappings. Performance: +6.7% recall improvement over MiniLM.\n\n```python\nfrom sentence_transformers import SentenceTransformer\nmodel = SentenceTransformer('nomic-ai/nomic-embed-text-v1.5', trust_remote_code=True)\nquery_emb = model.encode(\"search_query: How do I authenticate?\")\ndoc_emb = model.encode(\"search_document: Authentication requires valid credentials...\")\n```\n\nSee skill_embedding_models.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_embedding_models_001_q2", "cluster_id": "skill_embedding_models_001", "question": "Which embedding model works best with Procrustes projection?", "answer": "Use nomic-embed-text-v1.5 for Procrustes projection. It produces well-separated embeddings for queries vs documents with asymmetric prefixes (`search_query:`, `search_document:`) that help Procrustes learn cleaner mappings, delivering +6.7% recall improvement over MiniLM. Load with: `SentenceTransformer('nomic-ai/nomic-embed-text-v1.5', trust_remote_code=True)`. Encode queries with `search_query:` prefix and documents with `search_document:` prefix for optimal projection performance.", "question_type": "medium", "topics": ["Quickstart", "Embedding Model Selection"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["embeddings", "semantic-search", "nomic"], "related_skills": ["skill_embedding_models.md"], "related_docs": ["sandbox/docs/proposals/SEARCH_METHODS_COMPARISON.md", "docs/proposals/MINIMAL_TRANSFORMATION_PROJECTION.md"], "original_answer": "Use nomic-embed-text-v1.5 for Q&A mapping. It produces well-separated embeddings for queries vs documents with asymmetric prefixes (`search_query:`, `search_document:`) that help Procrustes projection learn cleaner mappings. Performance: +6.7% recall improvement over MiniLM.\n\n```python\nfrom sentence_transformers import SentenceTransformer\nmodel = SentenceTransformer('nomic-ai/nomic-embed-text-v1.5', trust_remote_code=True)\nquery_emb = model.encode(\"search_query: How do I authenticate?\")\ndoc_emb = model.encode(\"search_document: Authentication requires valid credentials...\")\n```\n\nSee skill_embedding_models.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_embedding_models_002_q0", "cluster_id": "skill_embedding_models_002", "question": "I need a lightweight, fast embedding model. What should I use?", "answer": "Use all-MiniLM-L6-v2 for lightweight, fast embeddings. It has 384 dimensions, 256-token context window, and minimal RAM requirements (~0.1-0.2 GB), making it ideal for resource-constrained environments and microservices.\n\n```python\nfrom sentence_transformers import SentenceTransformer\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\nembedding = model.encode(\"How do I log in?\")\n```\n\nThis model prioritizes speed and efficiency over semantic quality. If you need better semantic accuracy for Q/A mapping, use nomic-embed-text-v1.5 instead, though it's larger (768 dimensions).", "question_type": "medium", "topics": ["Quickstart", "Embedding Model Selection"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["embeddings", "lightweight", "performance"], "related_skills": ["skill_embedding_models.md"], "related_docs": [], "original_answer": "Use all-MiniLM-L6-v2 for resource-constrained environments. It's the fastest and smallest option with 384 dimensions, 256-token context, and only ~0.1-0.2 GB RAM usage.\n\n```python\nfrom sentence_transformers import SentenceTransformer\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\nembedding = model.encode(\"How do I log in?\")\n```\n\nBest for quick prototyping and microservices. See skill_embedding_models.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_embedding_models_002_q1", "cluster_id": "skill_embedding_models_002", "question": "What's the smallest embedding model?", "answer": "The smallest embedding model is all-MiniLM-L6-v2, with only 384 dimensions and ~0.1-0.2 GB RAM usage. It's also the fastest option with a 256-token context limit. Use it for resource-constrained environments, microservices, and quick prototyping. Load it with: `from sentence_transformers import SentenceTransformer; model = SentenceTransformer('all-MiniLM-L6-v2'); embedding = model.encode(\"text\")`", "question_type": "medium", "topics": ["Quickstart", "Embedding Model Selection"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["embeddings", "lightweight", "performance"], "related_skills": ["skill_embedding_models.md"], "related_docs": [], "original_answer": "Use all-MiniLM-L6-v2 for resource-constrained environments. It's the fastest and smallest option with 384 dimensions, 256-token context, and only ~0.1-0.2 GB RAM usage.\n\n```python\nfrom sentence_transformers import SentenceTransformer\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\nembedding = model.encode(\"How do I log in?\")\n```\n\nBest for quick prototyping and microservices. See skill_embedding_models.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_embedding_models_002_q2", "cluster_id": "skill_embedding_models_002", "question": "Which embedding model uses the least memory?", "answer": "all-MiniLM-L6-v2 uses the least memory of the recommended embedding models, consuming only ~0.1-0.2 GB RAM. It has 384 dimensions (vs. 768 for nomic and BERT), a 256-token context window, and is optimized for speed. Use it when memory is constrained or you need quick prototyping in microservices environments.\n\nfrom sentence_transformers import SentenceTransformer\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\nembedding = model.encode(\"Your text here\")", "question_type": "medium", "topics": ["Quickstart", "Embedding Model Selection"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["embeddings", "lightweight", "performance"], "related_skills": ["skill_embedding_models.md"], "related_docs": [], "original_answer": "Use all-MiniLM-L6-v2 for resource-constrained environments. It's the fastest and smallest option with 384 dimensions, 256-token context, and only ~0.1-0.2 GB RAM usage.\n\n```python\nfrom sentence_transformers import SentenceTransformer\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\nembedding = model.encode(\"How do I log in?\")\n```\n\nBest for quick prototyping and microservices. See skill_embedding_models.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_embedding_models_002_q3", "cluster_id": "skill_embedding_models_002", "question": "What embedding model is fastest for microservices?", "answer": "Use all-MiniLM-L6-v2 for the fastest embedding model in microservices. It has the smallest footprint (384 dimensions, 256-token context) and only requires ~0.1-0.2 GB RAM, making it ideal for resource-constrained environments. Install with `from sentence_transformers import SentenceTransformer` and encode with `model.encode(\"text\")`. It trades some semantic quality for speed and memory efficiency, so choose nomic-embed-text-v1.5 if accuracy is critical.", "question_type": "medium", "topics": ["Quickstart", "Embedding Model Selection"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["embeddings", "lightweight", "performance"], "related_skills": ["skill_embedding_models.md"], "related_docs": [], "original_answer": "Use all-MiniLM-L6-v2 for resource-constrained environments. It's the fastest and smallest option with 384 dimensions, 256-token context, and only ~0.1-0.2 GB RAM usage.\n\n```python\nfrom sentence_transformers import SentenceTransformer\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\nembedding = model.encode(\"How do I log in?\")\n```\n\nBest for quick prototyping and microservices. See skill_embedding_models.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_embedding_models_003_q0", "cluster_id": "skill_embedding_models_003", "question": "How do I compute entropy or probability scores from embeddings?", "answer": "Use BERT-base or ModernBERT to compute entropy/probability scores from embeddings via their logits output. For short text, both models produce similar entropy values. For longer text exceeding 512 tokens, ModernBERT is preferable as it supports up to 8192-token context windows and handles longer sequences more effectively. You can compute entropy using logits with the command: `python3 scripts/mindmap/hierarchy_objective.py --entropy-source logits --entropy-model answerdotai/ModernBERT-base --tree hierarchy.json`. Alternatively, for faster computation on any embedding model, use Fisher entropy instead of logits-based entropy.", "question_type": "medium", "topics": ["Quickstart", "Embedding Model Selection"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["embeddings", "entropy", "BERT", "modernBERT"], "related_skills": ["skill_embedding_models.md", "skill_hierarchy_objective.md"], "related_docs": [], "original_answer": "Use BERT-base or ModernBERT to compute entropy/probability via logits. For short text, both produce similar entropy values. For longer text (>512 tokens), ModernBERT handles context better with its 8192-token window.\n\n```bash\n# Logits entropy with ModernBERT\npython3 scripts/mindmap/hierarchy_objective.py \\\n  --entropy-source logits \\\n  --entropy-model answerdotai/ModernBERT-base \\\n  --tree hierarchy.json\n```\n\nFor faster results, use Fisher entropy with any embedding model. See skill_embedding_models.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_embedding_models_003_q1", "cluster_id": "skill_embedding_models_003", "question": "Which embedding model supports logits for entropy?", "answer": "Use BERT-base or ModernBERT to compute entropy/probability scores via logits. Both models produce similar entropy values for short text. For longer text exceeding 512 tokens, ModernBERT is preferable due to its superior context handling with an 8192-token window. You can compute logits entropy using: `python3 scripts/mindmap/hierarchy_objective.py --entropy-source logits --entropy-model answerdotai/ModernBERT-base --tree hierarchy.json`. For faster results when logits aren't required, use Fisher entropy with any embedding model.", "question_type": "medium", "topics": ["Quickstart", "Embedding Model Selection"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["embeddings", "entropy", "BERT", "modernBERT"], "related_skills": ["skill_embedding_models.md", "skill_hierarchy_objective.md"], "related_docs": [], "original_answer": "Use BERT-base or ModernBERT to compute entropy/probability via logits. For short text, both produce similar entropy values. For longer text (>512 tokens), ModernBERT handles context better with its 8192-token window.\n\n```bash\n# Logits entropy with ModernBERT\npython3 scripts/mindmap/hierarchy_objective.py \\\n  --entropy-source logits \\\n  --entropy-model answerdotai/ModernBERT-base \\\n  --tree hierarchy.json\n```\n\nFor faster results, use Fisher entropy with any embedding model. See skill_embedding_models.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_embedding_models_003_q2", "cluster_id": "skill_embedding_models_003", "question": "How do I get calibrated probability scores?", "answer": "To get calibrated probability scores, use BERT-base or ModernBERT to compute entropy/probability via logits. BERT-base works well for short text (\u2264512 tokens), while ModernBERT handles longer text better with its 8192-token context window. Both models produce similar entropy values for short text but may diverge for longer passages. Alternatively, use Fisher entropy with any embedding model for faster computation. Run: `python3 scripts/mindmap/hierarchy_objective.py --entropy-source logits --entropy-model answerdotai/ModernBERT-base --tree hierarchy.json`", "question_type": "medium", "topics": ["Quickstart", "Embedding Model Selection"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["embeddings", "entropy", "BERT", "modernBERT"], "related_skills": ["skill_embedding_models.md", "skill_hierarchy_objective.md"], "related_docs": [], "original_answer": "Use BERT-base or ModernBERT to compute entropy/probability via logits. For short text, both produce similar entropy values. For longer text (>512 tokens), ModernBERT handles context better with its 8192-token window.\n\n```bash\n# Logits entropy with ModernBERT\npython3 scripts/mindmap/hierarchy_objective.py \\\n  --entropy-source logits \\\n  --entropy-model answerdotai/ModernBERT-base \\\n  --tree hierarchy.json\n```\n\nFor faster results, use Fisher entropy with any embedding model. See skill_embedding_models.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_embedding_models_004_q0", "cluster_id": "skill_embedding_models_004", "question": "I'm deploying to Go, Rust, or C#. Which embedding model should I use?", "answer": "For Go, Rust, or C# deployment, use all-MiniLM-L6-v2 as it has the widest ONNX support across all three languages.\n\n**Go:** Use ONNX via Candle FFI in `src/unifyweaver/targets/go_runtime/embedder/embedder_candle.go`\n\n**Rust:** Use native Candle in `src/unifyweaver/targets/rust_runtime/embedding.rs` with support for BERT and ModernBERT via `MODEL_TYPE` environment variable\n\n**C#:** Use ONNX Runtime in `src/unifyweaver/targets/csharp_query_runtime/OnnxEmbeddingProvider.cs`\n\nAll implementations use NumPy `.npy`/`.npz` format for cross-platform compatibility. See skill_embedding_models.md for implementation details.", "question_type": "medium", "topics": ["Quickstart", "Embedding Model Selection"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["embeddings", "Go", "Rust", "C#", "ONNX"], "related_skills": ["skill_embedding_models.md"], "related_docs": [], "original_answer": "Use all-MiniLM-L6-v2 for widest ONNX support across Go, Rust, and C#.\n\n**Go:** ONNX-based via Candle FFI in `src/unifyweaver/targets/go_runtime/embedder/embedder_candle.go`\n\n**Rust:** Native Candle in `src/unifyweaver/targets/rust_runtime/embedding.rs` - supports BERT, ModernBERT via `MODEL_TYPE` env var\n\n**C#:** ONNX Runtime in `src/unifyweaver/targets/csharp_query_runtime/OnnxEmbeddingProvider.cs`\n\nAll use NumPy `.npy`/`.npz` format for cross-platform compatibility. See skill_embedding_models.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_embedding_models_004_q1", "cluster_id": "skill_embedding_models_004", "question": "What embedding models work with ONNX?", "answer": "For ONNX compatibility across Go, Rust, and C#, use all-MiniLM-L6-v2. Go uses ONNX via Candle FFI in src/unifyweaver/targets/go_runtime/embedder/embedder_candle.go. Rust uses native Candle in src/unifyweaver/targets/rust_runtime/embedding.rs supporting BERT and ModernBERT via MODEL_TYPE environment variable. C# uses ONNX Runtime in src/unifyweaver/targets/csharp_query_runtime/OnnxEmbeddingProvider.cs. All platforms share embeddings using NumPy .npy/.npz format.", "question_type": "medium", "topics": ["Quickstart", "Embedding Model Selection"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["embeddings", "Go", "Rust", "C#", "ONNX"], "related_skills": ["skill_embedding_models.md"], "related_docs": [], "original_answer": "Use all-MiniLM-L6-v2 for widest ONNX support across Go, Rust, and C#.\n\n**Go:** ONNX-based via Candle FFI in `src/unifyweaver/targets/go_runtime/embedder/embedder_candle.go`\n\n**Rust:** Native Candle in `src/unifyweaver/targets/rust_runtime/embedding.rs` - supports BERT, ModernBERT via `MODEL_TYPE` env var\n\n**C#:** ONNX Runtime in `src/unifyweaver/targets/csharp_query_runtime/OnnxEmbeddingProvider.cs`\n\nAll use NumPy `.npy`/`.npz` format for cross-platform compatibility. See skill_embedding_models.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_embedding_models_004_q2", "cluster_id": "skill_embedding_models_004", "question": "How do I use embeddings in compiled languages?", "answer": "Use all-MiniLM-L6-v2 for the widest ONNX support across Go, Rust, and C#. In Go, use ONNX via Candle FFI in `src/unifyweaver/targets/go_runtime/embedder/embedder_candle.go`. In Rust, use native Candle in `src/unifyweaver/targets/rust_runtime/embedding.rs` with support for BERT and ModernBERT via the `MODEL_TYPE` environment variable. In C#, use ONNX Runtime in `src/unifyweaver/targets/csharp_query_runtime/OnnxEmbeddingProvider.cs`. All implementations use NumPy `.npy`/`.npz` format for cross-platform compatibility.", "question_type": "medium", "topics": ["Quickstart", "Embedding Model Selection"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["embeddings", "Go", "Rust", "C#", "ONNX"], "related_skills": ["skill_embedding_models.md"], "related_docs": [], "original_answer": "Use all-MiniLM-L6-v2 for widest ONNX support across Go, Rust, and C#.\n\n**Go:** ONNX-based via Candle FFI in `src/unifyweaver/targets/go_runtime/embedder/embedder_candle.go`\n\n**Rust:** Native Candle in `src/unifyweaver/targets/rust_runtime/embedding.rs` - supports BERT, ModernBERT via `MODEL_TYPE` env var\n\n**C#:** ONNX Runtime in `src/unifyweaver/targets/csharp_query_runtime/OnnxEmbeddingProvider.cs`\n\nAll use NumPy `.npy`/`.npz` format for cross-platform compatibility. See skill_embedding_models.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_embedding_models_005_q0", "cluster_id": "skill_embedding_models_005", "question": "I need to process documents longer than 512 tokens. What model should I use?", "answer": "Use nomic-embed-text-v1.5 or ModernBERT for documents exceeding 512 tokens. Both support 8192-token context windows.\n\nnomic-embed-text-v1.5: 768 dimensions, includes asymmetric prefixes for Q/A mapping, works on mobile devices (tested on Samsung S24+). Use `search_query:` and `search_document:` prefixes for best results.\n\nModernBERT: 768 dimensions, optimized with Flash Attention for faster inference. Requires Python 3.10+ and transformers >= 4.48.0.\n\nFor older Linux systems with ModernBERT, create a virtual environment:\n```bash\npython3.10 -m venv ~/.venvs/modernbert\nsource ~/.venvs/modernbert/bin/activate\npip install torch transformers>=4.48.0 flash-attn --no-build-isolation\n```\n\nFor Q/A mapping tasks specifically, nomic-embed-text-v1.5 is recommended due to its superior asymmetric search quality.", "question_type": "medium", "topics": ["Quickstart", "Embedding Model Selection"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["embeddings", "long-context", "nomic", "modernBERT"], "related_skills": ["skill_embedding_models.md"], "related_docs": [], "original_answer": "Use nomic-embed-text-v1.5 or ModernBERT for documents exceeding 512 tokens. Both support 8192-token context windows.\n\n**nomic-embed-text-v1.5:** 768 dimensions, asymmetric prefixes, works well on mobile (tested S24+)\n\n**ModernBERT:** 768 dimensions, faster with Flash Attention, requires Python 3.10+ and transformers >= 4.48.0\n\nFor older Linux systems, create a virtual environment:\n```bash\npython3.10 -m venv ~/.venvs/modernbert\nsource ~/.venvs/modernbert/bin/activate\npip install torch transformers>=4.48.0 flash-attn --no-build-isolation\n```\n\nSee skill_embedding_models.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_embedding_models_005_q1", "cluster_id": "skill_embedding_models_005", "question": "Which embedding model supports long context?", "answer": "nomic-embed-text-v1.5 and ModernBERT both support long context (8192 tokens), compared to standard BERT's 512-token limit. nomic-embed-text-v1.5 has 768 dimensions with asymmetric prefixes for Q/A mapping and works on mobile devices. ModernBERT uses Flash Attention for faster inference and requires Python 3.10+ with transformers >= 4.48.0. For older Linux systems, use: python3.10 -m venv ~/.venvs/modernbert && source ~/.venvs/modernbert/bin/activate && pip install torch transformers>=4.48.0 flash-attn --no-build-isolation", "question_type": "medium", "topics": ["Quickstart", "Embedding Model Selection"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["embeddings", "long-context", "nomic", "modernBERT"], "related_skills": ["skill_embedding_models.md"], "related_docs": [], "original_answer": "Use nomic-embed-text-v1.5 or ModernBERT for documents exceeding 512 tokens. Both support 8192-token context windows.\n\n**nomic-embed-text-v1.5:** 768 dimensions, asymmetric prefixes, works well on mobile (tested S24+)\n\n**ModernBERT:** 768 dimensions, faster with Flash Attention, requires Python 3.10+ and transformers >= 4.48.0\n\nFor older Linux systems, create a virtual environment:\n```bash\npython3.10 -m venv ~/.venvs/modernbert\nsource ~/.venvs/modernbert/bin/activate\npip install torch transformers>=4.48.0 flash-attn --no-build-isolation\n```\n\nSee skill_embedding_models.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_embedding_models_005_q2", "cluster_id": "skill_embedding_models_005", "question": "Can I use embeddings for documents over 512 tokens?", "answer": "Yes, you can use embeddings for documents over 512 tokens. Use nomic-embed-text-v1.5 or ModernBERT, both supporting 8192-token context windows.\n\nnomic-embed-text-v1.5: 768 dimensions, asymmetric prefixes (`search_document:` prefix recommended), tested on mobile (Samsung S24+).\n\nModernBERT: 768 dimensions, faster with Flash Attention, requires Python 3.10+ and transformers >= 4.48.0. For older Linux systems:\n```bash\npython3.10 -m venv ~/.venvs/modernbert\nsource ~/.venvs/modernbert/bin/activate\npip install torch transformers>=4.48.0 flash-attn --no-build-isolation\n```\n\nFor Q/A mapping specifically, nomic-embed-text-v1.5 is recommended due to superior asymmetric search quality.", "question_type": "medium", "topics": ["Quickstart", "Embedding Model Selection"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["embeddings", "long-context", "nomic", "modernBERT"], "related_skills": ["skill_embedding_models.md"], "related_docs": [], "original_answer": "Use nomic-embed-text-v1.5 or ModernBERT for documents exceeding 512 tokens. Both support 8192-token context windows.\n\n**nomic-embed-text-v1.5:** 768 dimensions, asymmetric prefixes, works well on mobile (tested S24+)\n\n**ModernBERT:** 768 dimensions, faster with Flash Attention, requires Python 3.10+ and transformers >= 4.48.0\n\nFor older Linux systems, create a virtual environment:\n```bash\npython3.10 -m venv ~/.venvs/modernbert\nsource ~/.venvs/modernbert/bin/activate\npip install torch transformers>=4.48.0 flash-attn --no-build-isolation\n```\n\nSee skill_embedding_models.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_embedding_models_006_q0", "cluster_id": "skill_embedding_models_006", "question": "Can I use embeddings on mobile devices like Android or iOS?", "answer": "Yes, you can use embeddings on mobile devices like Android or iOS. The nomic-embed-text-v1.5 model is recommended for mobile deployment. Despite having 768 dimensions, it runs efficiently on modern smartphones and has been successfully tested on Samsung S24+ for on-device semantic search. It supports an 8192-token context window and includes asymmetric prefixes (search_query: and search_document:) that work effectively on mobile hardware.\n\nTo use it:\n```python\nfrom sentence_transformers import SentenceTransformer\nmodel = SentenceTransformer('nomic-ai/nomic-embed-text-v1.5', trust_remote_code=True)\nembedding = model.encode(\"search_query: How do I authenticate?\")\n```\n\nFor more resource-constrained mobile environments, all-MiniLM-L6-v2 is a lighter alternative with 384 dimensions and very fast inference, though with a shorter 256-token context window.", "question_type": "medium", "topics": ["Quickstart", "Embedding Model Selection"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["embeddings", "mobile", "nomic", "on-device"], "related_skills": ["skill_embedding_models.md"], "related_docs": [], "original_answer": "Yes, use nomic-embed-text-v1.5. Despite 768 dimensions, it runs well on modern smartphones (tested successfully on Samsung S24+ for on-device semantic search).\n\n```python\nfrom sentence_transformers import SentenceTransformer\nmodel = SentenceTransformer('nomic-ai/nomic-embed-text-v1.5', trust_remote_code=True)\nembedding = model.encode(\"search_query: How do I authenticate?\")\n```\n\nThe 8192-token context and asymmetric prefixes work effectively on mobile hardware. See skill_embedding_models.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_embedding_models_006_q1", "cluster_id": "skill_embedding_models_006", "question": "Which embedding model runs on smartphones?", "answer": "Yes, nomic-embed-text-v1.5 is the recommended embedding model for smartphones. Despite its 768 dimensions, it runs effectively on modern mobile devices like the Samsung S24+. You can use it with: `from sentence_transformers import SentenceTransformer; model = SentenceTransformer('nomic-ai/nomic-embed-text-v1.5', trust_remote_code=True); embedding = model.encode('search_query: your text here')`. The 8192-token context window and asymmetric search prefixes work well on mobile hardware.", "question_type": "medium", "topics": ["Quickstart", "Embedding Model Selection"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["embeddings", "mobile", "nomic", "on-device"], "related_skills": ["skill_embedding_models.md"], "related_docs": [], "original_answer": "Yes, use nomic-embed-text-v1.5. Despite 768 dimensions, it runs well on modern smartphones (tested successfully on Samsung S24+ for on-device semantic search).\n\n```python\nfrom sentence_transformers import SentenceTransformer\nmodel = SentenceTransformer('nomic-ai/nomic-embed-text-v1.5', trust_remote_code=True)\nembedding = model.encode(\"search_query: How do I authenticate?\")\n```\n\nThe 8192-token context and asymmetric prefixes work effectively on mobile hardware. See skill_embedding_models.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_embedding_models_006_q2", "cluster_id": "skill_embedding_models_006", "question": "Is semantic search possible on mobile?", "answer": "Yes, semantic search is possible on mobile using nomic-embed-text-v1.5. Despite its 768-dimensional embeddings, the model runs efficiently on modern smartphones\u2014it has been successfully tested on Samsung S24+ for on-device semantic search. The model's 8192-token context window and asymmetric search prefixes (`search_query:` and `search_document:`) work effectively on mobile hardware. Use the SentenceTransformer library to load and encode text: `model = SentenceTransformer('nomic-ai/nomic-embed-text-v1.5', trust_remote_code=True)` then encode queries with the `search_query:` prefix for best results.", "question_type": "medium", "topics": ["Quickstart", "Embedding Model Selection"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["embeddings", "mobile", "nomic", "on-device"], "related_skills": ["skill_embedding_models.md"], "related_docs": [], "original_answer": "Yes, use nomic-embed-text-v1.5. Despite 768 dimensions, it runs well on modern smartphones (tested successfully on Samsung S24+ for on-device semantic search).\n\n```python\nfrom sentence_transformers import SentenceTransformer\nmodel = SentenceTransformer('nomic-ai/nomic-embed-text-v1.5', trust_remote_code=True)\nembedding = model.encode(\"search_query: How do I authenticate?\")\n```\n\nThe 8192-token context and asymmetric prefixes work effectively on mobile hardware. See skill_embedding_models.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_express_api_001_q0", "cluster_id": "skill_express_api_001", "question": "How do I create an Express API?", "answer": "To create an Express API, use the Express generator module. For a basic router, call `generate_express_router(my_api, [], Code)` and specify your endpoints with `api_endpoint('/path', [method(post), module(python_module), function(func_name), input_schema(...), output_schema(...)])`. For a complete application, use `generate_express_app(my_api, [port(3001)], AppCode)`. Define endpoints declaratively with HTTP methods, Python module/function mappings, and input/output schemas. Pre-defined endpoint groups are available for common use cases like `math_endpoints` or `numpy_endpoints`.", "question_type": "medium", "topics": ["Quickstart", "Express API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["express", "api", "rest", "nodejs"], "related_skills": ["skill_express_api.md"], "related_docs": ["src/unifyweaver/glue/express_generator.pl", "src/unifyweaver/glue/rpyc_security.pl"], "original_answer": "Use the Express generator to create routers and apps. Start with `generate_express_router(my_api, [], Code)` for a basic router or `generate_express_app(my_api, [port(3001)], AppCode)` for a complete app. Define endpoints with `api_endpoint('/path', [method(post), module(python_module), function(func_name), ...])`. See skill_express_api.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_express_api_001_q1", "cluster_id": "skill_express_api_001", "question": "How do I build a Node.js REST API?", "answer": "To build a Node.js REST API, use the Express generator. For a basic router, call `generate_express_router(my_api, [], Code)`. For a complete Express app, use `generate_express_app(my_api, [port(3001)], AppCode)`. Define endpoints with `api_endpoint('/path', [method(post), module(python_module), function(func_name), input_schema(...), output_schema(...)])`. The generator creates TypeScript routers with automatic input validation, error handling, and Python function bridging via RPyC.", "question_type": "medium", "topics": ["Quickstart", "Express API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["express", "api", "rest", "nodejs"], "related_skills": ["skill_express_api.md"], "related_docs": ["src/unifyweaver/glue/express_generator.pl", "src/unifyweaver/glue/rpyc_security.pl"], "original_answer": "Use the Express generator to create routers and apps. Start with `generate_express_router(my_api, [], Code)` for a basic router or `generate_express_app(my_api, [port(3001)], AppCode)` for a complete app. Define endpoints with `api_endpoint('/path', [method(post), module(python_module), function(func_name), ...])`. See skill_express_api.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_express_api_001_q2", "cluster_id": "skill_express_api_001", "question": "Can I expose Python functions via HTTP endpoints?", "answer": "Yes. Use the Express generator to expose Python functions via HTTP. Define endpoints with `api_endpoint('/path', [method(post), module(python_module), function(func_name), input_schema(...), output_schema(...)])`, then generate a router with `generate_express_router(my_api, [endpoints(['/path'])], Code)` or a complete app with `generate_express_app(my_api, [port(3001)], AppCode)`. The generated Express.js endpoints will call your Python functions via the RPyC bridge with automatic input validation and error handling.", "question_type": "medium", "topics": ["Quickstart", "Express API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["express", "api", "rest", "nodejs"], "related_skills": ["skill_express_api.md"], "related_docs": ["src/unifyweaver/glue/express_generator.pl", "src/unifyweaver/glue/rpyc_security.pl"], "original_answer": "Use the Express generator to create routers and apps. Start with `generate_express_router(my_api, [], Code)` for a basic router or `generate_express_app(my_api, [port(3001)], AppCode)` for a complete app. Define endpoints with `api_endpoint('/path', [method(post), module(python_module), function(func_name), ...])`. See skill_express_api.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_express_api_002_q0", "cluster_id": "skill_express_api_002", "question": "How do I define API endpoints with input validation?", "answer": "To define API endpoints with input validation, use the api_endpoint/2 predicate with input_schema and output_schema options. Example: `api_endpoint('/numpy/mean', [method(post), module(numpy), function(mean), input_schema([data: array(number)]), output_schema(number)])`. The Express generator automatically creates TypeScript validation code using validateCall() that checks inputs against your schema before calling the underlying Python function. This ensures type safety and prevents invalid data from reaching your API handlers.", "question_type": "long", "topics": ["Quickstart", "Express API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["validation", "types", "schema", "typescript"], "related_skills": ["skill_express_api.md"], "related_docs": ["src/unifyweaver/glue/express_generator.pl", "src/unifyweaver/glue/rpyc_security.pl"], "original_answer": "Define endpoints with input_schema and output_schema. Example: `api_endpoint('/numpy/mean', [method(post), module(numpy), function(mean), input_schema([data: array(number)]), output_schema(number), description('Calculate mean')])`. The generator automatically creates TypeScript types and validation using validateCall(). See skill_express_api.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_express_api_002_q1", "cluster_id": "skill_express_api_002", "question": "How do I specify input and output types for endpoints?", "answer": "Use `input_schema` and `output_schema` in the endpoint declaration. For input_schema, provide a list of field names with their types like `[data: array(number), threshold: number]`. For output_schema, specify the return type like `number`, `string`, `array(object)`, etc. Example: `api_endpoint('/numpy/mean', [method(post), module(numpy), function(mean), input_schema([data: array(number)]), output_schema(number)])`. The Express generator automatically creates TypeScript type definitions and request validation based on these schemas.", "question_type": "long", "topics": ["Quickstart", "Express API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["validation", "types", "schema", "typescript"], "related_skills": ["skill_express_api.md"], "related_docs": ["src/unifyweaver/glue/express_generator.pl", "src/unifyweaver/glue/rpyc_security.pl"], "original_answer": "Define endpoints with input_schema and output_schema. Example: `api_endpoint('/numpy/mean', [method(post), module(numpy), function(mean), input_schema([data: array(number)]), output_schema(number), description('Calculate mean')])`. The generator automatically creates TypeScript types and validation using validateCall(). See skill_express_api.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_express_api_002_q2", "cluster_id": "skill_express_api_002", "question": "Can I validate endpoint request bodies?", "answer": "Yes, you can validate endpoint request bodies by defining endpoints with `input_schema` and `output_schema`. For example: `api_endpoint('/numpy/mean', [method(post), module(numpy), function(mean), input_schema([data: array(number)]), output_schema(number)])`. The generator automatically creates TypeScript validation using `validateCall()` to check request bodies against your schema before calling the underlying function.", "question_type": "long", "topics": ["Quickstart", "Express API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["validation", "types", "schema", "typescript"], "related_skills": ["skill_express_api.md"], "related_docs": ["src/unifyweaver/glue/express_generator.pl", "src/unifyweaver/glue/rpyc_security.pl"], "original_answer": "Define endpoints with input_schema and output_schema. Example: `api_endpoint('/numpy/mean', [method(post), module(numpy), function(mean), input_schema([data: array(number)]), output_schema(number), description('Calculate mean')])`. The generator automatically creates TypeScript types and validation using validateCall(). See skill_express_api.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_express_api_003_q0", "cluster_id": "skill_express_api_003", "question": "How do I use pre-defined endpoint groups?", "answer": "To use pre-defined endpoint groups in Express router generation, pass them to the `endpoints` option in `generate_express_router`. Available groups include: `math_endpoints` (sqrt, pow, pi, e), `numpy_endpoints` (mean, std, sum, min, max), and `statistics_endpoints` (mean, median, stdev). Example: `generate_express_router(my_api, [endpoints([math_endpoints, numpy_endpoints])], Code)`. This generates routers with all endpoints from the specified groups automatically configured.", "question_type": "medium", "topics": ["Quickstart", "Express API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["endpoints", "groups", "predefined", "libraries"], "related_skills": ["skill_express_api.md"], "related_docs": ["src/unifyweaver/glue/express_generator.pl"], "original_answer": "Use pre-defined endpoint groups for common libraries: `math_endpoints` (sqrt, pow, pi, e), `numpy_endpoints` (mean, std, sum, min, max), `statistics_endpoints` (mean, median, stdev). Pass them to the router: `generate_express_router(my_api, [endpoints([math_endpoints, numpy_endpoints])], Code)`. See skill_express_api.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_express_api_003_q1", "cluster_id": "skill_express_api_003", "question": "Can I add math or numpy endpoints easily?", "answer": "Yes, you can add math or numpy endpoints easily using pre-defined endpoint groups. Use `generate_express_router(my_api, [endpoints([math_endpoints, numpy_endpoints])], Code)` to include all math functions (sqrt, pow, pi, e) and numpy functions (mean, std, sum, min, max) in your Express router. If you need specific endpoints, you can also declare individual endpoints using `api_endpoint(Path, Config)` with the appropriate `method`, `module`, `function`, and `output_schema` options.", "question_type": "medium", "topics": ["Quickstart", "Express API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["endpoints", "groups", "predefined", "libraries"], "related_skills": ["skill_express_api.md"], "related_docs": ["src/unifyweaver/glue/express_generator.pl"], "original_answer": "Use pre-defined endpoint groups for common libraries: `math_endpoints` (sqrt, pow, pi, e), `numpy_endpoints` (mean, std, sum, min, max), `statistics_endpoints` (mean, median, stdev). Pass them to the router: `generate_express_router(my_api, [endpoints([math_endpoints, numpy_endpoints])], Code)`. See skill_express_api.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_express_api_003_q2", "cluster_id": "skill_express_api_003", "question": "What endpoint groups are available?", "answer": "Pre-defined endpoint groups available are: `math_endpoints` (sqrt, pow, pi, e), `numpy_endpoints` (mean, std, sum, min, max), and `statistics_endpoints` (mean, median, stdev). Use them by passing group names to `generate_express_router(name, [endpoints([group_name])], Code)`.", "question_type": "medium", "topics": ["Quickstart", "Express API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["endpoints", "groups", "predefined", "libraries"], "related_skills": ["skill_express_api.md"], "related_docs": ["src/unifyweaver/glue/express_generator.pl"], "original_answer": "Use pre-defined endpoint groups for common libraries: `math_endpoints` (sqrt, pow, pi, e), `numpy_endpoints` (mean, std, sum, min, max), `statistics_endpoints` (mean, median, stdev). Pass them to the router: `generate_express_router(my_api, [endpoints([math_endpoints, numpy_endpoints])], Code)`. See skill_express_api.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_express_api_004_q0", "cluster_id": "skill_express_api_004", "question": "How do I add security middleware to my API?", "answer": "To add security middleware to your Express API, use `generate_secure_router(Name, Code)` which automatically generates a router with built-in security middleware. This includes rate limiting to prevent abuse, request timeout to handle long-running requests, and input validation to sanitize incoming data. The generated router applies securityMiddleware to all endpoints, validating requests through RPyC security rules before calling Python functions.", "question_type": "medium", "topics": ["Quickstart", "Express API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["security", "middleware", "rate-limiting", "validation"], "related_skills": ["skill_express_api.md", "skill_frontend_security.md"], "related_docs": ["src/unifyweaver/glue/express_generator.pl", "src/unifyweaver/glue/rpyc_security.pl"], "original_answer": "Use `generate_secure_router(Name, Code)` to automatically add security middleware including rate limiting, request timeout, and input validation. The generated router includes securityMiddleware that validates all requests through RPyC security rules. See skill_express_api.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_express_api_004_q1", "cluster_id": "skill_express_api_004", "question": "How do I enable rate limiting and input validation?", "answer": "Use `generate_secure_router(Name, Code)` to automatically add security middleware. This generates an Express router with built-in rate limiting via `rateLimiter`, input validation through `validateCall()` and `validateAttr()` functions, and request timeout handling via `timeoutMiddleware`. All requests are validated against RPyC security rules before being passed to Python functions. For more granular control, you can configure rate limiting options and validation schemas using the endpoint declaration system with `input_schema()` to define expected field types.", "question_type": "medium", "topics": ["Quickstart", "Express API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["security", "middleware", "rate-limiting", "validation"], "related_skills": ["skill_express_api.md", "skill_frontend_security.md"], "related_docs": ["src/unifyweaver/glue/express_generator.pl", "src/unifyweaver/glue/rpyc_security.pl"], "original_answer": "Use `generate_secure_router(Name, Code)` to automatically add security middleware including rate limiting, request timeout, and input validation. The generated router includes securityMiddleware that validates all requests through RPyC security rules. See skill_express_api.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "Base answer lacks specific implementation details about how to configure rate limiting thresholds or customize validation rules. The generated code example shown is incomplete, making it unclear what the full middleware stack looks like or how to tune rate limiting parameters."}
{"pair_id": "skill_express_api_004_q2", "cluster_id": "skill_express_api_004", "question": "Can I secure my endpoints automatically?", "answer": "Yes, use `generate_secure_router(Name, Code)` to automatically add security middleware to your endpoints. This generates a router with built-in rate limiting, request timeout, and input validation that applies to all endpoints, protecting against common security threats without requiring manual middleware setup.", "question_type": "medium", "topics": ["Quickstart", "Express API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["security", "middleware", "rate-limiting", "validation"], "related_skills": ["skill_express_api.md", "skill_frontend_security.md"], "related_docs": ["src/unifyweaver/glue/express_generator.pl", "src/unifyweaver/glue/rpyc_security.pl"], "original_answer": "Use `generate_secure_router(Name, Code)` to automatically add security middleware including rate limiting, request timeout, and input validation. The generated router includes securityMiddleware that validates all requests through RPyC security rules. See skill_express_api.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_express_api_005_q0", "cluster_id": "skill_express_api_005", "question": "How do I access Python attributes like constants in my API?", "answer": "To access Python attributes like constants in your Express API, use the `attr(Attribute)` configuration option in your endpoint declaration. For example, to expose the `pi` constant from Python's math module: `api_endpoint('/math/pi', [method(get), module(math), attr(pi), output_schema(number), description('Get pi constant')])`. The generator creates a GET handler that retrieves the attribute value and returns it in the response. Use `attr()` instead of `function()` when you want to access module-level constants or attributes rather than call functions.", "question_type": "long", "topics": ["Quickstart", "Express API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["attributes", "constants", "python", "get-endpoints"], "related_skills": ["skill_express_api.md"], "related_docs": ["src/unifyweaver/glue/express_generator.pl", "src/unifyweaver/glue/rpyc_security.pl"], "original_answer": "Use the `attr(Attribute)` configuration for GET endpoints. Example: `api_endpoint('/math/pi', [method(get), module(math), attr(pi), output_schema(number), description('Get pi constant')])`. The generator creates a GET handler that retrieves the attribute using validateAttr(). See skill_express_api.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_express_api_005_q1", "cluster_id": "skill_express_api_005", "question": "Can I expose Python constants like math.pi?", "answer": "Yes, you can expose Python constants like math.pi using the `attr(Attribute)` configuration. Define a GET endpoint with `api_endpoint('/math/pi', [method(get), module(math), attr(pi), output_schema(number), description('Get pi constant')])`. The Express generator will create a handler that retrieves the attribute via the RPyC bridge and returns it as JSON.", "question_type": "long", "topics": ["Quickstart", "Express API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["attributes", "constants", "python", "get-endpoints"], "related_skills": ["skill_express_api.md"], "related_docs": ["src/unifyweaver/glue/express_generator.pl", "src/unifyweaver/glue/rpyc_security.pl"], "original_answer": "Use the `attr(Attribute)` configuration for GET endpoints. Example: `api_endpoint('/math/pi', [method(get), module(math), attr(pi), output_schema(number), description('Get pi constant')])`. The generator creates a GET handler that retrieves the attribute using validateAttr(). See skill_express_api.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_express_api_005_q2", "cluster_id": "skill_express_api_005", "question": "How do I create GET endpoints for Python attributes?", "answer": "To create GET endpoints for Python attributes, use the `attr(Attribute)` configuration option in your endpoint definition. Example: `api_endpoint('/math/pi', [method(get), module(math), attr(pi), output_schema(number), description('Get pi constant')])`. The Express generator will create a GET handler that retrieves the attribute value using the `validateAttr()` validator and returns it in the response.", "question_type": "long", "topics": ["Quickstart", "Express API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["attributes", "constants", "python", "get-endpoints"], "related_skills": ["skill_express_api.md"], "related_docs": ["src/unifyweaver/glue/express_generator.pl", "src/unifyweaver/glue/rpyc_security.pl"], "original_answer": "Use the `attr(Attribute)` configuration for GET endpoints. Example: `api_endpoint('/math/pi', [method(get), module(math), attr(pi), output_schema(number), description('Get pi constant')])`. The generator creates a GET handler that retrieves the attribute using validateAttr(). See skill_express_api.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_express_api_006_q0", "cluster_id": "skill_express_api_006", "question": "How do I generate TypeScript types for my API endpoints?", "answer": "Use `generate_endpoint_types(Name, Code)` to create TypeScript interfaces for your API endpoints. This generates input interfaces (e.g., NumpyMeanInput) and output types, plus a generic ApiResponse<T> wrapper for type-safe requests and responses. The generated types match your endpoint declarations defined in `api_endpoint` rules.", "question_type": "long", "topics": ["Quickstart", "Express API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["typescript", "types", "interfaces", "code-generation"], "related_skills": ["skill_express_api.md"], "related_docs": ["src/unifyweaver/glue/express_generator.pl"], "original_answer": "Use `generate_endpoint_types(Name, Code)` to create TypeScript interfaces for each endpoint. It generates input interfaces (e.g., NumpyMeanInput) and output types, plus a generic ApiResponse<T> wrapper. This ensures type-safe requests and responses across your API. See skill_express_api.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "Base answer lacks detail on how to invoke the function, what parameters it expects, and how the generated types integrate with the router. The skill document doesn't show example usage of `generate_endpoint_types` or sample generated TypeScript output."}
{"pair_id": "skill_express_api_006_q1", "cluster_id": "skill_express_api_006", "question": "Can I get type definitions for endpoint requests and responses?", "answer": "Yes, use `generate_endpoint_types(Name, Code)` to create TypeScript interfaces for endpoint requests and responses. This generates input interfaces (e.g., NumpyMeanInput) and output types, plus a generic ApiResponse<T> wrapper for type-safe API communication.", "question_type": "long", "topics": ["Quickstart", "Express API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["typescript", "types", "interfaces", "code-generation"], "related_skills": ["skill_express_api.md"], "related_docs": ["src/unifyweaver/glue/express_generator.pl"], "original_answer": "Use `generate_endpoint_types(Name, Code)` to create TypeScript interfaces for each endpoint. It generates input interfaces (e.g., NumpyMeanInput) and output types, plus a generic ApiResponse<T> wrapper. This ensures type-safe requests and responses across your API. See skill_express_api.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer references 'skill_express_api.md' which may not exist or be accessible; the answer could be more specific about how to use the generated types in actual requests"}
{"pair_id": "skill_express_api_006_q2", "cluster_id": "skill_express_api_006", "question": "How do I ensure type safety across my API?", "answer": "Use `generate_endpoint_types(Name, Code)` to automatically create TypeScript interfaces for each endpoint. This generates input interfaces (like NumpyMeanInput) and output types, along with a generic ApiResponse<T> wrapper. These interfaces ensure type-safe requests and responses across your entire API, preventing type mismatches at compile time and runtime.", "question_type": "long", "topics": ["Quickstart", "Express API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["typescript", "types", "interfaces", "code-generation"], "related_skills": ["skill_express_api.md"], "related_docs": ["src/unifyweaver/glue/express_generator.pl"], "original_answer": "Use `generate_endpoint_types(Name, Code)` to create TypeScript interfaces for each endpoint. It generates input interfaces (e.g., NumpyMeanInput) and output types, plus a generic ApiResponse<T> wrapper. This ensures type-safe requests and responses across your API. See skill_express_api.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer references 'skill_express_api.md' for details, but the skill document provided doesn't show the endpoint types generation section. The answer is accurate based on the skill overview, but lacks implementation examples of how the generated types are actually used in code."}
{"pair_id": "skill_fastapi_001_q0", "cluster_id": "skill_fastapi_001", "question": "How do I create a FastAPI application with type-validated endpoints?", "answer": "Use the FastAPI generator to create a complete application with type-validated endpoints. Call `generate_fastapi_app([endpoint_names], [app_name('YourAPI')], Code)` to generate a full FastAPI app with Pydantic models for type validation, async handlers, CORS middleware, base response models, health checks, and automatic OpenAPI schemas. For individual endpoints, use `generate_fastapi_query_handler` for GET requests and `generate_fastapi_mutation_handler` for POST/PUT/DELETE operations with automatic Pydantic input validation.", "question_type": "medium", "topics": ["Quickstart", "FastAPI"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["api", "fastapi", "rest", "async", "python"], "related_skills": ["skill_fastapi.md"], "related_docs": ["src/unifyweaver/glue/fastapi_generator.pl"], "original_answer": "Use the FastAPI generator to create a complete app with Pydantic models and async handlers. Call `generate_fastapi_app([endpoint_names], [app_name('YourAPI')], Code)` to generate a full application with CORS middleware, base response models, health checks, and OpenAPI schemas. See skill_fastapi.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_fastapi_001_q1", "cluster_id": "skill_fastapi_001", "question": "How do I build a FastAPI REST API?", "answer": "To build a FastAPI REST API, use the FastAPI generator module. Call `generate_fastapi_app([endpoint_names], [app_name('YourAPI')], Code)` to generate a complete application with Pydantic models, async handlers, CORS middleware, and automatic OpenAPI documentation. For individual endpoints, use `generate_fastapi_query_handler()` for GET requests, `generate_fastapi_mutation_handler()` for POST/PUT/DELETE, or `generate_fastapi_infinite_handler()` for cursor-based pagination. Define Pydantic models with `generate_pydantic_model(name, [field_definitions], Code)` for type validation.", "question_type": "medium", "topics": ["Quickstart", "FastAPI"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["api", "fastapi", "rest", "async", "python"], "related_skills": ["skill_fastapi.md"], "related_docs": ["src/unifyweaver/glue/fastapi_generator.pl"], "original_answer": "Use the FastAPI generator to create a complete app with Pydantic models and async handlers. Call `generate_fastapi_app([endpoint_names], [app_name('YourAPI')], Code)` to generate a full application with CORS middleware, base response models, health checks, and OpenAPI schemas. See skill_fastapi.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_fastapi_001_q2", "cluster_id": "skill_fastapi_001", "question": "What's the best way to create a typed Python API?", "answer": "Use FastAPI with Pydantic models for creating a typed Python API. FastAPI automatically provides type validation, async/await support, and generates OpenAPI documentation. Create Pydantic models for request/response schemas using field definitions (string, number, integer, boolean, datetime, optional, list types), then define async handler functions with type hints for GET/POST/PUT/DELETE endpoints. FastAPI's type system ensures runtime validation and IDE support. For a complete setup, use the FastAPI generator to scaffold an app with CORS middleware, base response models, health checks, and automatic schema generation.", "question_type": "medium", "topics": ["Quickstart", "FastAPI"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["api", "fastapi", "rest", "async", "python"], "related_skills": ["skill_fastapi.md"], "related_docs": ["src/unifyweaver/glue/fastapi_generator.pl"], "original_answer": "Use the FastAPI generator to create a complete app with Pydantic models and async handlers. Call `generate_fastapi_app([endpoint_names], [app_name('YourAPI')], Code)` to generate a full application with CORS middleware, base response models, health checks, and OpenAPI schemas. See skill_fastapi.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_fastapi_001_q3", "cluster_id": "skill_fastapi_001", "question": "How do I generate FastAPI endpoints with automatic documentation?", "answer": "Use the FastAPI generator to create endpoints with automatic OpenAPI documentation. Call `generate_fastapi_app([endpoint_names], [app_name('YourAPI')], Code)` to generate a complete application with async handlers, Pydantic models for type validation, CORS middleware, and auto-generated OpenAPI schemas. You can also use specific handlers like `generate_fastapi_query_handler()` for GET endpoints and `generate_fastapi_mutation_handler()` for POST/PUT/DELETE operations, each with automatic type hints and validation.", "question_type": "medium", "topics": ["Quickstart", "FastAPI"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["api", "fastapi", "rest", "async", "python"], "related_skills": ["skill_fastapi.md"], "related_docs": ["src/unifyweaver/glue/fastapi_generator.pl"], "original_answer": "Use the FastAPI generator to create a complete app with Pydantic models and async handlers. Call `generate_fastapi_app([endpoint_names], [app_name('YourAPI')], Code)` to generate a full application with CORS middleware, base response models, health checks, and OpenAPI schemas. See skill_fastapi.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_fastapi_002_q0", "cluster_id": "skill_fastapi_002", "question": "How do I create a GET endpoint with query parameters and pagination?", "answer": "Use `generate_fastapi_query_handler(endpoint_name, [endpoint('/api/path')], [], Code)` to create a GET endpoint with query parameters and pagination. This automatically generates an async handler with `page` and `limit` query parameters (with validation: page \u2265 1, limit between 1-100), includes error handling via HTTPException, and returns a structured JSON response with pagination metadata (page, limit, total, hasMore). The generated endpoint includes proper docstrings and async/await patterns.", "question_type": "long", "topics": ["Quickstart", "FastAPI"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["api", "fastapi", "get", "pagination", "query"], "related_skills": ["skill_fastapi.md"], "related_docs": ["src/unifyweaver/glue/fastapi_generator.pl"], "original_answer": "Generate a query handler with `generate_fastapi_query_handler(endpoint_name, [endpoint('/api/path')], [], Code)`. This creates an async GET endpoint with automatic page and limit parameters, includes error handling with HTTPException, and returns structured JSON with pagination metadata. See skill_fastapi.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_fastapi_002_q1", "cluster_id": "skill_fastapi_002", "question": "How do I add pagination to API endpoints?", "answer": "To add pagination to API endpoints, use `generate_fastapi_query_handler(endpoint_name, [endpoint('/api/path')], [], Code)` to create an async GET endpoint. This automatically generates page and limit query parameters with validation (page >= 1, 1 <= limit <= 100), includes try-catch error handling with HTTPException, and returns JSON with pagination metadata including current page, limit, total count, and hasMore flag. The generated handler calculates offset as (page - 1) * limit for fetching the correct data slice.", "question_type": "long", "topics": ["Quickstart", "FastAPI"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["api", "fastapi", "get", "pagination", "query"], "related_skills": ["skill_fastapi.md"], "related_docs": ["src/unifyweaver/glue/fastapi_generator.pl"], "original_answer": "Generate a query handler with `generate_fastapi_query_handler(endpoint_name, [endpoint('/api/path')], [], Code)`. This creates an async GET endpoint with automatic page and limit parameters, includes error handling with HTTPException, and returns structured JSON with pagination metadata. See skill_fastapi.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_fastapi_002_q2", "cluster_id": "skill_fastapi_002", "question": "How do I create a FastAPI query handler?", "answer": "Use `generate_fastapi_query_handler(endpoint_name, [endpoint('/api/path')], [], Code)` to create a FastAPI query handler. This generates an async GET endpoint with automatic `page` and `limit` query parameters, includes HTTPException error handling, and returns a JSON response with pagination metadata (page, limit, total, hasMore). The handler supports type hints through Query validation.", "question_type": "long", "topics": ["Quickstart", "FastAPI"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["api", "fastapi", "get", "pagination", "query"], "related_skills": ["skill_fastapi.md"], "related_docs": ["src/unifyweaver/glue/fastapi_generator.pl"], "original_answer": "Generate a query handler with `generate_fastapi_query_handler(endpoint_name, [endpoint('/api/path')], [], Code)`. This creates an async GET endpoint with automatic page and limit parameters, includes error handling with HTTPException, and returns structured JSON with pagination metadata. See skill_fastapi.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_fastapi_002_q3", "cluster_id": "skill_fastapi_002", "question": "How do I handle GET requests with optional parameters?", "answer": "Use `generate_fastapi_query_handler(endpoint_name, [endpoint('/api/path')], [], Code)` to create a GET endpoint that automatically includes `page` and `limit` query parameters with validation. The handler generates an async function with type hints, validation constraints (e.g., `ge=1`, `le=100`), and error handling. Optional parameters are defined using `Query(default_value, description=\"...\")`. All responses include structured JSON with pagination metadata (page, limit, total, hasMore).", "question_type": "long", "topics": ["Quickstart", "FastAPI"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["api", "fastapi", "get", "pagination", "query"], "related_skills": ["skill_fastapi.md"], "related_docs": ["src/unifyweaver/glue/fastapi_generator.pl"], "original_answer": "Generate a query handler with `generate_fastapi_query_handler(endpoint_name, [endpoint('/api/path')], [], Code)`. This creates an async GET endpoint with automatic page and limit parameters, includes error handling with HTTPException, and returns structured JSON with pagination metadata. See skill_fastapi.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_fastapi_003_q0", "cluster_id": "skill_fastapi_003", "question": "How do I create POST, PUT, or DELETE endpoints?", "answer": "Use `generate_fastapi_mutation_handler(name, [endpoint('/api/path'), method('POST|PUT|DELETE')], [], Code)` to create POST, PUT, or DELETE endpoints. This generates mutation handlers with Pydantic input validation, automatic type checking, error handling, and support for path parameters like `{id}`. Each handler includes try-catch blocks and returns standardized success/error responses. For POST endpoints, input data is validated through a Pydantic model; for DELETE endpoints, use path parameters to specify the resource. See skill_fastapi.md for complete examples and additional configuration options.", "question_type": "long", "topics": ["Quickstart", "FastAPI"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["api", "fastapi", "post", "mutation", "crud"], "related_skills": ["skill_fastapi.md"], "related_docs": ["src/unifyweaver/glue/fastapi_generator.pl"], "original_answer": "Use `generate_fastapi_mutation_handler(name, [endpoint('/api/path'), method('POST|PUT|DELETE')], [], Code)`. This generates mutation endpoints with Pydantic input validation, automatic type checking, error handling, and support for path parameters like `{id}`. Each handler includes try-catch and returns standardized success/error responses. See skill_fastapi.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_fastapi_003_q1", "cluster_id": "skill_fastapi_003", "question": "How do I handle mutations in FastAPI?", "answer": "To handle mutations in FastAPI, use `generate_fastapi_mutation_handler(name, [endpoint('/api/path'), method('POST|PUT|DELETE')], [], Code)`. This generates mutation endpoints with automatic Pydantic input validation, type checking, and error handling. POST endpoints accept input models, while DELETE and PUT can use path parameters like `{id}`. All handlers return standardized JSON responses with success status and data fields, wrapped in try-catch blocks.", "question_type": "long", "topics": ["Quickstart", "FastAPI"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["api", "fastapi", "post", "mutation", "crud"], "related_skills": ["skill_fastapi.md"], "related_docs": ["src/unifyweaver/glue/fastapi_generator.pl"], "original_answer": "Use `generate_fastapi_mutation_handler(name, [endpoint('/api/path'), method('POST|PUT|DELETE')], [], Code)`. This generates mutation endpoints with Pydantic input validation, automatic type checking, error handling, and support for path parameters like `{id}`. Each handler includes try-catch and returns standardized success/error responses. See skill_fastapi.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_fastapi_003_q2", "cluster_id": "skill_fastapi_003", "question": "How do I create a FastAPI mutation handler?", "answer": "To create a FastAPI mutation handler, use `generate_fastapi_mutation_handler(name, [endpoint('/api/path'), method('POST|PUT|DELETE')], [], Code)`. This generates POST, PUT, or DELETE endpoints with Pydantic input validation, automatic type checking, error handling, and support for path parameters like `{id}`. Each handler includes try-catch blocks and returns standardized responses with success/error status. For POST handlers, input is validated through a Pydantic model; for DELETE handlers, parameters are extracted from the URL path.", "question_type": "long", "topics": ["Quickstart", "FastAPI"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["api", "fastapi", "post", "mutation", "crud"], "related_skills": ["skill_fastapi.md"], "related_docs": ["src/unifyweaver/glue/fastapi_generator.pl"], "original_answer": "Use `generate_fastapi_mutation_handler(name, [endpoint('/api/path'), method('POST|PUT|DELETE')], [], Code)`. This generates mutation endpoints with Pydantic input validation, automatic type checking, error handling, and support for path parameters like `{id}`. Each handler includes try-catch and returns standardized success/error responses. See skill_fastapi.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_fastapi_003_q3", "cluster_id": "skill_fastapi_003", "question": "How do I add POST/DELETE endpoints to my API?", "answer": "To add POST/DELETE endpoints to your FastAPI API, use `generate_fastapi_mutation_handler(name, [endpoint('/api/path'), method('POST|PUT|DELETE')], [], Code)`. This generates mutation handlers with Pydantic input validation, automatic type checking, error handling, and path parameter support (e.g., `{id}`). Each handler includes try-catch blocks and returns standardized success/error responses.", "question_type": "long", "topics": ["Quickstart", "FastAPI"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["api", "fastapi", "post", "mutation", "crud"], "related_skills": ["skill_fastapi.md"], "related_docs": ["src/unifyweaver/glue/fastapi_generator.pl"], "original_answer": "Use `generate_fastapi_mutation_handler(name, [endpoint('/api/path'), method('POST|PUT|DELETE')], [], Code)`. This generates mutation endpoints with Pydantic input validation, automatic type checking, error handling, and support for path parameters like `{id}`. Each handler includes try-catch and returns standardized success/error responses. See skill_fastapi.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_fastapi_004_q0", "cluster_id": "skill_fastapi_004", "question": "How do I define and generate Pydantic models for my API?", "answer": "Use `generate_pydantic_model(name, [field(name, type), ...], Code)` to define Pydantic models for your API. Supported field types include: string, number, integer, boolean, datetime, optional(Type), and list(Type). For creating multiple models simultaneously, use `generate_pydantic_models([schema(name, fields), ...], [], Code)`. Generated models automatically include a Config class with from_attributes=True to enable ORM compatibility.", "question_type": "long", "topics": ["Quickstart", "FastAPI"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["api", "fastapi", "pydantic", "models", "validation"], "related_skills": ["skill_fastapi.md"], "related_docs": ["src/unifyweaver/glue/fastapi_generator.pl"], "original_answer": "Generate Pydantic models with `generate_pydantic_model(name, [field(name, type), ...], Code)`. Supported types: string, number, integer, boolean, datetime, optional(Type), list(Type). For multiple models at once, use `generate_pydantic_models([schema(name, fields), ...], [], Code)`. Generated models include Config class with from_attributes=True for ORM compatibility. See skill_fastapi.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_fastapi_004_q1", "cluster_id": "skill_fastapi_004", "question": "How do I create type-validated data models?", "answer": "Use `generate_pydantic_model(name, [field(name, type), ...], Code)` to create type-validated data models. Supported field types include: string, number, integer, boolean, datetime, optional(Type), and list(Type). For multiple models simultaneously, use `generate_pydantic_models([schema(name, fields), ...], [], Code)`. Generated models include a Config class with from_attributes=True for ORM compatibility.", "question_type": "long", "topics": ["Quickstart", "FastAPI"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["api", "fastapi", "pydantic", "models", "validation"], "related_skills": ["skill_fastapi.md"], "related_docs": ["src/unifyweaver/glue/fastapi_generator.pl"], "original_answer": "Generate Pydantic models with `generate_pydantic_model(name, [field(name, type), ...], Code)`. Supported types: string, number, integer, boolean, datetime, optional(Type), list(Type). For multiple models at once, use `generate_pydantic_models([schema(name, fields), ...], [], Code)`. Generated models include Config class with from_attributes=True for ORM compatibility. See skill_fastapi.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_fastapi_004_q2", "cluster_id": "skill_fastapi_004", "question": "How do I define API request/response schemas?", "answer": "Define API request/response schemas using Pydantic models. Use `generate_pydantic_model(name, [field(name, type), ...], Code)` to create individual models, or `generate_pydantic_models([schema(name, fields), ...], [], Code)` for multiple schemas. Supported field types include: string (str), number (float), integer (int), boolean (bool), datetime, optional(Type), and list(Type). Generated models automatically include a Config class with from_attributes=True for ORM compatibility, enabling seamless integration with database models.", "question_type": "long", "topics": ["Quickstart", "FastAPI"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["api", "fastapi", "pydantic", "models", "validation"], "related_skills": ["skill_fastapi.md"], "related_docs": ["src/unifyweaver/glue/fastapi_generator.pl"], "original_answer": "Generate Pydantic models with `generate_pydantic_model(name, [field(name, type), ...], Code)`. Supported types: string, number, integer, boolean, datetime, optional(Type), list(Type). For multiple models at once, use `generate_pydantic_models([schema(name, fields), ...], [], Code)`. Generated models include Config class with from_attributes=True for ORM compatibility. See skill_fastapi.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_fastapi_004_q3", "cluster_id": "skill_fastapi_004", "question": "How do I generate Pydantic models with FastAPI?", "answer": "To generate Pydantic models with FastAPI, use `generate_pydantic_model(name, [field(name, type), ...], Code)`. Supported field types include: string, number, integer, boolean, datetime, optional(Type), and list(Type). For multiple models simultaneously, use `generate_pydantic_models([schema(name, fields), ...], [], Code)`. Generated models automatically include a Config class with from_attributes=True for ORM compatibility, enabling seamless integration with database models.", "question_type": "long", "topics": ["Quickstart", "FastAPI"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["api", "fastapi", "pydantic", "models", "validation"], "related_skills": ["skill_fastapi.md"], "related_docs": ["src/unifyweaver/glue/fastapi_generator.pl"], "original_answer": "Generate Pydantic models with `generate_pydantic_model(name, [field(name, type), ...], Code)`. Supported types: string, number, integer, boolean, datetime, optional(Type), list(Type). For multiple models at once, use `generate_pydantic_models([schema(name, fields), ...], [], Code)`. Generated models include Config class with from_attributes=True for ORM compatibility. See skill_fastapi.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_fastapi_005_q0", "cluster_id": "skill_fastapi_005", "question": "How do I implement infinite scroll or cursor-based pagination?", "answer": "To implement infinite scroll or cursor-based pagination in FastAPI, use `generate_fastapi_infinite_handler(name, [endpoint('/api/path')], [], Code)`. This generates a GET endpoint with `cursor` and `limit` query parameters. The cursor tracks your position in the dataset, allowing frontend clients to load more items by passing the cursor from the previous response. This approach is more efficient than offset-based pagination because it doesn't require counting or skipping rows. The handler automatically manages pagination state through cursor tokens rather than page numbers.", "question_type": "long", "topics": ["Quickstart", "FastAPI"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["api", "fastapi", "pagination", "infinite-scroll", "cursor"], "related_skills": ["skill_fastapi.md"], "related_docs": ["src/unifyweaver/glue/fastapi_generator.pl"], "original_answer": "Generate an infinite scroll handler with `generate_fastapi_infinite_handler(name, [endpoint('/api/path')], [], Code)`. This creates a GET endpoint with cursor and limit query parameters instead of page-based pagination. Use cursor tokens to track position in the dataset, enabling efficient infinite scroll on frontend with better performance than offset pagination. See skill_fastapi.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_fastapi_005_q1", "cluster_id": "skill_fastapi_005", "question": "How do I implement cursor-based pagination?", "answer": "To implement cursor-based pagination, use `generate_fastapi_infinite_handler(name, [endpoint('/api/path')], [], Code)` to create a GET endpoint with cursor and limit query parameters. This approach uses cursor tokens to track position in the dataset instead of offset-based pagination, enabling efficient infinite scroll on the frontend with better performance. The generated handler accepts an optional cursor query parameter and a limit parameter, returning paginated results with the cursor token for fetching the next batch.", "question_type": "long", "topics": ["Quickstart", "FastAPI"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["api", "fastapi", "pagination", "infinite-scroll", "cursor"], "related_skills": ["skill_fastapi.md"], "related_docs": ["src/unifyweaver/glue/fastapi_generator.pl"], "original_answer": "Generate an infinite scroll handler with `generate_fastapi_infinite_handler(name, [endpoint('/api/path')], [], Code)`. This creates a GET endpoint with cursor and limit query parameters instead of page-based pagination. Use cursor tokens to track position in the dataset, enabling efficient infinite scroll on frontend with better performance than offset pagination. See skill_fastapi.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_fastapi_005_q2", "cluster_id": "skill_fastapi_005", "question": "How do I create an infinite scroll endpoint?", "answer": "To create an infinite scroll endpoint in FastAPI, use `generate_fastapi_infinite_handler(name, [endpoint('/api/path')], [], Code)`. This generates a GET endpoint with `cursor` and `limit` query parameters for cursor-based pagination instead of offset/page-based pagination. The cursor tracks your position in the dataset, enabling efficient infinite scroll on the frontend with better performance than traditional pagination. The generated endpoint accepts an optional cursor token to fetch the next batch of items and a configurable limit (typically 20-100 items). See skill_fastapi.md for the complete Prolog syntax and output examples.", "question_type": "long", "topics": ["Quickstart", "FastAPI"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["api", "fastapi", "pagination", "infinite-scroll", "cursor"], "related_skills": ["skill_fastapi.md"], "related_docs": ["src/unifyweaver/glue/fastapi_generator.pl"], "original_answer": "Generate an infinite scroll handler with `generate_fastapi_infinite_handler(name, [endpoint('/api/path')], [], Code)`. This creates a GET endpoint with cursor and limit query parameters instead of page-based pagination. Use cursor tokens to track position in the dataset, enabling efficient infinite scroll on frontend with better performance than offset pagination. See skill_fastapi.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_fastapi_005_q3", "cluster_id": "skill_fastapi_005", "question": "How do I paginate large datasets efficiently?", "answer": "To paginate large datasets efficiently, use `generate_fastapi_infinite_handler(name, [endpoint('/api/path')], [], Code)` to create a GET endpoint with cursor-based pagination. This approach uses cursor tokens instead of offset-based page numbers, which scales better for large datasets by avoiding offset computation on each request. The generated handler accepts `cursor` and `limit` query parameters, allowing the frontend to implement infinite scroll efficiently. Cursor-based pagination is superior to offset pagination for performance when dealing with large datasets.", "question_type": "long", "topics": ["Quickstart", "FastAPI"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["api", "fastapi", "pagination", "infinite-scroll", "cursor"], "related_skills": ["skill_fastapi.md"], "related_docs": ["src/unifyweaver/glue/fastapi_generator.pl"], "original_answer": "Generate an infinite scroll handler with `generate_fastapi_infinite_handler(name, [endpoint('/api/path')], [], Code)`. This creates a GET endpoint with cursor and limit query parameters instead of page-based pagination. Use cursor tokens to track position in the dataset, enabling efficient infinite scroll on frontend with better performance than offset pagination. See skill_fastapi.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_fastapi_006_q0", "cluster_id": "skill_fastapi_006", "question": "How do I add authentication endpoints to my FastAPI app?", "answer": "To add authentication endpoints to your FastAPI app, use `generate_fastapi_auth_handlers([], Code)`. This generates UserLogin and UserRegister Pydantic models for request validation, an AuthResponse model for JWT tokens, a POST `/api/auth/login` endpoint that validates email/password credentials, and a POST `/api/auth/register` endpoint with password confirmation validation. The generated handlers return authentication tokens that can be used for subsequent authenticated requests.", "question_type": "long", "topics": ["Quickstart", "FastAPI"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["api", "fastapi", "auth", "authentication", "login"], "related_skills": ["skill_fastapi.md"], "related_docs": ["src/unifyweaver/glue/fastapi_generator.pl"], "original_answer": "Generate authentication handlers with `generate_fastapi_auth_handlers([], Code)`. This creates UserLogin and UserRegister Pydantic models, AuthResponse model for tokens, POST `/api/auth/login` endpoint with email/password validation, and POST `/api/auth/register` endpoint with password confirmation checks. See skill_fastapi.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "Answer assumes user is familiar with the FastAPI skill module syntax; doesn't mention JWT specifics or token usage patterns, which would strengthen the answer"}
{"pair_id": "skill_fastapi_006_q1", "cluster_id": "skill_fastapi_006", "question": "How do I implement user login and registration?", "answer": "To implement user login and registration, use `generate_fastapi_auth_handlers([], Code)` which creates UserLogin and UserRegister Pydantic models for request validation, an AuthResponse model for token responses, a POST `/api/auth/login` endpoint that validates email/password credentials, and a POST `/api/auth/register` endpoint that validates password confirmation. This generates type-safe authentication endpoints with automatic OpenAPI documentation.", "question_type": "long", "topics": ["Quickstart", "FastAPI"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["api", "fastapi", "auth", "authentication", "login"], "related_skills": ["skill_fastapi.md"], "related_docs": ["src/unifyweaver/glue/fastapi_generator.pl"], "original_answer": "Generate authentication handlers with `generate_fastapi_auth_handlers([], Code)`. This creates UserLogin and UserRegister Pydantic models, AuthResponse model for tokens, POST `/api/auth/login` endpoint with email/password validation, and POST `/api/auth/register` endpoint with password confirmation checks. See skill_fastapi.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "Base answer lacks specifics on token generation mechanism (JWT, session, etc.) and password hashing strategy, which are critical for production login/registration. Answer assumes these are handled by the skill but doesn't clarify."}
{"pair_id": "skill_fastapi_006_q2", "cluster_id": "skill_fastapi_006", "question": "How do I add auth to my FastAPI API?", "answer": "To add authentication to your FastAPI API, use `generate_fastapi_auth_handlers([], Code)` which creates UserLogin and UserRegister Pydantic models, an AuthResponse model for JWT tokens, a POST `/api/auth/login` endpoint that validates email/password credentials, and a POST `/api/auth/register` endpoint with password confirmation validation. This generates complete auth handlers with token generation and validation built-in.", "question_type": "long", "topics": ["Quickstart", "FastAPI"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["api", "fastapi", "auth", "authentication", "login"], "related_skills": ["skill_fastapi.md"], "related_docs": ["src/unifyweaver/glue/fastapi_generator.pl"], "original_answer": "Generate authentication handlers with `generate_fastapi_auth_handlers([], Code)`. This creates UserLogin and UserRegister Pydantic models, AuthResponse model for tokens, POST `/api/auth/login` endpoint with email/password validation, and POST `/api/auth/register` endpoint with password confirmation checks. See skill_fastapi.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer mentions token handling but doesn't explicitly clarify JWT token generation or middleware setup for protecting endpoints, which are common follow-up questions about FastAPI auth."}
{"pair_id": "skill_fastapi_006_q3", "cluster_id": "skill_fastapi_006", "question": "How do I create authentication endpoints?", "answer": "To create authentication endpoints, use `generate_fastapi_auth_handlers([], Code)`. This generates UserLogin and UserRegister Pydantic models for request validation, an AuthResponse model for token responses, a POST `/api/auth/login` endpoint that validates email/password credentials, and a POST `/api/auth/register` endpoint with password confirmation validation. The generated endpoints return JWT tokens or registration confirmation in the AuthResponse format.", "question_type": "long", "topics": ["Quickstart", "FastAPI"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["api", "fastapi", "auth", "authentication", "login"], "related_skills": ["skill_fastapi.md"], "related_docs": ["src/unifyweaver/glue/fastapi_generator.pl"], "original_answer": "Generate authentication handlers with `generate_fastapi_auth_handlers([], Code)`. This creates UserLogin and UserRegister Pydantic models, AuthResponse model for tokens, POST `/api/auth/login` endpoint with email/password validation, and POST `/api/auth/register` endpoint with password confirmation checks. See skill_fastapi.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_flask_api_001_q0", "cluster_id": "skill_flask_api_001", "question": "How do I create a Flask REST API?", "answer": "Use the Flask API skill to generate complete REST APIs from Prolog specifications. Call `generate_flask_app([fetch_tasks, create_task], [app_name('TaskAPI')], Code)` to create a full Flask application with CORS support, error handlers, and a health check endpoint. For individual route handlers, use `generate_flask_query_handler` for GET endpoints with pagination, `generate_flask_mutation_handler` for POST/PUT/DELETE operations, or `generate_flask_blueprint` to organize handlers into blueprints. The skill also provides auth handlers for login and registration endpoints.", "question_type": "medium", "topics": ["Quickstart", "Web Frameworks", "Flask API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["REST API", "Flask", "web frameworks", "quickstart"], "related_skills": ["skill_flask_api.md", "skill_web_frameworks.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl"], "original_answer": "Use the Flask API skill to generate complete REST APIs from specifications. Generate a full app with `generate_flask_app([fetch_tasks, create_task], [app_name('TaskAPI')], Code).` This creates an app with CORS support, error handlers, and a health check endpoint. See skill_flask_api.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_flask_api_001_q1", "cluster_id": "skill_flask_api_001", "question": "How do I build a Flask API?", "answer": "To build a Flask API, use the Flask API skill to generate complete REST APIs from Prolog specifications. Use `generate_flask_app([fetch_tasks, create_task], [app_name('TaskAPI')], Code).` to create a full application with CORS support, error handlers, and a health check endpoint. For individual handlers, use `generate_flask_query_handler` for GET endpoints with pagination, `generate_flask_mutation_handler` for POST/PUT/DELETE operations, or `generate_flask_infinite_handler` for cursor-based pagination. For organized code, use `generate_flask_blueprint` to group related routes. See skill_flask_api.md for complete documentation.", "question_type": "medium", "topics": ["Quickstart", "Web Frameworks", "Flask API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["REST API", "Flask", "web frameworks", "quickstart"], "related_skills": ["skill_flask_api.md", "skill_web_frameworks.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl"], "original_answer": "Use the Flask API skill to generate complete REST APIs from specifications. Generate a full app with `generate_flask_app([fetch_tasks, create_task], [app_name('TaskAPI')], Code).` This creates an app with CORS support, error handlers, and a health check endpoint. See skill_flask_api.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_flask_api_001_q2", "cluster_id": "skill_flask_api_001", "question": "What's the best way to create REST endpoints with Flask?", "answer": "Use the Flask API skill to generate REST endpoints. For simple endpoints, use `generate_flask_query_handler()` for GET requests with pagination and `generate_flask_mutation_handler()` for POST/PUT/DELETE operations. For a complete application, use `generate_flask_app()` which generates all routes with CORS support, error handlers, and health checks. For organized APIs with multiple routes, use `generate_flask_blueprint()` to group related endpoints under a blueprint with a common URL prefix.", "question_type": "medium", "topics": ["Quickstart", "Web Frameworks", "Flask API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["REST API", "Flask", "web frameworks", "quickstart"], "related_skills": ["skill_flask_api.md", "skill_web_frameworks.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl"], "original_answer": "Use the Flask API skill to generate complete REST APIs from specifications. Generate a full app with `generate_flask_app([fetch_tasks, create_task], [app_name('TaskAPI')], Code).` This creates an app with CORS support, error handlers, and a health check endpoint. See skill_flask_api.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_flask_api_001_q3", "cluster_id": "skill_flask_api_001", "question": "How do I generate Flask API routes?", "answer": "Use the Flask API skill to generate routes with `generate_flask_app([fetch_tasks, create_task], [app_name('TaskAPI')], Code).` This creates a complete Flask app with all routes, CORS support, error handlers, and a health check endpoint. For individual route generation, use `generate_flask_query_handler(fetch_items, [endpoint('/api/items')], [], Code)` for GET endpoints, `generate_flask_mutation_handler(create_item, [endpoint('/api/items'), method('POST')], [], Code)` for POST/PUT/DELETE, or `generate_flask_infinite_handler(load_feed, [endpoint('/api/feed'), page_param('cursor')], [], Code)` for infinite scroll. See skill_flask_api.md for complete documentation.", "question_type": "medium", "topics": ["Quickstart", "Web Frameworks", "Flask API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["REST API", "Flask", "web frameworks", "quickstart"], "related_skills": ["skill_flask_api.md", "skill_web_frameworks.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl"], "original_answer": "Use the Flask API skill to generate complete REST APIs from specifications. Generate a full app with `generate_flask_app([fetch_tasks, create_task], [app_name('TaskAPI')], Code).` This creates an app with CORS support, error handlers, and a health check endpoint. See skill_flask_api.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_flask_api_002_q0", "cluster_id": "skill_flask_api_002", "question": "How do I create GET endpoints with pagination?", "answer": "To create GET endpoints with pagination, use `generate_flask_query_handler(fetch_items, [endpoint('/api/items')], [], Code).` This generates a GET route that accepts `page` and `limit` query parameters, automatically calculates offset, and returns a JSON response with pagination metadata including page number, limit, total count, and a `hasMore` boolean flag to indicate if more results exist.", "question_type": "long", "topics": ["Quickstart", "Web Frameworks", "Flask API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["GET endpoints", "pagination", "query handlers", "REST"], "related_skills": ["skill_flask_api.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl"], "original_answer": "Use `generate_flask_query_handler(fetch_items, [endpoint('/api/items')], [], Code).` This generates a GET endpoint with built-in pagination support, including page/limit parameters, offset calculation, and a JSON response with pagination metadata (page, limit, total, hasMore). See skill_flask_api.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_flask_api_002_q1", "cluster_id": "skill_flask_api_002", "question": "How do I add query handlers to Flask?", "answer": "To add query handlers to Flask, use `generate_flask_query_handler(handler_name, [endpoint('/api/path')], [], Code)` to generate a GET endpoint with automatic pagination support. This creates routes with page and limit parameters, offset calculation, and returns a JSON response containing your data plus pagination metadata (page, limit, total, hasMore). The generated handler includes try-catch error handling and validates pagination parameters (page \u2265 1, limit between 1-100).", "question_type": "long", "topics": ["Quickstart", "Web Frameworks", "Flask API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["GET endpoints", "pagination", "query handlers", "REST"], "related_skills": ["skill_flask_api.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl"], "original_answer": "Use `generate_flask_query_handler(fetch_items, [endpoint('/api/items')], [], Code).` This generates a GET endpoint with built-in pagination support, including page/limit parameters, offset calculation, and a JSON response with pagination metadata (page, limit, total, hasMore). See skill_flask_api.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_flask_api_002_q2", "cluster_id": "skill_flask_api_002", "question": "How do I implement paginated endpoints?", "answer": "To implement paginated endpoints, use `generate_flask_query_handler(fetch_items, [endpoint('/api/items')], [], Code).` to generate a GET endpoint with built-in pagination. It automatically handles page and limit query parameters, calculates the offset, and returns a JSON response with pagination metadata including page number, limit, total count, and a hasMore boolean flag indicating if more results are available. This approach provides cursor-independent offset-based pagination suitable for standard paginated queries.", "question_type": "long", "topics": ["Quickstart", "Web Frameworks", "Flask API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["GET endpoints", "pagination", "query handlers", "REST"], "related_skills": ["skill_flask_api.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl"], "original_answer": "Use `generate_flask_query_handler(fetch_items, [endpoint('/api/items')], [], Code).` This generates a GET endpoint with built-in pagination support, including page/limit parameters, offset calculation, and a JSON response with pagination metadata (page, limit, total, hasMore). See skill_flask_api.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_flask_api_002_q3", "cluster_id": "skill_flask_api_002", "question": "How do I handle GET requests with page/limit parameters?", "answer": "Use `generate_flask_query_handler(fetch_items, [endpoint('/api/items')], [], Code).` to create a GET endpoint that automatically handles page and limit query parameters. The generated handler extracts these from `request.args`, validates them (page minimum 1, limit capped at 100), calculates the offset, and returns a JSON response with the data plus pagination metadata (page, limit, total, hasMore) indicating whether more results exist.", "question_type": "long", "topics": ["Quickstart", "Web Frameworks", "Flask API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["GET endpoints", "pagination", "query handlers", "REST"], "related_skills": ["skill_flask_api.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl"], "original_answer": "Use `generate_flask_query_handler(fetch_items, [endpoint('/api/items')], [], Code).` This generates a GET endpoint with built-in pagination support, including page/limit parameters, offset calculation, and a JSON response with pagination metadata (page, limit, total, hasMore). See skill_flask_api.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_flask_api_003_q0", "cluster_id": "skill_flask_api_003", "question": "How do I create POST, PUT, or DELETE endpoints?", "answer": "Use `generate_flask_mutation_handler` to create POST, PUT, or DELETE endpoints. Specify the handler name, endpoint path, HTTP method, and any options. Example: `generate_flask_mutation_handler(create_item, [endpoint('/api/items'), method('POST')], [], Code).` for POST, or `generate_flask_mutation_handler(delete_item, [endpoint('/api/items/<id>'), method('DELETE')], [], Code).` for DELETE. This generates handlers with automatic error handling and JSON responses. For complete Flask app generation with multiple endpoints, use `generate_flask_app(Patterns, Options, Code).`", "question_type": "long", "topics": ["Quickstart", "Web Frameworks", "Flask API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["POST", "DELETE", "PUT", "mutations", "REST"], "related_skills": ["skill_flask_api.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl"], "original_answer": "Use mutation handlers to generate POST, PUT, or DELETE endpoints. For example: `generate_flask_mutation_handler(create_item, [endpoint('/api/items'), method('POST')], [], Code).` or `generate_flask_mutation_handler(delete_item, [endpoint('/api/items/<id>'), method('DELETE')], [], Code).` These generate handlers with proper error handling and JSON responses. See skill_flask_api.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_flask_api_003_q1", "cluster_id": "skill_flask_api_003", "question": "How do I add mutation handlers to Flask?", "answer": "Use `generate_flask_mutation_handler/4` to create POST, PUT, or DELETE endpoints. Specify the handler name, endpoint path with optional URL parameters (e.g., `<id>`), HTTP method, and options list. Example: `generate_flask_mutation_handler(create_item, [endpoint('/api/items'), method('POST')], [], Code).` generates a POST handler with JSON request body parsing, error handling, and JSON response. For DELETE with path parameters: `generate_flask_mutation_handler(delete_item, [endpoint('/api/items/<id>'), method('DELETE')], [], Code).` The generated handlers include try-catch blocks and proper HTTP status codes.", "question_type": "long", "topics": ["Quickstart", "Web Frameworks", "Flask API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["POST", "DELETE", "PUT", "mutations", "REST"], "related_skills": ["skill_flask_api.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl"], "original_answer": "Use mutation handlers to generate POST, PUT, or DELETE endpoints. For example: `generate_flask_mutation_handler(create_item, [endpoint('/api/items'), method('POST')], [], Code).` or `generate_flask_mutation_handler(delete_item, [endpoint('/api/items/<id>'), method('DELETE')], [], Code).` These generate handlers with proper error handling and JSON responses. See skill_flask_api.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_flask_api_003_q2", "cluster_id": "skill_flask_api_003", "question": "How do I handle form submissions in Flask?", "answer": "To handle form submissions in Flask, use mutation handlers to generate POST endpoints. For example: `generate_flask_mutation_handler(create_item, [endpoint('/api/items'), method('POST')], [], Code).` This generates a handler that accepts form data, validates it, and returns a JSON response with proper error handling. The generated handler automatically wraps your logic in try-catch blocks and returns success/error JSON responses suitable for form submission workflows.", "question_type": "long", "topics": ["Quickstart", "Web Frameworks", "Flask API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["POST", "DELETE", "PUT", "mutations", "REST"], "related_skills": ["skill_flask_api.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl"], "original_answer": "Use mutation handlers to generate POST, PUT, or DELETE endpoints. For example: `generate_flask_mutation_handler(create_item, [endpoint('/api/items'), method('POST')], [], Code).` or `generate_flask_mutation_handler(delete_item, [endpoint('/api/items/<id>'), method('DELETE')], [], Code).` These generate handlers with proper error handling and JSON responses. See skill_flask_api.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "The base answer doesn't explicitly mention form data handling (request.form), file uploads, or content-type considerations. It focuses on the Prolog API generation rather than practical form submission details like multipart/form-data encoding or form field validation patterns."}
{"pair_id": "skill_flask_api_003_q3", "cluster_id": "skill_flask_api_003", "question": "How do I implement create/update/delete operations?", "answer": "To implement create/update/delete operations in Flask, use mutation handlers. For POST (create): `generate_flask_mutation_handler(create_item, [endpoint('/api/items'), method('POST')], [], Code).` For PUT (update): `generate_flask_mutation_handler(update_item, [endpoint('/api/items/<id>'), method('PUT')], [], Code).` For DELETE: `generate_flask_mutation_handler(delete_item, [endpoint('/api/items/<id>'), method('DELETE')], [], Code).` Each generates a handler with JSON request/response handling, error handling, and proper HTTP semantics.", "question_type": "long", "topics": ["Quickstart", "Web Frameworks", "Flask API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["POST", "DELETE", "PUT", "mutations", "REST"], "related_skills": ["skill_flask_api.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl"], "original_answer": "Use mutation handlers to generate POST, PUT, or DELETE endpoints. For example: `generate_flask_mutation_handler(create_item, [endpoint('/api/items'), method('POST')], [], Code).` or `generate_flask_mutation_handler(delete_item, [endpoint('/api/items/<id>'), method('DELETE')], [], Code).` These generate handlers with proper error handling and JSON responses. See skill_flask_api.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_flask_api_004_q0", "cluster_id": "skill_flask_api_004", "question": "How do I implement infinite scroll or cursor-based pagination?", "answer": "To implement infinite scroll or cursor-based pagination with Flask, use the `generate_flask_infinite_handler` predicate. Call `generate_flask_infinite_handler(load_feed, [endpoint('/api/feed'), page_param('cursor')], [], Code)` to generate a handler that uses cursor-based pagination instead of offset-based. This generates an endpoint that returns a `nextCursor` value and a `hasMore` boolean flag, which the frontend uses to fetch subsequent pages by passing the cursor in the next request. This approach is more efficient than offset-based pagination for large datasets.", "question_type": "long", "topics": ["Quickstart", "Web Frameworks", "Flask API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["infinite scroll", "cursor pagination", "feeds"], "related_skills": ["skill_flask_api.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl"], "original_answer": "Use `generate_flask_infinite_handler(load_feed, [endpoint('/api/feed'), page_param('cursor')], [], Code).` This generates a cursor-based pagination handler that returns nextCursor and hasMore fields, perfect for infinite scroll interfaces. See skill_flask_api.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_flask_api_004_q1", "cluster_id": "skill_flask_api_004", "question": "How do I add infinite scroll to my API?", "answer": "To add infinite scroll to your API, use `generate_flask_infinite_handler(load_feed, [endpoint('/api/feed'), page_param('cursor')], [], Code).` This generates a cursor-based pagination handler that returns `nextCursor` and `hasMore` fields. The handler accepts a `cursor` parameter for fetching the next batch of results, enabling efficient infinite scroll implementation without loading all data upfront.", "question_type": "long", "topics": ["Quickstart", "Web Frameworks", "Flask API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["infinite scroll", "cursor pagination", "feeds"], "related_skills": ["skill_flask_api.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl"], "original_answer": "Use `generate_flask_infinite_handler(load_feed, [endpoint('/api/feed'), page_param('cursor')], [], Code).` This generates a cursor-based pagination handler that returns nextCursor and hasMore fields, perfect for infinite scroll interfaces. See skill_flask_api.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_flask_api_004_q2", "cluster_id": "skill_flask_api_004", "question": "How do I implement cursor-based pagination?", "answer": "To implement cursor-based pagination, use the `generate_flask_infinite_handler` predicate with the `page_param('cursor')` option. This generates a Flask route that accepts a cursor parameter from the client, fetches the next batch of results, and returns both a `nextCursor` for the following request and a `hasMore` boolean to indicate if additional data exists. This approach is ideal for infinite scroll implementations where clients progressively load data without knowing total counts.", "question_type": "long", "topics": ["Quickstart", "Web Frameworks", "Flask API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["infinite scroll", "cursor pagination", "feeds"], "related_skills": ["skill_flask_api.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl"], "original_answer": "Use `generate_flask_infinite_handler(load_feed, [endpoint('/api/feed'), page_param('cursor')], [], Code).` This generates a cursor-based pagination handler that returns nextCursor and hasMore fields, perfect for infinite scroll interfaces. See skill_flask_api.md for details.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null}
{"pair_id": "skill_flask_api_004_q3", "cluster_id": "skill_flask_api_004", "question": "How do I create a feed endpoint?", "answer": "Use `generate_flask_infinite_handler(load_feed, [endpoint('/api/feed'), page_param('cursor')], [], Code).` to create a feed endpoint with cursor-based pagination. This generates a handler that returns `nextCursor` and `hasMore` fields, enabling infinite scroll functionality. The endpoint accepts `cursor` and `limit` query parameters.", "question_type": "long", "topics": ["Quickstart", "Web Frameworks", "Flask API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["infinite scroll", "cursor pagination", "feeds"], "related_skills": ["skill_flask_api.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl"], "original_answer": "Use `generate_flask_infinite_handler(load_feed, [endpoint('/api/feed'), page_param('cursor')], [], Code).` This generates a cursor-based pagination handler that returns nextCursor and hasMore fields, perfect for infinite scroll interfaces. See skill_flask_api.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_flask_api_005_q0", "cluster_id": "skill_flask_api_005", "question": "How do I organize my Flask API with blueprints?", "answer": "Use the `generate_flask_blueprint` predicate to organize related endpoints into modular blueprints. For example, `generate_flask_blueprint(tasks, [fetch_tasks, create_task, delete_task], [], Code)` creates a Blueprint named 'tasks' with a URL prefix (/api/tasks) that groups task-related endpoints together. This modular approach keeps your code organized and maintainable as your API grows, allowing you to separate concerns by domain (tasks, users, etc.) and easily manage each section independently.", "question_type": "medium", "topics": ["Quickstart", "Web Frameworks", "Flask API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["blueprints", "API organization", "modular design"], "related_skills": ["skill_flask_api.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl"], "original_answer": "Use `generate_flask_blueprint(tasks, [fetch_tasks, create_task, delete_task], [], Code).` This creates a reusable Blueprint with a URL prefix (/api/tasks) for organizing related endpoints. Blueprints are ideal for modular API design and keeping code maintainable as your API grows. See skill_flask_api.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_flask_api_005_q1", "cluster_id": "skill_flask_api_005", "question": "How do I structure large Flask applications?", "answer": "Use Flask Blueprints to organize your application into modules. Create blueprints for each feature area (e.g., tasks, users, auth) with `generate_flask_blueprint(module_name, [handler_list], [], Code)`. Each blueprint gets its own URL prefix (/api/module_name) and groups related endpoints together. This modular approach keeps your codebase maintainable as complexity grows\u2014each blueprint is independent and can be registered with your main Flask app. For larger applications, combine blueprints with separate config files, middleware layers, and organized directory structures.", "question_type": "medium", "topics": ["Quickstart", "Web Frameworks", "Flask API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["blueprints", "API organization", "modular design"], "related_skills": ["skill_flask_api.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl"], "original_answer": "Use `generate_flask_blueprint(tasks, [fetch_tasks, create_task, delete_task], [], Code).` This creates a reusable Blueprint with a URL prefix (/api/tasks) for organizing related endpoints. Blueprints are ideal for modular API design and keeping code maintainable as your API grows. See skill_flask_api.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "Base answer focuses narrowly on Blueprints but the question asks about structuring large applications more broadly. The answer adds general architectural guidance (config files, middleware, directory structure) that isn't covered in the base answer or skill document. This is inference beyond the documented skill."}
{"pair_id": "skill_flask_api_005_q2", "cluster_id": "skill_flask_api_005", "question": "How do I group related endpoints together?", "answer": "Use Flask Blueprints to group related endpoints. Call `generate_flask_blueprint(blueprint_name, [handler1, handler2, ...], [], Code)` to create a reusable Blueprint with automatic URL prefix organization (e.g., `/api/blueprint_name`). This keeps related endpoints modular and maintainable as your API grows.", "question_type": "medium", "topics": ["Quickstart", "Web Frameworks", "Flask API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["blueprints", "API organization", "modular design"], "related_skills": ["skill_flask_api.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl"], "original_answer": "Use `generate_flask_blueprint(tasks, [fetch_tasks, create_task, delete_task], [], Code).` This creates a reusable Blueprint with a URL prefix (/api/tasks) for organizing related endpoints. Blueprints are ideal for modular API design and keeping code maintainable as your API grows. See skill_flask_api.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_flask_api_005_q3", "cluster_id": "skill_flask_api_005", "question": "How do I create modular Flask routes?", "answer": "Use `generate_flask_blueprint(name, [route_patterns], [], Code)` to create modular Flask routes. This generates a reusable Blueprint with automatic URL prefix organization (e.g., `/api/{name}`) for keeping related endpoints together. Blueprints let you define handlers separately and combine them into a complete app, making your API structure maintainable and scalable. Each blueprint can have its own set of GET, POST, PUT, DELETE handlers organized by domain.", "question_type": "medium", "topics": ["Quickstart", "Web Frameworks", "Flask API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["blueprints", "API organization", "modular design"], "related_skills": ["skill_flask_api.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl"], "original_answer": "Use `generate_flask_blueprint(tasks, [fetch_tasks, create_task, delete_task], [], Code).` This creates a reusable Blueprint with a URL prefix (/api/tasks) for organizing related endpoints. Blueprints are ideal for modular API design and keeping code maintainable as your API grows. See skill_flask_api.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_flask_api_006_q0", "cluster_id": "skill_flask_api_006", "question": "How do I add authentication to my Flask API?", "answer": "Use `generate_flask_auth_handlers([], Code).` to add authentication to your Flask API. This generates two standard endpoints: `/api/auth/login` for email/password authentication and `/api/auth/register` for user registration. Both include built-in input validation and provide a secure foundation for managing user authentication. For implementation details, see skill_flask_api.md.", "question_type": "medium", "topics": ["Quickstart", "Web Frameworks", "Flask API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["authentication", "login", "registration", "security"], "related_skills": ["skill_flask_api.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl"], "original_answer": "Use `generate_flask_auth_handlers([], Code).` This generates standard authentication endpoints: `/api/auth/login` for email/password login and `/api/auth/register` for user registration with built-in validation. These provide a secure foundation for user management in your API. See skill_flask_api.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "Base answer lacks specifics on validation details, security features (password hashing, token management), and how to integrate the generated handlers into an existing Flask app. The answer assumes users know how to use the generated Code output."}
{"pair_id": "skill_flask_api_006_q1", "cluster_id": "skill_flask_api_006", "question": "How do I implement user login and registration?", "answer": "To implement user login and registration, use `generate_flask_auth_handlers([], Code).` This Prolog predicate generates two standard Flask authentication endpoints: `/api/auth/login` for email/password authentication and `/api/auth/register` for new user registration with built-in input validation. Both endpoints provide a secure foundation for managing user authentication in your Flask API.", "question_type": "medium", "topics": ["Quickstart", "Web Frameworks", "Flask API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["authentication", "login", "registration", "security"], "related_skills": ["skill_flask_api.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl"], "original_answer": "Use `generate_flask_auth_handlers([], Code).` This generates standard authentication endpoints: `/api/auth/login` for email/password login and `/api/auth/register` for user registration with built-in validation. These provide a secure foundation for user management in your API. See skill_flask_api.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_flask_api_006_q2", "cluster_id": "skill_flask_api_006", "question": "How do I add auth endpoints to Flask?", "answer": "To add auth endpoints to Flask, use the `generate_flask_auth_handlers([], Code).` Prolog predicate. This generates two standard authentication endpoints: `/api/auth/login` for email/password authentication and `/api/auth/register` for user registration. Both endpoints include built-in validation and provide a secure foundation for user management. The generated code handles request validation, error responses, and follows Flask REST conventions.", "question_type": "medium", "topics": ["Quickstart", "Web Frameworks", "Flask API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["authentication", "login", "registration", "security"], "related_skills": ["skill_flask_api.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl"], "original_answer": "Use `generate_flask_auth_handlers([], Code).` This generates standard authentication endpoints: `/api/auth/login` for email/password login and `/api/auth/register` for user registration with built-in validation. These provide a secure foundation for user management in your API. See skill_flask_api.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_flask_api_006_q3", "cluster_id": "skill_flask_api_006", "question": "How do I handle user authentication in my API?", "answer": "To handle user authentication in your API, use the `generate_flask_auth_handlers([], Code).` predicate. This generates two standard endpoints: `/api/auth/login` for email/password authentication and `/api/auth/register` for user registration. Both endpoints include built-in input validation and provide a secure foundation for managing user sessions and access control in your Flask API.", "question_type": "medium", "topics": ["Quickstart", "Web Frameworks", "Flask API"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["authentication", "login", "registration", "security"], "related_skills": ["skill_flask_api.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl"], "original_answer": "Use `generate_flask_auth_handlers([], Code).` This generates standard authentication endpoints: `/api/auth/login` for email/password login and `/api/auth/register` for user registration with built-in validation. These provide a secure foundation for user management in your API. See skill_flask_api.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_frontend_security_001_q0", "cluster_id": "skill_frontend_security_001", "question": "How do I prevent unauthorized Python function calls from my frontend app?", "answer": "To prevent unauthorized Python function calls from your frontend app, use the RPyC security module to whitelist allowed Python modules and functions. By default, only safe modules are allowed (math, statistics, numpy, json, datetime). Validate each call using `is_call_allowed(Module, Function)` which returns false for unauthorized modules like `os` or `sys`. Add new modules with `add_allowed_module(scipy, [optimize, integrate])` if needed. Generate TypeScript security middleware with `generate_typescript_whitelist(Code)` to get validation functions (`isCallAllowed()`, `isAttrAllowed()`) that enforce these rules in your frontend before any Python calls are made.", "question_type": "medium", "topics": ["Quickstart", "Frontend Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["rpyc", "whitelist", "python-bridge", "security"], "related_skills": ["skill_frontend_security.md"], "related_docs": ["src/unifyweaver/glue/rpyc_security.pl"], "original_answer": "Use the RPyC security module to define allowed Python modules and functions. Add allowed modules with `add_allowed_module(scipy, [optimize, integrate])` or use the default whitelist (math, statistics, numpy, json, datetime). Validate calls with `is_call_allowed(math, sqrt, true)` - returns false for unauthorized modules like `os.system`. Generate TypeScript security code with `generate_typescript_security(Code)` to get `isCallAllowed()` and `isAttrAllowed()` functions in your frontend. See skill_frontend_security.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_frontend_security_001_q1", "cluster_id": "skill_frontend_security_001", "question": "How do I whitelist Python modules for my JavaScript bridge?", "answer": "To whitelist Python modules for your JavaScript bridge, use the RPyC security module in `src/unifyweaver/glue/rpyc_security.pl`. Add allowed modules with `add_allowed_module(scipy, [optimize, integrate, interpolate])` in your Prolog rules. The default whitelist includes math, statistics, numpy, json, and datetime modules with their safe functions pre-approved. Validate that calls are allowed before execution using `is_call_allowed(Module, Function, Result)` - this returns true only for whitelisted module-function pairs. Generate TypeScript security code with `generate_typescript_whitelist(Code)` to produce frontend guard functions like `isCallAllowed()` that prevent unauthorized Python calls from JavaScript. This declarative approach ensures only safe Python operations can be invoked from your frontend.", "question_type": "medium", "topics": ["Quickstart", "Frontend Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["rpyc", "whitelist", "python-bridge", "security"], "related_skills": ["skill_frontend_security.md"], "related_docs": ["src/unifyweaver/glue/rpyc_security.pl"], "original_answer": "Use the RPyC security module to define allowed Python modules and functions. Add allowed modules with `add_allowed_module(scipy, [optimize, integrate])` or use the default whitelist (math, statistics, numpy, json, datetime). Validate calls with `is_call_allowed(math, sqrt, true)` - returns false for unauthorized modules like `os.system`. Generate TypeScript security code with `generate_typescript_security(Code)` to get `isCallAllowed()` and `isAttrAllowed()` functions in your frontend. See skill_frontend_security.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer references `generate_typescript_security(Code)` but the skill document shows `generate_typescript_whitelist(Code)` - corrected in tailored answer. The base answer's mention of 'detailed result' validation is accurate but the full output structure for `validate_call()` predicate could be clearer to users implementing this."}
{"pair_id": "skill_frontend_security_001_q2", "cluster_id": "skill_frontend_security_001", "question": "How do I secure RPyC calls from TypeScript?", "answer": "To secure RPyC calls from TypeScript, use the RPyC security module to whitelist allowed Python modules and functions. Define allowed modules with `add_allowed_module(scipy, [optimize, integrate])` or rely on default whitelisted modules: math, statistics, numpy, json, and datetime. Validate each call with `is_call_allowed(module, function)` before execution\u2014this returns false for unauthorized modules like `os`. Generate TypeScript security middleware with `generate_typescript_whitelist(Code)` to create frontend guard functions (`isCallAllowed()`, `isAttrAllowed()`) that enforce the whitelist before any RPyC bridge invocation.", "question_type": "medium", "topics": ["Quickstart", "Frontend Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["rpyc", "whitelist", "python-bridge", "security"], "related_skills": ["skill_frontend_security.md"], "related_docs": ["src/unifyweaver/glue/rpyc_security.pl"], "original_answer": "Use the RPyC security module to define allowed Python modules and functions. Add allowed modules with `add_allowed_module(scipy, [optimize, integrate])` or use the default whitelist (math, statistics, numpy, json, datetime). Validate calls with `is_call_allowed(math, sqrt, true)` - returns false for unauthorized modules like `os.system`. Generate TypeScript security code with `generate_typescript_security(Code)` to get `isCallAllowed()` and `isAttrAllowed()` functions in your frontend. See skill_frontend_security.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_frontend_security_002_q0", "cluster_id": "skill_frontend_security_002", "question": "How do I add rate limiting and input validation to my API endpoints?", "answer": "Generate Express security middleware using `generate_express_security_middleware(Code)` to add rate limiting and input validation to your API endpoints. This creates middleware that enforces rate limiting (100 requests/second with 20 burst capacity), request timeout (5000ms), and validates all incoming calls against Python module/function whitelists. Configure rate limits with `rpyc_rate_limit(config(requests_per_second(100), burst_size(20), timeout_ms(5000)))`. The middleware automatically validates module and function names, checks whitelists, and rejects non-serializable arguments. Stack the generated middleware in your Express app for automatic security enforcement on all requests.", "question_type": "medium", "topics": ["Quickstart", "Frontend Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["rate-limiting", "express", "middleware", "validation"], "related_skills": ["skill_frontend_security.md"], "related_docs": ["src/unifyweaver/glue/rpyc_security.pl"], "original_answer": "Generate Express security middleware with `generate_express_security_middleware(Code)`. This creates rate limiting (100 requests/second, 20 burst), request timeout (5000ms), and call validation middleware. Configure rates with `rpyc_rate_limit(config(requests_per_second(100), burst_size(20), timeout_ms(5000)))`. The middleware validates module/function names, checks whitelists, and rejects non-serializable arguments. Stack middleware in your Express app for automatic security enforcement. See skill_frontend_security.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_frontend_security_002_q1", "cluster_id": "skill_frontend_security_002", "question": "How do I generate Express middleware for security?", "answer": "Generate Express security middleware using `generate_express_security_middleware(Code)`. This creates middleware that enforces rate limiting (100 requests/second with 20-request burst capacity), applies 5000ms request timeouts, and validates all RPyC calls against the module/function whitelist. Configure rate limits by setting `rpyc_rate_limit(config(requests_per_second(100), burst_size(20), timeout_ms(5000)))`. The generated middleware automatically rejects calls to non-whitelisted modules/functions and blocks arguments that aren't JSON-serializable. Add the middleware to your Express app to enforce security policies on all Python bridge calls.", "question_type": "medium", "topics": ["Quickstart", "Frontend Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["rate-limiting", "express", "middleware", "validation"], "related_skills": ["skill_frontend_security.md"], "related_docs": ["src/unifyweaver/glue/rpyc_security.pl"], "original_answer": "Generate Express security middleware with `generate_express_security_middleware(Code)`. This creates rate limiting (100 requests/second, 20 burst), request timeout (5000ms), and call validation middleware. Configure rates with `rpyc_rate_limit(config(requests_per_second(100), burst_size(20), timeout_ms(5000)))`. The middleware validates module/function names, checks whitelists, and rejects non-serializable arguments. Stack middleware in your Express app for automatic security enforcement. See skill_frontend_security.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "Base answer mentions middleware generation but lacks specific implementation details like how to integrate it into Express (e.g., app.use()). The configuration format for rpyc_rate_limit is inferred from the skill document but not explicitly shown in usage context."}
{"pair_id": "skill_frontend_security_002_q2", "cluster_id": "skill_frontend_security_002", "question": "How do I prevent API abuse in my frontend service?", "answer": "To prevent API abuse in your frontend service, generate Express security middleware using `generate_express_security_middleware(Code)`. This creates rate limiting (100 requests/second with 20 burst capacity), request timeout (5000ms), and call validation middleware. Configure rate limits with `rpyc_rate_limit(config(requests_per_second(100), burst_size(20), timeout_ms(5000)))`. The middleware validates module and function names against whitelists, checks serialization compatibility, and rejects unauthorized calls. Stack the middleware in your Express app to automatically enforce these security policies across all RPyC bridge calls.", "question_type": "medium", "topics": ["Quickstart", "Frontend Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["rate-limiting", "express", "middleware", "validation"], "related_skills": ["skill_frontend_security.md"], "related_docs": ["src/unifyweaver/glue/rpyc_security.pl"], "original_answer": "Generate Express security middleware with `generate_express_security_middleware(Code)`. This creates rate limiting (100 requests/second, 20 burst), request timeout (5000ms), and call validation middleware. Configure rates with `rpyc_rate_limit(config(requests_per_second(100), burst_size(20), timeout_ms(5000)))`. The middleware validates module/function names, checks whitelists, and rejects non-serializable arguments. Stack middleware in your Express app for automatic security enforcement. See skill_frontend_security.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer conflates RPyC security (Python bridge protection) with general API abuse prevention. The answer addresses the specific use case well but doesn't mention other common API abuse patterns (duplicate request detection, authentication checks, IP-based rate limiting) that might be relevant depending on the user's actual service architecture."}
{"pair_id": "skill_frontend_security_003_q0", "cluster_id": "skill_frontend_security_003", "question": "How do I set up firewall rules for my backend services?", "answer": "Use the firewall module to define backend service security policies. Create rules with `rule_firewall(predicate/arity, [execution([bash]), services([sql])])` to control which services each predicate can access. Whitelist backend hosts with `network_hosts(['*.internal.company.com'])` and control network access with `network_access(allowed)`. Restrict allowed Python modules with `python_modules([math, json])`. Deny specific services using `denied([llm])`. Set global firewall defaults with `firewall_default([...])`. Validate rules against your firewall policies with `validate_against_firewall(Target, Options, Firewall)`. Use `set_firewall_mode(strict|warn|permissive|disabled)` to control enforcement. For details, see skill_frontend_security.md.", "question_type": "medium", "topics": ["Quickstart", "Frontend Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["firewall", "policies", "network-access", "services"], "related_skills": ["skill_frontend_security.md"], "related_docs": ["src/unifyweaver/core/firewall.pl", "src/unifyweaver/core/firewall_v2.pl"], "original_answer": "Use the firewall module to define per-predicate security policies. Create rules with `rule_firewall(predicate/arity, [execution([bash]), services([sql])])`. Control network access with `network_access(allowed)` and whitelist hosts with `network_hosts(['*.internal.company.com'])`. Restrict Python imports with `python_modules([math, json])`. Deny services with `denied([llm])`. Set global defaults with `firewall_default([...])`. Validate rules against firewall policies with `validate_against_firewall(Target, Options, Firewall)`. Use `set_firewall_mode(strict|warn|permissive|disabled)` for enforcement levels. See skill_frontend_security.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "The base answer conflates frontend security patterns with backend firewall rules. The skill document focuses on RPyC Python bridge security and TypeScript whitelisting, not backend service firewalls. The answer adapts the available predicates but the firewall module's actual backend service capabilities are unclear from the skill document."}
{"pair_id": "skill_frontend_security_003_q1", "cluster_id": "skill_frontend_security_003", "question": "How do I restrict which services my code can access?", "answer": "Use the firewall module to define per-predicate security policies that restrict service access. Create rules with `rule_firewall(predicate/arity, [services([sql, http])])` to specify which services each predicate can access. Control network access with `network_access(allowed)` and `network_hosts(['*.internal.company.com'])` to whitelist trusted hosts. Restrict Python module imports with `python_modules([math, json])` to prevent access to dangerous libraries. Deny entire service categories with `denied([llm, shell])`. Set global defaults with `firewall_default([...])` to apply baseline restrictions across all predicates. Validate rules with `validate_against_firewall(Target, Options, Firewall)`. Use `set_firewall_mode(strict|warn|permissive|disabled)` to control enforcement levels from strict blocking to permissive logging.", "question_type": "medium", "topics": ["Quickstart", "Frontend Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["firewall", "policies", "network-access", "services"], "related_skills": ["skill_frontend_security.md"], "related_docs": ["src/unifyweaver/core/firewall.pl", "src/unifyweaver/core/firewall_v2.pl"], "original_answer": "Use the firewall module to define per-predicate security policies. Create rules with `rule_firewall(predicate/arity, [execution([bash]), services([sql])])`. Control network access with `network_access(allowed)` and whitelist hosts with `network_hosts(['*.internal.company.com'])`. Restrict Python imports with `python_modules([math, json])`. Deny services with `denied([llm])`. Set global defaults with `firewall_default([...])`. Validate rules against firewall policies with `validate_against_firewall(Target, Options, Firewall)`. Use `set_firewall_mode(strict|warn|permissive|disabled)` for enforcement levels. See skill_frontend_security.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "Base answer covers firewall mechanics but lacks concrete examples of service names or typical use cases. Answer assumes familiarity with Prolog rule syntax. Confidence is moderate because the skill document provides implementation details but the question about 'restricting services' could mean different layers (API services, external APIs, internal services) which the answer partially addresses."}
{"pair_id": "skill_frontend_security_003_q2", "cluster_id": "skill_frontend_security_003", "question": "How do I create network and file access policies?", "answer": "Use the firewall module to create network and file access policies. Define per-predicate rules with `rule_firewall(predicate/arity, [execution([bash]), services([sql])])`. For network access, use `network_access(allowed)` to permit outbound connections and `network_hosts(['*.internal.company.com'])` to whitelist specific hosts or domains. For file access, include file path restrictions in your firewall rules. Control which Python modules can be imported with `python_modules([math, json])`. Deny specific services with `denied([llm])`. Set global defaults with `firewall_default([...])` and enforcement levels with `set_firewall_mode(strict|warn|permissive|disabled)`. Validate policies with `validate_against_firewall(Target, Options, Firewall)`.", "question_type": "medium", "topics": ["Quickstart", "Frontend Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["firewall", "policies", "network-access", "services"], "related_skills": ["skill_frontend_security.md"], "related_docs": ["src/unifyweaver/core/firewall.pl", "src/unifyweaver/core/firewall_v2.pl"], "original_answer": "Use the firewall module to define per-predicate security policies. Create rules with `rule_firewall(predicate/arity, [execution([bash]), services([sql])])`. Control network access with `network_access(allowed)` and whitelist hosts with `network_hosts(['*.internal.company.com'])`. Restrict Python imports with `python_modules([math, json])`. Deny services with `denied([llm])`. Set global defaults with `firewall_default([...])`. Validate rules against firewall policies with `validate_against_firewall(Target, Options, Firewall)`. Use `set_firewall_mode(strict|warn|permissive|disabled)` for enforcement levels. See skill_frontend_security.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "Base answer does not explicitly address file access policies - only network and Python modules are covered. File path restrictions are inferred but not detailed in the original material."}
{"pair_id": "skill_frontend_security_004_q0", "cluster_id": "skill_frontend_security_004", "question": "How do I generate a TypeScript whitelist of allowed Python functions?", "answer": "Call `generate_typescript_whitelist(Code)` to create a TypeScript module with `ALLOWED_MODULES` and `ALLOWED_ATTRS` as Sets. The output includes helper functions `isCallAllowed(module, func)` and `isAttrAllowed(module, attr)` to validate Python function calls from TypeScript. For advanced validation with rate limits and sanitization, use `generate_typescript_security(Code)` instead. All generated code includes type definitions and input sanitization to prevent injection attacks.", "question_type": "long", "topics": ["Quickstart", "Frontend Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["typescript", "whitelist", "codegen", "validation"], "related_skills": ["skill_frontend_security.md"], "related_docs": ["src/unifyweaver/glue/rpyc_security.pl"], "original_answer": "Call `generate_typescript_whitelist(Code)` to create a TypeScript module with `ALLOWED_MODULES` and `ALLOWED_ATTRS` as Maps. The output includes helper functions `isCallAllowed(module, func)` and `isAttrAllowed(module, attr)`. For advanced validation with rate limits and sanitization, use `generate_typescript_security(Code)` which combines whitelist and validator. For just validation logic, use `generate_typescript_validator(Code)`. All generated code includes type definitions and input sanitization to prevent injection attacks. See skill_frontend_security.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_frontend_security_004_q1", "cluster_id": "skill_frontend_security_004", "question": "How do I export security whitelists to my frontend?", "answer": "To export security whitelists to your frontend, call `generate_typescript_whitelist(Code)` which creates a TypeScript module containing `ALLOWED_MODULES` and `ALLOWED_ATTRS` as Sets with the whitelisted Python modules and their functions. The generated code includes helper functions `isCallAllowed(module, func)` and `isAttrAllowed(module, attr)` for validation. For more comprehensive security, use `generate_typescript_security(Code)` to combine the whitelist with rate limiting and sanitization logic, or `generate_typescript_validator(Code)` for validation-only code. All output includes TypeScript type definitions and input sanitization to prevent injection attacks.", "question_type": "long", "topics": ["Quickstart", "Frontend Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["typescript", "whitelist", "codegen", "validation"], "related_skills": ["skill_frontend_security.md"], "related_docs": ["src/unifyweaver/glue/rpyc_security.pl"], "original_answer": "Call `generate_typescript_whitelist(Code)` to create a TypeScript module with `ALLOWED_MODULES` and `ALLOWED_ATTRS` as Maps. The output includes helper functions `isCallAllowed(module, func)` and `isAttrAllowed(module, attr)`. For advanced validation with rate limits and sanitization, use `generate_typescript_security(Code)` which combines whitelist and validator. For just validation logic, use `generate_typescript_validator(Code)`. All generated code includes type definitions and input sanitization to prevent injection attacks. See skill_frontend_security.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "Base answer mentions 'Maps' but generated code uses 'Sets' according to the skill document. Also assumes user knows the distinction between the three generation functions; could clarify when to use each."}
{"pair_id": "skill_frontend_security_004_q2", "cluster_id": "skill_frontend_security_004", "question": "How do I create type-safe validators in TypeScript?", "answer": "To create type-safe validators in TypeScript, call `generate_typescript_whitelist(Code)` to generate a module with `ALLOWED_MODULES` and `ALLOWED_ATTRS` as Maps, along with helper functions `isCallAllowed(module, func)` and `isAttrAllowed(module, attr)`. For comprehensive validation with type safety, use `generate_typescript_security(Code)` to combine whitelist checking with input sanitization and rate limiting. The generated code includes full type definitions and protects against injection attacks. Use `generate_typescript_validator(Code)` if you only need validation logic without the whitelist.", "question_type": "long", "topics": ["Quickstart", "Frontend Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["typescript", "whitelist", "codegen", "validation"], "related_skills": ["skill_frontend_security.md"], "related_docs": ["src/unifyweaver/glue/rpyc_security.pl"], "original_answer": "Call `generate_typescript_whitelist(Code)` to create a TypeScript module with `ALLOWED_MODULES` and `ALLOWED_ATTRS` as Maps. The output includes helper functions `isCallAllowed(module, func)` and `isAttrAllowed(module, attr)`. For advanced validation with rate limits and sanitization, use `generate_typescript_security(Code)` which combines whitelist and validator. For just validation logic, use `generate_typescript_validator(Code)`. All generated code includes type definitions and input sanitization to prevent injection attacks. See skill_frontend_security.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "Base answer focuses on RPyC security and whitelist generation rather than general TypeScript validation patterns. The answer describes generated helper functions but doesn't explain how to use them in practice or how they ensure type safety beyond basic function checking."}
{"pair_id": "skill_frontend_security_005_q0", "cluster_id": "skill_frontend_security_005", "question": "How do I restrict file access and Python imports in sandboxed code?", "answer": "To restrict file access and Python imports in sandboxed code, define firewall rules using the firewall module. Use `file_read_patterns(['data/*.csv'])` to whitelist specific file paths for reading and `file_write_patterns([])` to deny all writes. Restrict Python imports by specifying allowed modules: `python_modules([math, json])`. Apply these rules via `rule_firewall(task_name/2, [execution([python]), python_modules([math, json]), network_access(denied), file_read_patterns(['data/*.csv']), file_write_patterns([])])`. Validate file access attempts with `validate_file_access(File, read, Firewall)`. Enable strict enforcement using `set_firewall_mode(strict)`. Whitelist cache directories with `cache_dirs([...])` if needed.", "question_type": "long", "topics": ["Quickstart", "Frontend Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sandboxing", "file-access", "python-modules", "isolation"], "related_skills": ["skill_frontend_security.md"], "related_docs": ["src/unifyweaver/core/firewall.pl"], "original_answer": "Define firewall rules with file and module restrictions. Use `file_read_patterns(['data/*.csv'])` to allow only specific file reads and `file_write_patterns([])` to prohibit writes. Restrict Python imports with `python_modules([math, json])`. Example: `rule_firewall(sandbox_task/2, [execution([python]), python_modules([math, json]), network_access(denied), file_read_patterns(['data/*.csv']), file_write_patterns([])])`. Validate file access with `validate_file_access(File, read, Firewall)`. Use `cache_dirs([...])` to whitelist cache directories. Combine with `set_firewall_mode(strict)` for enforcement. See skill_frontend_security.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_frontend_security_005_q1", "cluster_id": "skill_frontend_security_005", "question": "How do I prevent unauthorized file reads/writes?", "answer": "To prevent unauthorized file reads/writes, define firewall rules that explicitly restrict file access patterns. Use `file_read_patterns(['data/*.csv'])` to whitelist only specific files or directories for reading, and `file_write_patterns([])` to prohibit all writes (or specify allowed paths). Apply these rules within a firewall configuration: `rule_firewall(task_name/arity, [file_read_patterns(['data/*.csv']), file_write_patterns([])])`. Validate all file access attempts using `validate_file_access(File, read, Firewall)` before operations execute. For additional protection, restrict Python module imports to only necessary modules like `python_modules([math, json])` and set `set_firewall_mode(strict)` for strict enforcement of all rules.", "question_type": "long", "topics": ["Quickstart", "Frontend Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sandboxing", "file-access", "python-modules", "isolation"], "related_skills": ["skill_frontend_security.md"], "related_docs": ["src/unifyweaver/core/firewall.pl"], "original_answer": "Define firewall rules with file and module restrictions. Use `file_read_patterns(['data/*.csv'])` to allow only specific file reads and `file_write_patterns([])` to prohibit writes. Restrict Python imports with `python_modules([math, json])`. Example: `rule_firewall(sandbox_task/2, [execution([python]), python_modules([math, json]), network_access(denied), file_read_patterns(['data/*.csv']), file_write_patterns([])])`. Validate file access with `validate_file_access(File, read, Firewall)`. Use `cache_dirs([...])` to whitelist cache directories. Combine with `set_firewall_mode(strict)` for enforcement. See skill_frontend_security.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer mixes file access control with module whitelisting and network access policies. The tailored answer focuses on file access but could be clearer on how validation integrates into the actual runtime execution flow."}
{"pair_id": "skill_frontend_security_005_q2", "cluster_id": "skill_frontend_security_005", "question": "How do I create an isolated execution environment?", "answer": "To create an isolated execution environment, define firewall rules that restrict file access, Python module imports, and network connectivity. Use `file_read_patterns(['data/*.csv'])` to allow only specific files and `file_write_patterns([])` to block all writes. Restrict Python imports with `python_modules([math, json])`. Create a firewall rule like: `rule_firewall(sandbox_task/2, [execution([python]), python_modules([math, json]), network_access(denied), file_read_patterns(['data/*.csv']), file_write_patterns([])])`. Validate file access with `validate_file_access(File, read, Firewall)`. Whitelist cache directories with `cache_dirs([...])` and enforce isolation with `set_firewall_mode(strict)`.", "question_type": "long", "topics": ["Quickstart", "Frontend Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sandboxing", "file-access", "python-modules", "isolation"], "related_skills": ["skill_frontend_security.md"], "related_docs": ["src/unifyweaver/core/firewall.pl"], "original_answer": "Define firewall rules with file and module restrictions. Use `file_read_patterns(['data/*.csv'])` to allow only specific file reads and `file_write_patterns([])` to prohibit writes. Restrict Python imports with `python_modules([math, json])`. Example: `rule_firewall(sandbox_task/2, [execution([python]), python_modules([math, json]), network_access(denied), file_read_patterns(['data/*.csv']), file_write_patterns([])])`. Validate file access with `validate_file_access(File, read, Firewall)`. Use `cache_dirs([...])` to whitelist cache directories. Combine with `set_firewall_mode(strict)` for enforcement. See skill_frontend_security.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer provides syntax and patterns but lacks explanation of how these components work together to achieve isolation, and doesn't clarify what 'execution([python])' does or mention process-level isolation mechanisms."}
{"pair_id": "skill_frontend_security_006_q0", "cluster_id": "skill_frontend_security_006", "question": "How do I validate security policies based on environment and runtime conditions?", "answer": "To validate security policies based on environment and runtime conditions, use the firewall module's implication system. Define condition-to-policy mappings: `no_bash_available` denies bash, `network_access(denied)` denies network services, `environment(restricted)` denies external calls, `mode(offline)` denies network access. Environment-specific defaults: development restricts to localhost/127.0.0.1, corporate allows internal domains, CI/CD allows test domains. Call `derive_policy(Condition, Policies)` to compute effective policies from runtime conditions. Control enforcement levels with `set_firewall_mode(strict)` for production or `set_firewall_mode(warn)` for staging. Each mode automatically applies appropriate policy validations based on the current environment state.", "question_type": "long", "topics": ["Quickstart", "Frontend Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["firewall-implications", "environment", "conditions", "policy-derivation"], "related_skills": ["skill_frontend_security.md"], "related_docs": ["src/unifyweaver/core/firewall.pl"], "original_answer": "Use firewall implications to derive policies from conditions. Default implications include: `no_bash_available` \u2192 deny bash, `denied_target_language(bash)` \u2192 deny all bash, `network_access(denied)` \u2192 deny network services, `environment(restricted)` \u2192 deny external calls, `mode(offline)` \u2192 deny network. Define environment-specific defaults: development restricts to `['localhost', '127.0.0.1', '*.local']`, corporate allows `['*.internal.company.com']`, CI/CD allows `['*.test.*', 'localhost']`. Use `derive_policy(Condition, Policies)` to get effective policies. Toggle modes with `set_firewall_mode(strict)` for production, `set_firewall_mode(warn)` for staging. See skill_frontend_security.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "The base answer conflates two concepts: (1) deriving policies from conditions and (2) setting enforcement modes. The relationship between these mechanisms and how they interact during validation isn't fully clear. The answer would benefit from explicit examples of how to actually validate a policy against a specific condition. Also unclear if `derive_policy` is the primary validation mechanism or if modes provide validation."}
{"pair_id": "skill_frontend_security_006_q1", "cluster_id": "skill_frontend_security_006", "question": "How do I apply different security rules for dev vs production?", "answer": "Apply environment-specific security rules using firewall modes and implications. Set `set_firewall_mode(strict)` for production and `set_firewall_mode(warn)` for staging/development. Define environment-specific network allowlists: development restricts to `['localhost', '127.0.0.1', '*.local']`, production allows `['*.internal.company.com']`, CI/CD allows `['*.test.*', 'localhost']`. Use `derive_policy(Condition, Policies)` to get effective policies based on your environment. The firewall applies different implications per mode\u2014for example, `environment(restricted)` denies external calls in production, while development may allow them. Configure these in `rpyc_security.pl` using `rpyc_security_policy(Name, Rules)` for named policies tied to specific environments.", "question_type": "long", "topics": ["Quickstart", "Frontend Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["firewall-implications", "environment", "conditions", "policy-derivation"], "related_skills": ["skill_frontend_security.md"], "related_docs": ["src/unifyweaver/core/firewall.pl"], "original_answer": "Use firewall implications to derive policies from conditions. Default implications include: `no_bash_available` \u2192 deny bash, `denied_target_language(bash)` \u2192 deny all bash, `network_access(denied)` \u2192 deny network services, `environment(restricted)` \u2192 deny external calls, `mode(offline)` \u2192 deny network. Define environment-specific defaults: development restricts to `['localhost', '127.0.0.1', '*.local']`, corporate allows `['*.internal.company.com']`, CI/CD allows `['*.test.*', 'localhost']`. Use `derive_policy(Condition, Policies)` to get effective policies. Toggle modes with `set_firewall_mode(strict)` for production, `set_firewall_mode(warn)` for staging. See skill_frontend_security.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer covers the core mechanism but lacks explicit examples of how to configure environment detection (e.g., checking NODE_ENV or similar). The answer assumes familiarity with the firewall implications system, which may not be clear to new users."}
{"pair_id": "skill_frontend_security_006_q2", "cluster_id": "skill_frontend_security_006", "question": "How do I use firewall implications for conditional policies?", "answer": "Use firewall implications to conditionally apply policies based on environment states. Call `derive_policy(Condition, Policies)` with a condition (like `no_bash_available`, `network_access(denied)`, `environment(restricted)`, or `mode(offline)`) to get the resulting policies. Common implications: `no_bash_available` denies bash execution, `network_access(denied)` blocks network services, `environment(restricted)` blocks external calls, `mode(offline)` denies network access. Set environment-specific defaults: development restricts to `['localhost', '127.0.0.1', '*.local']`, corporate allows `['*.internal.company.com']`, CI/CD allows `['*.test.*', 'localhost']`. Use `set_firewall_mode(strict)` for production enforcement or `set_firewall_mode(warn)` for staging to control policy behavior.", "question_type": "long", "topics": ["Quickstart", "Frontend Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["firewall-implications", "environment", "conditions", "policy-derivation"], "related_skills": ["skill_frontend_security.md"], "related_docs": ["src/unifyweaver/core/firewall.pl"], "original_answer": "Use firewall implications to derive policies from conditions. Default implications include: `no_bash_available` \u2192 deny bash, `denied_target_language(bash)` \u2192 deny all bash, `network_access(denied)` \u2192 deny network services, `environment(restricted)` \u2192 deny external calls, `mode(offline)` \u2192 deny network. Define environment-specific defaults: development restricts to `['localhost', '127.0.0.1', '*.local']`, corporate allows `['*.internal.company.com']`, CI/CD allows `['*.test.*', 'localhost']`. Use `derive_policy(Condition, Policies)` to get effective policies. Toggle modes with `set_firewall_mode(strict)` for production, `set_firewall_mode(warn)` for staging. See skill_frontend_security.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "Answer assumes Prolog syntax for `derive_policy/2` predicate, but the skill document shows limited detail on actual implementation. Confidence reduced because the base answer references 'skill_frontend_security.md' for details, suggesting information may be incomplete in the provided context."}
{"pair_id": "skill_fuzzy_search_001_q0", "cluster_id": "skill_fuzzy_search_001", "question": "How do I combine search results from semantic and keyword search?", "answer": "Use `blend_scores/4` to combine scores from semantic and keyword search with weighted blending. Call it as `blend_scores(0.7, SemanticScores, KeywordScores, Combined)` to blend 70% semantic and 30% keyword results. The function normalizes scores from both sources and combines them into a unified ranking. For alternative approaches, you can also use Reciprocal Rank Fusion (RRF) to combine rankings instead of scores, or fuzzy logic operations like `f_or` for flexible matching across multiple search results.", "question_type": "medium", "topics": ["Quickstart", "Fuzzy Search"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["search", "blending", "combination"], "related_skills": ["skill_fuzzy_search.md", "skill_query_patterns.md"], "related_docs": ["src/unifyweaver/fuzzy/fuzzy.pl", "scripts/experiment_ensemble_blend.py"], "original_answer": "Use `blend_scores/4` to combine scores from multiple sources with weights. Example: `blend_scores(0.7, SemanticScores, KeywordScores, Combined)` blends 70% semantic and 30% keyword search. This normalizes and weighs the scores to create a unified ranking. See skill_fuzzy_search.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_fuzzy_search_001_q1", "cluster_id": "skill_fuzzy_search_001", "question": "How do I blend multiple search scores together?", "answer": "Use `blend_scores/4` to combine scores from multiple sources with weights. For example: `blend_scores(0.7, SemanticScores, KeywordScores, Combined)` blends 70% semantic search scores with 30% keyword search scores into a unified ranking. The predicate normalizes both score lists and applies the weight ratio to create combined scores. For more complex fusion (like combining 3+ sources), use weighted blending with multiple calls or fuzzy logic operations like `f_or` for flexible matching or `f_and` for strict matching across all sources.", "question_type": "medium", "topics": ["Quickstart", "Fuzzy Search"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["search", "blending", "combination"], "related_skills": ["skill_fuzzy_search.md", "skill_query_patterns.md"], "related_docs": ["src/unifyweaver/fuzzy/fuzzy.pl", "scripts/experiment_ensemble_blend.py"], "original_answer": "Use `blend_scores/4` to combine scores from multiple sources with weights. Example: `blend_scores(0.7, SemanticScores, KeywordScores, Combined)` blends 70% semantic and 30% keyword search. This normalizes and weighs the scores to create a unified ranking. See skill_fuzzy_search.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_fuzzy_search_001_q2", "cluster_id": "skill_fuzzy_search_001", "question": "How do I merge results from different search methods?", "answer": "Use `blend_scores/4` to combine scores from multiple sources with weights. Example: `blend_scores(0.7, SemanticScores, KeywordScores, Combined)` blends 70% semantic and 30% keyword search by normalizing and weighing the scores to create a unified ranking. For ranking-based fusion, use Reciprocal Rank Fusion (RRF) which combines rankings rather than raw scores. Choose score fusion for normalized result merging or RRF when combining rankings from different ranking systems.", "question_type": "medium", "topics": ["Quickstart", "Fuzzy Search"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["search", "blending", "combination"], "related_skills": ["skill_fuzzy_search.md", "skill_query_patterns.md"], "related_docs": ["src/unifyweaver/fuzzy/fuzzy.pl", "scripts/experiment_ensemble_blend.py"], "original_answer": "Use `blend_scores/4` to combine scores from multiple sources with weights. Example: `blend_scores(0.7, SemanticScores, KeywordScores, Combined)` blends 70% semantic and 30% keyword search. This normalizes and weighs the scores to create a unified ranking. See skill_fuzzy_search.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_fuzzy_search_002_q0", "cluster_id": "skill_fuzzy_search_002", "question": "How do I use fuzzy logic to require all search terms to match?", "answer": "Use `f_and/2` to require all search terms to match with strict conjunction logic. The function multiplies weighted scores together, so all terms must have non-zero scores to produce a non-zero result. Example: `f_and([bash:0.9, shell:0.5], Score)` where both 'bash' and 'shell' must match. Use the colon syntax `Term:Weight` to assign importance to each term. If any term has a score of 0, the entire AND expression evaluates to 0, enforcing the all-match requirement.", "question_type": "long", "topics": ["Quickstart", "Fuzzy Search"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["fuzzy", "logic", "matching", "operators"], "related_skills": ["skill_fuzzy_search.md"], "related_docs": ["src/unifyweaver/fuzzy/core.pl", "src/unifyweaver/fuzzy/eval.pl"], "original_answer": "Use `f_and/2` for strict matching where all terms must match (uses product of scores). Use `f_or/2` when any term can match (uses probabilistic sum). Example: `f_and([bash:0.9, shell:0.5], Score)` requires both terms. You can weight terms with `Term:Weight` syntax. See skill_fuzzy_search.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_fuzzy_search_002_q1", "cluster_id": "skill_fuzzy_search_002", "question": "What's the difference between AND and OR matching?", "answer": "f_and combines scores using multiplication (product), so all terms must match meaningfully for a high result. f_or uses probabilistic sum (1 - (1-s1)(1-s2)...), allowing any term to contribute, so you get a higher score if at least one term matches well. Use f_and when you need strict matching and f_or for flexible matching. Example: f_and([bash:0.9, shell:0.5]) with scores [bash-0.8, shell-0.6] gives 0.9*0.8 * 0.5*0.6 = 0.216. With f_or, a single strong match contributes more to the final score.", "question_type": "long", "topics": ["Quickstart", "Fuzzy Search"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["fuzzy", "logic", "matching", "operators"], "related_skills": ["skill_fuzzy_search.md"], "related_docs": ["src/unifyweaver/fuzzy/core.pl", "src/unifyweaver/fuzzy/eval.pl"], "original_answer": "Use `f_and/2` for strict matching where all terms must match (uses product of scores). Use `f_or/2` when any term can match (uses probabilistic sum). Example: `f_and([bash:0.9, shell:0.5], Score)` requires both terms. You can weight terms with `Term:Weight` syntax. See skill_fuzzy_search.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_fuzzy_search_002_q2", "cluster_id": "skill_fuzzy_search_002", "question": "How do I enforce strict matching on multiple terms?", "answer": "Use `f_and/2` for strict matching where all terms must match using a product of their scores. Example: `f_and([bash:0.9, shell:0.5], Score)` enforces that both terms must match. You can weight individual terms with `Term:Weight` syntax to assign importance. The formula multiplies weighted scores together, so if bash scores 0.8 and shell scores 0.6, the result is 0.9*0.8 * 0.5*0.6 = 0.216. This ensures all terms contribute to the final match score.", "question_type": "long", "topics": ["Quickstart", "Fuzzy Search"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["fuzzy", "logic", "matching", "operators"], "related_skills": ["skill_fuzzy_search.md"], "related_docs": ["src/unifyweaver/fuzzy/core.pl", "src/unifyweaver/fuzzy/eval.pl"], "original_answer": "Use `f_and/2` for strict matching where all terms must match (uses product of scores). Use `f_or/2` when any term can match (uses probabilistic sum). Example: `f_and([bash:0.9, shell:0.5], Score)` requires both terms. You can weight terms with `Term:Weight` syntax. See skill_fuzzy_search.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_fuzzy_search_003_q0", "cluster_id": "skill_fuzzy_search_003", "question": "How do I combine ranking results from multiple different models?", "answer": "Use Reciprocal Rank Fusion (RRF) to combine ranking results from multiple models. RRF converts each model's ranked results into scores using the formula: RRF(d) = sum(1 / (k + rank_i(d))), where k is typically 60. This approach works well when models produce incompatible or differently-scaled scores. Python implementation: `rrf_blend_scores([model1_scores, model2_scores, model3_scores], k=60)`. RRF combines relative rankings rather than absolute scores, making it robust for ensemble methods across different model types.", "question_type": "long", "topics": ["Quickstart", "Fuzzy Search"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["ranking", "ensemble", "fusion", "models"], "related_skills": ["skill_fuzzy_search.md"], "related_docs": ["scripts/experiment_ensemble_blend.py"], "original_answer": "Use Reciprocal Rank Fusion (RRF) when models have incompatible score scales. RRF formula: `RRF(d) = sum(1 / (k + rank_i(d)))`. Python example: `rrf_blend_scores([bge_scores, minilm_scores, nomic_scores], k=60)`. RRF combines relative rankings rather than absolute scores, making it ideal for ensemble methods. See skill_fuzzy_search.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_fuzzy_search_003_q1", "cluster_id": "skill_fuzzy_search_003", "question": "How do I use rank fusion instead of score fusion?", "answer": "Use Reciprocal Rank Fusion (RRF) when you need to combine rankings from multiple models with incompatible score scales. RRF converts each model's scores to ranks, then combines them using the formula: RRF(d) = sum(1 / (k + rank_i(d))), where k is typically 60. This approach treats all models equally regardless of their individual score distributions. Use `rrf_blend_scores([scores_list1, scores_list2, ...], k=60)` to blend rankings from multiple sources. RRF is particularly useful for ensemble methods where you want to avoid score scale mismatches that plague traditional score fusion.", "question_type": "long", "topics": ["Quickstart", "Fuzzy Search"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["ranking", "ensemble", "fusion", "models"], "related_skills": ["skill_fuzzy_search.md"], "related_docs": ["scripts/experiment_ensemble_blend.py"], "original_answer": "Use Reciprocal Rank Fusion (RRF) when models have incompatible score scales. RRF formula: `RRF(d) = sum(1 / (k + rank_i(d)))`. Python example: `rrf_blend_scores([bge_scores, minilm_scores, nomic_scores], k=60)`. RRF combines relative rankings rather than absolute scores, making it ideal for ensemble methods. See skill_fuzzy_search.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_fuzzy_search_003_q2", "cluster_id": "skill_fuzzy_search_003", "question": "When should I combine rankings instead of scores?", "answer": "Use Reciprocal Rank Fusion (RRF) when combining results from multiple models with incompatible or inconsistent score scales. RRF converts scores to rankings first, then combines them using the formula: RRF(d) = sum(1 / (k + rank_i(d))). This is ideal for ensemble methods because it treats all models equally regardless of their native score ranges\u2014a model giving scores 0-1 is weighted the same as one giving 0-100. Example: `rrf_blend_scores([bge_scores, minilm_scores, nomic_scores], k=60)`. Use score blending instead when models already produce comparable scores on the same scale.", "question_type": "long", "topics": ["Quickstart", "Fuzzy Search"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["ranking", "ensemble", "fusion", "models"], "related_skills": ["skill_fuzzy_search.md"], "related_docs": ["scripts/experiment_ensemble_blend.py"], "original_answer": "Use Reciprocal Rank Fusion (RRF) when models have incompatible score scales. RRF formula: `RRF(d) = sum(1 / (k + rank_i(d)))`. Python example: `rrf_blend_scores([bge_scores, minilm_scores, nomic_scores], k=60)`. RRF combines relative rankings rather than absolute scores, making it ideal for ensemble methods. See skill_fuzzy_search.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_fuzzy_search_004_q0", "cluster_id": "skill_fuzzy_search_004", "question": "How do I filter search results by type or other properties?", "answer": "Use boolean filter predicates to filter search results by type or other properties. Available predicates include `is_type(T)` for filtering by item type (e.g., pearl, tree), `has_account(A)` for account filtering, `has_tag(Tag)` for tag-based filtering, and `in_subtree(Root)` for hierarchical filtering. Combine multiple conditions using `b_and/2` for AND logic or `b_or/2` for OR logic. Example: `apply_filter(ScoredItems, is_type(pearl), Filtered)` keeps only pearl items. For multiple conditions: `apply_filter(ScoredItems, b_and([is_type(pearl), has_account(main)]), Filtered)` returns items that are both pearls AND belong to the main account. See the Fuzzy Search skill documentation for additional filtering techniques.", "question_type": "medium", "topics": ["Quickstart", "Fuzzy Search"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["filtering", "boolean", "conditions", "properties"], "related_skills": ["skill_fuzzy_search.md"], "related_docs": ["src/unifyweaver/fuzzy/boolean.pl", "src/unifyweaver/fuzzy/predicates.pl"], "original_answer": "Use boolean filter predicates like `is_type(T)`, `has_account(A)`, `has_tag(Tag)`, or `in_subtree(Root)`. Combine with `b_and/2` for AND logic or `b_or/2` for OR logic. Example: `apply_filter(ScoredItems, is_type(pearl), Filtered)` keeps only pearl items. Use `b_and([is_type(pearl), has_account(main)])` to require both conditions. See skill_fuzzy_search.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "Base answer references 'skill_fuzzy_search.md' but the provided skill document is about fuzzy logic operations and score fusion, not boolean filtering. The core filtering mechanism (apply_filter with predicates) is correct, but the reference location is potentially misleading. The answer could be strengthened by showing an actual code example or clarifying where these predicates are defined in the codebase."}
{"pair_id": "skill_fuzzy_search_004_q1", "cluster_id": "skill_fuzzy_search_004", "question": "How do I apply boolean filters to scored items?", "answer": "Use boolean filter predicates like `is_type(T)`, `has_account(A)`, `has_tag(Tag)`, or `in_subtree(Root)` to apply filters to scored items. Combine predicates with `b_and/2` for AND logic (all conditions must match) or `b_or/2` for OR logic (any condition can match). Example: `apply_filter(ScoredItems, is_type(pearl), Filtered)` returns only pearl items. For multiple conditions, use `b_and([is_type(pearl), has_account(main)])` to require both conditions must be true. These filters work on the scored items to select matching subsets while preserving scores.", "question_type": "medium", "topics": ["Quickstart", "Fuzzy Search"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["filtering", "boolean", "conditions", "properties"], "related_skills": ["skill_fuzzy_search.md"], "related_docs": ["src/unifyweaver/fuzzy/boolean.pl", "src/unifyweaver/fuzzy/predicates.pl"], "original_answer": "Use boolean filter predicates like `is_type(T)`, `has_account(A)`, `has_tag(Tag)`, or `in_subtree(Root)`. Combine with `b_and/2` for AND logic or `b_or/2` for OR logic. Example: `apply_filter(ScoredItems, is_type(pearl), Filtered)` keeps only pearl items. Use `b_and([is_type(pearl), has_account(main)])` to require both conditions. See skill_fuzzy_search.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "Base answer references `skill_fuzzy_search.md` but the truncated skill document doesn't include boolean filter details. The core explanation is sound but lacks implementation examples showing how `apply_filter/3` actually works with the boolean predicates."}
{"pair_id": "skill_fuzzy_search_004_q2", "cluster_id": "skill_fuzzy_search_004", "question": "How do I keep only results matching specific criteria?", "answer": "Use boolean filter predicates to keep only results matching specific criteria. Available predicates include `is_type(T)` for filtering by item type, `has_account(A)` for account filtering, `has_tag(Tag)` for tag matching, and `in_subtree(Root)` for hierarchical filtering. Combine multiple predicates using `b_and/2` for AND logic (all conditions must match) or `b_or/2` for OR logic (any condition can match). Apply filters with `apply_filter(ScoredItems, FilterPredicate, Filtered)`. Example: `apply_filter(Results, is_type(pearl), OnlyPearls)` keeps only pearl items, while `b_and([is_type(pearl), has_account(main)])` requires both pearl type AND main account.", "question_type": "medium", "topics": ["Quickstart", "Fuzzy Search"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["filtering", "boolean", "conditions", "properties"], "related_skills": ["skill_fuzzy_search.md"], "related_docs": ["src/unifyweaver/fuzzy/boolean.pl", "src/unifyweaver/fuzzy/predicates.pl"], "original_answer": "Use boolean filter predicates like `is_type(T)`, `has_account(A)`, `has_tag(Tag)`, or `in_subtree(Root)`. Combine with `b_and/2` for AND logic or `b_or/2` for OR logic. Example: `apply_filter(ScoredItems, is_type(pearl), Filtered)` keeps only pearl items. Use `b_and([is_type(pearl), has_account(main)])` to require both conditions. See skill_fuzzy_search.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_fuzzy_search_005_q0", "cluster_id": "skill_fuzzy_search_005", "question": "How do I boost search scores for recent or featured items?", "answer": "Use `apply_boost/3` to multiply scores based on item properties. For recent items, use `apply_boost(ScoredItems, recency_boost, Boosted)`. For featured items, combine multiple boost conditions with fuzzy OR: `apply_boost(Items, f_or([featured:1.5, popular:1.2]), Boosted)`. Boosts are multiplicative\u2014higher values amplify scores more. You can also create custom boost predicates based on timestamps or metadata flags. See skill_fuzzy_search.md for implementation details and additional fusion techniques.", "question_type": "long", "topics": ["Quickstart", "Fuzzy Search"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["boosting", "scoring", "ranking", "properties"], "related_skills": ["skill_fuzzy_search.md"], "related_docs": ["src/unifyweaver/fuzzy/core.pl"], "original_answer": "Use `apply_boost/3` to multiply scores based on item properties. Example: `apply_boost(ScoredItems, recency_boost, Boosted)` boosts recent items. Custom boosts: `apply_boost(Items, f_or([featured:1.5, popular:1.2]), Boosted)` applies fuzzy OR logic for multiple boost conditions. Boosts are multiplicative, so higher values increase scores more. See skill_fuzzy_search.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer assumes `apply_boost/3` exists and is the primary mechanism, but the skill document doesn't contain implementation details for this predicate or how it handles recency calculations. The confidence is moderate because the answer addresses the question well but lacks concrete examples of recency predicates or time-based boost calculations."}
{"pair_id": "skill_fuzzy_search_005_q1", "cluster_id": "skill_fuzzy_search_005", "question": "How do I apply multiplicative boosts to results?", "answer": "Use `apply_boost/3` to multiply scores by boost factors based on item properties. Example: `apply_boost(ScoredItems, recency_boost, Boosted)` applies a multiplicative recency boost. For multiple boost conditions, use fuzzy logic: `apply_boost(Items, f_or([featured:1.5, popular:1.2]), Boosted)` multiplies scores by the fuzzy OR result of the boost factors. Since boosts are multiplicative, higher boost values increase final scores more substantially. This is useful for re-ranking results based on derived item attributes like freshness, popularity, or feature flags.", "question_type": "long", "topics": ["Quickstart", "Fuzzy Search"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["boosting", "scoring", "ranking", "properties"], "related_skills": ["skill_fuzzy_search.md"], "related_docs": ["src/unifyweaver/fuzzy/core.pl"], "original_answer": "Use `apply_boost/3` to multiply scores based on item properties. Example: `apply_boost(ScoredItems, recency_boost, Boosted)` boosts recent items. Custom boosts: `apply_boost(Items, f_or([featured:1.5, popular:1.2]), Boosted)` applies fuzzy OR logic for multiple boost conditions. Boosts are multiplicative, so higher values increase scores more. See skill_fuzzy_search.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer references 'skill_fuzzy_search.md' but the skill document provided doesn't show apply_boost/3 implementation details or examples. The answer assumes apply_boost exists and works as described, but the truncated skill document doesn't fully document this predicate's behavior, parameter order, or whether it handles item identifiers internally."}
{"pair_id": "skill_fuzzy_search_005_q2", "cluster_id": "skill_fuzzy_search_005", "question": "How do I prioritize items by properties?", "answer": "Use `apply_boost/3` to multiply scores based on item properties. For example, `apply_boost(ScoredItems, recency_boost, Boosted)` boosts recent items by their recency score. For multiple property conditions, use fuzzy OR logic: `apply_boost(Items, f_or([featured:1.5, popular:1.2]), Boosted)` applies a 1.5x boost to featured items and 1.2x to popular items, with fuzzy combination if items match multiple properties. Boosts are multiplicative\u2014higher values proportionally increase scores. This works with any custom property boost function you define.", "question_type": "long", "topics": ["Quickstart", "Fuzzy Search"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["boosting", "scoring", "ranking", "properties"], "related_skills": ["skill_fuzzy_search.md"], "related_docs": ["src/unifyweaver/fuzzy/core.pl"], "original_answer": "Use `apply_boost/3` to multiply scores based on item properties. Example: `apply_boost(ScoredItems, recency_boost, Boosted)` boosts recent items. Custom boosts: `apply_boost(Items, f_or([featured:1.5, popular:1.2]), Boosted)` applies fuzzy OR logic for multiple boost conditions. Boosts are multiplicative, so higher values increase scores more. See skill_fuzzy_search.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer references 'skill_fuzzy_search.md' but the skill document provided focuses on score fusion and fuzzy logic operations rather than property-based boosting. The apply_boost/3 predicate and custom boost functions are mentioned but not fully documented in the provided skill material, creating uncertainty about implementation details and API correctness."}
{"pair_id": "skill_fuzzy_search_006_q0", "cluster_id": "skill_fuzzy_search_006", "question": "How do I evaluate weighted fuzzy logic expressions?", "answer": "Use `eval_fuzzy_expr/3` to evaluate weighted fuzzy logic expressions. Call it with three arguments: the fuzzy expression (e.g., `f_and([bash:0.9, shell:0.5])`), a list of term-score pairs (e.g., `[bash-0.8, shell-0.6]`), and an output variable for the result. Weights (like 0.9, 0.5) represent term importance, while scores (like 0.8, 0.6) represent actual match strengths. For `f_and`, the result multiplies weighted scores: 0.9*0.8 * 0.5*0.6 = 0.216. You can use either `w(Term, Weight)` or `Term:Weight` syntax for weights. The operation type (`f_and`, `f_or`, etc.) determines how weights and scores combine.", "question_type": "long", "topics": ["Quickstart", "Fuzzy Search"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["evaluation", "weights", "expressions", "scoring"], "related_skills": ["skill_fuzzy_search.md"], "related_docs": ["src/unifyweaver/fuzzy/eval.pl"], "original_answer": "Use `eval_fuzzy_expr/3` to evaluate fuzzy expressions with term weights. Syntax: `eval_fuzzy_expr(f_and([bash:0.9, shell:0.5]), [bash-0.8, shell-0.6], Result)`. Weights (0.9, 0.5) represent term importance, while scores (0.8, 0.6) are match strengths. For AND: Result = 0.9*0.8 * 0.5*0.6 = 0.216. Use `w(Term, Weight)` or `Term:Weight` syntax. See skill_fuzzy_search.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_fuzzy_search_006_q1", "cluster_id": "skill_fuzzy_search_006", "question": "How do I calculate scores from term weights and match scores?", "answer": "Use `eval_fuzzy_expr/3` to calculate combined scores from term weights and match scores. Call it with a fuzzy expression like `f_and([bash:0.9, shell:0.5])`, term-score pairs like `[bash-0.8, shell-0.6]`, and bind the result: `eval_fuzzy_expr(f_and([bash:0.9, shell:0.5]), [bash-0.8, shell-0.6], Result)`. The calculation multiplies weights by their corresponding match scores: for AND operations, Result = (0.9 \u00d7 0.8) \u00d7 (0.5 \u00d7 0.6) = 0.216. Use either `w(Term, Weight)` or `Term:Weight` syntax for weights, where weights represent term importance (0.0-1.0) and scores represent match strength (0.0-1.0).", "question_type": "long", "topics": ["Quickstart", "Fuzzy Search"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["evaluation", "weights", "expressions", "scoring"], "related_skills": ["skill_fuzzy_search.md"], "related_docs": ["src/unifyweaver/fuzzy/eval.pl"], "original_answer": "Use `eval_fuzzy_expr/3` to evaluate fuzzy expressions with term weights. Syntax: `eval_fuzzy_expr(f_and([bash:0.9, shell:0.5]), [bash-0.8, shell-0.6], Result)`. Weights (0.9, 0.5) represent term importance, while scores (0.8, 0.6) are match strengths. For AND: Result = 0.9*0.8 * 0.5*0.6 = 0.216. Use `w(Term, Weight)` or `Term:Weight` syntax. See skill_fuzzy_search.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_fuzzy_search_006_q2", "cluster_id": "skill_fuzzy_search_006", "question": "How do I assign importance weights to search terms?", "answer": "Assign importance weights to search terms using the `w(Term, Weight)` syntax or the colon notation `Term:Weight`. For example, to make \"bash\" more important than \"shell\", use `f_and([w(bash, 0.9), w(shell, 0.5)])` or `f_and([bash:0.9, shell:0.5])`. Weights (0.0-1.0) represent term importance. Then evaluate with `eval_fuzzy_expr(Expression, [term-score, ...], Result)` where scores are match strengths. For AND operations: importance_weight * match_score are multiplied together. Higher weights increase a term's contribution to the final score.", "question_type": "long", "topics": ["Quickstart", "Fuzzy Search"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["evaluation", "weights", "expressions", "scoring"], "related_skills": ["skill_fuzzy_search.md"], "related_docs": ["src/unifyweaver/fuzzy/eval.pl"], "original_answer": "Use `eval_fuzzy_expr/3` to evaluate fuzzy expressions with term weights. Syntax: `eval_fuzzy_expr(f_and([bash:0.9, shell:0.5]), [bash-0.8, shell-0.6], Result)`. Weights (0.9, 0.5) represent term importance, while scores (0.8, 0.6) are match strengths. For AND: Result = 0.9*0.8 * 0.5*0.6 = 0.216. Use `w(Term, Weight)` or `Term:Weight` syntax. See skill_fuzzy_search.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_gui_design_001_q0", "cluster_id": "skill_gui_design_001", "question": "How do I create consistent UI components that work across Vue, React Native, Flutter, and SwiftUI?", "answer": "UnifyWeaver's design system lets you create consistent UI components across platforms using declarative Prolog specifications that compile to platform-specific code. Define a component once and generate it for Vue, React Native, Flutter, and SwiftUI:\n\n```prolog\ncard(content, [title('Welcome'), elevated(true)], Spec),\ngenerate_component(Spec, vue, Code),\ngenerate_component(Spec, react_native, Code),\ngenerate_component(Spec, flutter, Code),\ngenerate_component(Spec, swiftui, Code).\n```\n\nThe system provides pre-built components (modals, cards, buttons, inputs, progress indicators) that automatically adapt to each platform's design conventions while maintaining visual consistency. Reference skill_gui_design.md for the complete component library and customization options.", "question_type": "medium", "topics": ["Quickstart", "GUI Design"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["cross-platform", "components", "code-generation"], "related_skills": ["skill_gui_design.md", "skill_component_library.md"], "related_docs": ["src/unifyweaver/components/component_library.pl"], "original_answer": "UnifyWeaver's design system uses declarative specifications that compile to platform-specific code. Define a component once and generate code for all targets:\n\n```prolog\ncard(content, [title('Welcome'), elevated(true)], Spec),\ngenerate_component(Spec, vue, Code).\n```\n\nSupported targets: react_native, vue, flutter, swiftui. See skill_gui_design.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_gui_design_001_q1", "cluster_id": "skill_gui_design_001", "question": "How can I build components for multiple platforms?", "answer": "UnifyWeaver's design system enables cross-platform component building through declarative specifications that compile to platform-specific code. Define your component once using Prolog syntax, then generate implementations for multiple targets:\n\n```prolog\ncard(content, [title('Welcome'), elevated(true)], Spec),\ngenerate_component(Spec, vue, Code),\ngenerate_component(Spec, react_native, Code),\ngenerate_component(Spec, flutter, Code),\ngenerate_component(Spec, swiftui, Code).\n```\n\nSupported platforms: Vue, React Native, Flutter, and SwiftUI. The component library includes pre-built components (modals, cards, toasts, buttons, inputs) that automatically compile to all target platforms. Reference skill_component_library.md for the complete list of available components and their Prolog signatures.", "question_type": "medium", "topics": ["Quickstart", "GUI Design"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["cross-platform", "components", "code-generation"], "related_skills": ["skill_gui_design.md", "skill_component_library.md"], "related_docs": ["src/unifyweaver/components/component_library.pl"], "original_answer": "UnifyWeaver's design system uses declarative specifications that compile to platform-specific code. Define a component once and generate code for all targets:\n\n```prolog\ncard(content, [title('Welcome'), elevated(true)], Spec),\ngenerate_component(Spec, vue, Code).\n```\n\nSupported targets: react_native, vue, flutter, swiftui. See skill_gui_design.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_gui_design_001_q2", "cluster_id": "skill_gui_design_001", "question": "How do I use a design system for cross-platform UIs?", "answer": "UnifyWeaver's design system enables cross-platform UI development through declarative specifications that compile to platform-specific code. Define your UI components once using Prolog-based declarations, then generate implementations for multiple targets (Vue, React Native, Flutter, SwiftUI) automatically.\n\nExample: `card(content, [title('Welcome'), elevated(true)], Spec), generate_component(Spec, vue, Code).`\n\nThis approach ensures visual consistency across platforms while leveraging each platform's native capabilities. Access the component library (modals, cards, inputs, progress indicators, etc.) and layout system documentation for platform-specific implementation details.", "question_type": "medium", "topics": ["Quickstart", "GUI Design"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["cross-platform", "components", "code-generation"], "related_skills": ["skill_gui_design.md", "skill_component_library.md"], "related_docs": ["src/unifyweaver/components/component_library.pl"], "original_answer": "UnifyWeaver's design system uses declarative specifications that compile to platform-specific code. Define a component once and generate code for all targets:\n\n```prolog\ncard(content, [title('Welcome'), elevated(true)], Spec),\ngenerate_component(Spec, vue, Code).\n```\n\nSupported targets: react_native, vue, flutter, swiftui. See skill_gui_design.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer assumes familiarity with Prolog syntax and doesn't explain the broader workflow (design \u2192 specification \u2192 generation). Added context about consistency benefits and component library access, but confidence is moderate due to the technical domain specificity."}
{"pair_id": "skill_gui_design_002_q0", "cluster_id": "skill_gui_design_002", "question": "What pre-built UI components are available and how do I use them?", "answer": "UnifyWeaver provides pre-built UI components organized into five categories:\n\n**Modal/Dialog Components**: `modal/3`, `alert_dialog/3`, `bottom_sheet/3`, `action_sheet/3`\n\n**Feedback Components**: `toast/3`, `snackbar/3`, `banner/3`\n\n**Content Components**: `card/3`, `list_item/3`, `avatar/3`, `badge/3`, `chip/3`\n\n**Progress Components**: `progress_bar/3`, `progress_circle/3`, `spinner/2`\n\n**Input Components**: `search_bar/2`, `rating/3`, `stepper/3`\n\nUsage follows a consistent pattern: `component(content, [options], Spec)`. For example:\n- `modal(alert, [title('Warning')], Spec)`\n- `card(content, [title('Title')], Spec)`\n- `toast('Saved!', [type(success)], Spec)`\n- `progress_bar(75, [max(100)], Spec)`\n- `rating(4, [max(5)], Spec)`\n\nEach component generates platform-specific code for Vue, React Native, Flutter, and SwiftUI. Refer to skill_component_library.md for complete specifications and additional options.", "question_type": "medium", "topics": ["Quickstart", "GUI Design"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["components", "modals", "feedback"], "related_skills": ["skill_gui_design.md", "skill_component_library.md"], "related_docs": ["src/unifyweaver/components/component_library.pl"], "original_answer": "UnifyWeaver provides modal, feedback, content, progress, and input components. Examples:\n\n- Modal: `modal(alert, [title('Warning')], Spec)`\n- Card: `card(content, [title('Title')], Spec)`\n- Toast: `toast('Saved!', [type(success)], Spec)`\n- Progress: `progress_bar(75, [max(100)], Spec)`\n- Rating: `rating(4, [max(5)], Spec)`\n\nEach generates platform-specific code. See skill_gui_design.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_gui_design_002_q1", "cluster_id": "skill_gui_design_002", "question": "What components can I use for modals, cards, and notifications?", "answer": "UnifyWeaver provides pre-built components for modals, cards, and notifications:\n\nModal/Dialog Components:\n- `modal(alert, [title('Warning')], Spec)` - Generic modal\n- `alert_dialog('Delete?', [message(...)], Spec)` - Alert with confirm\n- `bottom_sheet(content, [height(auto)], Spec)` - Bottom slide-up\n- `action_sheet([save, delete], [...], Spec)` - Action options\n\nContent Components:\n- `card(content, [title('Title')], Spec)` - Content card\n- `list_item('Item', [leading(icon)], Spec)` - List row\n- `avatar('url', [size(large)], Spec)` - User avatar\n\nFeedback/Notification Components:\n- `toast('Saved!', [type(success)], Spec)` - Brief notification\n- `snackbar('Undo?', [action(undo)], Spec)` - Snackbar with action\n- `banner('Update available', [...], Spec)` - Persistent banner\n\nEach component generates platform-specific code for Vue, React Native, Flutter, and SwiftUI.", "question_type": "medium", "topics": ["Quickstart", "GUI Design"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["components", "modals", "feedback"], "related_skills": ["skill_gui_design.md", "skill_component_library.md"], "related_docs": ["src/unifyweaver/components/component_library.pl"], "original_answer": "UnifyWeaver provides modal, feedback, content, progress, and input components. Examples:\n\n- Modal: `modal(alert, [title('Warning')], Spec)`\n- Card: `card(content, [title('Title')], Spec)`\n- Toast: `toast('Saved!', [type(success)], Spec)`\n- Progress: `progress_bar(75, [max(100)], Spec)`\n- Rating: `rating(4, [max(5)], Spec)`\n\nEach generates platform-specific code. See skill_gui_design.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_gui_design_002_q2", "cluster_id": "skill_gui_design_002", "question": "How do I add buttons, cards, and alerts to my UI?", "answer": "UnifyWeaver's component library provides pre-built UI elements that compile to platform-specific code. For buttons, cards, and alerts:\n\n- **Buttons**: Use `button/3` component with options like `button('Click me', [variant(outlined)], Spec)`\n- **Cards**: Use `card/3` for content containers: `card(content, [title('Title'), elevated(true)], Spec)`\n- **Alerts**: Use `alert_dialog/3` for confirmable alerts: `alert_dialog('Delete?', [message('This action cannot be undone')], Spec)` or `modal/3` for generic modals\n\nEach component generates code for Vue, React Native, Flutter, and SwiftUI. Access the full component reference in skill_component_library.md for all available options and styling properties.", "question_type": "medium", "topics": ["Quickstart", "GUI Design"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["components", "modals", "feedback"], "related_skills": ["skill_gui_design.md", "skill_component_library.md"], "related_docs": ["src/unifyweaver/components/component_library.pl"], "original_answer": "UnifyWeaver provides modal, feedback, content, progress, and input components. Examples:\n\n- Modal: `modal(alert, [title('Warning')], Spec)`\n- Card: `card(content, [title('Title')], Spec)`\n- Toast: `toast('Saved!', [type(success)], Spec)`\n- Progress: `progress_bar(75, [max(100)], Spec)`\n- Rating: `rating(4, [max(5)], Spec)`\n\nEach generates platform-specific code. See skill_gui_design.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "Base answer omits buttons entirely (the question specifically asks about buttons). Button component exists in skill document but details are truncated. Alert_dialog is mentioned in the skill doc and better addresses 'alerts' than generic modals, but base answer only references modal/toast."}
{"pair_id": "skill_gui_design_003_q0", "cluster_id": "skill_gui_design_003", "question": "How do I create responsive layouts that adapt to different screen sizes?", "answer": "Use standard breakpoints (xs \u2264575px, sm \u2265576px, md \u2265768px, lg \u2265992px, xl \u22651200px) or semantic ones (mobile \u2264767px, tablet 768-1023px, desktop \u22651024px) to create responsive layouts. Define your layout with breakpoint overrides using the responsive_layout predicate:\n\n```prolog\nresponsive_layout(card_grid, [\n    default([strategy(grid), columns([\"1fr\"]), gap(\"1rem\")]),\n    at(sm, [columns([\"repeat(2, 1fr)\"])]),\n    at(lg, [columns([\"repeat(4, 1fr)\"])])\n]).\n```\n\nThis approach lets you declare how your grid columns change at different screen sizes\u2014starting with 1 column on mobile, expanding to 2 columns at small screens, and 4 columns on large screens. You can apply this same pattern to any layout component by specifying different style rules at each breakpoint.", "question_type": "medium", "topics": ["Quickstart", "GUI Design"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["responsive", "breakpoints", "mobile", "layout"], "related_skills": ["skill_gui_design.md", "skill_responsive_design.md"], "related_docs": ["src/unifyweaver/glue/responsive_generator.pl"], "original_answer": "Use standard breakpoints (xs \u2264575px, sm \u2265576px, md \u2265768px, lg \u2265992px, xl \u22651200px) or semantic ones (mobile \u2264767px, tablet 768-1023px, desktop \u22651024px). Define responsive layouts with breakpoint overrides:\n\n```prolog\nresponsive_layout(card_grid, [\n    default([strategy(grid), columns([\"1fr\"]), gap(\"1rem\")]),\n    at(sm, [columns([\"repeat(2, 1fr)\"])]),\n    at(lg, [columns([\"repeat(4, 1fr)\"])])\n]).\n```\n\nSee skill_gui_design.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_gui_design_003_q1", "cluster_id": "skill_gui_design_003", "question": "How do I make layouts work on mobile and desktop?", "answer": "Use responsive layouts with breakpoint definitions to adapt your UI for different screen sizes. UnifyWeaver provides standard breakpoints: xs (\u2264575px), sm (\u2265576px), md (\u2265768px), lg (\u2265992px), xl (\u22651200px). Define your layout with a default configuration and override it at specific breakpoints:\n\n```prolog\nresponsive_layout(card_grid, [\n    default([strategy(grid), columns([\"1fr\"]), gap(\"1rem\")]),\n    at(sm, [columns([\"repeat(2, 1fr)\"])]),\n    at(lg, [columns([\"repeat(4, 1fr)\"])])\n]).\n```\n\nThis creates a single-column layout on mobile, two columns on tablets, and four columns on larger screens. Alternatively, use semantic breakpoints (mobile \u2264767px, tablet 768-1023px, desktop \u22651024px) for more intuitive organization. See skill_responsive_design.md for complete responsive design options.", "question_type": "medium", "topics": ["Quickstart", "GUI Design"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["responsive", "breakpoints", "mobile", "layout"], "related_skills": ["skill_gui_design.md", "skill_responsive_design.md"], "related_docs": ["src/unifyweaver/glue/responsive_generator.pl"], "original_answer": "Use standard breakpoints (xs \u2264575px, sm \u2265576px, md \u2265768px, lg \u2265992px, xl \u22651200px) or semantic ones (mobile \u2264767px, tablet 768-1023px, desktop \u22651024px). Define responsive layouts with breakpoint overrides:\n\n```prolog\nresponsive_layout(card_grid, [\n    default([strategy(grid), columns([\"1fr\"]), gap(\"1rem\")]),\n    at(sm, [columns([\"repeat(2, 1fr)\"])]),\n    at(lg, [columns([\"repeat(4, 1fr)\"])])\n]).\n```\n\nSee skill_gui_design.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_gui_design_003_q2", "cluster_id": "skill_gui_design_003", "question": "What breakpoints should I use for responsive design?", "answer": "Use standard breakpoints (xs \u2264575px, sm \u2265576px, md \u2265768px, lg \u2265992px, xl \u22651200px) or semantic ones (mobile \u2264767px, tablet 768-1023px, desktop \u22651024px). Define responsive layouts with breakpoint overrides:\n\n```prolog\nresponsive_layout(card_grid, [\n    default([strategy(grid), columns([\"1fr\"]), gap(\"1rem\")]),\n    at(sm, [columns([\"repeat(2, 1fr)\"])]),\n    at(lg, [columns([\"repeat(4, 1fr)\"])])\n]).\n```", "question_type": "medium", "topics": ["Quickstart", "GUI Design"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["responsive", "breakpoints", "mobile", "layout"], "related_skills": ["skill_gui_design.md", "skill_responsive_design.md"], "related_docs": ["src/unifyweaver/glue/responsive_generator.pl"], "original_answer": "Use standard breakpoints (xs \u2264575px, sm \u2265576px, md \u2265768px, lg \u2265992px, xl \u22651200px) or semantic ones (mobile \u2264767px, tablet 768-1023px, desktop \u22651024px). Define responsive layouts with breakpoint overrides:\n\n```prolog\nresponsive_layout(card_grid, [\n    default([strategy(grid), columns([\"1fr\"]), gap(\"1rem\")]),\n    at(sm, [columns([\"repeat(2, 1fr)\"])]),\n    at(lg, [columns([\"repeat(4, 1fr)\"])])\n]).\n```\n\nSee skill_gui_design.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_gui_design_004_q0", "cluster_id": "skill_gui_design_004", "question": "How do I organize layouts with rows, columns, grids, and spacing?", "answer": "Use layout primitives with declarative syntax to organize your UI:\n\n**Rows** arrange items horizontally: `row([justify(space_between), gap(md)], [child1, child2], Spec)`\n\n**Columns** stack items vertically: `column([gap(lg), padding(md)], [header, body], Spec)`\n\n**Grids** create multi-column layouts: `grid([columns(3), gap(sm)], Items, Spec)`\n\n**Wrapping** flows items to next line: `wrap([gap(xs)], Tags, Spec)`\n\nControl spacing with the scale: xs(4px), sm(8px), md(16px), lg(24px), xl(32px), xxl(48px). Align items using justify (start/center/space_between) and align (start/center/stretch) options. Each primitive compiles to platform-specific layout code across Vue, React Native, Flutter, and SwiftUI.", "question_type": "medium", "topics": ["Quickstart", "GUI Design"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["layout", "spacing", "flexbox", "grid"], "related_skills": ["skill_gui_design.md", "skill_layout_system.md"], "related_docs": ["src/unifyweaver/layout/layout.pl"], "original_answer": "Use layout primitives with declarative syntax:\n\n- Row: `row([justify(space_between), gap(md)], [child1, child2], Spec)`\n- Column: `column([gap(lg), padding(md)], [header, body], Spec)`\n- Grid: `grid([columns(3), gap(sm)], Items, Spec)`\n- Wrap: `wrap([gap(xs)], Tags, Spec)`\n\nSpacing scale: xs(4px), sm(8px), md(16px), lg(24px), xl(32px), xxl(48px). Alignment options: justify (start/center/space_between), align (start/center/stretch). See skill_gui_design.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_gui_design_004_q1", "cluster_id": "skill_gui_design_004", "question": "How do I use flexbox and grid layouts?", "answer": "UnifyWeaver's layout system provides declarative primitives for flexbox and grid layouts:\n\n**Flexbox layouts:**\n- Row: `row([justify(space_between), gap(md)], [child1, child2], Spec)` - horizontal layout with spacing and alignment\n- Column: `column([gap(lg), padding(md)], [header, body], Spec)` - vertical layout with gaps and padding\n- Wrap: `wrap([gap(xs)], Tags, Spec)` - wrapping layout for responsive behavior\n\n**Grid layouts:**\n- Grid: `grid([columns(3), gap(sm)], Items, Spec)` - multi-column grid with configurable column count and spacing\n\n**Common options:**\n- Spacing scale: xs(4px), sm(8px), md(16px), lg(24px), xl(32px), xxl(48px)\n- Alignment: justify(start/center/space_between), align(start/center/stretch)\n\nThese primitives generate platform-specific code for Vue, React, Flutter, and other targets.", "question_type": "medium", "topics": ["Quickstart", "GUI Design"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["layout", "spacing", "flexbox", "grid"], "related_skills": ["skill_gui_design.md", "skill_layout_system.md"], "related_docs": ["src/unifyweaver/layout/layout.pl"], "original_answer": "Use layout primitives with declarative syntax:\n\n- Row: `row([justify(space_between), gap(md)], [child1, child2], Spec)`\n- Column: `column([gap(lg), padding(md)], [header, body], Spec)`\n- Grid: `grid([columns(3), gap(sm)], Items, Spec)`\n- Wrap: `wrap([gap(xs)], Tags, Spec)`\n\nSpacing scale: xs(4px), sm(8px), md(16px), lg(24px), xl(32px), xxl(48px). Alignment options: justify (start/center/space_between), align (start/center/stretch). See skill_gui_design.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_gui_design_004_q2", "cluster_id": "skill_gui_design_004", "question": "How do I arrange elements with proper spacing?", "answer": "Use layout primitives with declarative syntax to arrange elements with proper spacing:\n\n- Row: `row([justify(space_between), gap(md)], [child1, child2], Spec)` - arranges children horizontally\n- Column: `column([gap(lg), padding(md)], [header, body], Spec)` - arranges children vertically\n- Grid: `grid([columns(3), gap(sm)], Items, Spec)` - arranges children in a grid layout\n- Wrap: `wrap([gap(xs)], Tags, Spec)` - wraps children with automatic line breaking\n\nSpacing scale: xs(4px), sm(8px), md(16px), lg(24px), xl(32px), xxl(48px). Use `gap()` for spacing between elements and `padding()` for internal spacing. Control alignment with `justify()` (start/center/space_between) and `align()` (start/center/stretch) options.", "question_type": "medium", "topics": ["Quickstart", "GUI Design"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["layout", "spacing", "flexbox", "grid"], "related_skills": ["skill_gui_design.md", "skill_layout_system.md"], "related_docs": ["src/unifyweaver/layout/layout.pl"], "original_answer": "Use layout primitives with declarative syntax:\n\n- Row: `row([justify(space_between), gap(md)], [child1, child2], Spec)`\n- Column: `column([gap(lg), padding(md)], [header, body], Spec)`\n- Grid: `grid([columns(3), gap(sm)], Items, Spec)`\n- Wrap: `wrap([gap(xs)], Tags, Spec)`\n\nSpacing scale: xs(4px), sm(8px), md(16px), lg(24px), xl(32px), xxl(48px). Alignment options: justify (start/center/space_between), align (start/center/stretch). See skill_gui_design.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_gui_design_005_q0", "cluster_id": "skill_gui_design_005", "question": "How do I create and apply themes with colors, fonts, and dark mode?", "answer": "Define themes using design tokens with colors, typography, and spacing. Create a theme definition in Prolog:\n\n```prolog\ndefine_theme(my_app, [\n    colors([primary-'#007AFF', secondary-'#5AC8FA', background-'#FFFFFF', text-'#000000']),\n    typography([family-'Inter', sizeBase-16, sizeHeading-24]),\n    spacing([xs-4, sm-8, md-16, lg-24])\n]).\n```\n\nFor dark mode, define a variant that overrides specific tokens:\n\n```prolog\ndefine_variant(my_app, dark, [\n    colors([background-'#1C1C1E', text-'#FFFFFF', surface-'#2C2C2E'])\n]).\n```\n\nGenerate platform-specific code:\n\n```prolog\ngenerate_theme_code(my_app, vue, Code).      % CSS variables\ngenerate_theme_code(my_app, swift, Code).    % Type-safe structs\ngenerate_theme_code(my_app, flutter, Code).  % Constants\ngenerate_theme_code(my_app, react_native, Code).  % Objects\n```\n\nEach platform receives optimized output: Vue gets CSS custom properties, Swift gets structs, Flutter gets constants, and React Native gets theme objects. Apply themes to components by referencing the theme tokens.", "question_type": "medium", "topics": ["Quickstart", "GUI Design"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["theming", "dark-mode", "design-tokens", "typography"], "related_skills": ["skill_gui_design.md", "skill_theming.md"], "related_docs": ["src/unifyweaver/theming/theming.pl"], "original_answer": "Define themes using design tokens, then generate for each platform:\n\n```prolog\ndefine_theme(my_app, [\n    colors([primary-'#007AFF', background-'#FFFFFF']),\n    typography([family-'Inter', sizeBase-16]),\n    spacing([xs-4, md-16])\n]).\n\ndefine_variant(my_app, dark, [colors([background-'#1C1C1E'])]),\ngenerate_theme_code(my_app, vue, Code).\n```\n\nGenerates CSS variables for Vue, type-safe structs for Swift, constants for Flutter, and objects for React Native. See skill_gui_design.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer is somewhat generic about platform outputs. Added more concrete examples of color and typography tokens, and showed the variant syntax more clearly for dark mode implementation."}
{"pair_id": "skill_gui_design_005_q1", "cluster_id": "skill_gui_design_005", "question": "How do I set up consistent styling across the app?", "answer": "Define themes using design tokens with the `define_theme/2` predicate to establish consistent colors, typography, and spacing across your app. For example:\n\n```prolog\ndefine_theme(my_app, [\n    colors([primary-'#007AFF', background-'#FFFFFF']),\n    typography([family-'Inter', sizeBase-16]),\n    spacing([xs-4, md-16])\n]).\n```\n\nAdd platform-specific variants like dark mode using `define_variant/3`:\n\n```prolog\ndefine_variant(my_app, dark, [colors([background-'#1C1C1E'])]).\n```\n\nThen generate platform-specific code with `generate_theme_code/3`. This automatically produces CSS variables for Vue, type-safe structs for Swift, constants for Flutter, and objects for React Native\u2014ensuring consistency across all platforms without manual duplication.", "question_type": "medium", "topics": ["Quickstart", "GUI Design"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["theming", "dark-mode", "design-tokens", "typography"], "related_skills": ["skill_gui_design.md", "skill_theming.md"], "related_docs": ["src/unifyweaver/theming/theming.pl"], "original_answer": "Define themes using design tokens, then generate for each platform:\n\n```prolog\ndefine_theme(my_app, [\n    colors([primary-'#007AFF', background-'#FFFFFF']),\n    typography([family-'Inter', sizeBase-16]),\n    spacing([xs-4, md-16])\n]).\n\ndefine_variant(my_app, dark, [colors([background-'#1C1C1E'])]),\ngenerate_theme_code(my_app, vue, Code).\n```\n\nGenerates CSS variables for Vue, type-safe structs for Swift, constants for Flutter, and objects for React Native. See skill_gui_design.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_gui_design_005_q2", "cluster_id": "skill_gui_design_005", "question": "How do I implement dark mode?", "answer": "To implement dark mode, define themes using design tokens that specify colors, typography, and spacing for both light and dark variants:\n\n```prolog\ndefine_theme(my_app, [\n    colors([primary-'#007AFF', background-'#FFFFFF']),\n    typography([family-'Inter', sizeBase-16]),\n    spacing([xs-4, md-16])\n]).\n\ndefine_variant(my_app, dark, [colors([background-'#1C1C1E', primary-'#0A84FF'])]).\n```\n\nThen generate for your target platform:\n\n```prolog\ngenerate_theme_code(my_app, vue, Code).  % Generates CSS variables\ngenerate_theme_code(my_app, swift, Code).  % Generates type-safe structs\ngenerate_theme_code(my_app, flutter, Code).  % Generates constants\ngenerate_theme_code(my_app, react_native, Code).  % Generates objects\n```\n\nUnifyWeaver automatically handles platform-specific theme implementation\u2014CSS variables for web, native color constants for mobile platforms.", "question_type": "medium", "topics": ["Quickstart", "GUI Design"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["theming", "dark-mode", "design-tokens", "typography"], "related_skills": ["skill_gui_design.md", "skill_theming.md"], "related_docs": ["src/unifyweaver/theming/theming.pl"], "original_answer": "Define themes using design tokens, then generate for each platform:\n\n```prolog\ndefine_theme(my_app, [\n    colors([primary-'#007AFF', background-'#FFFFFF']),\n    typography([family-'Inter', sizeBase-16]),\n    spacing([xs-4, md-16])\n]).\n\ndefine_variant(my_app, dark, [colors([background-'#1C1C1E'])]),\ngenerate_theme_code(my_app, vue, Code).\n```\n\nGenerates CSS variables for Vue, type-safe structs for Swift, constants for Flutter, and objects for React Native. See skill_gui_design.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "Base answer includes theme definition but could be more explicit about the define_variant syntax for dark mode. The confidence is slightly lower because the base answer format uses Prolog but doesn't explicitly show the dark variant structure as clearly as needed for a direct answer."}
{"pair_id": "skill_gui_design_006_q0", "cluster_id": "skill_gui_design_006", "question": "How do I build a complete dashboard UI with responsive grid areas?", "answer": "To build a complete dashboard UI with responsive grid areas, use responsive_layout with grid strategy and area definitions that adapt per breakpoint. Define your layout structure at different screen sizes (default, md, lg) with corresponding grid areas and column proportions. For example, at small screens stack nav, main, and aside vertically in a single column. At medium screens arrange them as nav spanning full width with main and aside side-by-side. At large screens add a sidebar column. Combine this with themed cards from the component library (card/3) and responsive grids to create a fully responsive dashboard system. The grid areas automatically reflow content based on viewport, eliminating the need for separate mobile layouts.", "question_type": "long", "topics": ["Quickstart", "GUI Design"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["dashboard", "grid-areas", "responsive", "layout"], "related_skills": ["skill_gui_design.md", "skill_responsive_design.md", "skill_layout_system.md"], "related_docs": ["src/unifyweaver/layout/layout.pl", "src/unifyweaver/glue/responsive_generator.pl"], "original_answer": "Use responsive_layout with grid areas and column definitions that change per breakpoint:\n\n```prolog\nresponsive_layout(dashboard, [\n    default([strategy(grid), areas([[\"nav\"],[\"main\"],[\"aside\"]]), columns([\"1fr\"])]),\n    at(md, [areas([[\"nav\",\"nav\"],[\"main\",\"aside\"]]), columns([\"1fr\",\"300px\"])]),\n    at(lg, [areas([[\"nav\",\"nav\",\"nav\"],[\"sidebar\",\"main\",\"aside\"]]), columns([\"240px\",\"1fr\",\"300px\"])])\n]).\n```\n\nCombine with themed cards and responsive grids for complete dashboard systems. See skill_gui_design.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_gui_design_006_q1", "cluster_id": "skill_gui_design_006", "question": "How do I create a mobile-first dashboard layout?", "answer": "To create a mobile-first dashboard layout, use responsive_layout with grid areas that progressively enhance from mobile to desktop. Start with a single-column layout for mobile, then add multi-column layouts at medium and large breakpoints:\n\n```prolog\nresponsive_layout(dashboard, [\n    default([strategy(grid), areas([[\"nav\"],[\"main\"],[\"aside\"]]), columns([\"1fr\"])]),\n    at(md, [areas([[\"nav\",\"nav\"],[\"main\",\"aside\"]]), columns([\"1fr\",\"300px\"])]),\n    at(lg, [areas([[\"nav\",\"nav\",\"nav\"],[\"sidebar\",\"main\",\"aside\"]]), columns([\"240px\",\"1fr\",\"300px\"])])\n]).\n```\n\nThis approach stacks all elements vertically on mobile, adds a two-column layout at medium screens (sidebar visible), and expands to a full three-column layout on large screens. Combine with themed cards from the component library and responsive grids for a complete mobile-first dashboard system.", "question_type": "long", "topics": ["Quickstart", "GUI Design"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["dashboard", "grid-areas", "responsive", "layout"], "related_skills": ["skill_gui_design.md", "skill_responsive_design.md", "skill_layout_system.md"], "related_docs": ["src/unifyweaver/layout/layout.pl", "src/unifyweaver/glue/responsive_generator.pl"], "original_answer": "Use responsive_layout with grid areas and column definitions that change per breakpoint:\n\n```prolog\nresponsive_layout(dashboard, [\n    default([strategy(grid), areas([[\"nav\"],[\"main\"],[\"aside\"]]), columns([\"1fr\"])]),\n    at(md, [areas([[\"nav\",\"nav\"],[\"main\",\"aside\"]]), columns([\"1fr\",\"300px\"])]),\n    at(lg, [areas([[\"nav\",\"nav\",\"nav\"],[\"sidebar\",\"main\",\"aside\"]]), columns([\"240px\",\"1fr\",\"300px\"])])\n]).\n```\n\nCombine with themed cards and responsive grids for complete dashboard systems. See skill_gui_design.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_gui_design_006_q2", "cluster_id": "skill_gui_design_006", "question": "How do I use grid template areas for complex layouts?", "answer": "Use responsive_layout with grid_areas to define named layout regions that adapt across breakpoints:\n\n```prolog\nresponsive_layout(dashboard, [\n    default([\n        strategy(grid),\n        areas([['header', 'header'],\n               ['sidebar', 'main'],\n               ['footer', 'footer']]),\n        columns(['240px', '1fr']),\n        rows(['auto', '1fr', 'auto']\n    ]),\n    at(md, [\n        areas([['header', 'header', 'header'],\n               ['sidebar', 'main', 'aside'],\n               ['footer', 'footer', 'footer']]),\n        columns(['240px', '1fr', '300px']),\n        rows(['auto', '1fr', 'auto']\n    ])\n]).\n```\n\nEach breakpoint defines grid_areas (named regions), columns (widths), and rows (heights). Reference areas in child components with area('header') to place them in the grid. This generates CSS Grid template-areas syntax for web and constraint layouts for native platforms.", "question_type": "long", "topics": ["Quickstart", "GUI Design"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["dashboard", "grid-areas", "responsive", "layout"], "related_skills": ["skill_gui_design.md", "skill_responsive_design.md", "skill_layout_system.md"], "related_docs": ["src/unifyweaver/layout/layout.pl", "src/unifyweaver/glue/responsive_generator.pl"], "original_answer": "Use responsive_layout with grid areas and column definitions that change per breakpoint:\n\n```prolog\nresponsive_layout(dashboard, [\n    default([strategy(grid), areas([[\"nav\"],[\"main\"],[\"aside\"]]), columns([\"1fr\"])]),\n    at(md, [areas([[\"nav\",\"nav\"],[\"main\",\"aside\"]]), columns([\"1fr\",\"300px\"])]),\n    at(lg, [areas([[\"nav\",\"nav\",\"nav\"],[\"sidebar\",\"main\",\"aside\"]]), columns([\"240px\",\"1fr\",\"300px\"])])\n]).\n```\n\nCombine with themed cards and responsive grids for complete dashboard systems. See skill_gui_design.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "Base answer covers grid areas and breakpoints but lacks details on: (1) how child components reference specific areas, (2) rows parameter not mentioned in original, (3) no clarification of how this compiles to CSS Grid template-areas syntax. Answer reconstructed from pattern but actual API syntax for area references unconfirmed."}
{"pair_id": "skill_gui_generation_001_q0", "cluster_id": "skill_gui_generation_001", "question": "How do I generate a complete frontend application?", "answer": "To generate a complete frontend application with UnifyWeaver, define your app specification in Prolog with screens and navigation, select your target framework (Vue, React Native, Flutter, or SwiftUI), then call generate_complete_project/4. For example: `generate_complete_project(app(myapp, [navigation(tabs, [screen(home, 'HomeView', []), screen(about, 'AboutView', [])], [])]), [frontend-vue], 'output/myapp', Result).` This creates a fully scaffolded project with TypeScript/Dart/Swift code, build configuration, and dependencies ready to build and run.", "question_type": "medium", "topics": ["Quickstart", "GUI Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["app-generation", "scaffolding", "frontend", "setup"], "related_skills": ["skill_gui_generation.md"], "related_docs": ["src/unifyweaver/glue/app_generator.pl", "src/unifyweaver/targets/vue_target.pl", "src/unifyweaver/targets/react_native_target.pl", "src/unifyweaver/targets/flutter_target.pl", "src/unifyweaver/targets/swiftui_target.pl"], "original_answer": "Use UnifyWeaver's app generation to create complete frontend applications from Prolog specifications. Define your app structure with screens and navigation, select a target (Vue, React Native, Flutter, or SwiftUI), then call generate_complete_project/4. For example: `generate_complete_project(app(myapp, [navigation(tabs, [screen(home, 'HomeView', []), screen(about, 'AboutView', [])], [])]), [frontend-vue], 'output/myapp', Result).` The generator creates TypeScript code, build files, and project structure ready to run. See skill_gui_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_gui_generation_001_q1", "cluster_id": "skill_gui_generation_001", "question": "How do I scaffold a new frontend app?", "answer": "To scaffold a new frontend app with UnifyWeaver, define your app structure in Prolog with screens and navigation, then use generate_complete_project/4 to generate code for your chosen target. Start by specifying your app with navigation(tabs, [...]) or another navigation type, define your screens with screen(id, 'ComponentName', [...]), select a target framework (frontend-vue, frontend-react_native, frontend-flutter, or frontend-swiftui), and call: generate_complete_project(app(myapp, [navigation(tabs, [...])]), [frontend-vue], 'output/myapp', Result). This creates a complete project with TypeScript code, build configuration, dependencies, and project structure ready to run.", "question_type": "medium", "topics": ["Quickstart", "GUI Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["app-generation", "scaffolding", "frontend", "setup"], "related_skills": ["skill_gui_generation.md"], "related_docs": ["src/unifyweaver/glue/app_generator.pl", "src/unifyweaver/targets/vue_target.pl", "src/unifyweaver/targets/react_native_target.pl", "src/unifyweaver/targets/flutter_target.pl", "src/unifyweaver/targets/swiftui_target.pl"], "original_answer": "Use UnifyWeaver's app generation to create complete frontend applications from Prolog specifications. Define your app structure with screens and navigation, select a target (Vue, React Native, Flutter, or SwiftUI), then call generate_complete_project/4. For example: `generate_complete_project(app(myapp, [navigation(tabs, [screen(home, 'HomeView', []), screen(about, 'AboutView', [])], [])]), [frontend-vue], 'output/myapp', Result).` The generator creates TypeScript code, build files, and project structure ready to run. See skill_gui_generation.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_gui_generation_001_q2", "cluster_id": "skill_gui_generation_001", "question": "What's the process for generating a frontend project?", "answer": "To generate a frontend project with UnifyWeaver, define your app structure in Prolog with screens and navigation, select a target framework (Vue, React Native, Flutter, or SwiftUI), then call generate_complete_project/4. For example: `generate_complete_project(app(myapp, [navigation(tabs, [screen(home, 'HomeView', []), screen(about, 'AboutView', [])], [])]), [frontend-vue], 'output/myapp', Result).` This generates TypeScript/Dart/Swift code, build configuration, and a ready-to-run project structure.", "question_type": "medium", "topics": ["Quickstart", "GUI Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["app-generation", "scaffolding", "frontend", "setup"], "related_skills": ["skill_gui_generation.md"], "related_docs": ["src/unifyweaver/glue/app_generator.pl", "src/unifyweaver/targets/vue_target.pl", "src/unifyweaver/targets/react_native_target.pl", "src/unifyweaver/targets/flutter_target.pl", "src/unifyweaver/targets/swiftui_target.pl"], "original_answer": "Use UnifyWeaver's app generation to create complete frontend applications from Prolog specifications. Define your app structure with screens and navigation, select a target (Vue, React Native, Flutter, or SwiftUI), then call generate_complete_project/4. For example: `generate_complete_project(app(myapp, [navigation(tabs, [screen(home, 'HomeView', []), screen(about, 'AboutView', [])], [])]), [frontend-vue], 'output/myapp', Result).` The generator creates TypeScript code, build files, and project structure ready to run. See skill_gui_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_gui_generation_002_q0", "cluster_id": "skill_gui_generation_002", "question": "What frontend frameworks can I generate code for?", "answer": "UnifyWeaver supports four frontend frameworks: Vue 3 + Vite for web applications, React Native + Expo for iOS/Android, Flutter + Dart for cross-platform development, and SwiftUI for native Apple apps. Specify your target when generating a project using parameters like `frontend-vue`, `frontend-react_native`, `frontend-flutter`, or `frontend-swiftui`.", "question_type": "medium", "topics": ["Quickstart", "GUI Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["targets", "frameworks", "frontend-types"], "related_skills": ["skill_gui_generation.md"], "related_docs": ["src/unifyweaver/targets/vue_target.pl", "src/unifyweaver/targets/react_native_target.pl", "src/unifyweaver/targets/flutter_target.pl", "src/unifyweaver/targets/swiftui_target.pl"], "original_answer": "UnifyWeaver supports four frontend targets: Vue 3 + Vite for modern web apps, React Native + Expo for iOS/Android mobile development, Flutter + Dart for cross-platform mobile/web/desktop, and SwiftUI for native Apple applications. All targets generate TypeScript or language-appropriate code with proper build configurations. Choose your target when calling generate_complete_project/4 as a parameter like `[frontend-vue]` or `[frontend-react_native]`. See skill_gui_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_gui_generation_002_q1", "cluster_id": "skill_gui_generation_002", "question": "Which targets are supported for app generation?", "answer": "UnifyWeaver supports four frontend targets for app generation: frontend-vue (Vue 3 + Vite for web apps), frontend-react_native (React Native + Expo for iOS/Android), frontend-flutter (Flutter + Dart for cross-platform mobile/web/desktop), and frontend-swiftui (SwiftUI for native Apple apps). Specify your target when calling generate_complete_project/4, for example [frontend-vue] or [frontend-react_native].", "question_type": "medium", "topics": ["Quickstart", "GUI Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["targets", "frameworks", "frontend-types"], "related_skills": ["skill_gui_generation.md"], "related_docs": ["src/unifyweaver/targets/vue_target.pl", "src/unifyweaver/targets/react_native_target.pl", "src/unifyweaver/targets/flutter_target.pl", "src/unifyweaver/targets/swiftui_target.pl"], "original_answer": "UnifyWeaver supports four frontend targets: Vue 3 + Vite for modern web apps, React Native + Expo for iOS/Android mobile development, Flutter + Dart for cross-platform mobile/web/desktop, and SwiftUI for native Apple applications. All targets generate TypeScript or language-appropriate code with proper build configurations. Choose your target when calling generate_complete_project/4 as a parameter like `[frontend-vue]` or `[frontend-react_native]`. See skill_gui_generation.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_gui_generation_002_q2", "cluster_id": "skill_gui_generation_002", "question": "Can I generate React Native or Flutter apps?", "answer": "Yes, UnifyWeaver supports generating React Native and Flutter apps. React Native with Expo generates iOS/Android mobile applications, while Flutter with Dart generates cross-platform apps for mobile, web, and desktop. To generate either, specify the target when calling generate_complete_project/4: use `[frontend-react_native]` for React Native or `[frontend-flutter]` for Flutter. Both targets generate appropriate code with proper build configurations and dependencies.", "question_type": "medium", "topics": ["Quickstart", "GUI Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["targets", "frameworks", "frontend-types"], "related_skills": ["skill_gui_generation.md"], "related_docs": ["src/unifyweaver/targets/vue_target.pl", "src/unifyweaver/targets/react_native_target.pl", "src/unifyweaver/targets/flutter_target.pl", "src/unifyweaver/targets/swiftui_target.pl"], "original_answer": "UnifyWeaver supports four frontend targets: Vue 3 + Vite for modern web apps, React Native + Expo for iOS/Android mobile development, Flutter + Dart for cross-platform mobile/web/desktop, and SwiftUI for native Apple applications. All targets generate TypeScript or language-appropriate code with proper build configurations. Choose your target when calling generate_complete_project/4 as a parameter like `[frontend-vue]` or `[frontend-react_native]`. See skill_gui_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_gui_generation_003_q0", "cluster_id": "skill_gui_generation_003", "question": "How do I define navigation in my app specification?", "answer": "Define navigation in your app specification using the `navigation/3` predicate with the structure: `navigation(Type, Screens, Options)`. Choose from three navigation types: `tabs` for bottom tab bar navigation (ideal for mobile apps), `drawer` for side menu navigation (suitable for complex navigation), or `stack` for stack-based navigation (useful for wizards and sequential flows). Within the Screens list, define each screen using `screen(screen_id, 'ComponentName', [options])`. Screen options can include `icon(IconName)` for navigation icons, `guard(GuardName)` for authentication guards, `params([param1, param2])` for route parameters, and `lazy(true)` for lazy loading. For example: `navigation(tabs, [screen(home, 'HomeView', [icon(home)]), screen(search, 'SearchView', [icon(search)]), screen(profile, 'ProfileView', [icon(person)])], [])`.", "question_type": "long", "topics": ["Quickstart", "GUI Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["navigation", "screens", "app-structure"], "related_skills": ["skill_gui_generation.md", "skill_app_generation.md"], "related_docs": ["src/unifyweaver/glue/app_generator.pl"], "original_answer": "Define navigation in your app specification using the navigation/3 structure. Three navigation types are supported: `tabs` for bottom tab bar navigation (best for mobile), `drawer` for side menu navigation (complex navigation needs), and `stack` for stack-based navigation (wizards and flows). Example: `navigation(tabs, [screen(home, 'HomeView', [icon(home)]), screen(search, 'SearchView', [icon(search)])], [])`. Screens can include icons, auth guards, route parameters, and lazy-loading flags. See skill_gui_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_gui_generation_003_q1", "cluster_id": "skill_gui_generation_003", "question": "What navigation types are available?", "answer": "Three navigation types are available in UnifyWeaver's GUI generation: `tabs` for bottom tab bar navigation (ideal for mobile apps), `drawer` for side drawer menu navigation (suited for complex navigation structures), and `stack` for stack-based navigation (used for wizards and linear flows). Each type is defined in the navigation/3 structure within your app specification, specifying the type, list of screens, and options.", "question_type": "long", "topics": ["Quickstart", "GUI Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["navigation", "screens", "app-structure"], "related_skills": ["skill_gui_generation.md", "skill_app_generation.md"], "related_docs": ["src/unifyweaver/glue/app_generator.pl"], "original_answer": "Define navigation in your app specification using the navigation/3 structure. Three navigation types are supported: `tabs` for bottom tab bar navigation (best for mobile), `drawer` for side menu navigation (complex navigation needs), and `stack` for stack-based navigation (wizards and flows). Example: `navigation(tabs, [screen(home, 'HomeView', [icon(home)]), screen(search, 'SearchView', [icon(search)])], [])`. Screens can include icons, auth guards, route parameters, and lazy-loading flags. See skill_gui_generation.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_gui_generation_003_q2", "cluster_id": "skill_gui_generation_003", "question": "How do I set up tabs or drawer menus in my app?", "answer": "To set up tabs or drawer menus, define navigation in your app specification using the `navigation/3` structure. For tab navigation, use `navigation(tabs, [screen(home, 'HomeView', [icon(home)]), screen(search, 'SearchView', [icon(search)])], [])` - this creates a bottom tab bar best for mobile apps. For drawer navigation, use `navigation(drawer, [screen(dashboard, 'DashboardView', []), screen(settings, 'SettingsView', [])], [header('My App')])` - this creates a side menu for complex navigation. Each screen can include icons, auth guards, route parameters, and lazy-loading settings.", "question_type": "long", "topics": ["Quickstart", "GUI Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["navigation", "screens", "app-structure"], "related_skills": ["skill_gui_generation.md", "skill_app_generation.md"], "related_docs": ["src/unifyweaver/glue/app_generator.pl"], "original_answer": "Define navigation in your app specification using the navigation/3 structure. Three navigation types are supported: `tabs` for bottom tab bar navigation (best for mobile), `drawer` for side menu navigation (complex navigation needs), and `stack` for stack-based navigation (wizards and flows). Example: `navigation(tabs, [screen(home, 'HomeView', [icon(home)]), screen(search, 'SearchView', [icon(search)])], [])`. Screens can include icons, auth guards, route parameters, and lazy-loading flags. See skill_gui_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_gui_generation_004_q0", "cluster_id": "skill_gui_generation_004", "question": "How do I generate a full-stack application with backend?", "answer": "Generate full-stack applications by using generate_complete_project/4 with multiple targets. Pass both frontend and backend targets like [frontend-vue, backend-fastapi] to create an integrated project. Supported backends include backend-fastapi (Python), backend-flask (Python), and backend-express (Node.js). Example: generate_complete_project(app(fullstack, [...]), [frontend-vue, backend-fastapi], 'output/app', Result). This generates a coordinated project structure with frontend and backend properly integrated.", "question_type": "long", "topics": ["Quickstart", "GUI Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["full-stack", "backend-integration", "generation"], "related_skills": ["skill_gui_generation.md"], "related_docs": ["src/unifyweaver/glue/app_generator.pl"], "original_answer": "Generate full-stack applications by specifying both frontend and backend targets in generate_complete_project/4. Pass multiple targets like `[frontend-vue, backend-fastapi]` to create coordinated frontend and backend code. Supported backends include `backend-fastapi` (Python), `backend-flask` (Python), and `backend-express` (Node.js). Example: `generate_complete_project(app(fullstack, [...]), [frontend-vue, backend-fastapi], 'output/app', Result).` This generates a complete project structure with both layers properly integrated. See skill_gui_generation.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "Base answer references skill_gui_generation.md but the skill document provided is actually skill_gui_generation (the master skill overview). The specific backend integration details and whether targets are automatically coordinated or require additional configuration are unclear from the provided context. Answer assumes targets are passed as a list but doesn't clarify backend specification syntax in the Prolog app definition."}
{"pair_id": "skill_gui_generation_004_q1", "cluster_id": "skill_gui_generation_004", "question": "Can I generate frontend and backend together?", "answer": "Yes, you can generate frontend and backend together using UnifyWeaver's full-stack generation. Pass multiple targets to `generate_complete_project/4`, such as `[frontend-vue, backend-fastapi]`, to create coordinated frontend and backend code in a single operation. Supported backends include FastAPI (Python), Flask (Python), and Express (Node.js). The generated project structure integrates both layers properly. Example: `generate_complete_project(app(fullstack, [...]), [frontend-vue, backend-fastapi], 'output/app', Result).`", "question_type": "long", "topics": ["Quickstart", "GUI Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["full-stack", "backend-integration", "generation"], "related_skills": ["skill_gui_generation.md"], "related_docs": ["src/unifyweaver/glue/app_generator.pl"], "original_answer": "Generate full-stack applications by specifying both frontend and backend targets in generate_complete_project/4. Pass multiple targets like `[frontend-vue, backend-fastapi]` to create coordinated frontend and backend code. Supported backends include `backend-fastapi` (Python), `backend-flask` (Python), and `backend-express` (Node.js). Example: `generate_complete_project(app(fullstack, [...]), [frontend-vue, backend-fastapi], 'output/app', Result).` This generates a complete project structure with both layers properly integrated. See skill_gui_generation.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer assumes full-stack generation is fully documented in skill_gui_generation.md, but the skill document shown is truncated and doesn't confirm backend generation details. The confidence reflects uncertainty about whether this feature is actually implemented or fully supported."}
{"pair_id": "skill_gui_generation_004_q2", "cluster_id": "skill_gui_generation_004", "question": "How do I create an app with Vue and FastAPI?", "answer": "To create an app with Vue and FastAPI, use generate_complete_project/4 with both targets specified. Define your app specification in Prolog with screens, navigation, and features. Then call: `generate_complete_project(app(myapp, [...]), [frontend-vue, backend-fastapi], 'output/app', Result).` This generates a complete Vue 3 + Vite frontend integrated with a FastAPI Python backend. The generated project includes proper API communication setup between the frontend and backend layers, build configurations for both targets, and coordinated dependency management.", "question_type": "long", "topics": ["Quickstart", "GUI Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["full-stack", "backend-integration", "generation"], "related_skills": ["skill_gui_generation.md"], "related_docs": ["src/unifyweaver/glue/app_generator.pl"], "original_answer": "Generate full-stack applications by specifying both frontend and backend targets in generate_complete_project/4. Pass multiple targets like `[frontend-vue, backend-fastapi]` to create coordinated frontend and backend code. Supported backends include `backend-fastapi` (Python), `backend-flask` (Python), and `backend-express` (Node.js). Example: `generate_complete_project(app(fullstack, [...]), [frontend-vue, backend-fastapi], 'output/app', Result).` This generates a complete project structure with both layers properly integrated. See skill_gui_generation.md for details.", "answer_tailored": true, "confidence": 0.75, "confidence_issues": "Base answer mentions full-stack generation and FastAPI support but lacks specific implementation details about Vue-FastAPI integration patterns, API endpoint communication setup, or concrete examples of how the frontend and backend coordinate in the generated code."}
{"pair_id": "skill_gui_generation_005_q0", "cluster_id": "skill_gui_generation_005", "question": "How do I add authentication to my generated app?", "answer": "Add authentication to your app specification using the auth/1 structure with your backend type (e.g., jwt) and guard configurations. Apply guards to specific screens to protect them. For example: `app(secureapp, [auth([backend(jwt), guards([authenticated])]), navigation(tabs, [screen(public, 'PublicView', []), screen(private, 'PrivateView', [guard(authenticated)])], [])])`. Pair this with a backend target like `backend-fastapi` for complete auth integration. The code generator will create authenticated routes and enforce screen protection based on your guard specifications.", "question_type": "long", "topics": ["Quickstart", "GUI Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["authentication", "security", "guards", "jwt"], "related_skills": ["skill_gui_generation.md"], "related_docs": ["src/unifyweaver/glue/app_generator.pl"], "original_answer": "Add authentication to your app specification using the auth/1 structure with backend type (e.g., jwt) and guard configurations. Apply guards to specific screens in the screen options. Example: `app(secureapp, [auth([backend(jwt), guards([authenticated])]), navigation(tabs, [screen(public, 'PublicView', []), screen(private, 'PrivateView', [guard(authenticated)])], [])])`. Combine with a backend target like `backend-fastapi` for complete auth integration. The generator creates authenticated routes and protected screens. See skill_gui_generation.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "Base answer references 'skill_gui_generation.md' which doesn't exist in the truncated document (skill_app_generation.md and skill_typescript_target.md are mentioned instead). Tailored answer removes this reference but confidence is reduced due to this documentation mismatch."}
{"pair_id": "skill_gui_generation_005_q1", "cluster_id": "skill_gui_generation_005", "question": "How do I set up auth guards for screens?", "answer": "To set up auth guards for screens, add guard configurations to your app specification. First, define authentication at the app level using `auth([backend(jwt)])`. Then apply guards to individual screens by adding `guard(guardName)` to their options. Example: `screen(private, 'PrivateView', [guard(authenticated)])`. When you generate the app with a backend target like `backend-fastapi`, the generator creates protected routes and enforces authentication checks on guarded screens before allowing access.", "question_type": "long", "topics": ["Quickstart", "GUI Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["authentication", "security", "guards", "jwt"], "related_skills": ["skill_gui_generation.md"], "related_docs": ["src/unifyweaver/glue/app_generator.pl"], "original_answer": "Add authentication to your app specification using the auth/1 structure with backend type (e.g., jwt) and guard configurations. Apply guards to specific screens in the screen options. Example: `app(secureapp, [auth([backend(jwt), guards([authenticated])]), navigation(tabs, [screen(public, 'PublicView', []), screen(private, 'PrivateView', [guard(authenticated)])], [])])`. Combine with a backend target like `backend-fastapi` for complete auth integration. The generator creates authenticated routes and protected screens. See skill_gui_generation.md for details.", "answer_tailored": true, "confidence": 0.75, "confidence_issues": "The base answer mentions guard configurations and backend integration, but the skill document excerpt is truncated, so the full details on available guard types and their configuration options are unclear. The answer is functional but could be more complete regarding specific guard options beyond 'authenticated'."}
{"pair_id": "skill_gui_generation_005_q2", "cluster_id": "skill_gui_generation_005", "question": "Can I generate an app with JWT authentication?", "answer": "Yes, you can generate an app with JWT authentication. Add the `auth([backend(jwt), guards([authenticated])])` structure to your app specification. Apply the `guard(authenticated)` option to screens that require authentication. Example: `app(secureapp, [auth([backend(jwt), guards([authenticated])]), navigation(tabs, [screen(public, 'PublicView', []), screen(private, 'PrivateView', [guard(authenticated)])], [])])`. Pair this with a backend target like `backend-fastapi` for complete JWT integration. The generator creates authenticated routes and protects screens based on your guard configurations.", "question_type": "long", "topics": ["Quickstart", "GUI Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["authentication", "security", "guards", "jwt"], "related_skills": ["skill_gui_generation.md"], "related_docs": ["src/unifyweaver/glue/app_generator.pl"], "original_answer": "Add authentication to your app specification using the auth/1 structure with backend type (e.g., jwt) and guard configurations. Apply guards to specific screens in the screen options. Example: `app(secureapp, [auth([backend(jwt), guards([authenticated])]), navigation(tabs, [screen(public, 'PublicView', []), screen(private, 'PrivateView', [guard(authenticated)])], [])])`. Combine with a backend target like `backend-fastapi` for complete auth integration. The generator creates authenticated routes and protected screens. See skill_gui_generation.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer correctly addresses JWT authentication capability, but the documentation excerpt is truncated, so some implementation details about JWT token handling, refresh mechanisms, or token storage strategies may not be fully represented in the answer."}
{"pair_id": "skill_gui_generation_006_q0", "cluster_id": "skill_gui_generation_006", "question": "What should I do after generating my app?", "answer": "After generating your app, navigate to the output directory and install dependencies with `npm install`. Start the development server with `npm run dev` to begin local development. The generated project includes all necessary build configurations, TypeScript setup, and dependencies pre-configured. For full-stack applications, set up your environment variables to connect the frontend to your backend services. The generated code is ready for you to extend with custom components and business logic.", "question_type": "medium", "topics": ["Quickstart", "GUI Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["build", "development", "setup", "dependencies"], "related_skills": ["skill_gui_generation.md"], "related_docs": ["src/unifyweaver/glue/app_generator.pl"], "original_answer": "After generating your project, navigate to the output directory and install dependencies with `npm install`, then start development server with `npm run dev`. The generated project includes all necessary build configurations, TypeScript setup, and dependencies. For full-stack apps, configure environment variables to connect frontend and backend. All generated code is ready to extend with custom components and business logic. See skill_gui_generation.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_gui_generation_006_q1", "cluster_id": "skill_gui_generation_006", "question": "How do I build and run a generated app?", "answer": "After generating your frontend app, navigate to the project directory and run `npm install` to install dependencies. Then start the development server with `npm run dev`. The generated project includes all necessary build configurations, TypeScript setup, and dependencies pre-configured. For apps with backend services, set up environment variables to connect the frontend to your backend API. The generated code is ready for further customization and feature development.", "question_type": "medium", "topics": ["Quickstart", "GUI Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["build", "development", "setup", "dependencies"], "related_skills": ["skill_gui_generation.md"], "related_docs": ["src/unifyweaver/glue/app_generator.pl"], "original_answer": "After generating your project, navigate to the output directory and install dependencies with `npm install`, then start development server with `npm run dev`. The generated project includes all necessary build configurations, TypeScript setup, and dependencies. For full-stack apps, configure environment variables to connect frontend and backend. All generated code is ready to extend with custom components and business logic. See skill_gui_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_gui_generation_006_q2", "cluster_id": "skill_gui_generation_006", "question": "What are the next steps after project generation?", "answer": "After project generation, navigate to the output directory and install dependencies with `npm install`. Start the development server with `npm run dev` to begin development. The generated project includes all necessary build configurations and TypeScript setup. For full-stack applications, configure environment variables to connect the frontend to your backend services. The generated code is ready for extension with custom components and business logic.", "question_type": "medium", "topics": ["Quickstart", "GUI Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["build", "development", "setup", "dependencies"], "related_skills": ["skill_gui_generation.md"], "related_docs": ["src/unifyweaver/glue/app_generator.pl"], "original_answer": "After generating your project, navigate to the output directory and install dependencies with `npm install`, then start development server with `npm run dev`. The generated project includes all necessary build configurations, TypeScript setup, and dependencies. For full-stack apps, configure environment variables to connect frontend and backend. All generated code is ready to extend with custom components and business logic. See skill_gui_generation.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer references 'skill_gui_generation.md' which appears to be 'skill_GUI_generation.md' based on the skill document structure. The answer assumes npm/Node.js tooling but the skill document mentions multiple targets (Vue, React Native, Flutter, SwiftUI) which may use different package managers and commands."}
{"pair_id": "skill_gui_runtime_001_q0", "cluster_id": "skill_gui_runtime_001", "question": "How do I run Python code in the browser?", "answer": "Use Pyodide to run full Python code directly in the browser with support for scientific libraries like NumPy, SciPy, and pandas. Generate a Pyodide module using `compile_pyodide_module(data_analysis, [packages([numpy, pandas, scipy]), exports([analyze, transform])], PythonCode).` For a complete solution with UI, generate an HTML page with `generate_pyodide_html('Data Analysis', [packages([numpy]), chart(true)], HTML).` This approach requires no server\u2014Python executes entirely client-side in the browser.", "question_type": "medium", "topics": ["Quickstart", "GUI Runtime"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["browser-execution", "python", "pyodide", "client-side"], "related_skills": ["skill_gui_runtime.md"], "related_docs": ["src/unifyweaver/targets/python_pyodide_target.pl"], "original_answer": "Use Pyodide to run full Python with scientific libraries (NumPy, SciPy, pandas) directly in the browser. Generate a Pyodide module with `compile_pyodide_module(data_analysis, [packages([numpy, pandas, scipy]), exports([analyze, transform])], PythonCode).` You can also generate a complete HTML page with chart integration using `generate_pyodide_html('Data Analysis', [packages([numpy]), chart(true)], HTML).` No server required. See skill_gui_runtime.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_gui_runtime_001_q1", "cluster_id": "skill_gui_runtime_001", "question": "Can I use Python in the browser without a server?", "answer": "Yes, you can run Python in the browser without a server using Pyodide. It executes full Python with scientific libraries (NumPy, SciPy, pandas) directly in the browser. Use `compile_pyodide_module(data_analysis, [packages([numpy, pandas, scipy]), exports([analyze, transform])], PythonCode)` to generate a Pyodide module, or `generate_pyodide_html('Data Analysis', [packages([numpy]), chart(true)], HTML)` to create a complete HTML page with optional chart integration. No server infrastructure is needed.", "question_type": "medium", "topics": ["Quickstart", "GUI Runtime"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["browser-execution", "python", "pyodide", "client-side"], "related_skills": ["skill_gui_runtime.md"], "related_docs": ["src/unifyweaver/targets/python_pyodide_target.pl"], "original_answer": "Use Pyodide to run full Python with scientific libraries (NumPy, SciPy, pandas) directly in the browser. Generate a Pyodide module with `compile_pyodide_module(data_analysis, [packages([numpy, pandas, scipy]), exports([analyze, transform])], PythonCode).` You can also generate a complete HTML page with chart integration using `generate_pyodide_html('Data Analysis', [packages([numpy]), chart(true)], HTML).` No server required. See skill_gui_runtime.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_gui_runtime_001_q2", "cluster_id": "skill_gui_runtime_001", "question": "How do I use NumPy and pandas on the client side?", "answer": "Use Pyodide to run NumPy, pandas, and SciPy directly in the browser without a server. Generate a Pyodide module with `compile_pyodide_module(data_analysis, [packages([numpy, pandas, scipy]), exports([analyze, transform])], PythonCode).` For a complete HTML page with charting, use `generate_pyodide_html('Data Analysis', [packages([numpy]), chart(true)], HTML).` See skill_browser_python.md for integration details and Web Worker support for background execution.", "question_type": "medium", "topics": ["Quickstart", "GUI Runtime"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["browser-execution", "python", "pyodide", "client-side"], "related_skills": ["skill_gui_runtime.md"], "related_docs": ["src/unifyweaver/targets/python_pyodide_target.pl"], "original_answer": "Use Pyodide to run full Python with scientific libraries (NumPy, SciPy, pandas) directly in the browser. Generate a Pyodide module with `compile_pyodide_module(data_analysis, [packages([numpy, pandas, scipy]), exports([analyze, transform])], PythonCode).` You can also generate a complete HTML page with chart integration using `generate_pyodide_html('Data Analysis', [packages([numpy]), chart(true)], HTML).` No server required. See skill_gui_runtime.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_gui_runtime_002_q0", "cluster_id": "skill_gui_runtime_002", "question": "How do I make my UI update in real-time with data changes?", "answer": "Use reactive data binding to connect your data sources to React components. Define a data source specifying the predicate, fields, and refresh interval (e.g., `refresh_interval(1000)` for 1-second updates), then generate a React hook with `generate_binding_hook(component_name, Hook)`. This approach supports one-way and two-way bindings, WebSocket real-time sync for immediate updates, and computed/derived sources. The generated hook automatically triggers UI re-renders when data changes.", "question_type": "medium", "topics": ["Quickstart", "GUI Runtime"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["reactive-binding", "react", "data-binding", "ui-state"], "related_skills": ["skill_gui_runtime.md"], "related_docs": ["src/unifyweaver/glue/data_binding_generator.pl"], "original_answer": "Use reactive data binding to connect data sources to React components. Define a data source with `data_source(metrics, [predicate(metric/3), fields([timestamp, name, value]), refresh_interval(1000)]).` Then create bindings and generate a React hook with `generate_binding_hook(metrics_chart, Hook).` Supports one-way/two-way bindings, WebSocket real-time sync, and computed sources. See skill_gui_runtime.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_gui_runtime_002_q1", "cluster_id": "skill_gui_runtime_002", "question": "How do I bind data to React components?", "answer": "Use reactive data binding to connect data sources to React components. Define a data source specifying the predicate, fields, and refresh interval (e.g., `data_source(metrics, [predicate(metric/3), fields([timestamp, name, value]), refresh_interval(1000)])`). Then generate a React hook with `generate_binding_hook(metrics_chart, Hook)` to bind that data to your component. This supports one-way and two-way bindings, WebSocket real-time sync, computed/derived sources, and polling with configurable intervals. See skill_data_binding.md for complete implementation details.", "question_type": "medium", "topics": ["Quickstart", "GUI Runtime"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["reactive-binding", "react", "data-binding", "ui-state"], "related_skills": ["skill_gui_runtime.md"], "related_docs": ["src/unifyweaver/glue/data_binding_generator.pl"], "original_answer": "Use reactive data binding to connect data sources to React components. Define a data source with `data_source(metrics, [predicate(metric/3), fields([timestamp, name, value]), refresh_interval(1000)]).` Then create bindings and generate a React hook with `generate_binding_hook(metrics_chart, Hook).` Supports one-way/two-way bindings, WebSocket real-time sync, and computed sources. See skill_gui_runtime.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_gui_runtime_002_q2", "cluster_id": "skill_gui_runtime_002", "question": "How do I create reactive UI state?", "answer": "Create reactive UI state using React hooks generated from data sources. Define your data source with `data_source(state_name, [predicate(...), fields(...), refresh_interval(...)])`, then generate a React hook with `generate_binding_hook(component_name, Hook)`. This supports one-way and two-way bindings, WebSocket real-time sync, and computed/derived sources. The generated hook automatically manages component re-renders when state changes.", "question_type": "medium", "topics": ["Quickstart", "GUI Runtime"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["reactive-binding", "react", "data-binding", "ui-state"], "related_skills": ["skill_gui_runtime.md"], "related_docs": ["src/unifyweaver/glue/data_binding_generator.pl"], "original_answer": "Use reactive data binding to connect data sources to React components. Define a data source with `data_source(metrics, [predicate(metric/3), fields([timestamp, name, value]), refresh_interval(1000)]).` Then create bindings and generate a React hook with `generate_binding_hook(metrics_chart, Hook).` Supports one-way/two-way bindings, WebSocket real-time sync, and computed sources. See skill_gui_runtime.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_gui_runtime_003_q0", "cluster_id": "skill_gui_runtime_003", "question": "How do I compile code to WebAssembly for performance?", "answer": "Compile performance-critical code to WebAssembly via LLVM. Use `compile_tail_recursion_llvm(factorial/2, [export(true)], LLVMCode)` for Prolog with guaranteed tail-call optimization (O(1) stack), then `compile_wasm_module([factorial], [], WASMCode)` to generate the WASM module, and `generate_ts_bindings([factorial], TSCode)` for TypeScript bindings. This approach supports FFI integration with Go, Rust, and C for interoperability. For detailed implementation steps, see skill_webassembly.md.", "question_type": "medium", "topics": ["Quickstart", "GUI Runtime"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["webassembly", "wasm", "performance", "llvm", "ffi"], "related_skills": ["skill_gui_runtime.md"], "related_docs": ["src/unifyweaver/targets/llvm_target.pl"], "original_answer": "Compile performance-critical code to WebAssembly via LLVM. Use `compile_tail_recursion_llvm(factorial/2, [export(true)], LLVMCode)` for Prolog with guaranteed tail-call optimization (O(1) stack), then `compile_wasm_module([factorial], [], WASMCode)` to generate WASM, and `generate_ts_bindings([factorial], TSCode)` for TypeScript bindings. Supports FFI with Go, Rust, and C. See skill_gui_runtime.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_gui_runtime_003_q1", "cluster_id": "skill_gui_runtime_003", "question": "How do I get native-speed execution in the browser?", "answer": "Compile performance-critical code to WebAssembly via LLVM. Use `compile_tail_recursion_llvm(factorial/2, [export(true)], LLVMCode)` for Prolog with guaranteed tail-call optimization (O(1) stack), then `compile_wasm_module([factorial], [], WASMCode)` to generate WASM, and `generate_ts_bindings([factorial], TSCode)` for TypeScript bindings. This provides native-speed execution in the browser with support for FFI with Go, Rust, and C.", "question_type": "medium", "topics": ["Quickstart", "GUI Runtime"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["webassembly", "wasm", "performance", "llvm", "ffi"], "related_skills": ["skill_gui_runtime.md"], "related_docs": ["src/unifyweaver/targets/llvm_target.pl"], "original_answer": "Compile performance-critical code to WebAssembly via LLVM. Use `compile_tail_recursion_llvm(factorial/2, [export(true)], LLVMCode)` for Prolog with guaranteed tail-call optimization (O(1) stack), then `compile_wasm_module([factorial], [], WASMCode)` to generate WASM, and `generate_ts_bindings([factorial], TSCode)` for TypeScript bindings. Supports FFI with Go, Rust, and C. See skill_gui_runtime.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "Base answer assumes Prolog/UnifyWeaver context but question uses generic phrasing ('how do I'). Answer is technically accurate but may benefit from a brief intro mentioning WebAssembly as the standard approach before diving into UnifyWeaver-specific API."}
{"pair_id": "skill_gui_runtime_003_q2", "cluster_id": "skill_gui_runtime_003", "question": "How do I use WebAssembly for compute-intensive algorithms?", "answer": "To use WebAssembly for compute-intensive algorithms, compile your performance-critical code to WebAssembly via LLVM. For Prolog code, use `compile_tail_recursion_llvm(algorithm/arity, [export(true)], LLVMCode)` to compile with guaranteed tail-call optimization that maintains O(1) stack space. Then generate the WASM module with `compile_wasm_module([algorithm], [], WASMCode)` and create TypeScript bindings using `generate_ts_bindings([algorithm], TSCode)` for integration with your browser application. This approach supports FFI integration with Go, Rust, and C for interoperability with other high-performance code.", "question_type": "medium", "topics": ["Quickstart", "GUI Runtime"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["webassembly", "wasm", "performance", "llvm", "ffi"], "related_skills": ["skill_gui_runtime.md"], "related_docs": ["src/unifyweaver/targets/llvm_target.pl"], "original_answer": "Compile performance-critical code to WebAssembly via LLVM. Use `compile_tail_recursion_llvm(factorial/2, [export(true)], LLVMCode)` for Prolog with guaranteed tail-call optimization (O(1) stack), then `compile_wasm_module([factorial], [], WASMCode)` to generate WASM, and `generate_ts_bindings([factorial], TSCode)` for TypeScript bindings. Supports FFI with Go, Rust, and C. See skill_gui_runtime.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "Base answer assumes Prolog as the source language, but the question is language-agnostic. The tailored answer clarifies this is for Prolog while keeping it general enough for the core concept. Confidence is slightly lower because the specific API examples may need verification against actual implementation."}
{"pair_id": "skill_gui_runtime_004_q0", "cluster_id": "skill_gui_runtime_004", "question": "Should I use WebAssembly or Pyodide for my project?", "answer": "Choose WebAssembly if you need native-speed performance for compute-intensive algorithms or have strict performance requirements. Choose Pyodide if you need scientific Python libraries (NumPy, pandas, SciPy) or want rapid prototyping with existing Python code. If your project requires both, you can use them together\u2014Pyodide for data analysis and WebAssembly for performance-critical computations. Consider data binding if you're building interactive UIs with frequent updates. Evaluate your primary constraint: raw computation speed points to WASM, scientific data analysis points to Pyodide, and reactive UI state points to data binding.", "question_type": "medium", "topics": ["Quickstart", "GUI Runtime"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["technology-selection", "architecture", "decision-guide"], "related_skills": ["skill_gui_runtime.md"], "related_docs": [], "original_answer": "Use WebAssembly when performance is critical or you have compute-intensive algorithms. Use Pyodide when you need scientific Python (NumPy, pandas, SciPy) or rapid prototyping. Use data binding when building interactive UIs with frequent data changes. Choose based on your needs: native-speed computation \u2192 WASM; scientific data analysis \u2192 Pyodide; reactive UI updates \u2192 data binding. See skill_gui_runtime.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_gui_runtime_004_q1", "cluster_id": "skill_gui_runtime_004", "question": "When should I use WebAssembly instead of Python?", "answer": "Use WebAssembly instead of Python when you need native-speed performance for compute-intensive algorithms. WebAssembly is ideal for performance-critical code that requires LLVM compilation and O(1) stack space via tail-call optimization. Use Pyodide (browser Python) when you need scientific libraries like NumPy, pandas, or SciPy, or when you prioritize rapid prototyping over raw performance. The choice depends on your bottleneck: if performance is the constraint, choose WASM; if you need scientific computing or faster development, choose Pyodide.", "question_type": "medium", "topics": ["Quickstart", "GUI Runtime"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["technology-selection", "architecture", "decision-guide"], "related_skills": ["skill_gui_runtime.md"], "related_docs": [], "original_answer": "Use WebAssembly when performance is critical or you have compute-intensive algorithms. Use Pyodide when you need scientific Python (NumPy, pandas, SciPy) or rapid prototyping. Use data binding when building interactive UIs with frequent data changes. Choose based on your needs: native-speed computation \u2192 WASM; scientific data analysis \u2192 Pyodide; reactive UI updates \u2192 data binding. See skill_gui_runtime.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_gui_runtime_004_q2", "cluster_id": "skill_gui_runtime_004", "question": "What's the difference between WASM and browser Python?", "answer": "WebAssembly (WASM) compiles to native-speed machine code for compute-intensive operations with O(1) stack space via tail-call optimization. Browser Python (Pyodide) runs full Python with scientific libraries like NumPy, pandas, and SciPy directly in the browser. Choose WASM for performance-critical algorithms where speed matters; choose Pyodide when you need scientific computing capabilities or rapid prototyping with Python ecosystem libraries.", "question_type": "medium", "topics": ["Quickstart", "GUI Runtime"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["technology-selection", "architecture", "decision-guide"], "related_skills": ["skill_gui_runtime.md"], "related_docs": [], "original_answer": "Use WebAssembly when performance is critical or you have compute-intensive algorithms. Use Pyodide when you need scientific Python (NumPy, pandas, SciPy) or rapid prototyping. Use data binding when building interactive UIs with frequent data changes. Choose based on your needs: native-speed computation \u2192 WASM; scientific data analysis \u2192 Pyodide; reactive UI updates \u2192 data binding. See skill_gui_runtime.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_gui_runtime_005_q0", "cluster_id": "skill_gui_runtime_005", "question": "How do I build a real-time dashboard with live data?", "answer": "To build a real-time dashboard with live data, define a data source with polling intervals: `data_source(dashboard_metrics, [predicate(metric/3), fields([timestamp, name, value]), refresh_interval(1000)])`. Create a data binding that maps your metrics to UI components: `binding(metrics_chart, dashboard_metrics, [x_axis(timestamp), y_axis(value), series(name)])`. Generate a React hook for the binding with `generate_binding_hook(metrics_chart, Hook)`. For true real-time synchronization instead of polling, use `generate_websocket_sync(dashboard_metrics, SyncCode)` to establish WebSocket connections for instant updates. This approach generates a complete live dashboard component with configurable refresh rates and WebSocket-based real-time data streaming.", "question_type": "long", "topics": ["Quickstart", "GUI Runtime"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["dashboard", "real-time", "websocket", "polling", "react"], "related_skills": ["skill_gui_runtime.md"], "related_docs": ["src/unifyweaver/glue/data_binding_generator.pl"], "original_answer": "Define a data source with polling: `data_source(metrics, [predicate(metric/3), fields([timestamp, name, value]), refresh_interval(1000)]).` Create a binding with `binding(metrics_chart, metrics, [x_axis(timestamp), y_axis(value), series(name)]).` Generate a React hook with `generate_binding_hook(metrics_chart, Hook).` For real-time sync, use `generate_websocket_sync(metrics, SyncCode).` This creates a complete live dashboard with WebSocket updates. See skill_gui_runtime.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer assumes Prolog-based code generation which may not be the user's actual tech stack. The answer assumes familiarity with Prolog syntax and UnifyWeaver's specific DSL. Real implementation details for integrating with actual data sources and frameworks are abstracted away."}
{"pair_id": "skill_gui_runtime_005_q1", "cluster_id": "skill_gui_runtime_005", "question": "How do I create a dashboard that updates automatically?", "answer": "To create a dashboard that updates automatically, define a data source with polling: `data_source(metrics, [predicate(metric/3), fields([timestamp, name, value]), refresh_interval(1000)]).` Then create a binding that maps your data to chart components: `binding(metrics_chart, metrics, [x_axis(timestamp), y_axis(value), series(name)]).` Generate a React hook with `generate_binding_hook(metrics_chart, Hook)` to enable automatic UI updates whenever the polled data changes. For real-time updates instead of polling, use `generate_websocket_sync(metrics, SyncCode)` to establish a WebSocket connection that pushes new data to the dashboard as it becomes available. This gives you a complete live dashboard with either periodic polling or push-based real-time synchronization.", "question_type": "long", "topics": ["Quickstart", "GUI Runtime"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["dashboard", "real-time", "websocket", "polling", "react"], "related_skills": ["skill_gui_runtime.md"], "related_docs": ["src/unifyweaver/glue/data_binding_generator.pl"], "original_answer": "Define a data source with polling: `data_source(metrics, [predicate(metric/3), fields([timestamp, name, value]), refresh_interval(1000)]).` Create a binding with `binding(metrics_chart, metrics, [x_axis(timestamp), y_axis(value), series(name)]).` Generate a React hook with `generate_binding_hook(metrics_chart, Hook).` For real-time sync, use `generate_websocket_sync(metrics, SyncCode).` This creates a complete live dashboard with WebSocket updates. See skill_gui_runtime.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_gui_runtime_005_q2", "cluster_id": "skill_gui_runtime_005", "question": "How do I poll data and update charts in real-time?", "answer": "To poll data and update charts in real-time, define a data source with polling interval: `data_source(metrics, [predicate(metric/3), fields([timestamp, name, value]), refresh_interval(1000)])`. Create a binding that maps data to chart axes: `binding(metrics_chart, metrics, [x_axis(timestamp), y_axis(value), series(name)])`. Generate a React hook with `generate_binding_hook(metrics_chart, Hook)` to automatically update the chart on data changes. The polling interval (1000ms in this example) controls how frequently data is fetched and the chart refreshes. For WebSocket-based real-time sync instead of polling, use `generate_websocket_sync(metrics, SyncCode)` which establishes a persistent connection for immediate updates.", "question_type": "long", "topics": ["Quickstart", "GUI Runtime"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["dashboard", "real-time", "websocket", "polling", "react"], "related_skills": ["skill_gui_runtime.md"], "related_docs": ["src/unifyweaver/glue/data_binding_generator.pl"], "original_answer": "Define a data source with polling: `data_source(metrics, [predicate(metric/3), fields([timestamp, name, value]), refresh_interval(1000)]).` Create a binding with `binding(metrics_chart, metrics, [x_axis(timestamp), y_axis(value), series(name)]).` Generate a React hook with `generate_binding_hook(metrics_chart, Hook).` For real-time sync, use `generate_websocket_sync(metrics, SyncCode).` This creates a complete live dashboard with WebSocket updates. See skill_gui_runtime.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_gui_runtime_006_q0", "cluster_id": "skill_gui_runtime_006", "question": "Can I combine WebAssembly with React components?", "answer": "Yes, you can combine WebAssembly with React components. Compile performance-critical code to WASM using `compile_wasm_module([matrix_multiply], [], WASMCode)`, then generate TypeScript bindings with `generate_ts_bindings([matrix_multiply], TSCode)`. Import these bindings into your React component and call them directly in event handlers or effects. For reactive display of WASM results, create a data source with `data_source(computation_result, [fields([input, output, time])])` and bind it to your component using `binding(result_display, computation_result, [x_axis(input), y_axis(output)])`. This architecture handles both computation (WASM) and UI state management (React bindings) seamlessly.", "question_type": "long", "topics": ["Quickstart", "GUI Runtime"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["webassembly", "react", "integration", "performance"], "related_skills": ["skill_gui_runtime.md"], "related_docs": ["src/unifyweaver/targets/llvm_target.pl", "src/unifyweaver/glue/data_binding_generator.pl"], "original_answer": "Yes, compile WASM for heavy computation with `compile_wasm_module([matrix_multiply], [], WASMCode)`, then create a data source for results: `data_source(computation_result, [fields([input, output, time])]).` Create a binding with `binding(result_display, computation_result, [x_axis(input), y_axis(output)]).` This pipes WASM output through reactive bindings into React components for display. See skill_gui_runtime.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer mentions data binding but the question specifically asks about combining WASM with React components. The tailored answer clarifies the integration path more directly (TypeScript bindings, React event handlers), but assumes the data source binding is necessary\u2014it's optional for simpler use cases where you just call WASM functions directly."}
{"pair_id": "skill_gui_runtime_006_q1", "cluster_id": "skill_gui_runtime_006", "question": "How do I use WASM results in my React UI?", "answer": "To use WASM results in your React UI, first compile your performance-critical functions to WebAssembly using `compile_wasm_module([your_function], [], WASMCode)`. Then define a data source to hold the computation results: `data_source(computation_result, [fields([input, output, computation_time])])`. Finally, create a reactive binding that connects the WASM output to your React component: `binding(result_display, computation_result, [x_axis(input), y_axis(output)])`. This pipes WASM computation results through reactive data binding, allowing your React components to automatically display and update with the results. See skill_data_binding.md for React hook patterns and skill_webassembly.md for WASM compilation details.", "question_type": "long", "topics": ["Quickstart", "GUI Runtime"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["webassembly", "react", "integration", "performance"], "related_skills": ["skill_gui_runtime.md"], "related_docs": ["src/unifyweaver/targets/llvm_target.pl", "src/unifyweaver/glue/data_binding_generator.pl"], "original_answer": "Yes, compile WASM for heavy computation with `compile_wasm_module([matrix_multiply], [], WASMCode)`, then create a data source for results: `data_source(computation_result, [fields([input, output, time])]).` Create a binding with `binding(result_display, computation_result, [x_axis(input), y_axis(output)]).` This pipes WASM output through reactive bindings into React components for display. See skill_gui_runtime.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer assumes familiarity with the data binding and WASM compilation workflow. The tailored answer clarifies the three-step process (compile \u2192 define data source \u2192 bind to React), but lacks detail on how WASM invocation triggers and how results flow into the data source in practice."}
{"pair_id": "skill_gui_runtime_006_q2", "cluster_id": "skill_gui_runtime_006", "question": "How do I bind WASM output to a React component?", "answer": "Compile your WASM module using `compile_wasm_module([function_name], [], WASMCode)`, then wrap the WASM function calls in a custom React hook. Create a data source for the WASM results: `data_source(wasm_results, [fields([input, output])]).` Then bind this to your React component using `binding(component_name, wasm_results, [x_axis(input), y_axis(output)]).` This creates reactive bindings that automatically update your component when WASM computations complete. For real-time updates, configure the data source with WebSocket sync or polling. See skill_data_binding.md and skill_webassembly.md for implementation details.", "question_type": "long", "topics": ["Quickstart", "GUI Runtime"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["webassembly", "react", "integration", "performance"], "related_skills": ["skill_gui_runtime.md"], "related_docs": ["src/unifyweaver/targets/llvm_target.pl", "src/unifyweaver/glue/data_binding_generator.pl"], "original_answer": "Yes, compile WASM for heavy computation with `compile_wasm_module([matrix_multiply], [], WASMCode)`, then create a data source for results: `data_source(computation_result, [fields([input, output, time])]).` Create a binding with `binding(result_display, computation_result, [x_axis(input), y_axis(output)]).` This pipes WASM output through reactive bindings into React components for display. See skill_gui_runtime.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "Base answer conflates WASM compilation with data binding concepts but doesn't clearly explain the integration pattern. The answer assumes familiarity with the data binding framework syntax and doesn't explicitly show how to invoke WASM functions from the React hook or handle async WASM calls."}
{"pair_id": "skill_gui_tools_001_q0", "cluster_id": "skill_gui_tools_001", "question": "How do I build a frontend app with Vue, React Native, Flutter, or SwiftUI?", "answer": "To build a frontend app with Vue, React Native, Flutter, or SwiftUI, use the app generation system with the `generate_complete_project/4` predicate. This takes a declarative app specification defining your navigation structure and theme, specifies your target platform ([frontend-vue], [frontend-react-native], [frontend-flutter], or [frontend-swiftui]), and outputs the complete generated project. For example, to generate a Vue app: `generate_complete_project(app(myapp, [navigation(tabs, [screen(home, 'HomeView', []), screen(settings, 'SettingsView', [])]), theme(default, [dark_mode(true)])]), [frontend-vue], '/tmp/myapp', Result)`. The system generates fully functional applications with navigation, theming, and responsive design built in.", "question_type": "medium", "topics": ["Quickstart", "GUI Tools"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["app-generation", "frontend", "multi-platform"], "related_skills": ["skill_gui_tools.md", "skill_gui_generation.md", "skill_app_generation.md", "skill_typescript_target.md"], "related_docs": ["src/unifyweaver/glue/app_generator.pl", "src/unifyweaver/targets/vue_target.pl", "education/other-books/book-gui-generation/"], "original_answer": "Use the app generation system to create complete frontend applications from declarative specifications. Supported targets include Vue 3 + Vite + TypeScript, React Native + Expo, Flutter + Dart, and SwiftUI for iOS/macOS. Generate a Vue app with: `generate_complete_project(app(myapp, [...]), [frontend-vue], '/tmp/myapp', Result)`. See skill_gui_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_gui_tools_001_q1", "cluster_id": "skill_gui_tools_001", "question": "What's the best way to generate a complete frontend application?", "answer": "Use the app generation system to create complete frontend applications from declarative Prolog specifications. The system supports Vue 3 + Vite + TypeScript, React Native + Expo, Flutter + Dart, and SwiftUI for iOS/macOS. Call `generate_complete_project(app(myapp, [navigation(tabs, [...]), theme(...)]), [frontend-vue], '/tmp/myapp', Result)` with your app configuration, target platform, output directory, and result variable. The app generation system is a sub-master skill that handles all scaffolding, configuration, and compilation needed to produce a ready-to-run frontend application.", "question_type": "medium", "topics": ["Quickstart", "GUI Tools"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["app-generation", "frontend", "multi-platform"], "related_skills": ["skill_gui_tools.md", "skill_gui_generation.md", "skill_app_generation.md", "skill_typescript_target.md"], "related_docs": ["src/unifyweaver/glue/app_generator.pl", "src/unifyweaver/targets/vue_target.pl", "education/other-books/book-gui-generation/"], "original_answer": "Use the app generation system to create complete frontend applications from declarative specifications. Supported targets include Vue 3 + Vite + TypeScript, React Native + Expo, Flutter + Dart, and SwiftUI for iOS/macOS. Generate a Vue app with: `generate_complete_project(app(myapp, [...]), [frontend-vue], '/tmp/myapp', Result)`. See skill_gui_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_gui_tools_001_q2", "cluster_id": "skill_gui_tools_001", "question": "Can I generate mobile and web apps from code specifications?", "answer": "Yes, you can generate mobile and web apps from code specifications using the app generation system. You can create complete frontend applications from declarative Prolog specifications targeting Vue 3 + Vite + TypeScript for web, React Native + Expo for cross-platform mobile, Flutter + Dart for mobile, and SwiftUI for iOS/macOS. Use the `generate_complete_project/4` predicate with your app specification and target framework to generate the full project structure.", "question_type": "medium", "topics": ["Quickstart", "GUI Tools"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["app-generation", "frontend", "multi-platform"], "related_skills": ["skill_gui_tools.md", "skill_gui_generation.md", "skill_app_generation.md", "skill_typescript_target.md"], "related_docs": ["src/unifyweaver/glue/app_generator.pl", "src/unifyweaver/targets/vue_target.pl", "education/other-books/book-gui-generation/"], "original_answer": "Use the app generation system to create complete frontend applications from declarative specifications. Supported targets include Vue 3 + Vite + TypeScript, React Native + Expo, Flutter + Dart, and SwiftUI for iOS/macOS. Generate a Vue app with: `generate_complete_project(app(myapp, [...]), [frontend-vue], '/tmp/myapp', Result)`. See skill_gui_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_gui_tools_001_q3", "cluster_id": "skill_gui_tools_001", "question": "How do I create apps for multiple platforms?", "answer": "Use the app generation system with declarative specifications to create frontend applications for multiple platforms. Supported targets include Vue 3 + Vite + TypeScript, React Native + Expo, Flutter + Dart, and SwiftUI for iOS/macOS. For each target platform, call generate_complete_project with the same app specification but different target parameters: [frontend-vue], [frontend-react-native], [frontend-flutter], or [frontend-swiftui]. This allows you to maintain a single codebase specification and generate platform-specific implementations. Example: `generate_complete_project(app(myapp, [...]), [frontend-react-native], '/tmp/myapp-android', Result)` for React Native on Android.", "question_type": "medium", "topics": ["Quickstart", "GUI Tools"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["app-generation", "frontend", "multi-platform"], "related_skills": ["skill_gui_tools.md", "skill_gui_generation.md", "skill_app_generation.md", "skill_typescript_target.md"], "related_docs": ["src/unifyweaver/glue/app_generator.pl", "src/unifyweaver/targets/vue_target.pl", "education/other-books/book-gui-generation/"], "original_answer": "Use the app generation system to create complete frontend applications from declarative specifications. Supported targets include Vue 3 + Vite + TypeScript, React Native + Expo, Flutter + Dart, and SwiftUI for iOS/macOS. Generate a Vue app with: `generate_complete_project(app(myapp, [...]), [frontend-vue], '/tmp/myapp', Result)`. See skill_gui_tools.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "Base answer mentions supported targets but doesn't explicitly explain the multi-platform workflow (same spec, different target parameters). The answer assumes users understand they can call generate_complete_project multiple times with different targets, which may not be immediately clear from the base text."}
{"pair_id": "skill_gui_tools_002_q0", "cluster_id": "skill_gui_tools_002", "question": "How do I design responsive user interfaces with layouts that adapt to different screen sizes?", "answer": "To design responsive user interfaces that adapt to different screen sizes, use the responsive layout system with breakpoints. Define breakpoints in your app configuration for different screen sizes: `layout(responsive, [breakpoint(mobile, 0, 768), breakpoint(tablet, 769, 1024), breakpoint(desktop, 1025, infinity)])`. This enables Grid and Flexbox layouts with component libraries that automatically adjust to each breakpoint. You can also use CSS media queries and responsive utility classes to customize behavior at specific viewport widths. The system automatically reflows layouts and adjusts component sizing based on the active breakpoint.", "question_type": "medium", "topics": ["Quickstart", "GUI Tools"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["responsive-design", "ui-layout", "breakpoints"], "related_skills": ["skill_gui_tools.md", "skill_gui_design.md", "skill_responsive_design.md", "skill_layout_system.md"], "related_docs": ["src/unifyweaver/targets/vue_target.pl", "education/other-books/book-gui-generation/"], "original_answer": "Use the responsive layout system with breakpoints for different screen sizes. Define breakpoints in your app configuration: `layout(responsive, [breakpoint(mobile, 0, 768), breakpoint(tablet, 769, 1024), breakpoint(desktop, 1025, infinity)])`. This enables Grid and Flexbox layouts with component libraries that automatically adapt. See skill_gui_tools.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "Base answer lacks specifics on CSS media queries and responsive utilities; confidence reflects good coverage of core breakpoint system but some implementation details are inferred rather than explicitly stated in the source material"}
{"pair_id": "skill_gui_tools_002_q1", "cluster_id": "skill_gui_tools_002", "question": "How do I make my UI work on mobile, tablet, and desktop?", "answer": "To make your UI work across mobile, tablet, and desktop, use the responsive layout system with breakpoints. Define breakpoints in your app configuration: `layout(responsive, [breakpoint(mobile, 0, 768), breakpoint(tablet, 769, 1024), breakpoint(desktop, 1025, infinity)])`. This enables Grid and Flexbox layouts that automatically adapt to different screen sizes. Component libraries integrated with this system will adjust their rendering based on the active breakpoint, ensuring your interface works seamlessly across all device sizes.", "question_type": "medium", "topics": ["Quickstart", "GUI Tools"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["responsive-design", "ui-layout", "breakpoints"], "related_skills": ["skill_gui_tools.md", "skill_gui_design.md", "skill_responsive_design.md", "skill_layout_system.md"], "related_docs": ["src/unifyweaver/targets/vue_target.pl", "education/other-books/book-gui-generation/"], "original_answer": "Use the responsive layout system with breakpoints for different screen sizes. Define breakpoints in your app configuration: `layout(responsive, [breakpoint(mobile, 0, 768), breakpoint(tablet, 769, 1024), breakpoint(desktop, 1025, infinity)])`. This enables Grid and Flexbox layouts with component libraries that automatically adapt. See skill_gui_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_gui_tools_002_q2", "cluster_id": "skill_gui_tools_002", "question": "What's the best approach for responsive design?", "answer": "For responsive design, use the responsive layout system with breakpoints configured in your app: `layout(responsive, [breakpoint(mobile, 0, 768), breakpoint(tablet, 769, 1024), breakpoint(desktop, 1025, infinity)])`. This enables Grid and Flexbox layouts that automatically adapt across screen sizes. Component libraries built into the GUI tools system handle responsive behavior automatically, adjusting layout and sizing based on the active breakpoint. Define your breakpoints once, and your UI components will adapt without additional media query code.", "question_type": "medium", "topics": ["Quickstart", "GUI Tools"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["responsive-design", "ui-layout", "breakpoints"], "related_skills": ["skill_gui_tools.md", "skill_gui_design.md", "skill_responsive_design.md", "skill_layout_system.md"], "related_docs": ["src/unifyweaver/targets/vue_target.pl", "education/other-books/book-gui-generation/"], "original_answer": "Use the responsive layout system with breakpoints for different screen sizes. Define breakpoints in your app configuration: `layout(responsive, [breakpoint(mobile, 0, 768), breakpoint(tablet, 769, 1024), breakpoint(desktop, 1025, infinity)])`. This enables Grid and Flexbox layouts with component libraries that automatically adapt. See skill_gui_tools.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer references 'skill_gui_design.md' for details, but doesn't explain what that skill contains. The tailored answer removes the external reference and focuses on the practical implementation approach. However, confidence is slightly lower because the answer doesn't explain how to actually apply different styles per breakpoint or provide a complete usage example."}
{"pair_id": "skill_gui_tools_002_q3", "cluster_id": "skill_gui_tools_002", "question": "How do I set up breakpoints for different devices?", "answer": "Set up breakpoints by defining them in your app configuration using the responsive layout system. Add breakpoints like: `layout(responsive, [breakpoint(mobile, 0, 768), breakpoint(tablet, 769, 1024), breakpoint(desktop, 1025, infinity)])`. This enables Grid and Flexbox layouts that automatically adapt components to different screen sizes. Component libraries will respond to these breakpoints, adjusting layouts and sizing based on the current viewport.", "question_type": "medium", "topics": ["Quickstart", "GUI Tools"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["responsive-design", "ui-layout", "breakpoints"], "related_skills": ["skill_gui_tools.md", "skill_gui_design.md", "skill_responsive_design.md", "skill_layout_system.md"], "related_docs": ["src/unifyweaver/targets/vue_target.pl", "education/other-books/book-gui-generation/"], "original_answer": "Use the responsive layout system with breakpoints for different screen sizes. Define breakpoints in your app configuration: `layout(responsive, [breakpoint(mobile, 0, 768), breakpoint(tablet, 769, 1024), breakpoint(desktop, 1025, infinity)])`. This enables Grid and Flexbox layouts with component libraries that automatically adapt. See skill_gui_tools.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "Base answer provides accurate technical setup, but assumes familiarity with Prolog syntax and doesn't explain how to actually apply breakpoints in component styling or mention which frameworks use this approach."}
{"pair_id": "skill_gui_tools_003_q0", "cluster_id": "skill_gui_tools_003", "question": "How do I run high-performance code in the browser using WebAssembly or Python?", "answer": "To run high-performance code in the browser, use WebAssembly or Python. For WebAssembly: include `wasm_modules([wasm(module_name, 'file.wasm', [])])` in your app configuration to execute compiled Rust or C code directly in the browser. For Python: use Pyodide to run Python code client-side. Both approaches eliminate server roundtrips for computation-heavy tasks. WebAssembly is ideal for performance-critical operations, while Pyodide is better for Python-based logic. Configure these in your frontend app definition to enable client-side runtime execution.", "question_type": "medium", "topics": ["Quickstart", "GUI Tools"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["webassembly", "python-browser", "performance"], "related_skills": ["skill_gui_tools.md", "skill_gui_runtime.md", "skill_webassembly.md", "skill_browser_python.md"], "related_docs": ["src/unifyweaver/glue/app_generator.pl", "education/other-books/book-gui-generation/"], "original_answer": "Include WebAssembly modules or Python in your app configuration for client-side runtime execution. For WASM: `wasm_modules([wasm(image_processor, 'image_processor.wasm', [])])`. WebAssembly supports Rust and C compilation to WASM, while Pyodide enables Python execution in the browser. This improves performance for computation-heavy tasks without server roundtrips. See skill_gui_tools.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer is slightly vague about implementation steps. The tailored version clarifies the choice between WASM and Python based on use case, but specific code examples or links to configuration documentation would strengthen the answer further."}
{"pair_id": "skill_gui_tools_003_q1", "cluster_id": "skill_gui_tools_003", "question": "Can I run compiled code directly in the browser?", "answer": "Yes, you can run compiled code directly in the browser using WebAssembly (WASM) or Python. For WebAssembly, include WASM modules in your app configuration: `wasm_modules([wasm(image_processor, 'image_processor.wasm', [])])`. WebAssembly supports compilation from Rust and C to WASM format. For Python, use Pyodide to run Python directly in the browser. Both approaches eliminate server roundtrips for computation-heavy tasks, improving performance. Configure these in your app's client-side runtime settings.", "question_type": "medium", "topics": ["Quickstart", "GUI Tools"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["webassembly", "python-browser", "performance"], "related_skills": ["skill_gui_tools.md", "skill_gui_runtime.md", "skill_webassembly.md", "skill_browser_python.md"], "related_docs": ["src/unifyweaver/glue/app_generator.pl", "education/other-books/book-gui-generation/"], "original_answer": "Include WebAssembly modules or Python in your app configuration for client-side runtime execution. For WASM: `wasm_modules([wasm(image_processor, 'image_processor.wasm', [])])`. WebAssembly supports Rust and C compilation to WASM, while Pyodide enables Python execution in the browser. This improves performance for computation-heavy tasks without server roundtrips. See skill_gui_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_gui_tools_003_q2", "cluster_id": "skill_gui_tools_003", "question": "How do I use WebAssembly modules in my app?", "answer": "To use WebAssembly modules in your app, include them in your app configuration under the client-side runtime section. For Rust or C code compiled to WASM, add `wasm_modules([wasm(module_name, 'path/to/module.wasm', [])])` to your app config. WebAssembly executes directly in the browser, providing high performance for computation-heavy tasks like image processing without requiring server requests. Alternatively, use Pyodide to run Python code client-side. This approach is useful for performance-critical operations that would be slow if executed server-side.", "question_type": "medium", "topics": ["Quickstart", "GUI Tools"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["webassembly", "python-browser", "performance"], "related_skills": ["skill_gui_tools.md", "skill_gui_runtime.md", "skill_webassembly.md", "skill_browser_python.md"], "related_docs": ["src/unifyweaver/glue/app_generator.pl", "education/other-books/book-gui-generation/"], "original_answer": "Include WebAssembly modules or Python in your app configuration for client-side runtime execution. For WASM: `wasm_modules([wasm(image_processor, 'image_processor.wasm', [])])`. WebAssembly supports Rust and C compilation to WASM, while Pyodide enables Python execution in the browser. This improves performance for computation-heavy tasks without server roundtrips. See skill_gui_tools.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer lacks concrete implementation examples (e.g., how to actually invoke WASM functions from Vue/React, bundling configuration). The answer assumes Prolog-style configuration syntax which may not match how users actually integrate WASM in their frontends."}
{"pair_id": "skill_gui_tools_003_q3", "cluster_id": "skill_gui_tools_003", "question": "How do I run Python code in the browser?", "answer": "To run Python code in the browser, use Pyodide, which enables Python execution directly in the client. Include it in your app configuration under client-side runtime settings. Pyodide allows you to run Python scripts, libraries, and computation-heavy tasks without server roundtrips, improving performance. You can also combine it with WebAssembly for mixed-language applications. See skill_gui_runtime.md and skill_browser_python.md for implementation details and examples.", "question_type": "medium", "topics": ["Quickstart", "GUI Tools"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["webassembly", "python-browser", "performance"], "related_skills": ["skill_gui_tools.md", "skill_gui_runtime.md", "skill_webassembly.md", "skill_browser_python.md"], "related_docs": ["src/unifyweaver/glue/app_generator.pl", "education/other-books/book-gui-generation/"], "original_answer": "Include WebAssembly modules or Python in your app configuration for client-side runtime execution. For WASM: `wasm_modules([wasm(image_processor, 'image_processor.wasm', [])])`. WebAssembly supports Rust and C compilation to WASM, while Pyodide enables Python execution in the browser. This improves performance for computation-heavy tasks without server roundtrips. See skill_gui_tools.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_gui_tools_004_q0", "cluster_id": "skill_gui_tools_004", "question": "How do I add navigation and screens to my app?", "answer": "To add navigation and screens to your app, define them in your app configuration using the `navigation()` structure with a layout pattern (like `tabs`) and a list of screens. Each screen specifies a name, component view path, and options: `navigation(tabs, [screen(home, 'HomeView', []), screen(settings, 'SettingsView', [])])`. This navigation structure works across all supported targets: Vue 3, React Native, Flutter, and SwiftUI. Each screen automatically maps to its corresponding component view in your generated project.", "question_type": "medium", "topics": ["Quickstart", "GUI Tools"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["navigation", "screens", "app-structure"], "related_skills": ["skill_gui_tools.md", "skill_gui_generation.md", "skill_app_generation.md"], "related_docs": ["src/unifyweaver/glue/app_generator.pl", "src/unifyweaver/targets/vue_target.pl", "education/other-books/book-gui-generation/"], "original_answer": "Define navigation in your app configuration using screens and navigation patterns. Example with tabs: `navigation(tabs, [screen(home, 'HomeView', []), screen(settings, 'SettingsView', [])])`. Each screen maps to a component view. This works across Vue, React Native, Flutter, and SwiftUI targets. See skill_gui_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_gui_tools_004_q1", "cluster_id": "skill_gui_tools_004", "question": "How do I create multiple screens or pages in my app?", "answer": "To create multiple screens or pages in your app, define a navigation structure in your app configuration using the `navigation()` construct with screen definitions. For example, use `navigation(tabs, [screen(home, 'HomeView', []), screen(settings, 'SettingsView', [])])` to create tab-based navigation with two screens. Each screen parameter specifies a route identifier, a component name, and component options. This navigation pattern works consistently across all supported targets: Vue 3, React Native, Flutter, and SwiftUI. Refer to skill_gui_generation.md for target-specific implementation details and additional navigation patterns beyond tabs.", "question_type": "medium", "topics": ["Quickstart", "GUI Tools"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["navigation", "screens", "app-structure"], "related_skills": ["skill_gui_tools.md", "skill_gui_generation.md", "skill_app_generation.md"], "related_docs": ["src/unifyweaver/glue/app_generator.pl", "src/unifyweaver/targets/vue_target.pl", "education/other-books/book-gui-generation/"], "original_answer": "Define navigation in your app configuration using screens and navigation patterns. Example with tabs: `navigation(tabs, [screen(home, 'HomeView', []), screen(settings, 'SettingsView', [])])`. Each screen maps to a component view. This works across Vue, React Native, Flutter, and SwiftUI targets. See skill_gui_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_gui_tools_004_q2", "cluster_id": "skill_gui_tools_004", "question": "How do I set up navigation between different views?", "answer": "To set up navigation between different views, define a navigation pattern in your app configuration using screens. For tab-based navigation, use: `navigation(tabs, [screen(home, 'HomeView', []), screen(settings, 'SettingsView', [])])`. Each screen element maps a route identifier to a component view. This navigation pattern translates consistently across all supported targets: Vue 3, React Native, Flutter, and SwiftUI. The navigation structure automatically generates the platform-specific navigation implementation for your chosen target.", "question_type": "medium", "topics": ["Quickstart", "GUI Tools"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["navigation", "screens", "app-structure"], "related_skills": ["skill_gui_tools.md", "skill_gui_generation.md", "skill_app_generation.md"], "related_docs": ["src/unifyweaver/glue/app_generator.pl", "src/unifyweaver/targets/vue_target.pl", "education/other-books/book-gui-generation/"], "original_answer": "Define navigation in your app configuration using screens and navigation patterns. Example with tabs: `navigation(tabs, [screen(home, 'HomeView', []), screen(settings, 'SettingsView', [])])`. Each screen maps to a component view. This works across Vue, React Native, Flutter, and SwiftUI targets. See skill_gui_tools.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer references 'skill_gui_tools.md for details' but doesn't explain how to actually implement navigation in practice (e.g., routing syntax, passing parameters between views, or handling navigation state). The answer assumes users understand the Prolog DSL syntax and doesn't clarify whether other navigation patterns beyond tabs are supported."}
{"pair_id": "skill_gui_tools_004_q3", "cluster_id": "skill_gui_tools_004", "question": "How do I organize screens with tabs or menus?", "answer": "Define navigation using the `navigation()` function in your app configuration. For tabs, use `navigation(tabs, [screen(home, 'HomeView', []), screen(settings, 'SettingsView', [])])`. Each screen parameter specifies a route identifier, component name, and optional props. This pattern works across Vue, React Native, Flutter, and SwiftUI. For menu-based navigation, replace `tabs` with `menu` or other navigation patterns supported by your target framework.", "question_type": "medium", "topics": ["Quickstart", "GUI Tools"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["navigation", "screens", "app-structure"], "related_skills": ["skill_gui_tools.md", "skill_gui_generation.md", "skill_app_generation.md"], "related_docs": ["src/unifyweaver/glue/app_generator.pl", "src/unifyweaver/targets/vue_target.pl", "education/other-books/book-gui-generation/"], "original_answer": "Define navigation in your app configuration using screens and navigation patterns. Example with tabs: `navigation(tabs, [screen(home, 'HomeView', []), screen(settings, 'SettingsView', [])])`. Each screen maps to a component view. This works across Vue, React Native, Flutter, and SwiftUI targets. See skill_gui_tools.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer references skill_gui_tools.md but the actual implementation details and available navigation patterns (menu, drawer, stack) are not fully specified in the provided context. Confidence is moderate because the core concept is clear but specific menu navigation syntax examples are missing."}
{"pair_id": "skill_gui_tools_005_q0", "cluster_id": "skill_gui_tools_005", "question": "How do I make my app accessible and secure for users?", "answer": "To make your app accessible and secure, implement ARIA attributes for screen readers and enable keyboard navigation for all interactive elements. Configure frontend security by setting up navigation guards for protected routes and establishing proper CORS policies. The GUI Tools system provides built-in accessibility features that work across Vue, React Native, Flutter, and SwiftUI targets. For validation, use client-side checks at input boundaries. Refer to skill_accessibility.md for detailed ARIA and keyboard patterns, and skill_frontend_security.md for navigation guards and CORS configuration.", "question_type": "medium", "topics": ["Quickstart", "GUI Tools"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["accessibility", "security", "user-experience"], "related_skills": ["skill_gui_tools.md", "skill_accessibility.md", "skill_frontend_security.md"], "related_docs": ["education/other-books/book-gui-generation/"], "original_answer": "Implement accessibility with ARIA attributes and keyboard navigation support. Configure frontend security with navigation guards and CORS settings. The GUI Tools system provides built-in accessibility features for screen readers and keyboard users, plus security patterns for client-side validation and protected routes. See skill_gui_tools.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_gui_tools_005_q1", "cluster_id": "skill_gui_tools_005", "question": "What should I do to ensure my app is accessible?", "answer": "To ensure your app is accessible, implement ARIA attributes for screen readers, add keyboard navigation support, and enable navigation with arrow keys and tab order. Use the GUI Tools accessibility features in skill_accessibility.md which provide built-in patterns for screen reader compatibility and keyboard-only navigation. Additionally, configure frontend security with navigation guards and client-side validation to protect user interactions.", "question_type": "medium", "topics": ["Quickstart", "GUI Tools"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["accessibility", "security", "user-experience"], "related_skills": ["skill_gui_tools.md", "skill_accessibility.md", "skill_frontend_security.md"], "related_docs": ["education/other-books/book-gui-generation/"], "original_answer": "Implement accessibility with ARIA attributes and keyboard navigation support. Configure frontend security with navigation guards and CORS settings. The GUI Tools system provides built-in accessibility features for screen readers and keyboard users, plus security patterns for client-side validation and protected routes. See skill_gui_tools.md for details.", "answer_tailored": true, "confidence": 0.75, "confidence_issues": "Base answer conflates accessibility with frontend security. The question specifically asks about accessibility; security guidance (navigation guards, CORS) is secondary context. Answer refocused on accessibility as primary concern."}
{"pair_id": "skill_gui_tools_005_q2", "cluster_id": "skill_gui_tools_005", "question": "How do I add keyboard navigation to my app?", "answer": "To add keyboard navigation to your app, use the accessibility features in skill_gui_tools.md. Implement ARIA attributes to label interactive elements, handle keyboard events (Enter, Space, Arrow keys) in your components, and ensure all controls are reachable via Tab key. The GUI Tools system provides built-in keyboard navigation support through the skill_accessibility.md sub-skill, which covers keyboard event handling, focus management, and screen reader compatibility. Configure navigation guards and client-side validation through skill_frontend_security.md for protected routes.", "question_type": "medium", "topics": ["Quickstart", "GUI Tools"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["accessibility", "security", "user-experience"], "related_skills": ["skill_gui_tools.md", "skill_accessibility.md", "skill_frontend_security.md"], "related_docs": ["education/other-books/book-gui-generation/"], "original_answer": "Implement accessibility with ARIA attributes and keyboard navigation support. Configure frontend security with navigation guards and CORS settings. The GUI Tools system provides built-in accessibility features for screen readers and keyboard users, plus security patterns for client-side validation and protected routes. See skill_gui_tools.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "Base answer is generic and doesn't provide specific implementation details (e.g., which framework APIs to use, code examples, or concrete keyboard event handling patterns). The answer references documentation without explaining the actual implementation approach for keyboard navigation."}
{"pair_id": "skill_gui_tools_005_q3", "cluster_id": "skill_gui_tools_005", "question": "What are the security best practices for frontend apps?", "answer": "Frontend security best practices include implementing navigation guards to protect routes, configuring CORS settings for safe cross-origin requests, and performing client-side validation. The GUI Tools system provides built-in security patterns through skill_frontend_security.md, which covers route protection, CORS configuration, and secure client-side validation practices. Additionally, ensure proper input sanitization, use HTTPS, implement Content Security Policy headers, and avoid storing sensitive data in browser storage.", "question_type": "medium", "topics": ["Quickstart", "GUI Tools"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["accessibility", "security", "user-experience"], "related_skills": ["skill_gui_tools.md", "skill_accessibility.md", "skill_frontend_security.md"], "related_docs": ["education/other-books/book-gui-generation/"], "original_answer": "Implement accessibility with ARIA attributes and keyboard navigation support. Configure frontend security with navigation guards and CORS settings. The GUI Tools system provides built-in accessibility features for screen readers and keyboard users, plus security patterns for client-side validation and protected routes. See skill_gui_tools.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "Base answer conflates accessibility with security; the original response mixes ARIA attributes and keyboard navigation (accessibility concerns) with actual security practices. The rewritten answer refocuses on genuine security best practices but the base answer's coverage of frontend security specifics is limited, making confidence moderate rather than high."}
{"pair_id": "skill_gui_tools_006_q0", "cluster_id": "skill_gui_tools_006", "question": "How do I apply theming and dark mode to my app?", "answer": "To apply theming and dark mode to your app, define it in your app configuration using `theme(default, [dark_mode(true)])`. This theming system supports color schemes and dark mode toggling that automatically applies across all UI components in Vue, React Native, Flutter, and SwiftUI targets, ensuring visual consistency throughout your application. The theme configuration integrates with your app generation setup and works across responsive layouts and component libraries.", "question_type": "medium", "topics": ["Quickstart", "GUI Tools"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["theming", "dark-mode", "styling"], "related_skills": ["skill_gui_tools.md", "skill_gui_design.md", "skill_theming.md"], "related_docs": ["src/unifyweaver/targets/vue_target.pl", "education/other-books/book-gui-generation/"], "original_answer": "Define theming in your app configuration: `theme(default, [dark_mode(true)])`. The theming system supports color schemes and dark mode toggling across all UI components. This ensures visual consistency across your entire application and works across Vue, React Native, Flutter, and SwiftUI targets. See skill_gui_tools.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer lacks concrete implementation details about how to actually apply themes to components or how users toggle dark mode at runtime. It would be stronger with examples of theme configuration structure or CSS/styling approaches per target platform."}
{"pair_id": "skill_gui_tools_006_q1", "cluster_id": "skill_gui_tools_006", "question": "How do I add a dark mode to my app?", "answer": "To add dark mode to your app, define it in your theme configuration: `theme(default, [dark_mode(true)])`. This enables dark mode toggling across all UI components in Vue, React Native, Flutter, and SwiftUI targets, ensuring visual consistency throughout your application.", "question_type": "medium", "topics": ["Quickstart", "GUI Tools"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["theming", "dark-mode", "styling"], "related_skills": ["skill_gui_tools.md", "skill_gui_design.md", "skill_theming.md"], "related_docs": ["src/unifyweaver/targets/vue_target.pl", "education/other-books/book-gui-generation/"], "original_answer": "Define theming in your app configuration: `theme(default, [dark_mode(true)])`. The theming system supports color schemes and dark mode toggling across all UI components. This ensures visual consistency across your entire application and works across Vue, React Native, Flutter, and SwiftUI targets. See skill_gui_tools.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_gui_tools_006_q2", "cluster_id": "skill_gui_tools_006", "question": "How do I create consistent styling across my app?", "answer": "Define theming in your app configuration using the `theme(default, [dark_mode(true)])` pattern. This theming system provides centralized control over color schemes and dark mode toggling, applying styling rules consistently across all UI components in Vue, React Native, Flutter, and SwiftUI targets. By configuring theme at the app level rather than per-component, you maintain visual consistency across your entire application without duplicating style definitions.", "question_type": "medium", "topics": ["Quickstart", "GUI Tools"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["theming", "dark-mode", "styling"], "related_skills": ["skill_gui_tools.md", "skill_gui_design.md", "skill_theming.md"], "related_docs": ["src/unifyweaver/targets/vue_target.pl", "education/other-books/book-gui-generation/"], "original_answer": "Define theming in your app configuration: `theme(default, [dark_mode(true)])`. The theming system supports color schemes and dark mode toggling across all UI components. This ensures visual consistency across your entire application and works across Vue, React Native, Flutter, and SwiftUI targets. See skill_gui_tools.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer is somewhat generic and lacks specific details about how to customize colors, define custom themes, or override theme values at the component level. The answer would be stronger with concrete examples of theme configuration syntax or mention of which CSS/styling frameworks are used per target."}
{"pair_id": "skill_gui_tools_006_q3", "cluster_id": "skill_gui_tools_006", "question": "How do I change colors and themes?", "answer": "Define theming in your app configuration using the `theme(default, [dark_mode(true)])` syntax. The theming system supports color schemes and dark mode toggling. You can customize colors by specifying color values in the theme configuration, which applies consistently across all UI components in Vue, React Native, Flutter, and SwiftUI targets. For detailed color customization options, see skill_theming.md.", "question_type": "medium", "topics": ["Quickstart", "GUI Tools"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["theming", "dark-mode", "styling"], "related_skills": ["skill_gui_tools.md", "skill_gui_design.md", "skill_theming.md"], "related_docs": ["src/unifyweaver/targets/vue_target.pl", "education/other-books/book-gui-generation/"], "original_answer": "Define theming in your app configuration: `theme(default, [dark_mode(true)])`. The theming system supports color schemes and dark mode toggling across all UI components. This ensures visual consistency across your entire application and works across Vue, React Native, Flutter, and SwiftUI targets. See skill_gui_tools.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "The base answer lacks specific details on HOW to actually change colors (color property names, syntax for custom palettes). The answer assumes users know the theme configuration syntax but doesn't explain color definition mechanisms or provide examples of color customization beyond dark mode."}
{"pair_id": "skill_hierarchy_objective_001_q0", "cluster_id": "skill_hierarchy_objective_001", "question": "How do I measure if my folder hierarchy or tree structure is well-organized?", "answer": "You can measure hierarchy quality using the objective function J = D/(1+H), where D measures semantic coherence (how tightly nodes cluster to their parents) and H measures informativeness (how much each hierarchical split adds information). Lower J values indicate better-organized hierarchies\u2014a good hierarchy typically has J < 0.2. To evaluate your folder structure or tree, run:\n\n```bash\npython3 scripts/mindmap/hierarchy_objective.py --tree hierarchy.json --embeddings embeddings.npy\n```\n\nThis analyzes your hierarchy and shows per-level statistics. You can also optimize new hierarchies using J-guided tree building or adjust the depth normalization with --depth-decay for deeper structures.", "question_type": "medium", "topics": ["Quickstart", "Hierarchy Objective Function"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["hierarchy", "evaluation", "structure"], "related_skills": ["skill_hierarchy_objective.md", "skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/hierarchy_objective.py"], "original_answer": "You can measure hierarchy quality using the objective function J = D/(1+H), where D measures how tightly nodes cluster to their parents and H measures how informative each split is. Lower J values indicate better hierarchies. Run:\n\n```bash\npython3 scripts/mindmap/hierarchy_objective.py --tree hierarchy.json --embeddings embeddings.npy\n```\n\nThis evaluates your existing hierarchy and shows per-level statistics. A good hierarchy typically has J < 0.2, increasing entropy depth, and consistent distance. See skill_hierarchy_objective.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_hierarchy_objective_001_q1", "cluster_id": "skill_hierarchy_objective_001", "question": "How do I evaluate the quality of my hierarchy?", "answer": "You can measure hierarchy quality using the objective function J = D/(1+H), where:\n\n- **D (Distance)** measures how tightly nodes cluster to their parents (semantic coherence)\n- **H (Entropy gain)** measures how informative each split is at each level\n\nLower J values indicate better hierarchies (typically J < 0.2 is good).\n\nTo evaluate your hierarchy, run:\n\n```bash\npython3 scripts/mindmap/hierarchy_objective.py --tree hierarchy.json --embeddings embeddings.npy\n```\n\nThis will show per-level statistics including the overall objective score, distance metrics, and entropy gains. For more detailed analysis with BERT-based entropy (higher accuracy), use:\n\n```bash\npython3 scripts/mindmap/hierarchy_objective.py --tree hierarchy.json --embeddings embeddings.npy --entropy-source logits --entropy-model answerdotai/ModernBERT-base\n```\n\nA good hierarchy has low distance (tight clusters), increasing entropy with depth (informative splits), and consistent distance across levels.", "question_type": "medium", "topics": ["Quickstart", "Hierarchy Objective Function"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["hierarchy", "evaluation", "structure"], "related_skills": ["skill_hierarchy_objective.md", "skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/hierarchy_objective.py"], "original_answer": "You can measure hierarchy quality using the objective function J = D/(1+H), where D measures how tightly nodes cluster to their parents and H measures how informative each split is. Lower J values indicate better hierarchies. Run:\n\n```bash\npython3 scripts/mindmap/hierarchy_objective.py --tree hierarchy.json --embeddings embeddings.npy\n```\n\nThis evaluates your existing hierarchy and shows per-level statistics. A good hierarchy typically has J < 0.2, increasing entropy depth, and consistent distance. See skill_hierarchy_objective.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_hierarchy_objective_001_q2", "cluster_id": "skill_hierarchy_objective_001", "question": "What makes a good folder organization?", "answer": "A good folder organization balances two key properties: tight semantic clustering and informative hierarchy levels. You can measure this with the objective function J = D/(1+H), where D is average semantic distance from items to their parent folder, and H is the information gained at each split. Lower J values indicate better organization\u2014typically J < 0.2 is good. To evaluate your folder structure: `python3 scripts/mindmap/hierarchy_objective.py --tree hierarchy.json --embeddings embeddings.npy`. This shows whether your folders are semantically coherent and whether each hierarchy level adds meaningful organization.", "question_type": "medium", "topics": ["Quickstart", "Hierarchy Objective Function"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["hierarchy", "evaluation", "structure"], "related_skills": ["skill_hierarchy_objective.md", "skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/hierarchy_objective.py"], "original_answer": "You can measure hierarchy quality using the objective function J = D/(1+H), where D measures how tightly nodes cluster to their parents and H measures how informative each split is. Lower J values indicate better hierarchies. Run:\n\n```bash\npython3 scripts/mindmap/hierarchy_objective.py --tree hierarchy.json --embeddings embeddings.npy\n```\n\nThis evaluates your existing hierarchy and shows per-level statistics. A good hierarchy typically has J < 0.2, increasing entropy depth, and consistent distance. See skill_hierarchy_objective.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer is technically sound but uses jargon ('entropy depth', 'Fisher criterion') that may be unclear without the skill document context. The tailored answer simplifies this but loses some technical precision about how to interpret the results."}
{"pair_id": "skill_hierarchy_objective_001_q3", "cluster_id": "skill_hierarchy_objective_001", "question": "How do I know if my hierarchy is good?", "answer": "You can measure hierarchy quality using the objective function J = D/(1+H), where D represents how tightly nodes cluster under their parents (semantic coherence) and H represents how informative each hierarchical split is. Lower J values indicate better hierarchies\u2014a good hierarchy typically has J < 0.2. To evaluate your hierarchy, run: `python3 scripts/mindmap/hierarchy_objective.py --tree hierarchy.json --embeddings embeddings.npy`. This provides per-level statistics including distance, entropy, and the overall objective score. Key indicators of a good hierarchy include consistent distance values across levels, increasing entropy gain at deeper levels, and balanced branching.", "question_type": "medium", "topics": ["Quickstart", "Hierarchy Objective Function"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["hierarchy", "evaluation", "structure"], "related_skills": ["skill_hierarchy_objective.md", "skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/hierarchy_objective.py"], "original_answer": "You can measure hierarchy quality using the objective function J = D/(1+H), where D measures how tightly nodes cluster to their parents and H measures how informative each split is. Lower J values indicate better hierarchies. Run:\n\n```bash\npython3 scripts/mindmap/hierarchy_objective.py --tree hierarchy.json --embeddings embeddings.npy\n```\n\nThis evaluates your existing hierarchy and shows per-level statistics. A good hierarchy typically has J < 0.2, increasing entropy depth, and consistent distance. See skill_hierarchy_objective.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_hierarchy_objective_002_q0", "cluster_id": "skill_hierarchy_objective_002", "question": "What's the difference between distance (D) and entropy (H) in a hierarchy?", "answer": "Distance (D) and entropy (H) measure two distinct properties of hierarchies. Distance (D) measures semantic coherence\u2014how similar children are to their parent node. Low D indicates tight clusters where children are semantically close to their parent; high D indicates scattered relationships where children are loosely related. Entropy (H) measures informativeness\u2014how much information each hierarchical split provides. High H means clear separation between sibling groups, making the split meaningful; low H means siblings blend together, making the split uninformative. Together, the objective function J = D/(1+H) balances these properties: you want low D (tight semantic clusters) combined with high H (clear, informative splits). A well-structured hierarchy typically shows H increasing with depth (more specificity at deeper levels) while D remains relatively constant or slightly increases per level (deeper nodes are expected to be more specific).", "question_type": "long", "topics": ["Quickstart", "Hierarchy Objective Function"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["distance", "entropy", "objective-function"], "related_skills": ["skill_hierarchy_objective.md"], "related_docs": ["education/book-13-semantic-search/07_density_scoring.md"], "original_answer": "Distance (D) measures semantic coherence - how similar children are to their parent. Low D means tight clusters; high D means scattered relationships. Entropy (H) measures informativeness - how much each split tells you. High H means clear separation between siblings; low H means blended concepts. The objective J = D/(1+H) balances both: you want tight clusters (low D) with informative splits (high H). Good hierarchies show increasing H with depth and D roughly constant or slightly increasing per level. See skill_hierarchy_objective.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_hierarchy_objective_002_q1", "cluster_id": "skill_hierarchy_objective_002", "question": "What do D and H mean in the objective function?", "answer": "In the objective function J = D/(1+H), D (Distance) measures semantic coherence by calculating the average semantic distance from nodes to their parents. Low D indicates tight, semantically similar clusters under a parent; high D indicates scattered, loosely related nodes. H (Entropy gain) measures how informative each hierarchical split is. High H means clear, meaningful separation between sibling groups; low H means siblings blend together with little distinction. Together, J balances these properties: you want low D (tight clusters) paired with high H (informative splits) to create a good hierarchy.", "question_type": "long", "topics": ["Quickstart", "Hierarchy Objective Function"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["distance", "entropy", "objective-function"], "related_skills": ["skill_hierarchy_objective.md"], "related_docs": ["education/book-13-semantic-search/07_density_scoring.md"], "original_answer": "Distance (D) measures semantic coherence - how similar children are to their parent. Low D means tight clusters; high D means scattered relationships. Entropy (H) measures informativeness - how much each split tells you. High H means clear separation between siblings; low H means blended concepts. The objective J = D/(1+H) balances both: you want tight clusters (low D) with informative splits (high H). Good hierarchies show increasing H with depth and D roughly constant or slightly increasing per level. See skill_hierarchy_objective.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_hierarchy_objective_002_q2", "cluster_id": "skill_hierarchy_objective_002", "question": "How does semantic distance affect hierarchy quality?", "answer": "Semantic distance (D) directly measures hierarchy quality by quantifying how tightly related children are to their parent. Low D indicates children cluster tightly around their parent semantically\u2014meaning the parent concept meaningfully groups similar items. High D indicates scattered relationships where children aren't closely related to their parent, signaling poor hierarchical organization. In the objective function J = D/(1+H), distance is the primary quality metric: minimizing D creates coherent, semantically meaningful clusters. As you descend the hierarchy, D can increase slightly because deeper nodes become more specific, but should remain relatively controlled. Distance violations (very high D at any level) suggest the hierarchy needs restructuring\u2014either the parent concept is too broad or children should be reorganized into different groups.", "question_type": "long", "topics": ["Quickstart", "Hierarchy Objective Function"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["distance", "entropy", "objective-function"], "related_skills": ["skill_hierarchy_objective.md"], "related_docs": ["education/book-13-semantic-search/07_density_scoring.md"], "original_answer": "Distance (D) measures semantic coherence - how similar children are to their parent. Low D means tight clusters; high D means scattered relationships. Entropy (H) measures informativeness - how much each split tells you. High H means clear separation between siblings; low H means blended concepts. The objective J = D/(1+H) balances both: you want tight clusters (low D) with informative splits (high H). Good hierarchies show increasing H with depth and D roughly constant or slightly increasing per level. See skill_hierarchy_objective.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_hierarchy_objective_002_q3", "cluster_id": "skill_hierarchy_objective_002", "question": "Why does entropy matter for hierarchies?", "answer": "Entropy (H) matters for hierarchies because it measures how informative each split is. High entropy means siblings in the tree represent clearly separated, distinct concepts\u2014each branching point teaches you something meaningful. Low entropy means sibling groups blend together without clear distinction, making the hierarchy less useful for navigation and understanding. Combined with distance (D) in the objective J = D/(1+H), entropy ensures your hierarchy doesn't just cluster tightly (low D) but also creates meaningful categorical splits (high H). Without high entropy, you'd have coherent but uninformative trees where distinctions feel arbitrary.", "question_type": "long", "topics": ["Quickstart", "Hierarchy Objective Function"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["distance", "entropy", "objective-function"], "related_skills": ["skill_hierarchy_objective.md"], "related_docs": ["education/book-13-semantic-search/07_density_scoring.md"], "original_answer": "Distance (D) measures semantic coherence - how similar children are to their parent. Low D means tight clusters; high D means scattered relationships. Entropy (H) measures informativeness - how much each split tells you. High H means clear separation between siblings; low H means blended concepts. The objective J = D/(1+H) balances both: you want tight clusters (low D) with informative splits (high H). Good hierarchies show increasing H with depth and D roughly constant or slightly increasing per level. See skill_hierarchy_objective.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_hierarchy_objective_003_q0", "cluster_id": "skill_hierarchy_objective_003", "question": "How do I build a hierarchy optimized for the J objective function?", "answer": "Use the J-guided tree builder to construct hierarchies that directly optimize the objective function J = D/(1+H):\n\n```python\nfrom scripts.mindmap.hierarchy_objective import build_j_guided_tree\nimport numpy as np\n\nembeddings = np.load(\"embeddings.npy\")\ntitles = [\"Machine Learning\", \"Deep Learning\", \"NLP\", ...]\n\ntree, stats, suggestions = build_j_guided_tree(\n    embeddings,\n    titles=titles,\n    use_bert_entropy=False,\n    verbose=True\n)\nprint(f\"Objective J: {stats.objective:.4f}\")\n```\n\nThis greedily optimizes at each step by balancing semantic coherence (D - how tightly nodes cluster under parents) and informative splits (H - how much each level separates siblings). The function returns the optimized tree structure, objective statistics, and suggestions for missing intermediate nodes.", "question_type": "long", "topics": ["Quickstart", "Hierarchy Objective Function"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["tree-construction", "optimization", "j-guided"], "related_skills": ["skill_hierarchy_objective.md", "skill_mst_folder_grouping.md", "skill_train_model.md"], "related_docs": ["scripts/mindmap/hierarchy_objective.py"], "original_answer": "Use the J-guided tree builder to construct hierarchies that directly optimize the objective function:\n\n```python\nfrom scripts.mindmap.hierarchy_objective import build_j_guided_tree\nimport numpy as np\n\nembeddings = np.load(\"embeddings.npy\")\ntitles = [\"Machine Learning\", \"Deep Learning\", \"NLP\", ...]\n\ntree, stats, suggestions = build_j_guided_tree(\n    embeddings,\n    titles=titles,\n    use_bert_entropy=False,\n    verbose=True\n)\nprint(f\"Objective J: {stats.objective:.4f}\")\n```\n\nThis builds a tree optimizing J at each step and provides suggestions for missing intermediate nodes. See skill_hierarchy_objective.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_hierarchy_objective_003_q1", "cluster_id": "skill_hierarchy_objective_003", "question": "How do I construct a hierarchy that minimizes J?", "answer": "To construct a hierarchy that minimizes J, use the J-guided tree builder which directly optimizes the objective function J = D/(1+H) at each step:\n\n```python\nfrom scripts.mindmap.hierarchy_objective import build_j_guided_tree\nimport numpy as np\n\nembeddings = np.load(\"embeddings.npy\")\ntitles = [\"Machine Learning\", \"Deep Learning\", \"NLP\", ...]\n\ntree, stats, suggestions = build_j_guided_tree(\n    embeddings,\n    titles=titles,\n    use_bert_entropy=False,\n    verbose=True\n)\nprint(f\"Objective J: {stats.objective:.4f}\")\n```\n\nThis algorithm minimizes J by:\n1. Creating tight clusters (low D) - grouping semantically similar nodes under parents\n2. Making informative splits (high H) - ensuring each hierarchy level provides clear separation between sibling groups\n\nThe function also provides suggestions for missing intermediate nodes that could further improve the objective. For more accurate entropy calculations, set `use_bert_entropy=True` with a transformer model, though this is slower.", "question_type": "long", "topics": ["Quickstart", "Hierarchy Objective Function"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["tree-construction", "optimization", "j-guided"], "related_skills": ["skill_hierarchy_objective.md", "skill_mst_folder_grouping.md", "skill_train_model.md"], "related_docs": ["scripts/mindmap/hierarchy_objective.py"], "original_answer": "Use the J-guided tree builder to construct hierarchies that directly optimize the objective function:\n\n```python\nfrom scripts.mindmap.hierarchy_objective import build_j_guided_tree\nimport numpy as np\n\nembeddings = np.load(\"embeddings.npy\")\ntitles = [\"Machine Learning\", \"Deep Learning\", \"NLP\", ...]\n\ntree, stats, suggestions = build_j_guided_tree(\n    embeddings,\n    titles=titles,\n    use_bert_entropy=False,\n    verbose=True\n)\nprint(f\"Objective J: {stats.objective:.4f}\")\n```\n\nThis builds a tree optimizing J at each step and provides suggestions for missing intermediate nodes. See skill_hierarchy_objective.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_hierarchy_objective_003_q2", "cluster_id": "skill_hierarchy_objective_003", "question": "Can I build a tree guided by the objective function?", "answer": "Yes, you can build a tree guided by the objective function J = D/(1+H) using the J-guided tree builder. This constructs hierarchies that directly optimize the objective function at each step:\n\n```python\nfrom scripts.mindmap.hierarchy_objective import build_j_guided_tree\nimport numpy as np\n\nembeddings = np.load(\"embeddings.npy\")\ntitles = [\"Machine Learning\", \"Deep Learning\", \"NLP\", ...]\n\ntree, stats, suggestions = build_j_guided_tree(\n    embeddings,\n    titles=titles,\n    use_bert_entropy=False,\n    verbose=True\n)\nprint(f\"Objective J: {stats.objective:.4f}\")\n```\n\nThe function builds a tree that balances semantic coherence (low distance D) with informative splits (high entropy H), resulting in a hierarchy where lower J indicates better structure. It also provides suggestions for missing intermediate nodes.", "question_type": "long", "topics": ["Quickstart", "Hierarchy Objective Function"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["tree-construction", "optimization", "j-guided"], "related_skills": ["skill_hierarchy_objective.md", "skill_mst_folder_grouping.md", "skill_train_model.md"], "related_docs": ["scripts/mindmap/hierarchy_objective.py"], "original_answer": "Use the J-guided tree builder to construct hierarchies that directly optimize the objective function:\n\n```python\nfrom scripts.mindmap.hierarchy_objective import build_j_guided_tree\nimport numpy as np\n\nembeddings = np.load(\"embeddings.npy\")\ntitles = [\"Machine Learning\", \"Deep Learning\", \"NLP\", ...]\n\ntree, stats, suggestions = build_j_guided_tree(\n    embeddings,\n    titles=titles,\n    use_bert_entropy=False,\n    verbose=True\n)\nprint(f\"Objective J: {stats.objective:.4f}\")\n```\n\nThis builds a tree optimizing J at each step and provides suggestions for missing intermediate nodes. See skill_hierarchy_objective.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_hierarchy_objective_003_q3", "cluster_id": "skill_hierarchy_objective_003", "question": "What's an alternative to MST for building hierarchies?", "answer": "Use the J-guided tree builder to construct hierarchies that directly optimize the objective function J = D/(1+H), which balances semantic coherence (low distance to parent) with informative splits (high entropy gain). Instead of MST's distance-only approach, this method optimizes both properties simultaneously:\n\n```python\nfrom scripts.mindmap.hierarchy_objective import build_j_guided_tree\nimport numpy as np\n\nembeddings = np.load(\"embeddings.npy\")\ntitles = [\"Machine Learning\", \"Deep Learning\", \"NLP\", ...]\n\ntree, stats, suggestions = build_j_guided_tree(\n    embeddings,\n    titles=titles,\n    verbose=True\n)\nprint(f\"Objective J: {stats.objective:.4f}\")\n```\n\nThis builds a tree greedily optimizing J at each step, automatically suggesting missing intermediate nodes. MST only minimizes edge weights (distance), while J-guided trees also ensure each hierarchical split adds meaningful information separation.", "question_type": "long", "topics": ["Quickstart", "Hierarchy Objective Function"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["tree-construction", "optimization", "j-guided"], "related_skills": ["skill_hierarchy_objective.md", "skill_mst_folder_grouping.md", "skill_train_model.md"], "related_docs": ["scripts/mindmap/hierarchy_objective.py"], "original_answer": "Use the J-guided tree builder to construct hierarchies that directly optimize the objective function:\n\n```python\nfrom scripts.mindmap.hierarchy_objective import build_j_guided_tree\nimport numpy as np\n\nembeddings = np.load(\"embeddings.npy\")\ntitles = [\"Machine Learning\", \"Deep Learning\", \"NLP\", ...]\n\ntree, stats, suggestions = build_j_guided_tree(\n    embeddings,\n    titles=titles,\n    use_bert_entropy=False,\n    verbose=True\n)\nprint(f\"Objective J: {stats.objective:.4f}\")\n```\n\nThis builds a tree optimizing J at each step and provides suggestions for missing intermediate nodes. See skill_hierarchy_objective.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_hierarchy_objective_004_q0", "cluster_id": "skill_hierarchy_objective_004", "question": "Should I use Fisher entropy or BERT logits for evaluating my hierarchy?", "answer": "Choose Fisher entropy (default) for fast evaluation with only embeddings required:\n\n```bash\npython3 scripts/mindmap/hierarchy_objective.py --tree hierarchy.json --embeddings embeddings.npy --entropy-source fisher\n```\n\nChoose BERT logits for higher theoretical accuracy, but note it requires node text and runs slower:\n\n```bash\npython3 scripts/mindmap/hierarchy_objective.py --tree hierarchy.json --embeddings embeddings.npy --entropy-source logits --entropy-model answerdotai/ModernBERT-base\n```\n\nFisher uses geometric variance ratios (between/within cluster variance) as a proxy for information gain. BERT logits directly measures entropy from transformer outputs, which is theoretically more precise. Use Fisher for rapid iteration and development; use logits when final accuracy matters most.", "question_type": "long", "topics": ["Quickstart", "Hierarchy Objective Function"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["entropy", "evaluation", "parameters"], "related_skills": ["skill_hierarchy_objective.md", "skill_embedding_models.md"], "related_docs": ["scripts/mindmap/hierarchy_objective.py"], "original_answer": "Fisher (default) is fast and works with embeddings alone - use this for quick evaluation:\n\n```bash\npython3 scripts/mindmap/hierarchy_objective.py --tree hierarchy.json --embeddings embeddings.npy --entropy-source fisher\n```\n\nBERT logits is slower but theoretically more accurate, requiring text for each node:\n\n```bash\npython3 scripts/mindmap/hierarchy_objective.py --tree hierarchy.json --embeddings embeddings.npy --entropy-source logits --entropy-model answerdotai/ModernBERT-base\n```\n\nUse Fisher for fast evaluation and iteration; use logits when you need best accuracy. See skill_hierarchy_objective.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_hierarchy_objective_004_q1", "cluster_id": "skill_hierarchy_objective_004", "question": "What entropy source should I use?", "answer": "Choose **Fisher** (default) for fast evaluation\u2014it uses only embeddings and no text required:\n\n```bash\npython3 scripts/mindmap/hierarchy_objective.py --tree hierarchy.json --embeddings embeddings.npy --entropy-source fisher\n```\n\nChoose **logits** for higher accuracy when you have text and can afford the slower speed:\n\n```bash\npython3 scripts/mindmap/hierarchy_objective.py --tree hierarchy.json --embeddings embeddings.npy --entropy-source logits --entropy-model answerdotai/ModernBERT-base\n```\n\nFisher is ideal for iterative tuning; logits when accuracy matters most.", "question_type": "long", "topics": ["Quickstart", "Hierarchy Objective Function"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["entropy", "evaluation", "parameters"], "related_skills": ["skill_hierarchy_objective.md", "skill_embedding_models.md"], "related_docs": ["scripts/mindmap/hierarchy_objective.py"], "original_answer": "Fisher (default) is fast and works with embeddings alone - use this for quick evaluation:\n\n```bash\npython3 scripts/mindmap/hierarchy_objective.py --tree hierarchy.json --embeddings embeddings.npy --entropy-source fisher\n```\n\nBERT logits is slower but theoretically more accurate, requiring text for each node:\n\n```bash\npython3 scripts/mindmap/hierarchy_objective.py --tree hierarchy.json --embeddings embeddings.npy --entropy-source logits --entropy-model answerdotai/ModernBERT-base\n```\n\nUse Fisher for fast evaluation and iteration; use logits when you need best accuracy. See skill_hierarchy_objective.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_hierarchy_objective_004_q2", "cluster_id": "skill_hierarchy_objective_004", "question": "Is Fisher or logits better for entropy?", "answer": "Fisher is better for fast iteration and quick evaluation since it only needs embeddings. Use the default Fisher entropy source:\n\n```bash\npython3 scripts/mindmap/hierarchy_objective.py --tree hierarchy.json --embeddings embeddings.npy\n```\n\nLogits-based entropy using BERT is theoretically more accurate but significantly slower because it requires text for each node and a transformer model. Use logits only when you need the highest accuracy:\n\n```bash\npython3 scripts/mindmap/hierarchy_objective.py --tree hierarchy.json --embeddings embeddings.npy --entropy-source logits --entropy-model answerdotai/ModernBERT-base\n```\n\nChoose based on your priority: Fisher for speed and iteration, logits for accuracy.", "question_type": "long", "topics": ["Quickstart", "Hierarchy Objective Function"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["entropy", "evaluation", "parameters"], "related_skills": ["skill_hierarchy_objective.md", "skill_embedding_models.md"], "related_docs": ["scripts/mindmap/hierarchy_objective.py"], "original_answer": "Fisher (default) is fast and works with embeddings alone - use this for quick evaluation:\n\n```bash\npython3 scripts/mindmap/hierarchy_objective.py --tree hierarchy.json --embeddings embeddings.npy --entropy-source fisher\n```\n\nBERT logits is slower but theoretically more accurate, requiring text for each node:\n\n```bash\npython3 scripts/mindmap/hierarchy_objective.py --tree hierarchy.json --embeddings embeddings.npy --entropy-source logits --entropy-model answerdotai/ModernBERT-base\n```\n\nUse Fisher for fast evaluation and iteration; use logits when you need best accuracy. See skill_hierarchy_objective.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_hierarchy_objective_004_q3", "cluster_id": "skill_hierarchy_objective_004", "question": "What's the difference between entropy methods?", "answer": "Fisher (default) uses variance between/within clusters from embeddings alone - fast for quick evaluation. BERT logits analyzes transformer token logits to compute semantic entropy - slower but theoretically more accurate since it understands language meaning. Choose Fisher for iteration speed, logits when you need best accuracy and have node text available.", "question_type": "long", "topics": ["Quickstart", "Hierarchy Objective Function"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["entropy", "evaluation", "parameters"], "related_skills": ["skill_hierarchy_objective.md", "skill_embedding_models.md"], "related_docs": ["scripts/mindmap/hierarchy_objective.py"], "original_answer": "Fisher (default) is fast and works with embeddings alone - use this for quick evaluation:\n\n```bash\npython3 scripts/mindmap/hierarchy_objective.py --tree hierarchy.json --embeddings embeddings.npy --entropy-source fisher\n```\n\nBERT logits is slower but theoretically more accurate, requiring text for each node:\n\n```bash\npython3 scripts/mindmap/hierarchy_objective.py --tree hierarchy.json --embeddings embeddings.npy --entropy-source logits --entropy-model answerdotai/ModernBERT-base\n```\n\nUse Fisher for fast evaluation and iteration; use logits when you need best accuracy. See skill_hierarchy_objective.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_hierarchy_objective_005_q0", "cluster_id": "skill_hierarchy_objective_005", "question": "How do I interpret the hierarchy statistics and know if something is wrong?", "answer": "To interpret hierarchy statistics, look for these key indicators:\n\n**Good signs:**\n- J < 0.2: Well-structured hierarchy\n- H (entropy) increasing with depth: Shows progressively more specific concepts at deeper levels\n- D (distance) roughly constant or slightly increasing per level: Indicates consistent semantic coherence\n\n**Warning signs:**\n- J > 0.5: Poor hierarchy structure\n- H decreasing with depth: Splits become uninformative as you go deeper\n- D jumping suddenly: Suggests incoherent relationships or structural problems\n\n**How to diagnose:**\nRun `python3 scripts/mindmap/hierarchy_objective.py --tree HIERARCHY.json --embeddings EMBEDDINGS.npy --output stats.json` to get per-level analysis. This reveals where problems occur.\n\n**Example:** J = 0.0955 indicates an excellent hierarchy. If you see H plateauing early or D spiking at a particular level, investigate that branch structure.", "question_type": "medium", "topics": ["Quickstart", "Hierarchy Objective Function"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["evaluation", "interpretation", "diagnostics"], "related_skills": ["skill_hierarchy_objective.md"], "related_docs": ["scripts/mindmap/hierarchy_objective.py"], "original_answer": "Good signs include J < 0.2 (well-structured), H increasing with depth (more specific concepts deeper), and D roughly constant or slightly increasing per level. Warning signs include J > 0.5 (poor structure), H decreasing with depth (uninformative splits), and D jumping suddenly (incoherent relationships).\n\nExample interpretation:\n- J = 0.0955: Excellent hierarchy\n- Level entropy increasing: Good conceptual depth\n- Sudden distance spike: May indicate structural problem\n\nRun with `--output stats.json` to save detailed per-level analysis. See skill_hierarchy_objective.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_hierarchy_objective_005_q1", "cluster_id": "skill_hierarchy_objective_005", "question": "What do the output statistics mean?", "answer": "The output statistics reveal hierarchy quality through three key metrics:\n\n**J (Objective Score)**: The overall hierarchy quality measure. J < 0.2 indicates excellent structure, 0.2-0.5 is acceptable, and J > 0.5 suggests poor organization. This single number quantifies the balance between semantic coherence (D) and informativeness (H).\n\n**D (Distance)**: Average semantic distance from child nodes to their parents. Should remain relatively constant or slightly increase per level\u2014sudden spikes indicate incoherent relationships or structural problems. Normalized by depth since deeper nodes are expected to be more specific.\n\n**H (Entropy Gain)**: Information content gained at each hierarchical level. Should increase with depth, showing that each level makes progressively more specific conceptual distinctions. Decreasing entropy suggests uninformative splits where sibling groups blend together.\n\n**Per-Level Analysis**: Run with `--output stats.json` to examine D and H values at each depth, helping identify exactly where structural issues occur.\n\nExample: A hierarchy with J = 0.0955, steadily increasing H, and stable D is well-designed. If H decreases or D spikes, investigate that level's clustering.", "question_type": "medium", "topics": ["Quickstart", "Hierarchy Objective Function"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["evaluation", "interpretation", "diagnostics"], "related_skills": ["skill_hierarchy_objective.md"], "related_docs": ["scripts/mindmap/hierarchy_objective.py"], "original_answer": "Good signs include J < 0.2 (well-structured), H increasing with depth (more specific concepts deeper), and D roughly constant or slightly increasing per level. Warning signs include J > 0.5 (poor structure), H decreasing with depth (uninformative splits), and D jumping suddenly (incoherent relationships).\n\nExample interpretation:\n- J = 0.0955: Excellent hierarchy\n- Level entropy increasing: Good conceptual depth\n- Sudden distance spike: May indicate structural problem\n\nRun with `--output stats.json` to save detailed per-level analysis. See skill_hierarchy_objective.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_hierarchy_objective_005_q2", "cluster_id": "skill_hierarchy_objective_005", "question": "How do I know if my hierarchy has problems?", "answer": "Check your hierarchy quality by computing the objective function J = D/(1+H). If J < 0.2, your hierarchy is well-structured. If J > 0.5, it likely has problems. Also examine: (1) Entropy H should increase with depth\u2014each level should introduce more specific concepts. If H decreases, your splits are uninformative. (2) Distance D should stay roughly constant or increase slightly per level. A sudden jump in D indicates incoherent relationships at that level. Run `python3 scripts/mindmap/hierarchy_objective.py --tree hierarchy.json --embeddings embeddings.npy --output stats.json` to get detailed per-level analysis. Use `--entropy-source logits` with a transformer model for more accurate entropy measurements if needed.", "question_type": "medium", "topics": ["Quickstart", "Hierarchy Objective Function"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["evaluation", "interpretation", "diagnostics"], "related_skills": ["skill_hierarchy_objective.md"], "related_docs": ["scripts/mindmap/hierarchy_objective.py"], "original_answer": "Good signs include J < 0.2 (well-structured), H increasing with depth (more specific concepts deeper), and D roughly constant or slightly increasing per level. Warning signs include J > 0.5 (poor structure), H decreasing with depth (uninformative splits), and D jumping suddenly (incoherent relationships).\n\nExample interpretation:\n- J = 0.0955: Excellent hierarchy\n- Level entropy increasing: Good conceptual depth\n- Sudden distance spike: May indicate structural problem\n\nRun with `--output stats.json` to save detailed per-level analysis. See skill_hierarchy_objective.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_hierarchy_objective_005_q3", "cluster_id": "skill_hierarchy_objective_005", "question": "What are good vs bad hierarchy metrics?", "answer": "Good hierarchies have J < 0.2, with entropy (H) increasing at deeper levels indicating more specific concepts, and distance (D) remaining roughly constant or slightly increasing per level. Bad hierarchies show J > 0.5, decreasing entropy with depth (uninformative splits), and sudden distance spikes (incoherent relationships). Use `python3 scripts/mindmap/hierarchy_objective.py --tree hierarchy.json --embeddings embeddings.npy --output stats.json` to analyze per-level metrics and identify structural problems.", "question_type": "medium", "topics": ["Quickstart", "Hierarchy Objective Function"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["evaluation", "interpretation", "diagnostics"], "related_skills": ["skill_hierarchy_objective.md"], "related_docs": ["scripts/mindmap/hierarchy_objective.py"], "original_answer": "Good signs include J < 0.2 (well-structured), H increasing with depth (more specific concepts deeper), and D roughly constant or slightly increasing per level. Warning signs include J > 0.5 (poor structure), H decreasing with depth (uninformative splits), and D jumping suddenly (incoherent relationships).\n\nExample interpretation:\n- J = 0.0955: Excellent hierarchy\n- Level entropy increasing: Good conceptual depth\n- Sudden distance spike: May indicate structural problem\n\nRun with `--output stats.json` to save detailed per-level analysis. See skill_hierarchy_objective.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_hierarchy_objective_006_q0", "cluster_id": "skill_hierarchy_objective_006", "question": "What does depth-surprisal correlation tell me about my hierarchy?", "answer": "Depth-surprisal correlation measures whether your hierarchy's structure matches concept specificity - general concepts should appear near the root, while more specific concepts should appear at deeper levels. A correlation > 0.5 indicates your hierarchy properly aligns depth with concept generality (good structure), while < 0.2 suggests the hierarchy doesn't reflect concept specificity (poor structure). A positive slope reinforces that depth tracks information gain correctly. You can compute this using:\n\n```python\nfrom scripts.mindmap.hierarchy_objective import JGuidedTreeBuilder\n\nbuilder = JGuidedTreeBuilder(embeddings, titles=titles)\ncorr, slope = builder.get_depth_surprisal_correlation()\nprint(f\"Correlation: {corr:.3f}\")\nprint(f\"Slope: {slope:.3f}\")\n```\n\nThis metric helps you validate that your hierarchy's organizational structure reflects meaningful conceptual relationships - not just clustering proximity.", "question_type": "long", "topics": ["Quickstart", "Hierarchy Objective Function"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["depth-surprisal", "diagnostics", "validation"], "related_skills": ["skill_hierarchy_objective.md", "skill_train_model.md"], "related_docs": ["scripts/mindmap/hierarchy_objective.py"], "original_answer": "Depth-surprisal correlation measures whether your hierarchy's depth matches concept generality - general concepts should be at the root, specific ones at leaves. Compute it using:\n\n```python\nfrom scripts.mindmap.hierarchy_objective import JGuidedTreeBuilder\n\nbuilder = JGuidedTreeBuilder(embeddings, titles=titles)\ncorr, slope = builder.get_depth_surprisal_correlation()\nprint(f\"Correlation: {corr:.3f}\")\nprint(f\"Slope: {slope:.3f}\")\n```\n\nInterpret as: correlation > 0.5 is good (proper concept generality alignment), < 0.2 is poor (hierarchy doesn't match concept specificity). Positive slope indicates depth properly tracks information. See skill_hierarchy_objective.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer assumes the JGuidedTreeBuilder class and method exist and are correctly documented, but I haven't verified the actual API. The interpretation thresholds (>0.5 good, <0.2 poor) are specific claims that should be validated against the actual implementation."}
{"pair_id": "skill_hierarchy_objective_006_q1", "cluster_id": "skill_hierarchy_objective_006", "question": "Why should depth correlate with surprisal?", "answer": "Depth should correlate with surprisal because hierarchies organize concepts from general (root) to specific (leaves). If this correlation is weak, it means your hierarchy doesn't properly reflect concept generality - you might have specific concepts near the root or general ones deep in the tree.\n\nMeasure this correlation using:\n\n```python\nfrom scripts.mindmap.hierarchy_objective import JGuidedTreeBuilder\n\nbuilder = JGuidedTreeBuilder(embeddings, titles=titles)\ncorr, slope = builder.get_depth_surprisal_correlation()\nprint(f\"Correlation: {corr:.3f}\")\nprint(f\"Slope: {slope:.3f}\")\n```\n\nInterpret the results:\n- **Correlation > 0.5**: Good - depth properly tracks information specificity\n- **Correlation < 0.2**: Poor - hierarchy doesn't align with concept generality\n- **Positive slope**: Indicates deeper nodes are more surprising (more specific), which is correct\n\nThis alignment ensures users intuitively navigate from broad topics to detailed subtopics.", "question_type": "long", "topics": ["Quickstart", "Hierarchy Objective Function"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["depth-surprisal", "diagnostics", "validation"], "related_skills": ["skill_hierarchy_objective.md", "skill_train_model.md"], "related_docs": ["scripts/mindmap/hierarchy_objective.py"], "original_answer": "Depth-surprisal correlation measures whether your hierarchy's depth matches concept generality - general concepts should be at the root, specific ones at leaves. Compute it using:\n\n```python\nfrom scripts.mindmap.hierarchy_objective import JGuidedTreeBuilder\n\nbuilder = JGuidedTreeBuilder(embeddings, titles=titles)\ncorr, slope = builder.get_depth_surprisal_correlation()\nprint(f\"Correlation: {corr:.3f}\")\nprint(f\"Slope: {slope:.3f}\")\n```\n\nInterpret as: correlation > 0.5 is good (proper concept generality alignment), < 0.2 is poor (hierarchy doesn't match concept specificity). Positive slope indicates depth properly tracks information. See skill_hierarchy_objective.md for details.", "answer_tailored": true, "confidence": 0.75, "confidence_issues": "The base answer provides correct technical content and interpretation thresholds, but doesn't fully explain the *why* (the conceptual reasoning for why this correlation matters for hierarchy quality). The tailored answer adds this missing intuition about navigating from general to specific concepts."}
{"pair_id": "skill_hierarchy_objective_006_q2", "cluster_id": "skill_hierarchy_objective_006", "question": "How do I check if concept generality aligns with depth?", "answer": "To check if concept generality aligns with depth, use the depth-surprisal correlation metric. This measures whether your hierarchy places general concepts near the root and specific concepts at the leaves. Calculate it with:\n\n```python\nfrom scripts.mindmap.hierarchy_objective import JGuidedTreeBuilder\n\nbuilder = JGuidedTreeBuilder(embeddings, titles=titles)\ncorr, slope = builder.get_depth_surprisal_correlation()\nprint(f\"Correlation: {corr:.3f}\")\nprint(f\"Slope: {slope:.3f}\")\n```\n\nInterpret the results: correlation > 0.5 indicates good alignment (concepts properly ordered by generality), < 0.2 indicates poor alignment (hierarchy doesn't match concept specificity). A positive slope confirms that depth correctly tracks information gain\u2014deeper nodes are appropriately more specific.", "question_type": "long", "topics": ["Quickstart", "Hierarchy Objective Function"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["depth-surprisal", "diagnostics", "validation"], "related_skills": ["skill_hierarchy_objective.md", "skill_train_model.md"], "related_docs": ["scripts/mindmap/hierarchy_objective.py"], "original_answer": "Depth-surprisal correlation measures whether your hierarchy's depth matches concept generality - general concepts should be at the root, specific ones at leaves. Compute it using:\n\n```python\nfrom scripts.mindmap.hierarchy_objective import JGuidedTreeBuilder\n\nbuilder = JGuidedTreeBuilder(embeddings, titles=titles)\ncorr, slope = builder.get_depth_surprisal_correlation()\nprint(f\"Correlation: {corr:.3f}\")\nprint(f\"Slope: {slope:.3f}\")\n```\n\nInterpret as: correlation > 0.5 is good (proper concept generality alignment), < 0.2 is poor (hierarchy doesn't match concept specificity). Positive slope indicates depth properly tracks information. See skill_hierarchy_objective.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_hierarchy_objective_006_q3", "cluster_id": "skill_hierarchy_objective_006", "question": "What's a good depth-surprisal correlation value?", "answer": "Depth-surprisal correlation measures whether your hierarchy's depth aligns with concept generality\u2014general concepts at the root, specific ones at leaves. A correlation > 0.5 indicates good alignment (your hierarchy properly matches concept specificity), while < 0.2 suggests poor alignment (hierarchy doesn't reflect concept structure). A positive slope is also important, confirming that depth correctly tracks information gain. Calculate it with: `corr, slope = builder.get_depth_surprisal_correlation()`. The exact threshold depends on your domain, but 0.5+ is a solid target for well-structured hierarchies.", "question_type": "long", "topics": ["Quickstart", "Hierarchy Objective Function"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["depth-surprisal", "diagnostics", "validation"], "related_skills": ["skill_hierarchy_objective.md", "skill_train_model.md"], "related_docs": ["scripts/mindmap/hierarchy_objective.py"], "original_answer": "Depth-surprisal correlation measures whether your hierarchy's depth matches concept generality - general concepts should be at the root, specific ones at leaves. Compute it using:\n\n```python\nfrom scripts.mindmap.hierarchy_objective import JGuidedTreeBuilder\n\nbuilder = JGuidedTreeBuilder(embeddings, titles=titles)\ncorr, slope = builder.get_depth_surprisal_correlation()\nprint(f\"Correlation: {corr:.3f}\")\nprint(f\"Slope: {slope:.3f}\")\n```\n\nInterpret as: correlation > 0.5 is good (proper concept generality alignment), < 0.2 is poor (hierarchy doesn't match concept specificity). Positive slope indicates depth properly tracks information. See skill_hierarchy_objective.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "Base answer provides the threshold values and interpretation, but the phrasing could be slightly more direct about what 'good' means in absolute terms. The answer assumes familiarity with the builder object initialization."}
{"pair_id": "skill_infrastructure_001_q0", "cluster_id": "skill_infrastructure_001", "question": "How do I deploy my service to production?", "answer": "To deploy your service to production with UnifyWeaver, declare your service using `declare_service/2` with host and port configuration, then generate deployment artifacts for your target platform: use `generate_dockerfile/3` for Docker containerization, `generate_k8s_deployment/3` for Kubernetes orchestration, or `generate_lambda_function/3` for serverless AWS Lambda deployment. Each command generates the complete configuration needed for production deployment on that platform.", "question_type": "medium", "topics": ["Quickstart", "Infrastructure (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["deployment", "docker", "kubernetes", "cloud"], "related_skills": ["skill_infrastructure.md", "skill_deployment.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "UnifyWeaver can generate deployment configurations for Docker, Kubernetes, and cloud functions. Use `generate_dockerfile(my_api, [], Dockerfile)` for Docker, `generate_k8s_deployment(my_api, [], Manifest)` for Kubernetes, or `generate_lambda_function(my_func, [], Package)` for AWS Lambda. Each generates the necessary configuration files for your target platform. See skill_infrastructure.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_infrastructure_001_q1", "cluster_id": "skill_infrastructure_001", "question": "How do I containerize and deploy my application?", "answer": "To containerize and deploy your application with UnifyWeaver, use the deployment glue module to generate platform-specific configurations. For Docker containerization, call `generate_dockerfile(my_api, [], Dockerfile)` to create a Dockerfile. For Kubernetes deployment, use `generate_k8s_deployment(my_api, [], Manifest)` to generate deployment manifests with services and ingress. For serverless deployment, use `generate_lambda_function(my_func, [], Package)` for AWS Lambda. First declare your service with `declare_service(my_api, [host('server.example.com'), port(8080), target(python), lifecycle(persistent)])` to specify configuration, then call the appropriate generation function for your target platform.", "question_type": "medium", "topics": ["Quickstart", "Infrastructure (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["deployment", "docker", "kubernetes", "cloud"], "related_skills": ["skill_infrastructure.md", "skill_deployment.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "UnifyWeaver can generate deployment configurations for Docker, Kubernetes, and cloud functions. Use `generate_dockerfile(my_api, [], Dockerfile)` for Docker, `generate_k8s_deployment(my_api, [], Manifest)` for Kubernetes, or `generate_lambda_function(my_func, [], Package)` for AWS Lambda. Each generates the necessary configuration files for your target platform. See skill_infrastructure.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer doesn't explicitly mention the service declaration step that appears necessary as a prerequisite. The answer assumes users know which platform to target but doesn't explain how to choose between Docker, Kubernetes, and cloud functions for different deployment scenarios."}
{"pair_id": "skill_infrastructure_001_q2", "cluster_id": "skill_infrastructure_001", "question": "What are the deployment options for my service?", "answer": "UnifyWeaver offers three primary deployment options: Docker (use `generate_dockerfile(my_api, [], Dockerfile)`), Kubernetes (use `generate_k8s_deployment(my_api, [], Manifest)`), and AWS Lambda cloud functions (use `generate_lambda_function(my_func, [], Package)`). Each option generates the necessary configuration files for your target platform, allowing you to deploy your service to containerized, orchestrated, or serverless environments respectively.", "question_type": "medium", "topics": ["Quickstart", "Infrastructure (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["deployment", "docker", "kubernetes", "cloud"], "related_skills": ["skill_infrastructure.md", "skill_deployment.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "UnifyWeaver can generate deployment configurations for Docker, Kubernetes, and cloud functions. Use `generate_dockerfile(my_api, [], Dockerfile)` for Docker, `generate_k8s_deployment(my_api, [], Manifest)` for Kubernetes, or `generate_lambda_function(my_func, [], Package)` for AWS Lambda. Each generates the necessary configuration files for your target platform. See skill_infrastructure.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_infrastructure_002_q0", "cluster_id": "skill_infrastructure_002", "question": "How do I set up authentication for my application?", "answer": "To set up authentication for your application, declare an `app` specification with an `auth` configuration block. Specify a backend (like `text_file` for simple file-based storage), password hashing method (like `bcrypt`), token type (like `jwt` for stateless tokens), and session duration in seconds. For example: `app(my_app, [auth([backend(text_file), password_hash(bcrypt), token_type(jwt), session_duration(86400)])])`. Then generate the auth server code by calling `generate_auth_server(AppSpec, node, Files)` with your app specification and target platform. UnifyWeaver supports multiple backends including text_file, SQLite, PostgreSQL, MongoDB, LDAP, and OAuth2 providers for more complex authentication scenarios.", "question_type": "medium", "topics": ["Quickstart", "Infrastructure (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["authentication", "auth", "jwt", "sessions", "oauth"], "related_skills": ["skill_infrastructure.md", "skill_authentication.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "Configure authentication in your app specification with backend, password hashing, and token options. Use `app(my_app, [auth([backend(text_file), password_hash(bcrypt), token_type(jwt), session_duration(86400)])])` to set up file-based auth with JWT tokens, then call `generate_auth_server(AppSpec, node, Files)` to generate the auth server code. UnifyWeaver supports multiple backends including text_file, SQLite, PostgreSQL, MongoDB, LDAP, and OAuth2. See skill_infrastructure.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_infrastructure_002_q1", "cluster_id": "skill_infrastructure_002", "question": "How do I add login and user authentication?", "answer": "To add login and user authentication, configure authentication in your app specification using the auth module. Define your app with authentication settings: `app(my_app, [auth([backend(text_file), password_hash(bcrypt), token_type(jwt), session_duration(86400)])])`. This sets up file-based user storage with bcrypt password hashing and JWT tokens. Then generate the auth server with `generate_auth_server(AppSpec, node, Files)` to get the implementation code. UnifyWeaver supports multiple backends (text_file, SQLite, PostgreSQL, MongoDB, LDAP, OAuth2) depending on your needs. Import the auth_backends module to access these capabilities.", "question_type": "medium", "topics": ["Quickstart", "Infrastructure (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["authentication", "auth", "jwt", "sessions", "oauth"], "related_skills": ["skill_infrastructure.md", "skill_authentication.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "Configure authentication in your app specification with backend, password hashing, and token options. Use `app(my_app, [auth([backend(text_file), password_hash(bcrypt), token_type(jwt), session_duration(86400)])])` to set up file-based auth with JWT tokens, then call `generate_auth_server(AppSpec, node, Files)` to generate the auth server code. UnifyWeaver supports multiple backends including text_file, SQLite, PostgreSQL, MongoDB, LDAP, and OAuth2. See skill_infrastructure.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_infrastructure_002_q2", "cluster_id": "skill_infrastructure_002", "question": "What authentication options are available?", "answer": "UnifyWeaver supports multiple authentication backends: text_file (simple file storage), SQLite, PostgreSQL, MongoDB, LDAP, and OAuth2. Configure authentication using `app(my_app, [auth([backend(text_file), password_hash(bcrypt), token_type(jwt), session_duration(86400)])])` to specify your backend, password hashing algorithm (bcrypt), token type (JWT), and session duration. Then generate the auth server with `generate_auth_server(AppSpec, node, Files)`. For development, a mock backend is available for client-side testing.", "question_type": "medium", "topics": ["Quickstart", "Infrastructure (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["authentication", "auth", "jwt", "sessions", "oauth"], "related_skills": ["skill_infrastructure.md", "skill_authentication.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "Configure authentication in your app specification with backend, password hashing, and token options. Use `app(my_app, [auth([backend(text_file), password_hash(bcrypt), token_type(jwt), session_duration(86400)])])` to set up file-based auth with JWT tokens, then call `generate_auth_server(AppSpec, node, Files)` to generate the auth server code. UnifyWeaver supports multiple backends including text_file, SQLite, PostgreSQL, MongoDB, LDAP, and OAuth2. See skill_infrastructure.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_infrastructure_002_q3", "cluster_id": "skill_infrastructure_002", "question": "How do I configure JWT tokens?", "answer": "To configure JWT tokens, use the auth specification in your app declaration with `token_type(jwt)`. Example: `app(my_app, [auth([backend(text_file), password_hash(bcrypt), token_type(jwt), session_duration(86400)])])`. This configures JWT as your token type with a 24-hour session duration. Then generate the auth server with `generate_auth_server(AppSpec, node, Files)` to produce the implementation. UnifyWeaver handles JWT token generation and validation automatically based on this configuration.", "question_type": "medium", "topics": ["Quickstart", "Infrastructure (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["authentication", "auth", "jwt", "sessions", "oauth"], "related_skills": ["skill_infrastructure.md", "skill_authentication.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "Configure authentication in your app specification with backend, password hashing, and token options. Use `app(my_app, [auth([backend(text_file), password_hash(bcrypt), token_type(jwt), session_duration(86400)])])` to set up file-based auth with JWT tokens, then call `generate_auth_server(AppSpec, node, Files)` to generate the auth server code. UnifyWeaver supports multiple backends including text_file, SQLite, PostgreSQL, MongoDB, LDAP, and OAuth2. See skill_infrastructure.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "Base answer is somewhat indirect\u2014it focuses on file-based auth setup rather than JWT-specific configuration details. The question asks specifically about JWT tokens, but the answer doesn't clarify JWT-specific options like token claims, signing algorithms, or refresh token handling. More detail on JWT-specific parameters would improve confidence."}
{"pair_id": "skill_infrastructure_003_q0", "cluster_id": "skill_infrastructure_003", "question": "How do I create an HTTP server for my API?", "answer": "To create an HTTP server for your API, use the `generate_http_server/4` predicate from the deployment glue module. Specify your target language (Python with Flask, Go with net/http, Rust with Actix-web, or Bash with curl), define your API endpoints, configure options like port (default 8080) and CORS settings, and UnifyWeaver generates complete, ready-to-deploy server code for you.", "question_type": "medium", "topics": ["Quickstart", "Infrastructure (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["http", "server", "api", "networking", "web"], "related_skills": ["skill_infrastructure.md", "skill_networking.md", "skill_web_frameworks.md"], "related_docs": ["src/unifyweaver/glue/network_glue.pl"], "original_answer": "Use `generate_http_server(Language, Endpoints, [port(8080), cors(true)], Code)` to generate an HTTP server in Python (Flask), Go (net/http), Rust (Actix-web), or Bash (curl). Specify your target language, define endpoints, configure the port and CORS settings, and UnifyWeaver generates the complete server code ready to deploy. See skill_infrastructure.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_infrastructure_003_q1", "cluster_id": "skill_infrastructure_003", "question": "How do I generate a web server?", "answer": "To generate a web server, use the `generate_http_server(Language, Endpoints, [port(8080), cors(true)], Code)` predicate from the deployment_glue module. Specify your target language (Python/Flask, Go/net/http, Rust/Actix-web, or Bash), define your endpoints, configure options like port and CORS settings, and UnifyWeaver generates the complete server code ready to deploy.", "question_type": "medium", "topics": ["Quickstart", "Infrastructure (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["http", "server", "api", "networking", "web"], "related_skills": ["skill_infrastructure.md", "skill_networking.md", "skill_web_frameworks.md"], "related_docs": ["src/unifyweaver/glue/network_glue.pl"], "original_answer": "Use `generate_http_server(Language, Endpoints, [port(8080), cors(true)], Code)` to generate an HTTP server in Python (Flask), Go (net/http), Rust (Actix-web), or Bash (curl). Specify your target language, define endpoints, configure the port and CORS settings, and UnifyWeaver generates the complete server code ready to deploy. See skill_infrastructure.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_infrastructure_003_q2", "cluster_id": "skill_infrastructure_003", "question": "How do I set up endpoints for my service?", "answer": "To set up endpoints for your service, use the `generate_http_server()` function from the networking module. Specify your target language (Python, Go, Rust, or Bash), define your endpoint routes and handlers, configure options like port and CORS, and UnifyWeaver generates the complete server code. For example: `generate_http_server(python, Endpoints, [port(8080), cors(true)], Code)` produces a Flask server with your endpoints ready to deploy.", "question_type": "medium", "topics": ["Quickstart", "Infrastructure (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["http", "server", "api", "networking", "web"], "related_skills": ["skill_infrastructure.md", "skill_networking.md", "skill_web_frameworks.md"], "related_docs": ["src/unifyweaver/glue/network_glue.pl"], "original_answer": "Use `generate_http_server(Language, Endpoints, [port(8080), cors(true)], Code)` to generate an HTTP server in Python (Flask), Go (net/http), Rust (Actix-web), or Bash (curl). Specify your target language, define endpoints, configure the port and CORS settings, and UnifyWeaver generates the complete server code ready to deploy. See skill_infrastructure.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_infrastructure_003_q3", "cluster_id": "skill_infrastructure_003", "question": "Which frameworks can I use for HTTP servers?", "answer": "You can use Flask for Python, net/http for Go, Actix-web for Rust, or curl for Bash. Use the `generate_http_server(Language, Endpoints, [port(8080), cors(true)], Code)` function to generate HTTP server code in your target language with configured port and CORS settings.", "question_type": "medium", "topics": ["Quickstart", "Infrastructure (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["http", "server", "api", "networking", "web"], "related_skills": ["skill_infrastructure.md", "skill_networking.md", "skill_web_frameworks.md"], "related_docs": ["src/unifyweaver/glue/network_glue.pl"], "original_answer": "Use `generate_http_server(Language, Endpoints, [port(8080), cors(true)], Code)` to generate an HTTP server in Python (Flask), Go (net/http), Rust (Actix-web), or Bash (curl). Specify your target language, define endpoints, configure the port and CORS settings, and UnifyWeaver generates the complete server code ready to deploy. See skill_infrastructure.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_infrastructure_004_q0", "cluster_id": "skill_infrastructure_004", "question": "How do I create an HTTP client to call other services?", "answer": "Use `generate_http_client(Language, Services, [timeout(30)], Code)` to create an HTTP client. Specify your target language (Python uses requests, Go uses net/http, Rust uses reqwest, Bash uses curl), list the services you need to call, configure options like timeout, and UnifyWeaver generates the client code with proper error handling.", "question_type": "medium", "topics": ["Quickstart", "Infrastructure (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["http", "client", "networking", "api-calls", "integration"], "related_skills": ["skill_infrastructure.md", "skill_networking.md"], "related_docs": ["src/unifyweaver/glue/network_glue.pl"], "original_answer": "Use `generate_http_client(Language, Services, [timeout(30)], Code)` to create an HTTP client in Python (requests), Go (net/http), Rust (reqwest), or Bash (curl). Specify your target language, list the services to call, set options like timeout, and UnifyWeaver generates the client code with proper error handling. See skill_infrastructure.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_infrastructure_004_q1", "cluster_id": "skill_infrastructure_004", "question": "How do I make requests to external APIs?", "answer": "To make requests to external APIs, use the `generate_http_client(Language, Services, [timeout(30)], Code)` function. Specify your programming language (Python with requests, Go with net/http, Rust with reqwest, or Bash with curl), list the external services you need to call, configure options like timeout and retry policies, and UnifyWeaver generates client code with built-in error handling and request formatting.", "question_type": "medium", "topics": ["Quickstart", "Infrastructure (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["http", "client", "networking", "api-calls", "integration"], "related_skills": ["skill_infrastructure.md", "skill_networking.md"], "related_docs": ["src/unifyweaver/glue/network_glue.pl"], "original_answer": "Use `generate_http_client(Language, Services, [timeout(30)], Code)` to create an HTTP client in Python (requests), Go (net/http), Rust (reqwest), or Bash (curl). Specify your target language, list the services to call, set options like timeout, and UnifyWeaver generates the client code with proper error handling. See skill_infrastructure.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer assumes the user knows about the UnifyWeaver glue module and how to invoke it. For users unfamiliar with the system, the answer could benefit from showing a concrete example of how to specify Services and call the function, rather than just listing available languages."}
{"pair_id": "skill_infrastructure_004_q2", "cluster_id": "skill_infrastructure_004", "question": "How do I generate code to call another service?", "answer": "Use `generate_http_client(Language, Services, [timeout(30)], Code)` to generate code that calls another service. Specify your target language (Python with requests, Go with net/http, Rust with reqwest, or Bash with curl), provide a list of the services you want to call, configure options like timeout, and UnifyWeaver generates the client code with proper error handling.", "question_type": "medium", "topics": ["Quickstart", "Infrastructure (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["http", "client", "networking", "api-calls", "integration"], "related_skills": ["skill_infrastructure.md", "skill_networking.md"], "related_docs": ["src/unifyweaver/glue/network_glue.pl"], "original_answer": "Use `generate_http_client(Language, Services, [timeout(30)], Code)` to create an HTTP client in Python (requests), Go (net/http), Rust (reqwest), or Bash (curl). Specify your target language, list the services to call, set options like timeout, and UnifyWeaver generates the client code with proper error handling. See skill_infrastructure.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_infrastructure_005_q0", "cluster_id": "skill_infrastructure_005", "question": "How do I set up socket communication between services?", "answer": "To set up socket communication between services, use `generate_socket_server(Language, Port, [buffer_size(65536)], Code)` to create a socket server and `generate_socket_client(Language, Host, Port, Options, Code)` to create a client. UnifyWeaver supports Python (socket), Go (net), and Rust (tokio) for efficient inter-service communication. Specify your language, port, and buffer configuration options when generating the code.", "question_type": "medium", "topics": ["Quickstart", "Infrastructure (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["socket", "networking", "communication", "realtime", "ipc"], "related_skills": ["skill_infrastructure.md", "skill_networking.md", "skill_ipc.md"], "related_docs": ["src/unifyweaver/glue/network_glue.pl"], "original_answer": "Use `generate_socket_server(Language, Port, [buffer_size(65536)], Code)` to create a socket server in Go or Rust with configurable buffer sizes. For socket clients, use `generate_socket_client(Language, Host, Port, Options, Code)`. UnifyWeaver generates low-level networking code supporting Python (socket), Go (net), and Rust (tokio) for efficient inter-service communication. See skill_infrastructure.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "Base answer doesn't explicitly explain the flow of how client and server work together or provide concrete usage examples. Answer could be more prescriptive about implementation steps."}
{"pair_id": "skill_infrastructure_005_q1", "cluster_id": "skill_infrastructure_005", "question": "How do I create a socket server?", "answer": "To create a socket server, use the `generate_socket_server(Language, Port, Options, Code)` predicate from the networking_glue module. Specify your target language (Python, Go, or Rust), the port number, and options like buffer_size. For example: `generate_socket_server(go, 9000, [buffer_size(65536)], Code)` generates a Go socket server on port 9000. UnifyWeaver supports Python (socket module), Go (net package), and Rust (tokio) for efficient inter-service communication.", "question_type": "medium", "topics": ["Quickstart", "Infrastructure (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["socket", "networking", "communication", "realtime", "ipc"], "related_skills": ["skill_infrastructure.md", "skill_networking.md", "skill_ipc.md"], "related_docs": ["src/unifyweaver/glue/network_glue.pl"], "original_answer": "Use `generate_socket_server(Language, Port, [buffer_size(65536)], Code)` to create a socket server in Go or Rust with configurable buffer sizes. For socket clients, use `generate_socket_client(Language, Host, Port, Options, Code)`. UnifyWeaver generates low-level networking code supporting Python (socket), Go (net), and Rust (tokio) for efficient inter-service communication. See skill_infrastructure.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_infrastructure_005_q2", "cluster_id": "skill_infrastructure_005", "question": "How do I enable real-time communication between services?", "answer": "UnifyWeaver enables real-time communication between services using socket servers and clients. Use `generate_socket_server(Language, Port, [buffer_size(65536)], Code)` to create a socket server in Go or Rust with configurable buffer sizes. For socket clients, use `generate_socket_client(Language, Host, Port, Options, Code)`. UnifyWeaver generates low-level networking code supporting Python (socket), Go (net), and Rust (tokio) for efficient inter-service communication. This approach provides direct, persistent connections suitable for real-time data exchange. See skill_infrastructure.md for implementation details.", "question_type": "medium", "topics": ["Quickstart", "Infrastructure (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["socket", "networking", "communication", "realtime", "ipc"], "related_skills": ["skill_infrastructure.md", "skill_networking.md", "skill_ipc.md"], "related_docs": ["src/unifyweaver/glue/network_glue.pl"], "original_answer": "Use `generate_socket_server(Language, Port, [buffer_size(65536)], Code)` to create a socket server in Go or Rust with configurable buffer sizes. For socket clients, use `generate_socket_client(Language, Host, Port, Options, Code)`. UnifyWeaver generates low-level networking code supporting Python (socket), Go (net), and Rust (tokio) for efficient inter-service communication. See skill_infrastructure.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "Base answer doesn't explicitly mention 'real-time' characteristics or advantages over alternatives (HTTP polling). Socket servers/clients are suitable for real-time communication but the answer could emphasize low-latency, persistent connections and when to prefer sockets over other networking methods."}
{"pair_id": "skill_infrastructure_006_q0", "cluster_id": "skill_infrastructure_006", "question": "How do I manage secrets and configuration for deployment?", "answer": "UnifyWeaver provides multiple secret management backends for deployment including HashiCorp Vault, AWS Secrets Manager, Azure Key Vault, and GCP Secret Manager. Configure secrets in your service declaration using `secrets([backend(vault), location('https://vault.example.com')])`. UnifyWeaver automatically generates the necessary configuration and code to securely load and manage sensitive data across development, staging, and production environments. Refer to skill_infrastructure.md for implementation details and additional configuration options.", "question_type": "medium", "topics": ["Quickstart", "Infrastructure (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["secrets", "security", "configuration", "vault", "credentials"], "related_skills": ["skill_infrastructure.md", "skill_deployment.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "UnifyWeaver supports multiple secret management backends including HashiCorp Vault, AWS Secrets Manager, Azure Key Vault, and GCP Secret Manager. Configure secrets in your service declaration with `secrets([backend(vault), location('https://vault.example.com')])` and UnifyWeaver generates the configuration and code to securely load and manage sensitive data across development, staging, and production environments. See skill_infrastructure.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_infrastructure_006_q1", "cluster_id": "skill_infrastructure_006", "question": "How do I securely store API keys and credentials?", "answer": "UnifyWeaver provides secure credential storage through multiple secret management backends: HashiCorp Vault, AWS Secrets Manager, Azure Key Vault, and GCP Secret Manager. Configure secrets in your service declaration using `secrets([backend(vault), location('https://vault.example.com')])` and UnifyWeaver automatically generates the necessary configuration and code to securely load and manage API keys and credentials across development, staging, and production environments. This approach ensures sensitive data is never hardcoded and is properly encrypted and accessed through authenticated channels.", "question_type": "medium", "topics": ["Quickstart", "Infrastructure (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["secrets", "security", "configuration", "vault", "credentials"], "related_skills": ["skill_infrastructure.md", "skill_deployment.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "UnifyWeaver supports multiple secret management backends including HashiCorp Vault, AWS Secrets Manager, Azure Key Vault, and GCP Secret Manager. Configure secrets in your service declaration with `secrets([backend(vault), location('https://vault.example.com')])` and UnifyWeaver generates the configuration and code to securely load and manage sensitive data across development, staging, and production environments. See skill_infrastructure.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_infrastructure_006_q2", "cluster_id": "skill_infrastructure_006", "question": "What secret management options are available?", "answer": "UnifyWeaver supports multiple secret management backends including HashiCorp Vault, AWS Secrets Manager, Azure Key Vault, and GCP Secret Manager. Configure secrets in your service declaration with `secrets([backend(vault), location('https://vault.example.com')])` and UnifyWeaver generates the necessary configuration and code to securely load and manage sensitive data across development, staging, and production environments.", "question_type": "medium", "topics": ["Quickstart", "Infrastructure (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["secrets", "security", "configuration", "vault", "credentials"], "related_skills": ["skill_infrastructure.md", "skill_deployment.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "UnifyWeaver supports multiple secret management backends including HashiCorp Vault, AWS Secrets Manager, Azure Key Vault, and GCP Secret Manager. Configure secrets in your service declaration with `secrets([backend(vault), location('https://vault.example.com')])` and UnifyWeaver generates the configuration and code to securely load and manage sensitive data across development, staging, and production environments. See skill_infrastructure.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_ipc_001_q0", "cluster_id": "skill_ipc_001", "question": "How do I connect Prolog to Python?", "answer": "You can connect Prolog to Python using three main approaches: (1) **Pipes** - Unix-style data pipelines using TSV/JSON formats for streaming ETL workflows, ideal for simple data flow; (2) **RPyC (Remote Python Call)** - network-based RPC that lets Prolog call Python functions remotely with live object proxies, use `rpyc_connect('localhost', [...], Proxy)` then `rpyc_call(Proxy, module, function, [...], Result)` for synchronous calls or `rpyc_async_call()` with `rpyc_await()` for async execution; (3) **Python Bridges** - direct embedding of Python in .NET, JVM, Rust, or Ruby runtimes for lowest-latency calls. Choose pipes for ETL pipelines, RPyC for isolated remote services, or bridges for embedded applications requiring direct access.", "question_type": "medium", "topics": ["Quickstart", "Inter-Process Communication"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["ipc", "interop", "python", "pipes", "rpc"], "related_skills": ["skill_ipc.md"], "related_docs": ["src/unifyweaver/glue/pipe_glue.pl", "src/unifyweaver/glue/rpyc_glue.pl", "src/unifyweaver/glue/python_bridges_glue.pl"], "original_answer": "You can connect Prolog to Python using three patterns: (1) **Pipes** - Unix-style data pipelines with TSV/JSON formats for streaming ETL, (2) **RPyC** - network-based RPC for remote Python services with live object proxies, or (3) **Python Bridges** - direct embedding in .NET, JVM, Rust, or Ruby for lowest latency. Use `rpyc_connect()` for network RPC or pipe-based orchestration for Unix data flows. See skill_ipc.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_ipc_001_q1", "cluster_id": "skill_ipc_001", "question": "Can I call Python from Prolog?", "answer": "Yes, you can call Python from Prolog using three main patterns: (1) **Pipes** - Unix-style data pipelines where Prolog writes TSV/JSON to stdin and reads from stdout, suitable for streaming ETL workflows; (2) **RPyC (Remote Python Call)** - network-based RPC that lets Prolog call Python functions remotely with live object proxies using `rpyc_connect()` and `rpyc_call()`; (3) **Python Bridges** - direct embedding for .NET, JVM, or Rust runtimes offering the lowest latency. Choose pipes for simple data flow, RPyC for remote services, or bridges for embedded scenarios.", "question_type": "medium", "topics": ["Quickstart", "Inter-Process Communication"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["ipc", "interop", "python", "pipes", "rpc"], "related_skills": ["skill_ipc.md"], "related_docs": ["src/unifyweaver/glue/pipe_glue.pl", "src/unifyweaver/glue/rpyc_glue.pl", "src/unifyweaver/glue/python_bridges_glue.pl"], "original_answer": "You can connect Prolog to Python using three patterns: (1) **Pipes** - Unix-style data pipelines with TSV/JSON formats for streaming ETL, (2) **RPyC** - network-based RPC for remote Python services with live object proxies, or (3) **Python Bridges** - direct embedding in .NET, JVM, Rust, or Ruby for lowest latency. Use `rpyc_connect()` for network RPC or pipe-based orchestration for Unix data flows. See skill_ipc.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_ipc_001_q2", "cluster_id": "skill_ipc_001", "question": "What are the ways to integrate Prolog with Python?", "answer": "You can integrate Prolog with Python using three main patterns: (1) **Pipes** - Unix-style data pipelines using TSV/JSON formats for streaming ETL workflows where Prolog orchestrates data flow through `generate_pipeline_script()`. (2) **RPyC** - network-based remote procedure calls using `rpyc_connect()` to call Python functions remotely with live object proxies, supporting async execution via `rpyc_async_call()`. (3) **Python Bridges** - direct embedding of Python in .NET, JVM, Rust, or Ruby runtimes via PythonNET, JPype, PyO3, or FFI for lowest-latency integration. Choose pipes for data pipelines, RPyC for process isolation and remote services, and bridges for embedded scenarios requiring maximum performance.", "question_type": "medium", "topics": ["Quickstart", "Inter-Process Communication"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["ipc", "interop", "python", "pipes", "rpc"], "related_skills": ["skill_ipc.md"], "related_docs": ["src/unifyweaver/glue/pipe_glue.pl", "src/unifyweaver/glue/rpyc_glue.pl", "src/unifyweaver/glue/python_bridges_glue.pl"], "original_answer": "You can connect Prolog to Python using three patterns: (1) **Pipes** - Unix-style data pipelines with TSV/JSON formats for streaming ETL, (2) **RPyC** - network-based RPC for remote Python services with live object proxies, or (3) **Python Bridges** - direct embedding in .NET, JVM, Rust, or Ruby for lowest latency. Use `rpyc_connect()` for network RPC or pipe-based orchestration for Unix data flows. See skill_ipc.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_ipc_002_q0", "cluster_id": "skill_ipc_002", "question": "How do I set up Unix pipe-based data flow between Prolog and other tools?", "answer": "Use the `pipe_glue` module to set up Unix pipe-based data flow. Generate TSV writers with `generate_pipe_writer(Language, Columns, Options, WriterCode)` and readers with `generate_pipe_reader(Language, Columns, Options, ReaderCode)`. Orchestrate multi-step pipelines using `generate_pipeline_script()` with step definitions specifying tool, location, and command. This pattern supports low-latency data flow across awk, python, bash, go, and rust using simple TSV or JSON formats. Ideal for ETL pipelines and streaming data processing.", "question_type": "medium", "topics": ["Quickstart", "Inter-Process Communication"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["pipes", "etl", "streaming", "unix", "awk"], "related_skills": ["skill_ipc.md", "skill_pipe_communication.md"], "related_docs": ["src/unifyweaver/glue/pipe_glue.pl"], "original_answer": "Use pipe communication for Unix pipelines with low latency and simple TSV/JSON formats. Generate pipe readers and writers with `generate_pipe_reader()` and `generate_pipe_writer()`, then orchestrate with `generate_pipeline_script()`. Example: `cat data.tsv | python transform.py | awk`. Best for ETL pipelines and streaming data processing across awk, python, bash, go, and rust. See skill_ipc.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_ipc_002_q1", "cluster_id": "skill_ipc_002", "question": "Can I use Unix pipes with Prolog for data processing?", "answer": "Yes, you can use Unix pipes with Prolog for data processing. Use pipe communication via the `pipe_glue` module to generate TSV or JSON pipe readers and writers. Create data flow pipelines with `generate_pipe_writer()` for output to pipes and `generate_pipe_reader()` for input from pipes, then orchestrate with `generate_pipeline_script()`. This pattern works well for ETL pipelines and streaming data, connecting Prolog to awk, Python, bash, Go, and Rust with low latency and simple data formats.", "question_type": "medium", "topics": ["Quickstart", "Inter-Process Communication"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["pipes", "etl", "streaming", "unix", "awk"], "related_skills": ["skill_ipc.md", "skill_pipe_communication.md"], "related_docs": ["src/unifyweaver/glue/pipe_glue.pl"], "original_answer": "Use pipe communication for Unix pipelines with low latency and simple TSV/JSON formats. Generate pipe readers and writers with `generate_pipe_reader()` and `generate_pipe_writer()`, then orchestrate with `generate_pipeline_script()`. Example: `cat data.tsv | python transform.py | awk`. Best for ETL pipelines and streaming data processing across awk, python, bash, go, and rust. See skill_ipc.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_ipc_002_q2", "cluster_id": "skill_ipc_002", "question": "How do I build pipelines connecting Prolog, Python, and AWK?", "answer": "Use pipe communication via the `pipe_glue` module to build Prolog-Python-AWK pipelines. Generate TSV writers and readers with `generate_pipe_writer(python, ...)` and `generate_pipe_reader(awk, ...)`, then orchestrate the full pipeline with `generate_pipeline_script()` specifying each step (extract, transform, load). Data flows as TSV between processes: `cat data.tsv | python transform.py | awk '{print $1}'`. This pattern has low latency and simple setup, making it ideal for ETL and streaming workflows across multiple Unix tools.", "question_type": "medium", "topics": ["Quickstart", "Inter-Process Communication"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["pipes", "etl", "streaming", "unix", "awk"], "related_skills": ["skill_ipc.md", "skill_pipe_communication.md"], "related_docs": ["src/unifyweaver/glue/pipe_glue.pl"], "original_answer": "Use pipe communication for Unix pipelines with low latency and simple TSV/JSON formats. Generate pipe readers and writers with `generate_pipe_reader()` and `generate_pipe_writer()`, then orchestrate with `generate_pipeline_script()`. Example: `cat data.tsv | python transform.py | awk`. Best for ETL pipelines and streaming data processing across awk, python, bash, go, and rust. See skill_ipc.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_ipc_003_q0", "cluster_id": "skill_ipc_003", "question": "How do I call remote Python functions from Prolog?", "answer": "Use RPyC (Remote Python Call) for network-based remote procedure calls to Python services from Prolog. First, connect to a Python service with `rpyc_connect('localhost', [security(unsecured), acknowledge_risk(true), remote_port(18812)], Proxy)`. Then call remote functions using `rpyc_call(Proxy, module, function, [Args], Result)`. For asynchronous calls, use `rpyc_async_call(Proxy, module, function, [Args], AsyncResult)` followed by `rpyc_await(AsyncResult, Result)` to retrieve the result. RPyC provides live object proxies, bidirectional calls, and supports SSH/SSL security options. When done, disconnect with `rpyc_disconnect(Proxy)`.", "question_type": "long", "topics": ["Quickstart", "Inter-Process Communication"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["rpyc", "network", "rpc", "async", "remote"], "related_skills": ["skill_ipc.md", "skill_rpyc.md"], "related_docs": ["src/unifyweaver/glue/rpyc_glue.pl"], "original_answer": "Use RPyC for network-based remote procedure calls to Python services. Connect with `rpyc_connect('localhost', [security(unsecured), acknowledge_risk(true), remote_port(18812)], Proxy)`, then call functions with `rpyc_call(Proxy, module, function, [Args], Result)`. For async calls, use `rpyc_async_call()` followed by `rpyc_await()`. RPyC supports live object proxies, bidirectional calls, and SSH/SSL security. See skill_ipc.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_ipc_003_q1", "cluster_id": "skill_ipc_003", "question": "Can I use Prolog to call a Python service over the network?", "answer": "Yes, use RPyC (Remote Python Call) for network-based remote procedure calls to Python services. Connect with `rpyc_connect('localhost', [security(unsecured), acknowledge_risk(true), remote_port(18812)], Proxy)`, then call remote functions with `rpyc_call(Proxy, module, function, [Args], Result)`. For asynchronous calls, use `rpyc_async_call()` followed by `rpyc_await()` to retrieve results. RPyC provides live object proxies, bidirectional communication, and supports SSH/SSL security options for production environments.", "question_type": "long", "topics": ["Quickstart", "Inter-Process Communication"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["rpyc", "network", "rpc", "async", "remote"], "related_skills": ["skill_ipc.md", "skill_rpyc.md"], "related_docs": ["src/unifyweaver/glue/rpyc_glue.pl"], "original_answer": "Use RPyC for network-based remote procedure calls to Python services. Connect with `rpyc_connect('localhost', [security(unsecured), acknowledge_risk(true), remote_port(18812)], Proxy)`, then call functions with `rpyc_call(Proxy, module, function, [Args], Result)`. For async calls, use `rpyc_async_call()` followed by `rpyc_await()`. RPyC supports live object proxies, bidirectional calls, and SSH/SSL security. See skill_ipc.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_ipc_003_q2", "cluster_id": "skill_ipc_003", "question": "How do I use RPyC with Prolog?", "answer": "To use RPyC with Prolog, use the `rpyc_glue` module. Connect to a Python service with `rpyc_connect('localhost', [security(unsecured), acknowledge_risk(true), remote_port(18812)], Proxy)`. Make synchronous calls with `rpyc_call(Proxy, module, function, [Args], Result)`. For asynchronous calls, use `rpyc_async_call(Proxy, module, function, [Args], AsyncResult)` followed by `rpyc_await(AsyncResult, Result)`. RPyC provides live object proxies, bidirectional calls, and security options including SSH and SSL. Disconnect with `rpyc_disconnect(Proxy)` when done.", "question_type": "long", "topics": ["Quickstart", "Inter-Process Communication"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["rpyc", "network", "rpc", "async", "remote"], "related_skills": ["skill_ipc.md", "skill_rpyc.md"], "related_docs": ["src/unifyweaver/glue/rpyc_glue.pl"], "original_answer": "Use RPyC for network-based remote procedure calls to Python services. Connect with `rpyc_connect('localhost', [security(unsecured), acknowledge_risk(true), remote_port(18812)], Proxy)`, then call functions with `rpyc_call(Proxy, module, function, [Args], Result)`. For async calls, use `rpyc_async_call()` followed by `rpyc_await()`. RPyC supports live object proxies, bidirectional calls, and SSH/SSL security. See skill_ipc.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_ipc_004_q0", "cluster_id": "skill_ipc_004", "question": "What is the best way to embed Python in .NET, Java, or Rust?", "answer": "Use Python bridges for native cross-runtime embedding with very low latency. For .NET: Python.NET or CSnakes. For Java: JPype or jpy. For Rust: PyO3. Use `detect_all_bridges()` to find available bridges on your platform or `auto_select_bridge()` to let Prolog select the optimal option. Generate client code with language-specific generators like `generate_pythonnet_rpyc_client()` for .NET, `generate_jpype_rpyc_client()` for Java, or `generate_pyo3_rpyc_client()` for Rust.", "question_type": "medium", "topics": ["Quickstart", "Inter-Process Communication"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["bridges", "embedding", "dotnet", "jvm", "rust", "ffi"], "related_skills": ["skill_ipc.md", "skill_python_bridges.md"], "related_docs": ["src/unifyweaver/glue/python_bridges_glue.pl"], "original_answer": "Use Python bridges for native cross-runtime embedding with very low latency. Options: **Python.NET or CSnakes** for .NET, **JPype or jpy** for JVM, **PyO3** for Rust, **PyCall.rb** for Ruby, and **koffi/ffi-napi** for Go/Node.js via FFI. Use `detect_all_bridges()` to find available bridges or `auto_select_bridge()` to let Prolog choose the best option for your platform. Generate client code with language-specific generators. See skill_ipc.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_ipc_004_q1", "cluster_id": "skill_ipc_004", "question": "How do I integrate Python into my .NET/JVM/Rust application?", "answer": "Use Python bridges for native cross-runtime embedding with very low latency. For .NET, use Python.NET or CSnakes. For JVM, use JPype or jpy. For Rust, use PyO3. For Ruby, use PyCall.rb. For Go/Node.js, use koffi or ffi-napi via FFI. Call `detect_all_bridges()` to discover available bridges on your system, or use `auto_select_bridge()` to let Prolog automatically select the best option for your platform and preferences. Generate language-specific client code using the appropriate generator (e.g., `generate_pythonnet_rpyc_client()` for .NET, `generate_jpype_rpyc_client()` for JVM, `generate_pyo3_rpyc_client()` for Rust).", "question_type": "medium", "topics": ["Quickstart", "Inter-Process Communication"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["bridges", "embedding", "dotnet", "jvm", "rust", "ffi"], "related_skills": ["skill_ipc.md", "skill_python_bridges.md"], "related_docs": ["src/unifyweaver/glue/python_bridges_glue.pl"], "original_answer": "Use Python bridges for native cross-runtime embedding with very low latency. Options: **Python.NET or CSnakes** for .NET, **JPype or jpy** for JVM, **PyO3** for Rust, **PyCall.rb** for Ruby, and **koffi/ffi-napi** for Go/Node.js via FFI. Use `detect_all_bridges()` to find available bridges or `auto_select_bridge()` to let Prolog choose the best option for your platform. Generate client code with language-specific generators. See skill_ipc.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_ipc_004_q2", "cluster_id": "skill_ipc_004", "question": "What are the Python bridge options for different languages?", "answer": "Python bridge options vary by target language: **Python.NET or CSnakes** for .NET, **JPype or jpy** for JVM, **PyO3** for Rust, **PyCall.rb** for Ruby, and **koffi/ffi-napi** for Go/Node.js via FFI. These enable native cross-runtime embedding with very low latency. Use `detect_all_bridges()` to identify available bridges on your system or `auto_select_bridge()` to automatically select the best option for your platform. Language-specific client code generators are available for each bridge type.", "question_type": "medium", "topics": ["Quickstart", "Inter-Process Communication"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["bridges", "embedding", "dotnet", "jvm", "rust", "ffi"], "related_skills": ["skill_ipc.md", "skill_python_bridges.md"], "related_docs": ["src/unifyweaver/glue/python_bridges_glue.pl"], "original_answer": "Use Python bridges for native cross-runtime embedding with very low latency. Options: **Python.NET or CSnakes** for .NET, **JPype or jpy** for JVM, **PyO3** for Rust, **PyCall.rb** for Ruby, and **koffi/ffi-napi** for Go/Node.js via FFI. Use `detect_all_bridges()` to find available bridges or `auto_select_bridge()` to let Prolog choose the best option for your platform. Generate client code with language-specific generators. See skill_ipc.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_ipc_005_q0", "cluster_id": "skill_ipc_005", "question": "Which IPC pattern should I use for my use case?", "answer": "Choose based on your needs: **Pipes** (low latency, low complexity) for Unix ETL pipelines and streaming data between processes using TSV/JSON formats; **RPyC** (medium latency, medium complexity) for remote Python services with process isolation, network access, and security options (SSH/SSL); **Bridges** (very low latency, high complexity) for native embedded Python directly in .NET, JVM, Rust, or Ruby runtimes. Pipes are best for `cat data.tsv | python script.py | awk` workflows. RPyC excels at calling remote Python functions over networks. Bridges provide direct function calls when Python must run within another language's runtime.", "question_type": "medium", "topics": ["Quickstart", "Inter-Process Communication"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["comparison", "pipes", "rpyc", "bridges", "patterns"], "related_skills": ["skill_ipc.md", "skill_pipe_communication.md", "skill_rpyc.md", "skill_python_bridges.md"], "related_docs": ["src/unifyweaver/glue/pipe_glue.pl", "src/unifyweaver/glue/rpyc_glue.pl", "src/unifyweaver/glue/python_bridges_glue.pl"], "original_answer": "Choose based on your needs: **Pipes** (low latency, low complexity) for Unix ETL pipelines and streaming; **RPyC** (medium latency, medium complexity) for remote Python services with process isolation and network access; **Bridges** (very low latency, high complexity) for native embedded Python in .NET, JVM, Rust with direct function calls. Pipes use TSV/JSON formats, RPyC supports SSH/SSL security, bridges require language-specific setup. See skill_ipc.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_ipc_005_q1", "cluster_id": "skill_ipc_005", "question": "Should I use pipes, RPyC, or bridges?", "answer": "Choose based on your deployment model: Use **Pipes** for Unix ETL pipelines and streaming data\u2014they have low latency and complexity, perfect for `cat data.csv | python transform.py | awk` workflows. Use **RPyC** for remote Python services where you need process isolation and network communication with SSH/SSL security options. Use **Bridges** (.NET, JVM, Rust) when you need to embed Python directly in another language runtime for the lowest latency with direct function calls, though they require language-specific setup. Match the pattern to your architecture: local pipelines \u2192 Pipes; remote services \u2192 RPyC; embedded scenarios \u2192 Bridges.", "question_type": "medium", "topics": ["Quickstart", "Inter-Process Communication"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["comparison", "pipes", "rpyc", "bridges", "patterns"], "related_skills": ["skill_ipc.md", "skill_pipe_communication.md", "skill_rpyc.md", "skill_python_bridges.md"], "related_docs": ["src/unifyweaver/glue/pipe_glue.pl", "src/unifyweaver/glue/rpyc_glue.pl", "src/unifyweaver/glue/python_bridges_glue.pl"], "original_answer": "Choose based on your needs: **Pipes** (low latency, low complexity) for Unix ETL pipelines and streaming; **RPyC** (medium latency, medium complexity) for remote Python services with process isolation and network access; **Bridges** (very low latency, high complexity) for native embedded Python in .NET, JVM, Rust with direct function calls. Pipes use TSV/JSON formats, RPyC supports SSH/SSL security, bridges require language-specific setup. See skill_ipc.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_ipc_005_q2", "cluster_id": "skill_ipc_005", "question": "What are the differences between pipe communication, RPyC, and Python bridges?", "answer": "Pipe communication, RPyC, and Python bridges differ in three key dimensions: **Latency and Performance** - Pipes have low latency suitable for streaming data (TSV/JSON formats via stdin/stdout), RPyC has medium latency with network overhead but enables process isolation, and bridges have very low latency with direct function calls in the same process. **Complexity and Setup** - Pipes require minimal setup for Unix pipelines, RPyC requires network configuration and security handling (SSH/SSL or unsecured mode), and bridges demand language-specific integration (.NET, JVM, Rust, Ruby). **Use Cases** - Pipes excel at ETL workflows and Unix data flow, RPyC handles remote Python services with bidirectional calls and async execution, and bridges embed Python directly in compiled languages for performance-critical applications.", "question_type": "medium", "topics": ["Quickstart", "Inter-Process Communication"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["comparison", "pipes", "rpyc", "bridges", "patterns"], "related_skills": ["skill_ipc.md", "skill_pipe_communication.md", "skill_rpyc.md", "skill_python_bridges.md"], "related_docs": ["src/unifyweaver/glue/pipe_glue.pl", "src/unifyweaver/glue/rpyc_glue.pl", "src/unifyweaver/glue/python_bridges_glue.pl"], "original_answer": "Choose based on your needs: **Pipes** (low latency, low complexity) for Unix ETL pipelines and streaming; **RPyC** (medium latency, medium complexity) for remote Python services with process isolation and network access; **Bridges** (very low latency, high complexity) for native embedded Python in .NET, JVM, Rust with direct function calls. Pipes use TSV/JSON formats, RPyC supports SSH/SSL security, bridges require language-specific setup. See skill_ipc.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_ipc_006_q0", "cluster_id": "skill_ipc_006", "question": "How do I securely connect to a remote Python service from Prolog?", "answer": "RPyC provides three security options for connecting to remote Python services from Prolog. For production environments, use SSH tunneling to encrypt all communications, or SSL certificates to authenticate endpoints. For development and trusted networks, you can use unsecured mode by including the `acknowledge_risk(true)` flag in your `rpyc_connect()` call. Example: `rpyc_connect('localhost', [security(ssh), remote_port(18812)], Proxy)` for SSH, or `rpyc_connect('localhost', [security(ssl), cert_file('path/to/cert')], Proxy)` for SSL. Unsecured mode sacrifices encryption but allows rapid prototyping: `rpyc_connect('localhost', [security(unsecured), acknowledge_risk(true)], Proxy)`.", "question_type": "long", "topics": ["Quickstart", "Inter-Process Communication"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["security", "rpyc", "ssh", "ssl", "authentication"], "related_skills": ["skill_ipc.md", "skill_rpyc.md"], "related_docs": ["src/unifyweaver/glue/rpyc_glue.pl"], "original_answer": "RPyC supports multiple security options: **SSH tunneling** for encrypted connections, **SSL certificates** for authenticated endpoints, or **unsecured with explicit acknowledgment** for development/trusted networks. Use `rpyc_connect()` with security configuration parameters. For production, use SSH or SSL to protect credentials and data in transit. Unsecured mode requires `acknowledge_risk(true)` flag. See skill_ipc.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_ipc_006_q1", "cluster_id": "skill_ipc_006", "question": "How do I set up SSH or SSL for RPyC connections?", "answer": "RPyC provides three security options for connections: SSH tunneling for encrypted communication through SSH channels, SSL certificates for authenticated TLS endpoints, and unsecured mode for development environments (requires `acknowledge_risk(true)` flag). Configure security using the `rpyc_connect()` predicate with the `security/1` parameter. For SSH, specify the tunnel endpoint; for SSL, provide certificate paths. Production deployments should use SSH or SSL to encrypt credentials and data in transit. Unsecured connections are only recommended for trusted, isolated networks during development.", "question_type": "long", "topics": ["Quickstart", "Inter-Process Communication"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["security", "rpyc", "ssh", "ssl", "authentication"], "related_skills": ["skill_ipc.md", "skill_rpyc.md"], "related_docs": ["src/unifyweaver/glue/rpyc_glue.pl"], "original_answer": "RPyC supports multiple security options: **SSH tunneling** for encrypted connections, **SSL certificates** for authenticated endpoints, or **unsecured with explicit acknowledgment** for development/trusted networks. Use `rpyc_connect()` with security configuration parameters. For production, use SSH or SSL to protect credentials and data in transit. Unsecured mode requires `acknowledge_risk(true)` flag. See skill_ipc.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "Base answer lacks specific configuration examples for SSH tunneling setup and SSL certificate path handling. The skill document truncates before detailed implementation, so specific parameter names and SSL configuration patterns cannot be verified against actual API."}
{"pair_id": "skill_ipc_006_q2", "cluster_id": "skill_ipc_006", "question": "How do I authenticate Prolog connections to Python services?", "answer": "RPyC provides three authentication approaches for Prolog-to-Python connections: (1) SSH tunneling for encrypted, authenticated connections over existing SSH infrastructure; (2) SSL certificates for direct authenticated endpoints with mutual verification; (3) unsecured mode for development/trusted networks (requires explicit `acknowledge_risk(true)` flag). Configure via `rpyc_connect()` security parameters. For production deployments, SSH or SSL is required to protect credentials and data in transit.", "question_type": "long", "topics": ["Quickstart", "Inter-Process Communication"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["security", "rpyc", "ssh", "ssl", "authentication"], "related_skills": ["skill_ipc.md", "skill_rpyc.md"], "related_docs": ["src/unifyweaver/glue/rpyc_glue.pl"], "original_answer": "RPyC supports multiple security options: **SSH tunneling** for encrypted connections, **SSL certificates** for authenticated endpoints, or **unsecured with explicit acknowledgment** for development/trusted networks. Use `rpyc_connect()` with security configuration parameters. For production, use SSH or SSL to protect credentials and data in transit. Unsecured mode requires `acknowledge_risk(true)` flag. See skill_ipc.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer assumes RPyC security options exist but doesn't provide concrete Prolog syntax examples. The tailored answer maintains this limitation while being more specific about authentication methods. Confidence is moderate because the authentication patterns are plausible for RPyC but should be verified against actual rpyc_glue implementation."}
{"pair_id": "skill_layout_system_001_q0", "cluster_id": "skill_layout_system_001", "question": "How do I create a horizontal row layout with spacing between items?", "answer": "Use the `row/3` predicate to create a horizontal layout with spacing. Example: `row([justify(space_between), align(center), gap(md)], [logo, nav, user], Spec)` creates a row with items spaced evenly, vertically centered, and medium gaps between them. The `justify(space_between)` option distributes items with equal spacing, while `gap(md)` controls the spacing scale. Generate platform-specific code using `generate_layout(Spec, Target, Code)` for Vue, React Native, Flutter, or SwiftUI.", "question_type": "medium", "topics": ["Quickstart", "Layout System"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["layout", "flexbox", "spacing", "alignment"], "related_skills": ["skill_layout_system.md", "skill_component_library.md", "skill_responsive_design.md", "skill_theming.md"], "related_docs": ["src/unifyweaver/layout/layout.pl"], "original_answer": "Use the `row/3` predicate with layout options. Example: `row([justify(space_between), align(center), gap(md)], [logo, nav, user], Spec)` creates a horizontal layout with items spaced apart, centered vertically, and medium gaps between them. Generate code for your target platform (Vue, React Native, Flutter, SwiftUI) using `generate_layout(Spec, Target, Code)`. See skill_layout_system.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_layout_system_001_q1", "cluster_id": "skill_layout_system_001", "question": "How do I arrange items horizontally?", "answer": "Use the `row/3` predicate to arrange items horizontally. Example: `row([justify(space_between), align(center), gap(md)], [logo, nav, user], Spec)` creates a horizontal layout with items spaced apart, vertically centered, and medium gaps between them. Then generate code for your target platform using `generate_layout(Spec, Target, Code)` where Target is vue, react_native, flutter, or swiftui.", "question_type": "medium", "topics": ["Quickstart", "Layout System"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["layout", "flexbox", "spacing", "alignment"], "related_skills": ["skill_layout_system.md", "skill_component_library.md", "skill_responsive_design.md", "skill_theming.md"], "related_docs": ["src/unifyweaver/layout/layout.pl"], "original_answer": "Use the `row/3` predicate with layout options. Example: `row([justify(space_between), align(center), gap(md)], [logo, nav, user], Spec)` creates a horizontal layout with items spaced apart, centered vertically, and medium gaps between them. Generate code for your target platform (Vue, React Native, Flutter, SwiftUI) using `generate_layout(Spec, Target, Code)`. See skill_layout_system.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_layout_system_001_q2", "cluster_id": "skill_layout_system_001", "question": "How do I create a row with gaps between elements?", "answer": "Use the `row/3` predicate with the `gap` option to create a row with gaps between elements. Example: `row([gap(md)], [child1, child2, child3], Spec)` creates a horizontal layout with medium-sized gaps between items. The gap accepts named values (xs, sm, md, lg, xl, xxl) or pixel numbers. Compile to your target platform with `generate_layout(Spec, vue, Code)` or similar for React Native, Flutter, and SwiftUI.", "question_type": "medium", "topics": ["Quickstart", "Layout System"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["layout", "flexbox", "spacing", "alignment"], "related_skills": ["skill_layout_system.md", "skill_component_library.md", "skill_responsive_design.md", "skill_theming.md"], "related_docs": ["src/unifyweaver/layout/layout.pl"], "original_answer": "Use the `row/3` predicate with layout options. Example: `row([justify(space_between), align(center), gap(md)], [logo, nav, user], Spec)` creates a horizontal layout with items spaced apart, centered vertically, and medium gaps between them. Generate code for your target platform (Vue, React Native, Flutter, SwiftUI) using `generate_layout(Spec, Target, Code)`. See skill_layout_system.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_layout_system_001_q3", "cluster_id": "skill_layout_system_001", "question": "What's the best way to lay out items side by side?", "answer": "Use the `row/3` predicate to lay out items side by side. Example: `row([justify(space_between), align(center), gap(md)], [logo, nav, user], Spec)` creates a horizontal flexbox layout with items spaced apart, centered vertically, and medium gaps between them. Then generate code for your target platform using `generate_layout(Spec, Target, Code)`. For alternative layouts, you can also use `wrap/3` for items that should wrap to the next line.", "question_type": "medium", "topics": ["Quickstart", "Layout System"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["layout", "flexbox", "spacing", "alignment"], "related_skills": ["skill_layout_system.md", "skill_component_library.md", "skill_responsive_design.md", "skill_theming.md"], "related_docs": ["src/unifyweaver/layout/layout.pl"], "original_answer": "Use the `row/3` predicate with layout options. Example: `row([justify(space_between), align(center), gap(md)], [logo, nav, user], Spec)` creates a horizontal layout with items spaced apart, centered vertically, and medium gaps between them. Generate code for your target platform (Vue, React Native, Flutter, SwiftUI) using `generate_layout(Spec, Target, Code)`. See skill_layout_system.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_layout_system_002_q0", "cluster_id": "skill_layout_system_002", "question": "How do I create a vertical stacked layout?", "answer": "Use the `column/3` predicate to create a vertical stacked layout. Example: `column([gap(lg), padding(md)], [header, body, footer], Spec)` stacks children vertically with large gaps between them and medium padding around the container. The gap option controls spacing between children, and padding controls spacing around the edges. Generate code for your target platform with `generate_layout(Spec, Target, Code)` where Target is `vue`, `react_native`, `flutter`, or `swiftui`.", "question_type": "medium", "topics": ["Quickstart", "Layout System"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["layout", "flexbox", "column", "vertical"], "related_skills": ["skill_layout_system.md", "skill_component_library.md", "skill_responsive_design.md"], "related_docs": ["src/unifyweaver/layout/layout.pl"], "original_answer": "Use the `column/3` predicate for vertical layouts. Example: `column([gap(lg), padding(md)], [header, body, footer], Spec)` stacks children vertically with large gaps and medium padding. Use `row/3` for horizontal layouts and `column/3` for vertical. Generate output for your target platform with `generate_layout(Spec, Target, Code)`. See skill_layout_system.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_layout_system_002_q1", "cluster_id": "skill_layout_system_002", "question": "How do I stack items vertically?", "answer": "Use the `column/3` predicate to stack items vertically. Example: `column([gap(lg), padding(md)], [header, body, footer], Spec)` stacks the children vertically with large gaps between them and medium padding around them. After defining your column layout, generate code for your target platform using `generate_layout(Spec, Target, Code)`.", "question_type": "medium", "topics": ["Quickstart", "Layout System"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["layout", "flexbox", "column", "vertical"], "related_skills": ["skill_layout_system.md", "skill_component_library.md", "skill_responsive_design.md"], "related_docs": ["src/unifyweaver/layout/layout.pl"], "original_answer": "Use the `column/3` predicate for vertical layouts. Example: `column([gap(lg), padding(md)], [header, body, footer], Spec)` stacks children vertically with large gaps and medium padding. Use `row/3` for horizontal layouts and `column/3` for vertical. Generate output for your target platform with `generate_layout(Spec, Target, Code)`. See skill_layout_system.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_layout_system_002_q2", "cluster_id": "skill_layout_system_002", "question": "How do I create a column layout?", "answer": "Use the `column/3` predicate to create a vertical layout. Example: `column([gap(lg), padding(md)], [header, body, footer], Spec)` stacks children vertically with large gaps between items and medium padding around them. After creating the spec, generate code for your platform using `generate_layout(Spec, Target, Code)` where Target is `vue`, `react_native`, `flutter`, or `swiftui`.", "question_type": "medium", "topics": ["Quickstart", "Layout System"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["layout", "flexbox", "column", "vertical"], "related_skills": ["skill_layout_system.md", "skill_component_library.md", "skill_responsive_design.md"], "related_docs": ["src/unifyweaver/layout/layout.pl"], "original_answer": "Use the `column/3` predicate for vertical layouts. Example: `column([gap(lg), padding(md)], [header, body, footer], Spec)` stacks children vertically with large gaps and medium padding. Use `row/3` for horizontal layouts and `column/3` for vertical. Generate output for your target platform with `generate_layout(Spec, Target, Code)`. See skill_layout_system.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_layout_system_002_q3", "cluster_id": "skill_layout_system_002", "question": "How do I arrange elements in a vertical column?", "answer": "Use the `column/3` predicate to arrange elements vertically. Example: `column([gap(lg), padding(md)], [header, body, footer], Spec)` stacks children vertically with large gaps between items and medium padding. The spacing scale supports named values like `lg` (24px) for gaps. Generate platform-specific code with `generate_layout(Spec, Target, Code)` where Target is `vue`, `react_native`, `flutter`, or `swiftui`.", "question_type": "medium", "topics": ["Quickstart", "Layout System"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["layout", "flexbox", "column", "vertical"], "related_skills": ["skill_layout_system.md", "skill_component_library.md", "skill_responsive_design.md"], "related_docs": ["src/unifyweaver/layout/layout.pl"], "original_answer": "Use the `column/3` predicate for vertical layouts. Example: `column([gap(lg), padding(md)], [header, body, footer], Spec)` stacks children vertically with large gaps and medium padding. Use `row/3` for horizontal layouts and `column/3` for vertical. Generate output for your target platform with `generate_layout(Spec, Target, Code)`. See skill_layout_system.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_layout_system_003_q0", "cluster_id": "skill_layout_system_003", "question": "How do I create a grid layout with multiple columns?", "answer": "Use the `grid/3` predicate to create multi-column grid layouts. The syntax is `grid([columns(N), gap(spacing)], Items, Spec)` where N is the number of columns. For example: `grid([columns(3), gap(md)], Items, Spec)` creates a 3-column grid with medium gaps. After defining your grid spec, generate platform-specific code using `generate_layout(Spec, Target, Code)` where Target is your platform (vue, react_native, flutter, swiftui).", "question_type": "medium", "topics": ["Quickstart", "Layout System"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["layout", "grid", "css-grid", "columns"], "related_skills": ["skill_layout_system.md", "skill_responsive_design.md"], "related_docs": ["src/unifyweaver/layout/layout.pl"], "original_answer": "Use the `grid/3` predicate to define grid layouts. Example: `grid([columns(3), gap(md)], Items, Spec)` creates a 3-column grid with medium gaps between items. For wrapping rows of items, use `wrap([gap(xs)], TagChips, Spec)`. Generate code with `generate_layout(Spec, Target, Code)` for your target platform. See skill_layout_system.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_layout_system_003_q1", "cluster_id": "skill_layout_system_003", "question": "How do I create a multi-column grid?", "answer": "Use the `grid/3` predicate with a `columns` option to create a multi-column grid. Example: `grid([columns(3), gap(md)], Items, Spec)` creates a 3-column grid with medium gaps between items. The `columns(N)` option specifies the number of columns. Then generate code for your target platform with `generate_layout(Spec, Target, Code)` where Target is `vue`, `react_native`, `flutter`, or `swiftui`. For items that need to wrap across multiple lines, use `wrap/3` instead.", "question_type": "medium", "topics": ["Quickstart", "Layout System"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["layout", "grid", "css-grid", "columns"], "related_skills": ["skill_layout_system.md", "skill_responsive_design.md"], "related_docs": ["src/unifyweaver/layout/layout.pl"], "original_answer": "Use the `grid/3` predicate to define grid layouts. Example: `grid([columns(3), gap(md)], Items, Spec)` creates a 3-column grid with medium gaps between items. For wrapping rows of items, use `wrap([gap(xs)], TagChips, Spec)`. Generate code with `generate_layout(Spec, Target, Code)` for your target platform. See skill_layout_system.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_layout_system_003_q2", "cluster_id": "skill_layout_system_003", "question": "How do I arrange items in a CSS Grid?", "answer": "Use the `grid/3` predicate to arrange items in a CSS Grid. Call `grid([columns(N), gap(Size)], Items, Spec)` where N is the number of columns and Size is the gap between items (e.g., `md` for medium, or a pixel value). For example: `grid([columns(3), gap(md)], Items, Spec)` creates a 3-column grid with medium spacing. Then generate code for your target platform using `generate_layout(Spec, Target, Code)`.", "question_type": "medium", "topics": ["Quickstart", "Layout System"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["layout", "grid", "css-grid", "columns"], "related_skills": ["skill_layout_system.md", "skill_responsive_design.md"], "related_docs": ["src/unifyweaver/layout/layout.pl"], "original_answer": "Use the `grid/3` predicate to define grid layouts. Example: `grid([columns(3), gap(md)], Items, Spec)` creates a 3-column grid with medium gaps between items. For wrapping rows of items, use `wrap([gap(xs)], TagChips, Spec)`. Generate code with `generate_layout(Spec, Target, Code)` for your target platform. See skill_layout_system.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_layout_system_003_q3", "cluster_id": "skill_layout_system_003", "question": "How do I create a grid with 3 columns?", "answer": "Use the `grid/3` predicate with the `columns(3)` option to create a 3-column grid: `grid([columns(3), gap(md)], Items, Spec)`. This creates a CSS Grid layout with 3 columns and medium gaps between items. Then generate code for your target platform with `generate_layout(Spec, Target, Code)` where Target is `vue`, `react_native`, `flutter`, or `swiftui`.", "question_type": "medium", "topics": ["Quickstart", "Layout System"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["layout", "grid", "css-grid", "columns"], "related_skills": ["skill_layout_system.md", "skill_responsive_design.md"], "related_docs": ["src/unifyweaver/layout/layout.pl"], "original_answer": "Use the `grid/3` predicate to define grid layouts. Example: `grid([columns(3), gap(md)], Items, Spec)` creates a 3-column grid with medium gaps between items. For wrapping rows of items, use `wrap([gap(xs)], TagChips, Spec)`. Generate code with `generate_layout(Spec, Target, Code)` for your target platform. See skill_layout_system.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_layout_system_004_q0", "cluster_id": "skill_layout_system_004", "question": "How do I center content on the page?", "answer": "Use `center/2` to center a single element on both axes: `center(child, Spec)`. For a centered container with max-width and padding, use `container/3`: `container([max_width(800), padding(lg)], [content], Spec)`. Then generate layout code with `generate_layout(Spec, Target, Code)` where Target is your platform (vue, react_native, flutter, swiftui).", "question_type": "medium", "topics": ["Quickstart", "Layout System"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["layout", "centering", "container", "alignment"], "related_skills": ["skill_layout_system.md", "skill_responsive_design.md"], "related_docs": ["src/unifyweaver/layout/layout.pl"], "original_answer": "Use `center/2` to center content on both axes, or `container/3` for max-width centering with padding. Example: `center(child, Spec)` centers a single child; `container([max_width(800), padding(lg)], [content], Spec)` creates a centered container with max-width and padding. Generate code with `generate_layout(Spec, Target, Code)`. See skill_layout_system.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_layout_system_004_q1", "cluster_id": "skill_layout_system_004", "question": "How do I center a container?", "answer": "Use `center/2` to center content on both axes: `center(child, Spec)`. For a centered container with max-width and padding, use `container/3`: `container([max_width(800), padding(lg)], [content], Spec)`. Then generate code with `generate_layout(Spec, Target, Code)` for your target platform (vue, react_native, flutter, or swiftui).", "question_type": "medium", "topics": ["Quickstart", "Layout System"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["layout", "centering", "container", "alignment"], "related_skills": ["skill_layout_system.md", "skill_responsive_design.md"], "related_docs": ["src/unifyweaver/layout/layout.pl"], "original_answer": "Use `center/2` to center content on both axes, or `container/3` for max-width centering with padding. Example: `center(child, Spec)` centers a single child; `container([max_width(800), padding(lg)], [content], Spec)` creates a centered container with max-width and padding. Generate code with `generate_layout(Spec, Target, Code)`. See skill_layout_system.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_layout_system_004_q2", "cluster_id": "skill_layout_system_004", "question": "How do I create a centered max-width layout?", "answer": "Use the `container/3` primitive for a centered max-width layout. Example: `container([max_width(800), padding(lg)], [content], Spec)` creates a centered container with a maximum width of 800px and large padding. For a simpler centered single element without max-width constraints, use `center(Child, Spec)`. After creating the spec, generate code for your target platform with `generate_layout(Spec, Target, Code)` where Target is 'vue', 'react_native', 'flutter', or 'swiftui'.", "question_type": "medium", "topics": ["Quickstart", "Layout System"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["layout", "centering", "container", "alignment"], "related_skills": ["skill_layout_system.md", "skill_responsive_design.md"], "related_docs": ["src/unifyweaver/layout/layout.pl"], "original_answer": "Use `center/2` to center content on both axes, or `container/3` for max-width centering with padding. Example: `center(child, Spec)` centers a single child; `container([max_width(800), padding(lg)], [content], Spec)` creates a centered container with max-width and padding. Generate code with `generate_layout(Spec, Target, Code)`. See skill_layout_system.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_layout_system_004_q3", "cluster_id": "skill_layout_system_004", "question": "How do I center items both horizontally and vertically?", "answer": "Use `center/2` to center a single child on both horizontal and vertical axes: `center(child, Spec)`. For multiple items or more control, use `container/3` with centering options: `container([max_width(800), padding(lg)], [content], Spec)`. Then generate code with `generate_layout(Spec, Target, Code)` targeting your platform (vue, react_native, flutter, swiftui).", "question_type": "medium", "topics": ["Quickstart", "Layout System"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["layout", "centering", "container", "alignment"], "related_skills": ["skill_layout_system.md", "skill_responsive_design.md"], "related_docs": ["src/unifyweaver/layout/layout.pl"], "original_answer": "Use `center/2` to center content on both axes, or `container/3` for max-width centering with padding. Example: `center(child, Spec)` centers a single child; `container([max_width(800), padding(lg)], [content], Spec)` creates a centered container with max-width and padding. Generate code with `generate_layout(Spec, Target, Code)`. See skill_layout_system.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_layout_system_005_q0", "cluster_id": "skill_layout_system_005", "question": "What spacing values should I use for gaps and padding?", "answer": "Use the named spacing scale for gaps and padding: `xs` (4px) for tight spacing like icons and chips, `sm` (8px) for spacing between related items, `md` (16px) for default spacing and sections, `lg` (24px) for major sections, `xl` (32px) for extra large gaps, and `xxl` (48px) for maximum spacing. You can also use raw numbers like `gap(12)` for custom values. Apply these with the `gap()` option in layout predicates like `row([gap(md)], Children, Spec)` or with `padding()` in containers.", "question_type": "medium", "topics": ["Quickstart", "Layout System"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["layout", "spacing", "scale", "design-system"], "related_skills": ["skill_layout_system.md"], "related_docs": ["src/unifyweaver/layout/layout.pl"], "original_answer": "Use the named spacing scale: `xs` (4px), `sm` (8px), `md` (16px), `lg` (24px), `xl` (32px), `xxl` (48px), or raw numbers like `gap(12)`. Use `xs`/`sm` for tight spacing (icons, chips), `md` for default/sections, `lg` for major sections, and `xl`/`xxl` for large gaps. Combine with `row()`, `column()`, or `grid()` predicates. See skill_layout_system.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_layout_system_005_q1", "cluster_id": "skill_layout_system_005", "question": "What are the standard spacing sizes?", "answer": "UnifyWeaver provides a standard spacing scale with named values that map to pixels: `xs` (4px) for tight spacing like icons and chips, `sm` (8px) for small spacing between related items, `md` (16px) for default/section spacing, `lg` (24px) for major sections, `xl` (32px) for extra large spacing, and `xxl` (48px) for maximum spacing. You can also use raw numbers like `gap(12)` for custom pixel values. Apply these with layout primitives like `row([gap(md)], Children, Spec)`, `column([gap(lg)], Children, Spec)`, or `grid([gap(md)], Items, Spec)`.", "question_type": "medium", "topics": ["Quickstart", "Layout System"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["layout", "spacing", "scale", "design-system"], "related_skills": ["skill_layout_system.md"], "related_docs": ["src/unifyweaver/layout/layout.pl"], "original_answer": "Use the named spacing scale: `xs` (4px), `sm` (8px), `md` (16px), `lg` (24px), `xl` (32px), `xxl` (48px), or raw numbers like `gap(12)`. Use `xs`/`sm` for tight spacing (icons, chips), `md` for default/sections, `lg` for major sections, and `xl`/`xxl` for large gaps. Combine with `row()`, `column()`, or `grid()` predicates. See skill_layout_system.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_layout_system_005_q2", "cluster_id": "skill_layout_system_005", "question": "How do I choose gap sizes?", "answer": "Use the named spacing scale based on context: `xs` (4px) for tight spacing like icons and chips, `sm` (8px) for spacing between related items, `md` (16px) as the default for general sections, `lg` (24px) for major sections, `xl` (32px) for extra-large gaps, and `xxl` (48px) for maximum spacing. You can also use raw pixel values like `gap(12)`. Apply these with layout predicates like `row([gap(md)], Children, Spec)`, `column([gap(lg)], Children, Spec)`, or `grid([gap(sm)], Items, Spec)`.", "question_type": "medium", "topics": ["Quickstart", "Layout System"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["layout", "spacing", "scale", "design-system"], "related_skills": ["skill_layout_system.md"], "related_docs": ["src/unifyweaver/layout/layout.pl"], "original_answer": "Use the named spacing scale: `xs` (4px), `sm` (8px), `md` (16px), `lg` (24px), `xl` (32px), `xxl` (48px), or raw numbers like `gap(12)`. Use `xs`/`sm` for tight spacing (icons, chips), `md` for default/sections, `lg` for major sections, and `xl`/`xxl` for large gaps. Combine with `row()`, `column()`, or `grid()` predicates. See skill_layout_system.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_layout_system_005_q3", "cluster_id": "skill_layout_system_005", "question": "What's the difference between xs, sm, md, lg spacing?", "answer": "The spacing scale defines five named values: `xs` (4px) for tight spacing like icons and chips, `sm` (8px) for spacing between related items, `md` (16px) as the default for sections, `lg` (24px) for major section separations, and `xl` (32px) for extra-large gaps. There's also `xxl` (48px) for maximum spacing. You can also use raw pixel numbers like `gap(12)` if needed.", "question_type": "medium", "topics": ["Quickstart", "Layout System"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["layout", "spacing", "scale", "design-system"], "related_skills": ["skill_layout_system.md"], "related_docs": ["src/unifyweaver/layout/layout.pl"], "original_answer": "Use the named spacing scale: `xs` (4px), `sm` (8px), `md` (16px), `lg` (24px), `xl` (32px), `xxl` (48px), or raw numbers like `gap(12)`. Use `xs`/`sm` for tight spacing (icons, chips), `md` for default/sections, `lg` for major sections, and `xl`/`xxl` for large gaps. Combine with `row()`, `column()`, or `grid()` predicates. See skill_layout_system.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_layout_system_006_q0", "cluster_id": "skill_layout_system_006", "question": "How do I generate layout code for different platforms like React Native or Flutter?", "answer": "Use `generate_layout(Spec, Target, Code)` where Target is `vue`, `react_native`, `flutter`, or `swiftui` to generate platform-specific layout code. Alternatively, use target-specific generators like `generate_vue_layout(Spec, Code)`, `generate_react_native_layout(Spec, Code)`, `generate_flutter_layout(Spec, Code)`, or `generate_swiftui_layout(Spec, Code)`. Each generator produces idiomatic code for its platform: Vue outputs Tailwind CSS classes, React Native outputs StyleSheet definitions, Flutter outputs widget trees, and SwiftUI outputs HStack/VStack layouts.", "question_type": "medium", "topics": ["Quickstart", "Layout System"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["layout", "code-generation", "cross-platform", "vue", "react-native", "flutter", "swiftui"], "related_skills": ["skill_layout_system.md"], "related_docs": ["src/unifyweaver/layout/layout.pl"], "original_answer": "Use `generate_layout(Spec, Target, Code)` where Target is `vue`, `react_native`, `flutter`, or `swiftui`. Or use target-specific generators like `generate_vue_layout(Spec, Code)` or `generate_flutter_layout(Spec, Code)`. Each outputs platform-idiomatic code: Vue uses Tailwind classes, React Native uses StyleSheet, Flutter uses widgets, SwiftUI uses HStack/VStack. See skill_layout_system.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "Base answer references 'skill_layout_system.md' which is not provided in the skill document excerpt. The actual API signatures and return types are not detailed in the base answer, so the tailored version makes reasonable inferences but lacks confirmation of exact parameter/return formats."}
{"pair_id": "skill_layout_system_006_q1", "cluster_id": "skill_layout_system_006", "question": "How do I output layout code for my target platform?", "answer": "Use `generate_layout(Spec, Target, Code)` where Target is `vue`, `react_native`, `flutter`, or `swiftui` to generate platform-specific layout code. Alternatively, use target-specific generators: `generate_vue_layout(Spec, Code)`, `generate_react_native_layout(Spec, Code)`, `generate_flutter_layout(Spec, Code)`, or `generate_swiftui_layout(Spec, Code)`. Each generator outputs idiomatic code for its platform: Vue uses Tailwind classes, React Native uses StyleSheet, Flutter uses widgets, and SwiftUI uses HStack/VStack.", "question_type": "medium", "topics": ["Quickstart", "Layout System"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["layout", "code-generation", "cross-platform", "vue", "react-native", "flutter", "swiftui"], "related_skills": ["skill_layout_system.md"], "related_docs": ["src/unifyweaver/layout/layout.pl"], "original_answer": "Use `generate_layout(Spec, Target, Code)` where Target is `vue`, `react_native`, `flutter`, or `swiftui`. Or use target-specific generators like `generate_vue_layout(Spec, Code)` or `generate_flutter_layout(Spec, Code)`. Each outputs platform-idiomatic code: Vue uses Tailwind classes, React Native uses StyleSheet, Flutter uses widgets, SwiftUI uses HStack/VStack. See skill_layout_system.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_layout_system_006_q2", "cluster_id": "skill_layout_system_006", "question": "How do I generate Vue/React/Flutter layouts?", "answer": "Use `generate_layout(Spec, Target, Code)` where Target is `vue`, `react_native`, `flutter`, or `swiftui` to generate layouts. Alternatively, use target-specific generators: `generate_vue_layout(Spec, Code)` for Vue, `generate_react_native_layout(Spec, Code)` for React Native, `generate_flutter_layout(Spec, Code)` for Flutter, or `generate_swiftui_layout(Spec, Code)` for SwiftUI. Each generator outputs platform-idiomatic code: Vue uses Tailwind CSS classes, React Native uses StyleSheet, Flutter uses widgets, and SwiftUI uses HStack/VStack. Start by defining your layout structure with primitives like `row/3`, `column/3`, or `grid/3`, then pass the resulting Spec to your chosen generator.", "question_type": "medium", "topics": ["Quickstart", "Layout System"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["layout", "code-generation", "cross-platform", "vue", "react-native", "flutter", "swiftui"], "related_skills": ["skill_layout_system.md"], "related_docs": ["src/unifyweaver/layout/layout.pl"], "original_answer": "Use `generate_layout(Spec, Target, Code)` where Target is `vue`, `react_native`, `flutter`, or `swiftui`. Or use target-specific generators like `generate_vue_layout(Spec, Code)` or `generate_flutter_layout(Spec, Code)`. Each outputs platform-idiomatic code: Vue uses Tailwind classes, React Native uses StyleSheet, Flutter uses widgets, SwiftUI uses HStack/VStack. See skill_layout_system.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_layout_system_006_q3", "cluster_id": "skill_layout_system_006", "question": "How do I convert layout specs to platform-specific code?", "answer": "Use `generate_layout(Spec, Target, Code)` where Target is `vue`, `react_native`, `flutter`, or `swiftui`. Each generator outputs platform-idiomatic code: Vue uses Tailwind classes, React Native uses StyleSheet, Flutter uses widgets, and SwiftUI uses HStack/VStack. Alternatively, use target-specific generators directly like `generate_vue_layout(Spec, Code)` or `generate_flutter_layout(Spec, Code)` for more explicit control.", "question_type": "medium", "topics": ["Quickstart", "Layout System"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["layout", "code-generation", "cross-platform", "vue", "react-native", "flutter", "swiftui"], "related_skills": ["skill_layout_system.md"], "related_docs": ["src/unifyweaver/layout/layout.pl"], "original_answer": "Use `generate_layout(Spec, Target, Code)` where Target is `vue`, `react_native`, `flutter`, or `swiftui`. Or use target-specific generators like `generate_vue_layout(Spec, Code)` or `generate_flutter_layout(Spec, Code)`. Each outputs platform-idiomatic code: Vue uses Tailwind classes, React Native uses StyleSheet, Flutter uses widgets, SwiftUI uses HStack/VStack. See skill_layout_system.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_ml_tools_001_q0", "cluster_id": "skill_ml_tools_001", "question": "Which embedding model should I use for semantic search?", "answer": "For semantic search, use **nomic-embed-text-v1.5** for best asymmetric search quality, or **all-MiniLM-L6-v2** if you need a lightweight, fast alternative with broad deployment support (Go, Rust, C#). Choose based on your performance requirements and runtime constraints.", "question_type": "medium", "topics": ["Quickstart", "ML Tools (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["embedding", "model-selection", "semantic-search"], "related_skills": ["skill_ml_tools.md", "skill_embedding_models.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "education/book-13-semantic-search/", "education/book-14-ai-training/"], "original_answer": "For semantic search, use **nomic-embed-text-v1.5** - it has the best asymmetric search quality. For fast/lightweight deployments, use **all-MiniLM-L6-v2**. For entropy computation, use BERT or ModernBERT for calibrated logits. For Go/Rust/C# deployment, all-MiniLM-L6-v2 has the widest ONNX support. See skill_ml_tools.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_ml_tools_001_q1", "cluster_id": "skill_ml_tools_001", "question": "What's the best embedding model for Q&A?", "answer": "For Q&A semantic search, use **nomic-embed-text-v1.5** - it has the best asymmetric search quality for question-answer pairs. If you need a lightweight alternative, **all-MiniLM-L6-v2** is faster and supports more deployment targets (Go, Rust, C#) via ONNX, though with lower semantic quality.", "question_type": "medium", "topics": ["Quickstart", "ML Tools (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["embedding", "model-selection", "semantic-search"], "related_skills": ["skill_ml_tools.md", "skill_embedding_models.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "education/book-13-semantic-search/", "education/book-14-ai-training/"], "original_answer": "For semantic search, use **nomic-embed-text-v1.5** - it has the best asymmetric search quality. For fast/lightweight deployments, use **all-MiniLM-L6-v2**. For entropy computation, use BERT or ModernBERT for calibrated logits. For Go/Rust/C# deployment, all-MiniLM-L6-v2 has the widest ONNX support. See skill_ml_tools.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_ml_tools_001_q2", "cluster_id": "skill_ml_tools_001", "question": "How do I choose between nomic, MiniLM, and BERT embeddings?", "answer": "Choose your embedding model based on your specific use case: Use **nomic-embed-text-v1.5** for semantic search applications\u2014it delivers the best asymmetric search quality for Q&A scenarios. Use **all-MiniLM-L6-v2** if you need speed and lightweight performance, or if you're deploying to Go, Rust, or C# (it has the widest ONNX support). Use **BERT or ModernBERT** if you need calibrated logits for entropy computation. Consider your deployment environment and performance requirements when making your choice.", "question_type": "medium", "topics": ["Quickstart", "ML Tools (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["embedding", "model-selection", "semantic-search"], "related_skills": ["skill_ml_tools.md", "skill_embedding_models.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "education/book-13-semantic-search/", "education/book-14-ai-training/"], "original_answer": "For semantic search, use **nomic-embed-text-v1.5** - it has the best asymmetric search quality. For fast/lightweight deployments, use **all-MiniLM-L6-v2**. For entropy computation, use BERT or ModernBERT for calibrated logits. For Go/Rust/C# deployment, all-MiniLM-L6-v2 has the widest ONNX support. See skill_ml_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_ml_tools_002_q0", "cluster_id": "skill_ml_tools_002", "question": "How do I train a federated model on my bookmark data?", "answer": "To train a federated model on your bookmark data, use the training script with your data file and preferred clustering method:\n\n```bash\npython3 scripts/train_pearltrees_federated.py \\\n  reports/pearltrees_targets.jsonl \\\n  models/federated.pkl \\\n  --model nomic-ai/nomic-embed-text-v1.5 \\\n  --cluster-method mst\n```\n\nThis script learns orthogonal transformations (Procrustes projection) from query to document space and applies MST clustering to preserve your bookmark hierarchy. The model will be saved to `models/federated.pkl` for later inference.", "question_type": "long", "topics": ["Quickstart", "ML Tools (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["training", "procrustes", "mst-clustering", "federation"], "related_skills": ["skill_ml_tools.md", "skill_train_model.md"], "related_docs": ["scripts/train_pearltrees_federated.py", "docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "Use the training script with your data and desired clustering method:\n```bash\npython3 scripts/train_pearltrees_federated.py \\\n  reports/pearltrees_targets.jsonl \\\n  models/federated.pkl \\\n  --model nomic-ai/nomic-embed-text-v1.5 \\\n  --cluster-method mst\n```\nThis learns orthogonal transformations (Procrustes) from query to document space and applies MST clustering to preserve hierarchy. See skill_ml_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_ml_tools_002_q1", "cluster_id": "skill_ml_tools_002", "question": "What's the process for training ML models?", "answer": "To train ML models in UnifyWeaver, use the federated training script with your data:\n\n```bash\npython3 scripts/train_pearltrees_federated.py \\\n  reports/pearltrees_targets.jsonl \\\n  models/federated.pkl \\\n  --model nomic-ai/nomic-embed-text-v1.5 \\\n  --cluster-method mst\n```\n\nThis pipeline: (1) generates embeddings from your text data, (2) learns orthogonal transformations (Procrustes projection) from query to document space, and (3) applies MST clustering to build and preserve hierarchy. The script outputs a trained model file ready for inference. Choose your embedding model based on your use case\u2014nomic-embed-text-v1.5 for best semantic search quality, or all-MiniLM-L6-v2 for lightweight deployment.", "question_type": "long", "topics": ["Quickstart", "ML Tools (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["training", "procrustes", "mst-clustering", "federation"], "related_skills": ["skill_ml_tools.md", "skill_train_model.md"], "related_docs": ["scripts/train_pearltrees_federated.py", "docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "Use the training script with your data and desired clustering method:\n```bash\npython3 scripts/train_pearltrees_federated.py \\\n  reports/pearltrees_targets.jsonl \\\n  models/federated.pkl \\\n  --model nomic-ai/nomic-embed-text-v1.5 \\\n  --cluster-method mst\n```\nThis learns orthogonal transformations (Procrustes) from query to document space and applies MST clustering to preserve hierarchy. See skill_ml_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_ml_tools_002_q2", "cluster_id": "skill_ml_tools_002", "question": "How do I use Procrustes projection for bookmarks?", "answer": "To use Procrustes projection for bookmarks, run the training script with your bookmark data:\n\n```bash\npython3 scripts/train_pearltrees_federated.py \\\n  reports/pearltrees_targets.jsonl \\\n  models/federated.pkl \\\n  --model nomic-ai/nomic-embed-text-v1.5 \\\n  --cluster-method mst\n```\n\nThis learns orthogonal transformations (Procrustes) that project embeddings from query space to document space, while MST clustering preserves the bookmark hierarchy. The resulting model can then be used for semantic inference with `scripts/infer_pearltrees_federated.py`.", "question_type": "long", "topics": ["Quickstart", "ML Tools (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["training", "procrustes", "mst-clustering", "federation"], "related_skills": ["skill_ml_tools.md", "skill_train_model.md"], "related_docs": ["scripts/train_pearltrees_federated.py", "docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "Use the training script with your data and desired clustering method:\n```bash\npython3 scripts/train_pearltrees_federated.py \\\n  reports/pearltrees_targets.jsonl \\\n  models/federated.pkl \\\n  --model nomic-ai/nomic-embed-text-v1.5 \\\n  --cluster-method mst\n```\nThis learns orthogonal transformations (Procrustes) from query to document space and applies MST clustering to preserve hierarchy. See skill_ml_tools.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer mentions 'query to document space' but could be clearer that Procrustes is specifically an orthogonal transformation technique. The answer would benefit from explaining why Procrustes is useful for bookmarks (e.g., preserving hierarchy structure during projection), but this level of detail may not be in the base answer."}
{"pair_id": "skill_ml_tools_003_q0", "cluster_id": "skill_ml_tools_003", "question": "How do I run inference to suggest folders for a bookmark?", "answer": "To run inference for folder suggestions on a bookmark, use the bookmark filing assistant:\n\n```bash\npython3 scripts/bookmark_filing_assistant.py \\\n  --model models/federated.pkl \\\n  --bookmark \"https://example.com\" \\\n  --suggest-folders 5\n```\n\nAlternatively, embed your bookmark's URL or title as a query and use the general inference script:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/federated.pkl \\\n  --query \"bookmark title or description\" \\\n  --top-k 5\n```\n\nThe system embeds the bookmark, projects it through learned matrices from your trained model, and ranks existing folders by relevance. This gives you ranked folder suggestions to file the bookmark into.", "question_type": "long", "topics": ["Quickstart", "ML Tools (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["inference", "semantic-search", "ranking"], "related_skills": ["skill_ml_tools.md", "skill_semantic_inference.md"], "related_docs": ["scripts/infer_pearltrees_federated.py", "scripts/bookmark_filing_assistant.py"], "original_answer": "Query your trained model with:\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/federated.pkl \\\n  --query \"your search query\" \\\n  --top-k 5\n```\nOr use the bookmark filing assistant:\n```bash\npython3 scripts/bookmark_filing_assistant.py \\\n  --model models/federated.pkl \\\n  --bookmark \"https://example.com\" \\\n  --suggest-folders 5\n```\nThe query gets embedded, projected through learned matrices, and ranked against bookmarks. See skill_ml_tools.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "Base answer mentions bookmark_filing_assistant.py but this script may not exist or may have different parameters. The general inference approach is more reliable but requires the user to manually convert bookmark metadata into a query string. Confidence is moderate due to uncertainty about script availability and exact parameter names."}
{"pair_id": "skill_ml_tools_003_q1", "cluster_id": "skill_ml_tools_003", "question": "How do I query a trained model?", "answer": "Query your trained model using the inference script:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/federated.pkl \\\n  --query \"your search query\" \\\n  --top-k 5\n```\n\nThis embeds your query, projects it through the learned transformation matrices, and returns the top-k ranked results from your dataset.\n\nFor bookmark filing, use:\n\n```bash\npython3 scripts/bookmark_filing_assistant.py \\\n  --model models/federated.pkl \\\n  --bookmark \"https://example.com\" \\\n  --suggest-folders 5\n```", "question_type": "long", "topics": ["Quickstart", "ML Tools (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["inference", "semantic-search", "ranking"], "related_skills": ["skill_ml_tools.md", "skill_semantic_inference.md"], "related_docs": ["scripts/infer_pearltrees_federated.py", "scripts/bookmark_filing_assistant.py"], "original_answer": "Query your trained model with:\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/federated.pkl \\\n  --query \"your search query\" \\\n  --top-k 5\n```\nOr use the bookmark filing assistant:\n```bash\npython3 scripts/bookmark_filing_assistant.py \\\n  --model models/federated.pkl \\\n  --bookmark \"https://example.com\" \\\n  --suggest-folders 5\n```\nThe query gets embedded, projected through learned matrices, and ranked against bookmarks. See skill_ml_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_ml_tools_003_q2", "cluster_id": "skill_ml_tools_003", "question": "How do I get folder suggestions from my ML model?", "answer": "To get folder suggestions from your ML model, run inference with your trained model:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/federated.pkl \\\n  --query \"your search query\" \\\n  --top-k 5\n```\n\nThe query is embedded, projected through the learned Procrustes matrices, and ranked against your bookmark hierarchy to suggest matching folders. For direct bookmark filing, use the bookmark filing assistant:\n\n```bash\npython3 scripts/bookmark_filing_assistant.py \\\n  --model models/federated.pkl \\\n  --bookmark \"https://example.com\" \\\n  --suggest-folders 5\n```\n\nBoth approaches use your trained federated model to provide contextual folder recommendations.", "question_type": "long", "topics": ["Quickstart", "ML Tools (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["inference", "semantic-search", "ranking"], "related_skills": ["skill_ml_tools.md", "skill_semantic_inference.md"], "related_docs": ["scripts/infer_pearltrees_federated.py", "scripts/bookmark_filing_assistant.py"], "original_answer": "Query your trained model with:\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/federated.pkl \\\n  --query \"your search query\" \\\n  --top-k 5\n```\nOr use the bookmark filing assistant:\n```bash\npython3 scripts/bookmark_filing_assistant.py \\\n  --model models/federated.pkl \\\n  --bookmark \"https://example.com\" \\\n  --suggest-folders 5\n```\nThe query gets embedded, projected through learned matrices, and ranked against bookmarks. See skill_ml_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_ml_tools_004_q0", "cluster_id": "skill_ml_tools_004", "question": "How do I measure if my hierarchy is good?", "answer": "Use the J = D/(1+H) objective to evaluate hierarchy quality:\n\n```bash\npython3 scripts/mindmap/hierarchy_objective.py \\\n  --tree hierarchy.json \\\n  --embeddings embeddings.npy\n```\n\nThis calculates three metrics:\n- **D** (semantic distance) - measures how semantically close child nodes are to their parents\n- **H** (entropy gain) - measures how informative each hierarchical split is\n- **J** (objective) - combines both: J = D/(1+H). Lower scores are better; J < 0.2 indicates good hierarchy quality\n\nFor more accurate entropy calculations, add: `--entropy-source logits --entropy-model bert-base-uncased`", "question_type": "long", "topics": ["Quickstart", "ML Tools (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["hierarchy", "evaluation", "objective-function"], "related_skills": ["skill_ml_tools.md", "skill_hierarchy_objective.md"], "related_docs": ["scripts/mindmap/hierarchy_objective.py"], "original_answer": "Use the J = D/(1+H) objective to evaluate hierarchy quality:\n```bash\npython3 scripts/mindmap/hierarchy_objective.py \\\n  --tree hierarchy.json \\\n  --embeddings embeddings.npy\n```\nThis calculates:\n- **D** (semantic distance) - how close nodes are to parents\n- **H** (entropy gain) - how informative each split is\n- **J** (objective) - lower is better, < 0.2 is good\n\nOptional entropy sources: `--entropy-source logits --entropy-model bert-base-uncased` for better accuracy. See skill_ml_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_ml_tools_004_q1", "cluster_id": "skill_ml_tools_004", "question": "What makes a good bookmark organization?", "answer": "A good bookmark organization minimizes semantic distance while maximizing information gain at each hierarchical level. Use the J = D/(1+H) objective to measure this: J = semantic_distance / (1 + entropy_gain). A score below 0.2 indicates well-organized bookmarks where parent-child relationships are semantically coherent and category splits are informative. To evaluate your organization:\n\n```bash\npython3 scripts/mindmap/hierarchy_objective.py \\\n  --tree hierarchy.json \\\n  --embeddings embeddings.npy\n```\n\nFor more precise entropy calculation, add: `--entropy-source logits --entropy-model bert-base-uncased`. Lower J scores mean better organization\u2014nodes cluster meaningfully under their parents, and each level of hierarchy adds genuine information rather than arbitrary splits.", "question_type": "long", "topics": ["Quickstart", "ML Tools (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["hierarchy", "evaluation", "objective-function"], "related_skills": ["skill_ml_tools.md", "skill_hierarchy_objective.md"], "related_docs": ["scripts/mindmap/hierarchy_objective.py"], "original_answer": "Use the J = D/(1+H) objective to evaluate hierarchy quality:\n```bash\npython3 scripts/mindmap/hierarchy_objective.py \\\n  --tree hierarchy.json \\\n  --embeddings embeddings.npy\n```\nThis calculates:\n- **D** (semantic distance) - how close nodes are to parents\n- **H** (entropy gain) - how informative each split is\n- **J** (objective) - lower is better, < 0.2 is good\n\nOptional entropy sources: `--entropy-source logits --entropy-model bert-base-uncased` for better accuracy. See skill_ml_tools.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "The base answer provides a metric for evaluating organization quality, but the question asks 'what makes a good bookmark organization' which could also mean conceptual principles (semantic coherence, meaningful categorization, etc.). The tailored answer stays technical/metric-focused rather than covering holistic organizational principles. The answer is accurate for the ML/metrics perspective but may not fully capture the broader intent of the question."}
{"pair_id": "skill_ml_tools_004_q2", "cluster_id": "skill_ml_tools_004", "question": "How do I calculate the J objective?", "answer": "To calculate the J objective for hierarchy quality, use:\n\n```bash\npython3 scripts/mindmap/hierarchy_objective.py \\\n  --tree hierarchy.json \\\n  --embeddings embeddings.npy\n```\n\nThe J = D/(1+H) metric evaluates your hierarchy by computing:\n- **D** (semantic distance) - measures how close child nodes are to their parents in embedding space\n- **H** (entropy gain) - measures information gain from each split in the hierarchy\n- **J** (objective value) - lower values indicate better hierarchies; values below 0.2 are considered good\n\nFor improved accuracy, add entropy computation from model logits:\n\n```bash\npython3 scripts/mindmap/hierarchy_objective.py \\\n  --tree hierarchy.json \\\n  --embeddings embeddings.npy \\\n  --entropy-source logits \\\n  --entropy-model bert-base-uncased\n```", "question_type": "long", "topics": ["Quickstart", "ML Tools (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["hierarchy", "evaluation", "objective-function"], "related_skills": ["skill_ml_tools.md", "skill_hierarchy_objective.md"], "related_docs": ["scripts/mindmap/hierarchy_objective.py"], "original_answer": "Use the J = D/(1+H) objective to evaluate hierarchy quality:\n```bash\npython3 scripts/mindmap/hierarchy_objective.py \\\n  --tree hierarchy.json \\\n  --embeddings embeddings.npy\n```\nThis calculates:\n- **D** (semantic distance) - how close nodes are to parents\n- **H** (entropy gain) - how informative each split is\n- **J** (objective) - lower is better, < 0.2 is good\n\nOptional entropy sources: `--entropy-source logits --entropy-model bert-base-uncased` for better accuracy. See skill_ml_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_ml_tools_004_q3", "cluster_id": "skill_ml_tools_004", "question": "How do I evaluate hierarchy quality?", "answer": "To evaluate hierarchy quality, use the J = D/(1+H) objective:\n\n```bash\npython3 scripts/mindmap/hierarchy_objective.py \\\n  --tree hierarchy.json \\\n  --embeddings embeddings.npy\n```\n\nThis computes:\n- **D** (semantic distance) - closeness of nodes to parents\n- **H** (entropy gain) - informativeness of each split\n- **J** (objective score) - lower values are better; < 0.2 indicates good hierarchy quality\n\nFor improved accuracy, optionally compute entropy from calibrated model logits:\n\n```bash\npython3 scripts/mindmap/hierarchy_objective.py \\\n  --tree hierarchy.json \\\n  --embeddings embeddings.npy \\\n  --entropy-source logits \\\n  --entropy-model bert-base-uncased\n```", "question_type": "long", "topics": ["Quickstart", "ML Tools (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["hierarchy", "evaluation", "objective-function"], "related_skills": ["skill_ml_tools.md", "skill_hierarchy_objective.md"], "related_docs": ["scripts/mindmap/hierarchy_objective.py"], "original_answer": "Use the J = D/(1+H) objective to evaluate hierarchy quality:\n```bash\npython3 scripts/mindmap/hierarchy_objective.py \\\n  --tree hierarchy.json \\\n  --embeddings embeddings.npy\n```\nThis calculates:\n- **D** (semantic distance) - how close nodes are to parents\n- **H** (entropy gain) - how informative each split is\n- **J** (objective) - lower is better, < 0.2 is good\n\nOptional entropy sources: `--entropy-source logits --entropy-model bert-base-uncased` for better accuracy. See skill_ml_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_ml_tools_005_q0", "cluster_id": "skill_ml_tools_005", "question": "How do I visualize embeddings and bookmark clusters?", "answer": "Start the density explorer visualization tool to explore embeddings and bookmark clusters:\n\n1. Start the Flask API backend:\n   python tools/density_explorer/flask_api.py --port 5000\n\n2. Start the Vue frontend:\n   cd tools/density_explorer/vue && npm run dev\n\n3. Open http://localhost:5173 in your browser\n\nThe density explorer provides:\n- Density heatmaps showing embedding concentration\n- Tree overlays (MST or J-guided clustering) to visualize bookmark hierarchy\n- Node selection and inspection to examine individual bookmarks\n- Depth filtering to focus on specific tree levels\n- Re-rooting functionality to reorganize and explore tree structure\n\nClick on nodes to inspect details and interactively modify the tree structure.", "question_type": "medium", "topics": ["Quickstart", "ML Tools (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["visualization", "density-explorer", "embeddings", "clustering"], "related_skills": ["skill_ml_tools.md", "skill_density_explorer.md"], "related_docs": ["tools/density_explorer/"], "original_answer": "Start the density explorer visualization:\n```bash\npython tools/density_explorer/flask_api.py --port 5000\ncd tools/density_explorer/vue && npm run dev\n```\nThen open http://localhost:5173. Features include density heatmaps, tree overlays (MST or J-guided), node selection, depth filtering, and re-rooting for exploration. Click nodes to inspect and reorganize tree structure. See skill_ml_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_ml_tools_005_q1", "cluster_id": "skill_ml_tools_005", "question": "How do I see my bookmark organization visually?", "answer": "Use the density explorer tool to visualize your bookmark organization. Start the Flask API and Vue frontend:\n\n```bash\npython tools/density_explorer/flask_api.py --port 5000\ncd tools/density_explorer/vue && npm run dev\n```\n\nThen open http://localhost:5173 in your browser. The visualization shows density heatmaps of your bookmarks, tree overlays representing their hierarchical relationships, and allows you to filter by depth, select nodes to inspect details, and re-root the tree to explore different organizational perspectives.", "question_type": "medium", "topics": ["Quickstart", "ML Tools (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["visualization", "density-explorer", "embeddings", "clustering"], "related_skills": ["skill_ml_tools.md", "skill_density_explorer.md"], "related_docs": ["tools/density_explorer/"], "original_answer": "Start the density explorer visualization:\n```bash\npython tools/density_explorer/flask_api.py --port 5000\ncd tools/density_explorer/vue && npm run dev\n```\nThen open http://localhost:5173. Features include density heatmaps, tree overlays (MST or J-guided), node selection, depth filtering, and re-rooting for exploration. Click nodes to inspect and reorganize tree structure. See skill_ml_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_ml_tools_005_q2", "cluster_id": "skill_ml_tools_005", "question": "How do I use the density explorer?", "answer": "To use the density explorer, start the Flask API backend and Vue frontend:\n\n1. Start the backend: `python tools/density_explorer/flask_api.py --port 5000`\n2. Start the frontend: `cd tools/density_explorer/vue && npm run dev`\n3. Open http://localhost:5173 in your browser\n\nThe density explorer provides interactive visualization with density heatmaps, tree overlays (MST or J-guided), node selection, depth filtering, and re-rooting. Click nodes to inspect and reorganize the tree structure for exploration.", "question_type": "medium", "topics": ["Quickstart", "ML Tools (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["visualization", "density-explorer", "embeddings", "clustering"], "related_skills": ["skill_ml_tools.md", "skill_density_explorer.md"], "related_docs": ["tools/density_explorer/"], "original_answer": "Start the density explorer visualization:\n```bash\npython tools/density_explorer/flask_api.py --port 5000\ncd tools/density_explorer/vue && npm run dev\n```\nThen open http://localhost:5173. Features include density heatmaps, tree overlays (MST or J-guided), node selection, depth filtering, and re-rooting for exploration. Click nodes to inspect and reorganize tree structure. See skill_ml_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_ml_tools_005_q3", "cluster_id": "skill_ml_tools_005", "question": "How do I view embedding clusters?", "answer": "To view embedding clusters, use the density explorer visualization tool. Start the backend API with `python tools/density_explorer/flask_api.py --port 5000`, then start the Vue frontend with `cd tools/density_explorer/vue && npm run dev`. Open http://localhost:5173 in your browser. The tool displays density heatmaps of your embeddings, overlay options for tree structures (MST or J-guided clustering), and allows you to select nodes, filter by depth, and re-root the tree for interactive exploration of cluster structure.", "question_type": "medium", "topics": ["Quickstart", "ML Tools (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["visualization", "density-explorer", "embeddings", "clustering"], "related_skills": ["skill_ml_tools.md", "skill_density_explorer.md"], "related_docs": ["tools/density_explorer/"], "original_answer": "Start the density explorer visualization:\n```bash\npython tools/density_explorer/flask_api.py --port 5000\ncd tools/density_explorer/vue && npm run dev\n```\nThen open http://localhost:5173. Features include density heatmaps, tree overlays (MST or J-guided), node selection, depth filtering, and re-rooting for exploration. Click nodes to inspect and reorganize tree structure. See skill_ml_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_ml_tools_006_q0", "cluster_id": "skill_ml_tools_006", "question": "What's the complete workflow for setting up semantic search on my bookmarks?", "answer": "To set up semantic search on your bookmarks:\n\n1. **Prepare data**: Ensure your bookmarks are in JSONL format with text content\n2. **Generate embeddings**: `python3 scripts/generate_embeddings.py --input data.jsonl --model nomic-ai/nomic-embed-text-v1.5`\n3. **Train federated model**: `python3 scripts/train_pearltrees_federated.py data.jsonl models/search.pkl --cluster-method mst`\n4. **Test with queries**: `python3 scripts/infer_pearltrees_federated.py --model models/search.pkl --query \"your search term\"`\n5. **Evaluate hierarchy quality**: `python3 scripts/mindmap/hierarchy_objective.py --tree tree.json --embeddings embeddings.npy`\n6. **Visualize results**: Run `python tools/density_explorer/flask_api.py --port 5000` and open the Vue interface at http://localhost:5173\n\nFor nomic-embed-text-v1.5: Best for asymmetric Q&A search; use all-MiniLM-L6-v2 for lightweight/fast alternatives. See skill_ml_tools.md and sub-skills for model selection and advanced tuning.", "question_type": "medium", "topics": ["Quickstart", "ML Tools (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["workflow", "semantic-search", "end-to-end", "training", "inference"], "related_skills": ["skill_ml_tools.md", "skill_embedding_models.md", "skill_train_model.md", "skill_semantic_inference.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "education/book-13-semantic-search/", "education/book-14-ai-training/"], "original_answer": "Complete semantic search workflow:\n1. **Generate embeddings**: `python3 scripts/generate_embeddings.py --input data.jsonl --model nomic-ai/nomic-embed-text-v1.5`\n2. **Train federated model**: `python3 scripts/train_pearltrees_federated.py data.jsonl models/search.pkl --cluster-method mst`\n3. **Test inference**: `python3 scripts/infer_pearltrees_federated.py --model models/search.pkl --query \"test\"`\n4. **Evaluate quality**: `python3 scripts/mindmap/hierarchy_objective.py --tree tree.json --embeddings embeddings.npy`\n5. **Visualize**: Start density explorer to inspect results\nSee skill_ml_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_ml_tools_006_q1", "cluster_id": "skill_ml_tools_006", "question": "How do I build a complete bookmark search system?", "answer": "To build a complete bookmark search system: (1) Generate embeddings from your bookmark data using `python3 scripts/generate_embeddings.py --input bookmarks.jsonl --model nomic-ai/nomic-embed-text-v1.5`; (2) Train a federated model with `python3 scripts/train_pearltrees_federated.py bookmarks.jsonl models/search.pkl --cluster-method mst`; (3) Run inference queries with `python3 scripts/infer_pearltrees_federated.py --model models/search.pkl --query \"your search\"` to get ranked bookmark suggestions; (4) Evaluate hierarchy quality using `python3 scripts/mindmap/hierarchy_objective.py` to measure J = D/(1+H); (5) Visualize results with the density explorer (`python tools/density_explorer/flask_api.py`) to inspect embeddings and clusters. This pipeline handles text encoding, semantic search ranking, and hierarchy optimization.", "question_type": "medium", "topics": ["Quickstart", "ML Tools (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["workflow", "semantic-search", "end-to-end", "training", "inference"], "related_skills": ["skill_ml_tools.md", "skill_embedding_models.md", "skill_train_model.md", "skill_semantic_inference.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "education/book-13-semantic-search/", "education/book-14-ai-training/"], "original_answer": "Complete semantic search workflow:\n1. **Generate embeddings**: `python3 scripts/generate_embeddings.py --input data.jsonl --model nomic-ai/nomic-embed-text-v1.5`\n2. **Train federated model**: `python3 scripts/train_pearltrees_federated.py data.jsonl models/search.pkl --cluster-method mst`\n3. **Test inference**: `python3 scripts/infer_pearltrees_federated.py --model models/search.pkl --query \"test\"`\n4. **Evaluate quality**: `python3 scripts/mindmap/hierarchy_objective.py --tree tree.json --embeddings embeddings.npy`\n5. **Visualize**: Start density explorer to inspect results\nSee skill_ml_tools.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_ml_tools_006_q2", "cluster_id": "skill_ml_tools_006", "question": "What are the steps to train and deploy a model?", "answer": "To train and deploy a semantic search model:\n\n**Training:**\n1. Generate embeddings: `python3 scripts/generate_embeddings.py --input data.jsonl --model nomic-ai/nomic-embed-text-v1.5`\n2. Train federated model: `python3 scripts/train_pearltrees_federated.py data.jsonl models/search.pkl --cluster-method mst`\n3. Evaluate hierarchy quality: `python3 scripts/mindmap/hierarchy_objective.py --tree tree.json --embeddings embeddings.npy`\n\n**Testing & Deployment:**\n4. Test inference locally: `python3 scripts/infer_pearltrees_federated.py --model models/search.pkl --query \"test\"`\n5. Visualize results with density explorer for validation before deployment\n\nFor production deployment, select an embedding model with your target runtime support (nomic-embed-text-v1.5 for Python, all-MiniLM-L6-v2 for cross-platform including Go/Rust/C#).", "question_type": "medium", "topics": ["Quickstart", "ML Tools (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["workflow", "semantic-search", "end-to-end", "training", "inference"], "related_skills": ["skill_ml_tools.md", "skill_embedding_models.md", "skill_train_model.md", "skill_semantic_inference.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "education/book-13-semantic-search/", "education/book-14-ai-training/"], "original_answer": "Complete semantic search workflow:\n1. **Generate embeddings**: `python3 scripts/generate_embeddings.py --input data.jsonl --model nomic-ai/nomic-embed-text-v1.5`\n2. **Train federated model**: `python3 scripts/train_pearltrees_federated.py data.jsonl models/search.pkl --cluster-method mst`\n3. **Test inference**: `python3 scripts/infer_pearltrees_federated.py --model models/search.pkl --query \"test\"`\n4. **Evaluate quality**: `python3 scripts/mindmap/hierarchy_objective.py --tree tree.json --embeddings embeddings.npy`\n5. **Visualize**: Start density explorer to inspect results\nSee skill_ml_tools.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_networking_001_q0", "cluster_id": "skill_networking_001", "question": "How do I create an HTTP server in Python?", "answer": "To create an HTTP server in Python, use the Networking skill's `generate_http_server(python, Endpoints, [port(8080), cors(true)], Code)` function. Define your endpoints using `endpoint('/path', handler_name, [methods(['GET'])])` format. This generates a Flask server with built-in CORS support, JSON handling, and error handling. The server will listen on port 8080 by default. For example: `generate_http_server(python, [endpoint('/api/process', process_data, [methods(['POST'])])], [port(8080), cors(true)], Code)` produces a complete Flask application ready to run.", "question_type": "medium", "topics": ["Quickstart", "Networking"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["http-server", "python", "flask"], "related_skills": ["skill_networking.md", "skill_infrastructure.md", "skill_deployment.md", "skill_authentication.md", "skill_web_frameworks.md"], "related_docs": ["src/unifyweaver/glue/network_glue.pl"], "original_answer": "Use the Networking skill to generate HTTP servers. Call `generate_http_server(python, Endpoints, [port(8080), cors(true)], Code)` with your endpoint definitions. For example, `endpoint('/api/process', process_data, [methods(['POST'])])` generates a Flask server with CORS enabled, JSON handling, and error handling. The server runs on port 8080 and accepts POST requests. See skill_networking.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_networking_001_q1", "cluster_id": "skill_networking_001", "question": "How do I build a web server?", "answer": "To build a web server, use the Networking skill's `generate_http_server()` function. Specify your target language (python, go, or rust), define endpoints as `endpoint(Path, Handler, Options)`, and set options like `port(8080)` and `cors(true)`. For example: `generate_http_server(python, [endpoint('/api/process', process_data, [methods(['POST'])])], [port(8080), cors(true)], Code)` generates a Flask server with CORS, JSON handling, and error handling. The generated server is production-ready and runs on your specified port.", "question_type": "medium", "topics": ["Quickstart", "Networking"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["http-server", "python", "flask"], "related_skills": ["skill_networking.md", "skill_infrastructure.md", "skill_deployment.md", "skill_authentication.md", "skill_web_frameworks.md"], "related_docs": ["src/unifyweaver/glue/network_glue.pl"], "original_answer": "Use the Networking skill to generate HTTP servers. Call `generate_http_server(python, Endpoints, [port(8080), cors(true)], Code)` with your endpoint definitions. For example, `endpoint('/api/process', process_data, [methods(['POST'])])` generates a Flask server with CORS enabled, JSON handling, and error handling. The server runs on port 8080 and accepts POST requests. See skill_networking.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_networking_001_q2", "cluster_id": "skill_networking_001", "question": "How do I set up a Flask server?", "answer": "To set up a Flask server, use the Networking skill's `generate_http_server(python, Endpoints, [port(8080), cors(true)], Code)` function. Define endpoints using `endpoint('/path', handler_name, [methods(['GET'|'POST'])])` format. The generated code includes Flask with CORS enabled, automatic JSON handling, and error handling. The server runs on port 8080 by default. Example: `generate_http_server(python, [endpoint('/api/process', process_data, [methods(['POST'])])], [port(8080), cors(true)], Code)` outputs a complete Flask application with request/response handling and exception management.", "question_type": "medium", "topics": ["Quickstart", "Networking"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["http-server", "python", "flask"], "related_skills": ["skill_networking.md", "skill_infrastructure.md", "skill_deployment.md", "skill_authentication.md", "skill_web_frameworks.md"], "related_docs": ["src/unifyweaver/glue/network_glue.pl"], "original_answer": "Use the Networking skill to generate HTTP servers. Call `generate_http_server(python, Endpoints, [port(8080), cors(true)], Code)` with your endpoint definitions. For example, `endpoint('/api/process', process_data, [methods(['POST'])])` generates a Flask server with CORS enabled, JSON handling, and error handling. The server runs on port 8080 and accepts POST requests. See skill_networking.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_networking_001_q3", "cluster_id": "skill_networking_001", "question": "How do I generate server code?", "answer": "Use the Networking skill to generate HTTP servers with `generate_http_server(Target, Endpoints, Options, Code)`. Specify your target language (python, go, or rust), define endpoints using `endpoint(Path, Handler, EndpointOptions)`, and set options like `port(8080)` and `cors(true)`. For example: `generate_http_server(python, [endpoint('/api/process', process_data, [methods(['POST'])])], [port(8080), cors(true)], Code)` generates a Flask server with CORS, JSON handling, and error handling. See skill_networking.md for language-specific examples and additional options.", "question_type": "medium", "topics": ["Quickstart", "Networking"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["http-server", "python", "flask"], "related_skills": ["skill_networking.md", "skill_infrastructure.md", "skill_deployment.md", "skill_authentication.md", "skill_web_frameworks.md"], "related_docs": ["src/unifyweaver/glue/network_glue.pl"], "original_answer": "Use the Networking skill to generate HTTP servers. Call `generate_http_server(python, Endpoints, [port(8080), cors(true)], Code)` with your endpoint definitions. For example, `endpoint('/api/process', process_data, [methods(['POST'])])` generates a Flask server with CORS enabled, JSON handling, and error handling. The server runs on port 8080 and accepts POST requests. See skill_networking.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_networking_002_q0", "cluster_id": "skill_networking_002", "question": "How do I call remote services from my code?", "answer": "Use the Networking skill's HTTP client generation with `generate_http_client(Target, Services, [timeout(30)], Code)` where Target is python, go, or bash. Define services with `service_def(Name, BaseURL, Endpoints)` or register them using `register_service(Name, URL, [timeout(60), retries(3)])`. For Python, this generates request helpers using the requests library with timeout handling and error management. The generated code handles connection management, timeouts, retries, and authentication (bearer tokens or basic auth).", "question_type": "medium", "topics": ["Quickstart", "Networking"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["http-client", "remote-services", "api-integration"], "related_skills": ["skill_networking.md", "skill_authentication.md"], "related_docs": ["src/unifyweaver/glue/network_glue.pl"], "original_answer": "Use the Networking skill's HTTP client generation. Call `generate_http_client(Target, Services, [timeout(30)], Code)` where Target is python, go, or bash. Define services using `service_def(Name, BaseURL, Endpoints)` format. For Python, this generates request helpers using the requests library with timeout handling and error management. You can also register services with `register_service(Name, URL, [timeout(60), retries(3)])` for reuse. See skill_networking.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_networking_002_q1", "cluster_id": "skill_networking_002", "question": "How do I make HTTP requests to other APIs?", "answer": "Use the Networking skill's HTTP client generation with `generate_http_client(Target, Services, Options, Code)` where Target is python, go, or bash. Define your services with `register_service(Name, URL, [timeout(30), retries(3)])` for connection pooling and error handling. For Python, this generates request helpers using the requests library with built-in timeout and retry logic. Pass options like `timeout(30)` and `auth(bearer(Token))` for authentication. The generated code handles errors automatically and supports multiple service endpoints.", "question_type": "medium", "topics": ["Quickstart", "Networking"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["http-client", "remote-services", "api-integration"], "related_skills": ["skill_networking.md", "skill_authentication.md"], "related_docs": ["src/unifyweaver/glue/network_glue.pl"], "original_answer": "Use the Networking skill's HTTP client generation. Call `generate_http_client(Target, Services, [timeout(30)], Code)` where Target is python, go, or bash. Define services using `service_def(Name, BaseURL, Endpoints)` format. For Python, this generates request helpers using the requests library with timeout handling and error management. You can also register services with `register_service(Name, URL, [timeout(60), retries(3)])` for reuse. See skill_networking.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "Base answer mentions `service_def()` which isn't documented in the skill reference; actual API uses `register_service()`. Answer assumes user knows which Target language to use. Confidence reduced because base answer conflates service definition with client generation - they're related but separate steps."}
{"pair_id": "skill_networking_002_q2", "cluster_id": "skill_networking_002", "question": "How do I generate an HTTP client?", "answer": "Use the Networking skill's HTTP client generation by calling `generate_http_client(Target, Services, Options, Code)` where Target is `python`, `go`, or `bash`. Define services using `service_def(Name, BaseURL, Endpoints)` format or register them with `register_service(Name, URL, [timeout(60), retries(3)])`. For Python, this generates request helpers using the requests library with timeout handling and error management. Options like `timeout(30)` and `retries(3)` control client behavior. See skill_networking.md for language-specific examples and additional configuration options.", "question_type": "medium", "topics": ["Quickstart", "Networking"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["http-client", "remote-services", "api-integration"], "related_skills": ["skill_networking.md", "skill_authentication.md"], "related_docs": ["src/unifyweaver/glue/network_glue.pl"], "original_answer": "Use the Networking skill's HTTP client generation. Call `generate_http_client(Target, Services, [timeout(30)], Code)` where Target is python, go, or bash. Define services using `service_def(Name, BaseURL, Endpoints)` format. For Python, this generates request helpers using the requests library with timeout handling and error management. You can also register services with `register_service(Name, URL, [timeout(60), retries(3)])` for reuse. See skill_networking.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "Base answer mentions 'bash' as a target but the skill document only explicitly documents 'python' and 'go'. The Services parameter format differs between the base answer (Services) and skill document examples (service_def format), creating potential confusion about the exact API signature."}
{"pair_id": "skill_networking_002_q3", "cluster_id": "skill_networking_002", "question": "How do I connect to external services?", "answer": "To connect to external services, use the Networking skill's HTTP client generation. Call `generate_http_client(Target, Services, [timeout(30)], Code)` where Target is python, go, or bash. Register services with `register_service(Name, URL, [timeout(60), retries(3), auth(bearer('token'))])` for connection management, timeout handling, retries, and authentication. The generated client provides request helpers with error handling and automatic retry logic. For Python specifically, this generates code using the requests library with built-in timeout and error management.", "question_type": "medium", "topics": ["Quickstart", "Networking"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["http-client", "remote-services", "api-integration"], "related_skills": ["skill_networking.md", "skill_authentication.md"], "related_docs": ["src/unifyweaver/glue/network_glue.pl"], "original_answer": "Use the Networking skill's HTTP client generation. Call `generate_http_client(Target, Services, [timeout(30)], Code)` where Target is python, go, or bash. Define services using `service_def(Name, BaseURL, Endpoints)` format. For Python, this generates request helpers using the requests library with timeout handling and error management. You can also register services with `register_service(Name, URL, [timeout(60), retries(3)])` for reuse. See skill_networking.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "Base answer mentions service_def format but the skill document uses register_service with different syntax. Clarified to match actual API shown in skill document."}
{"pair_id": "skill_networking_003_q0", "cluster_id": "skill_networking_003", "question": "How do I set up socket communication between applications?", "answer": "Use socket generation for low-latency communication between applications. Generate a server with `generate_socket_server(Target, Port, Options, Code)` specifying your target language (Go or Python) and port number. Generate a client with `generate_socket_client(Target, Host, [port(Port)], Code)` to connect to the server. Configure with options like `format(json)` or `format(tsv)` for data serialization and `buffer_size(65536)` for efficient I/O. Python clients automatically handle newline framing in send/receive methods. This approach provides efficient connection handling and supports both line-based and structured data protocols.", "question_type": "medium", "topics": ["Quickstart", "Networking"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sockets", "tcp", "low-latency"], "related_skills": ["skill_networking.md"], "related_docs": ["src/unifyweaver/glue/network_glue.pl"], "original_answer": "Use socket generation for low-latency communication. Generate a server with `generate_socket_server(Target, Port, [format(json), buffer_size(65536)], Code)` in Go or Python. Generate a client with `generate_socket_client(Target, Host, [port(Port)], Code)`. Sockets support line-based protocols with buffered I/O, JSON or TSV data formats, and efficient connection handling. Python clients include send/receive methods with automatic newline framing. See skill_networking.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer mentions 'skill_networking.md' which may not exist or be accessible in the user's context. The answer assumes familiarity with the Prolog-style syntax shown in the skill document."}
{"pair_id": "skill_networking_003_q1", "cluster_id": "skill_networking_003", "question": "How do I use low-latency sockets?", "answer": "Use socket generation for low-latency communication. Call `generate_socket_server(Target, Port, Options, Code)` to create a server in Go or Python, and `generate_socket_client(Target, Host, Options, Code)` for clients. Configure with options like `format(json)`, `buffer_size(65536)` for efficient I/O, and `port(Port)` to specify the connection port. Sockets support line-based protocols with buffered I/O and automatic newline framing. Python clients include send/receive methods for direct socket communication with minimal overhead.", "question_type": "medium", "topics": ["Quickstart", "Networking"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sockets", "tcp", "low-latency"], "related_skills": ["skill_networking.md"], "related_docs": ["src/unifyweaver/glue/network_glue.pl"], "original_answer": "Use socket generation for low-latency communication. Generate a server with `generate_socket_server(Target, Port, [format(json), buffer_size(65536)], Code)` in Go or Python. Generate a client with `generate_socket_client(Target, Host, [port(Port)], Code)`. Sockets support line-based protocols with buffered I/O, JSON or TSV data formats, and efficient connection handling. Python clients include send/receive methods with automatic newline framing. See skill_networking.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_networking_003_q2", "cluster_id": "skill_networking_003", "question": "How do I create a TCP server and client?", "answer": "Use socket generation for low-latency TCP communication. Generate a server with `generate_socket_server(Target, Port, Options, Code)` where Target is 'go' or 'python', and Options can include `[format(json), buffer_size(65536)]`. Generate a client with `generate_socket_client(Target, Host, Port, Options, Code)`. Sockets support line-based protocols with buffered I/O, JSON or TSV data formats, and efficient connection handling. Python clients include send/receive methods with automatic newline framing.", "question_type": "medium", "topics": ["Quickstart", "Networking"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sockets", "tcp", "low-latency"], "related_skills": ["skill_networking.md"], "related_docs": ["src/unifyweaver/glue/network_glue.pl"], "original_answer": "Use socket generation for low-latency communication. Generate a server with `generate_socket_server(Target, Port, [format(json), buffer_size(65536)], Code)` in Go or Python. Generate a client with `generate_socket_client(Target, Host, [port(Port)], Code)`. Sockets support line-based protocols with buffered I/O, JSON or TSV data formats, and efficient connection handling. Python clients include send/receive methods with automatic newline framing. See skill_networking.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer references 'skill_networking.md' but the skill document provided is truncated, so full details cannot be verified. The answer assumes socket generation is implemented but does not show concrete code examples for TCP specifically."}
{"pair_id": "skill_networking_003_q3", "cluster_id": "skill_networking_003", "question": "How do I generate socket code?", "answer": "To generate socket code, use `generate_socket_server(Target, Port, Options, Code)` for servers or `generate_socket_client(Target, Host, Options, Code)` for clients. Both support Go and Python targets. Common options include `format(json)` or `format(tsv)` for data encoding, `buffer_size(65536)` for I/O buffering, and `port(Port)` for client connections. Python clients automatically handle newline framing for line-based protocols. This approach enables low-latency communication with efficient connection handling and buffered I/O.", "question_type": "medium", "topics": ["Quickstart", "Networking"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sockets", "tcp", "low-latency"], "related_skills": ["skill_networking.md"], "related_docs": ["src/unifyweaver/glue/network_glue.pl"], "original_answer": "Use socket generation for low-latency communication. Generate a server with `generate_socket_server(Target, Port, [format(json), buffer_size(65536)], Code)` in Go or Python. Generate a client with `generate_socket_client(Target, Host, [port(Port)], Code)`. Sockets support line-based protocols with buffered I/O, JSON or TSV data formats, and efficient connection handling. Python clients include send/receive methods with automatic newline framing. See skill_networking.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_networking_004_q0", "cluster_id": "skill_networking_004", "question": "How do I build pipelines that combine local processing and remote API calls?", "answer": "Use network pipelines to combine local and remote operations by calling `generate_network_pipeline(Steps, [language(python)], Code)`. Define steps as `step(Name, local, 'script()')` for local processing or `step(Name, remote, 'http://url')` for remote API calls. Steps execute sequentially, with results passed between them. Example workflow: preprocess data locally, send to ml.example.com/predict for inference, then format results locally. Supports Python, Go, and Bash targets. Each step receives output from the previous step as input.", "question_type": "medium", "topics": ["Quickstart", "Networking"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["pipeline", "orchestration", "network-workflow"], "related_skills": ["skill_networking.md", "skill_infrastructure.md"], "related_docs": ["src/unifyweaver/glue/network_glue.pl"], "original_answer": "Use network pipelines to chain local and remote operations. Call `generate_network_pipeline(Steps, [language(python)], Code)` with steps defined as `step(Name, local, 'script()')` for local processing or `step(Name, remote, 'http://url')` for API calls. Steps execute in order, passing results between them. Example: preprocess locally, call ml.example.com/predict remotely, then format results locally. Supports Python, Go, and Bash targets. See skill_networking.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "Base answer references 'skill_networking.md' which is not in the provided skill document. The specific syntax for passing data between steps is not documented in the skill document, only inferred from the description."}
{"pair_id": "skill_networking_004_q1", "cluster_id": "skill_networking_004", "question": "How do I create workflows with local and remote steps?", "answer": "Use network pipelines to chain local and remote operations together. Call `generate_network_pipeline(Steps, [language(python)], Code)` where Steps are defined as `step(Name, local, 'script()')` for local processing or `step(Name, remote, 'http://service-url')` for remote API calls. Steps execute sequentially, automatically passing results from one step to the next. For example: preprocess data locally with a script, send it to a remote ML service for prediction, then format the results locally. The skill supports Python, Go, and Bash targets. Remote steps can leverage registered services with `register_service(Name, URL, Options)` for built-in timeout, retry, and authentication handling.", "question_type": "medium", "topics": ["Quickstart", "Networking"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["pipeline", "orchestration", "network-workflow"], "related_skills": ["skill_networking.md", "skill_infrastructure.md"], "related_docs": ["src/unifyweaver/glue/network_glue.pl"], "original_answer": "Use network pipelines to chain local and remote operations. Call `generate_network_pipeline(Steps, [language(python)], Code)` with steps defined as `step(Name, local, 'script()')` for local processing or `step(Name, remote, 'http://url')` for API calls. Steps execute in order, passing results between them. Example: preprocess locally, call ml.example.com/predict remotely, then format results locally. Supports Python, Go, and Bash targets. See skill_networking.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "The base answer references 'script()' syntax and execution flow, but the skill document shows limited detail on step result passing and sequential chaining. The answer infers workflow execution semantics not explicitly detailed in the provided documentation."}
{"pair_id": "skill_networking_004_q2", "cluster_id": "skill_networking_004", "question": "How do I chain data through preprocessing and remote services?", "answer": "Use network pipelines to chain local preprocessing with remote services. Call `generate_network_pipeline(Steps, [language(python)], Code)` where each step is either `step(Name, local, 'script()')` for local data processing or `step(Name, remote, 'http://service-url')` for remote API calls. Steps execute sequentially, with output from one step feeding as input to the next. Example workflow: preprocess data locally with a script, send results to ml.example.com/predict endpoint, then format the response locally. Supports Python, Go, and Bash. Check skill_networking.md for full pipeline syntax and available options.", "question_type": "medium", "topics": ["Quickstart", "Networking"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["pipeline", "orchestration", "network-workflow"], "related_skills": ["skill_networking.md", "skill_infrastructure.md"], "related_docs": ["src/unifyweaver/glue/network_glue.pl"], "original_answer": "Use network pipelines to chain local and remote operations. Call `generate_network_pipeline(Steps, [language(python)], Code)` with steps defined as `step(Name, local, 'script()')` for local processing or `step(Name, remote, 'http://url')` for API calls. Steps execute in order, passing results between them. Example: preprocess locally, call ml.example.com/predict remotely, then format results locally. Supports Python, Go, and Bash targets. See skill_networking.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "Base answer lacks explicit detail on how data flows between steps and doesn't clarify whether intermediate results are automatically passed or require manual specification. The example is helpful but could be more concrete about data format handling."}
{"pair_id": "skill_networking_005_q0", "cluster_id": "skill_networking_005", "question": "How do I register and manage services for reuse?", "answer": "Register services using `register_service(Name, URL, Options)` where Options include `timeout(Seconds)`, `retries(N)`, `format(json|tsv)`, and `auth(bearer(Token)|basic(User,Pass))`. Query registered services with `service(Name, URL)` to retrieve the URL, `service_options(Name, Options)` to get configuration, or `endpoint_url(Service, Endpoint, FullURL)` to construct full endpoint URLs. Unregister services with `unregister_service(Name)`. This creates a centralized service registry for consistent reuse across generated clients and network pipelines.", "question_type": "long", "topics": ["Quickstart", "Networking"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["service-registry", "configuration", "service-management"], "related_skills": ["skill_networking.md"], "related_docs": ["src/unifyweaver/glue/network_glue.pl"], "original_answer": "Register services using `register_service(Name, URL, Options)` with configuration like `timeout(60)`, `retries(3)`, `format(json|tsv)`, and `auth(bearer('token')|basic(user,pass))`. Query registered services with `service(Name, URL)`, `service_options(Name, Options)`, or `endpoint_url(Service, Endpoint, FullURL)`. Unregister with `unregister_service(Name)`. This creates a service registry for consistent configuration across generated clients and pipelines. See skill_networking.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_networking_005_q1", "cluster_id": "skill_networking_005", "question": "How do I store service endpoints?", "answer": "To store service endpoints, use `register_service(Name, URL, Options)` to register a service with its URL and configuration options like `timeout(60)`, `retries(3)`, `format(json|tsv)`, and `auth(bearer('token')|basic(user,pass))`. Once registered, query the service registry with `service(Name, URL)` to retrieve the URL, `service_options(Name, Options)` to get configuration, or `endpoint_url(Service, Endpoint, FullURL)` to get a full endpoint URL. Remove services with `unregister_service(Name)`.", "question_type": "long", "topics": ["Quickstart", "Networking"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["service-registry", "configuration", "service-management"], "related_skills": ["skill_networking.md"], "related_docs": ["src/unifyweaver/glue/network_glue.pl"], "original_answer": "Register services using `register_service(Name, URL, Options)` with configuration like `timeout(60)`, `retries(3)`, `format(json|tsv)`, and `auth(bearer('token')|basic(user,pass))`. Query registered services with `service(Name, URL)`, `service_options(Name, Options)`, or `endpoint_url(Service, Endpoint, FullURL)`. Unregister with `unregister_service(Name)`. This creates a service registry for consistent configuration across generated clients and pipelines. See skill_networking.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_networking_005_q2", "cluster_id": "skill_networking_005", "question": "How do I configure service timeouts and retries?", "answer": "Configure service timeouts and retries by registering services with `register_service(Name, URL, Options)`. Use `timeout(Seconds)` to set request timeout (e.g., `timeout(60)` for 60 seconds) and `retries(N)` to set retry count (e.g., `retries(3)` for 3 retries). Example: `register_service(ml_service, 'http://ml.example.com:8080', [timeout(60), retries(3)])`. Query configured services with `service_options(Name, Options)` to verify settings. Unregister with `unregister_service(Name)`.", "question_type": "long", "topics": ["Quickstart", "Networking"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["service-registry", "configuration", "service-management"], "related_skills": ["skill_networking.md"], "related_docs": ["src/unifyweaver/glue/network_glue.pl"], "original_answer": "Register services using `register_service(Name, URL, Options)` with configuration like `timeout(60)`, `retries(3)`, `format(json|tsv)`, and `auth(bearer('token')|basic(user,pass))`. Query registered services with `service(Name, URL)`, `service_options(Name, Options)`, or `endpoint_url(Service, Endpoint, FullURL)`. Unregister with `unregister_service(Name)`. This creates a service registry for consistent configuration across generated clients and pipelines. See skill_networking.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_networking_005_q3", "cluster_id": "skill_networking_005", "question": "How do I set up service registry?", "answer": "Set up a service registry using `register_service(Name, URL, Options)`. Define each service with a name, URL, and configuration options like `timeout(Seconds)`, `retries(N)`, `format(json|tsv)`, and `auth(bearer(Token)|basic(User,Pass))`. Once registered, query services with `service(Name, URL)`, `service_options(Name, Options)`, or `endpoint_url(Service, Endpoint, FullURL)` to retrieve configuration. Remove services with `unregister_service(Name)`. This centralizes service configuration for use across generated clients and network pipelines.", "question_type": "long", "topics": ["Quickstart", "Networking"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["service-registry", "configuration", "service-management"], "related_skills": ["skill_networking.md"], "related_docs": ["src/unifyweaver/glue/network_glue.pl"], "original_answer": "Register services using `register_service(Name, URL, Options)` with configuration like `timeout(60)`, `retries(3)`, `format(json|tsv)`, and `auth(bearer('token')|basic(user,pass))`. Query registered services with `service(Name, URL)`, `service_options(Name, Options)`, or `endpoint_url(Service, Endpoint, FullURL)`. Unregister with `unregister_service(Name)`. This creates a service registry for consistent configuration across generated clients and pipelines. See skill_networking.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_networking_006_q0", "cluster_id": "skill_networking_006", "question": "How do I generate knowledge graph and federated query endpoints?", "answer": "To generate knowledge graph and federated query endpoints, use `generate_kg_query_endpoint(Target, Options, Code)` to create POST /kg/query, POST /kg/register, and GET /kg/health endpoints for knowledge graph operations. For federated queries across distributed systems, use `generate_federation_endpoint(Target, Options, Code)` to create POST /kg/federated, POST /kg/federate, and GET /kg/federation/stats endpoints. For cross-model communication needs, use `generate_cross_model_endpoint(Target, Options, Code)`. These functions integrate with HTTP servers to enable distributed knowledge graph topology and federation capabilities.", "question_type": "long", "topics": ["Quickstart", "Networking"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["knowledge-graph", "federation", "distributed-systems"], "related_skills": ["skill_networking.md", "skill_infrastructure.md"], "related_docs": ["src/unifyweaver/glue/network_glue.pl"], "original_answer": "Generate specialized endpoints for distributed systems. Use `generate_kg_query_endpoint(Target, Options, Code)` to create POST /kg/query, POST /kg/register, and GET /kg/health endpoints. Use `generate_federation_endpoint(Target, Options, Code)` for federated queries with POST /kg/federated, POST /kg/federate, and GET /kg/federation/stats. Use `generate_cross_model_endpoint(Target, Options, Code)` for cross-model communication. These integrate with your HTTP servers to support distributed knowledge graph topology. See skill_networking.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "Base answer references 'skill_networking.md' but the skill document provided is 'Skill: Networking' with limited KG/federation details. The specific function signatures and endpoint behaviors are stated but not shown with concrete examples or parameter details in the base material."}
{"pair_id": "skill_networking_006_q1", "cluster_id": "skill_networking_006", "question": "How do I create distributed KG query endpoints?", "answer": "To create distributed KG query endpoints, use the networking skill's specialized endpoint generators: `generate_kg_query_endpoint(Target, Options, Code)` creates POST /kg/query, POST /kg/register, and GET /kg/health endpoints for single-node queries. For federated queries across multiple knowledge graphs, use `generate_federation_endpoint(Target, Options, Code)` which generates POST /kg/federated, POST /kg/federate, and GET /kg/federation/stats endpoints. For cross-model communication in distributed topologies, use `generate_cross_model_endpoint(Target, Options, Code)`. These generators integrate with HTTP servers (Python Flask, Go net/http, Rust Actix-web) to support distributed knowledge graph architectures.", "question_type": "long", "topics": ["Quickstart", "Networking"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["knowledge-graph", "federation", "distributed-systems"], "related_skills": ["skill_networking.md", "skill_infrastructure.md"], "related_docs": ["src/unifyweaver/glue/network_glue.pl"], "original_answer": "Generate specialized endpoints for distributed systems. Use `generate_kg_query_endpoint(Target, Options, Code)` to create POST /kg/query, POST /kg/register, and GET /kg/health endpoints. Use `generate_federation_endpoint(Target, Options, Code)` for federated queries with POST /kg/federated, POST /kg/federate, and GET /kg/federation/stats. Use `generate_cross_model_endpoint(Target, Options, Code)` for cross-model communication. These integrate with your HTTP servers to support distributed knowledge graph topology. See skill_networking.md for details.", "answer_tailored": true, "confidence": 0.75, "confidence_issues": "The base answer references 'skill_networking.md' which is not included in the provided skill document. The answer assumes these specific KG query functions exist in the networking glue module but they are not demonstrated in the Quick Start or HTTP Server Generation sections shown. The base answer lacks concrete code examples for these distributed KG operations."}
{"pair_id": "skill_networking_006_q2", "cluster_id": "skill_networking_006", "question": "How do I set up federation endpoints?", "answer": "To set up federation endpoints, use `generate_federation_endpoint(Target, Options, Code)` to create specialized endpoints for distributed systems. This generates POST /kg/federated for federated queries, POST /kg/federate for federation registration, and GET /kg/federation/stats for monitoring. You can also use `generate_kg_query_endpoint(Target, Options, Code)` for basic knowledge graph endpoints (POST /kg/query, POST /kg/register, GET /kg/health) and `generate_cross_model_endpoint(Target, Options, Code)` for cross-model communication. These integrate with HTTP servers to support distributed knowledge graph topology.", "question_type": "long", "topics": ["Quickstart", "Networking"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["knowledge-graph", "federation", "distributed-systems"], "related_skills": ["skill_networking.md", "skill_infrastructure.md"], "related_docs": ["src/unifyweaver/glue/network_glue.pl"], "original_answer": "Generate specialized endpoints for distributed systems. Use `generate_kg_query_endpoint(Target, Options, Code)` to create POST /kg/query, POST /kg/register, and GET /kg/health endpoints. Use `generate_federation_endpoint(Target, Options, Code)` for federated queries with POST /kg/federated, POST /kg/federate, and GET /kg/federation/stats. Use `generate_cross_model_endpoint(Target, Options, Code)` for cross-model communication. These integrate with your HTTP servers to support distributed knowledge graph topology. See skill_networking.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "The base answer lacks implementation details and concrete examples. No information about configuration options, authentication, or actual code samples. The connection between federation endpoints and HTTP servers could be clearer. Uncertain whether the API names and endpoint paths in the base answer are accurate without seeing the actual skill documentation."}
{"pair_id": "skill_networking_006_q3", "cluster_id": "skill_networking_006", "question": "How do I generate cross-model endpoints?", "answer": "Generate cross-model endpoints using `generate_cross_model_endpoint(Target, Options, Code)` for federation between models. This creates endpoints for cross-model communication. See `skill_networking.md` for HTTP/socket patterns and the networking module for implementation details.", "question_type": "long", "topics": ["Quickstart", "Networking"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["knowledge-graph", "federation", "distributed-systems"], "related_skills": ["skill_networking.md", "skill_infrastructure.md"], "related_docs": ["src/unifyweaver/glue/network_glue.pl"], "original_answer": "Generate specialized endpoints for distributed systems. Use `generate_kg_query_endpoint(Target, Options, Code)` to create POST /kg/query, POST /kg/register, and GET /kg/health endpoints. Use `generate_federation_endpoint(Target, Options, Code)` for federated queries with POST /kg/federated, POST /kg/federate, and GET /kg/federation/stats. Use `generate_cross_model_endpoint(Target, Options, Code)` for cross-model communication. These integrate with your HTTP servers to support distributed knowledge graph topology. See skill_networking.md for details.", "answer_tailored": true, "confidence": 0.7, "confidence_issues": "Cross-model endpoint specifics not fully documented", "manually_reviewed": true}
{"pair_id": "skill_pearl_dataset_001_q0", "cluster_id": "skill_pearl_dataset_001", "question": "How do I create training data from my Pearltrees bookmarks?", "answer": "To create training data from your Pearltrees bookmarks, use the `python scripts/generate_pearl_dataset.py` script. Run: `python scripts/generate_pearl_dataset.py --rdf data/your_account.rdf --output reports/pearltrees_targets.jsonl`. This generates JSONL training data containing your trees (folders) and pearls (bookmarks) with their hierarchical paths. For multi-account setups, pass multiple RDF files and use `--cross-account` flag. Use `--query-style` to customize the query format (raw, locate, file, similar, browse) depending on your use case.", "question_type": "medium", "topics": ["Quickstart", "Data Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["pearltrees", "training-data", "rdf", "export"], "related_skills": ["skill_pearl_dataset.md", "skill_synthetic_data.md"], "related_docs": ["scripts/generate_pearl_dataset.py"], "original_answer": "Use `python scripts/generate_pearl_dataset.py` to transform Pearltrees RDF exports into JSONL training data. Basic command: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --output reports/pearltrees_targets.jsonl`. The generated data includes trees (folders), pearls (bookmarks), and their materialized paths for semantic search, folder suggestion models, and bookmark filing. See skill_pearl_dataset.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pearl_dataset_001_q1", "cluster_id": "skill_pearl_dataset_001", "question": "How can I generate a dataset from Pearltrees?", "answer": "Use `python scripts/generate_pearl_dataset.py` to transform Pearltrees RDF exports into JSONL training data for semantic search. Basic command: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --output reports/pearltrees_targets.jsonl`. The script generates datasets containing trees (folders), pearls (bookmarks), and their materialized paths. You can customize the output with options like `--query-style` (raw, locate, file, similar, browse), `--pearls-only`, `--trees-only`, and `--cross-account` for multi-account linking. The resulting JSONL files are suitable for semantic search training, folder suggestion models, and bookmark filing assistants.", "question_type": "medium", "topics": ["Quickstart", "Data Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["pearltrees", "training-data", "rdf", "export"], "related_skills": ["skill_pearl_dataset.md", "skill_synthetic_data.md"], "related_docs": ["scripts/generate_pearl_dataset.py"], "original_answer": "Use `python scripts/generate_pearl_dataset.py` to transform Pearltrees RDF exports into JSONL training data. Basic command: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --output reports/pearltrees_targets.jsonl`. The generated data includes trees (folders), pearls (bookmarks), and their materialized paths for semantic search, folder suggestion models, and bookmark filing. See skill_pearl_dataset.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pearl_dataset_001_q2", "cluster_id": "skill_pearl_dataset_001", "question": "How do I export Pearltrees data for machine learning?", "answer": "Use the `python scripts/generate_pearl_dataset.py` script to export Pearltrees data for machine learning. This script transforms Pearltrees RDF exports into JSONL training datasets suitable for semantic search, folder suggestion models, and bookmark filing assistants. Basic usage: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --output reports/pearltrees_targets.jsonl`. The output includes trees (folders), pearls (bookmarks), and materialized paths in your hierarchy. Customize with options like `--query-style` (raw, locate, file, similar, browse), `--trees-only`, `--pearls-only`, and `--cross-account` for multi-account scenarios. For multi-account exports: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf data/s243a_groups.rdf --output reports/pearltrees_targets_multi.jsonl --cross-account`", "question_type": "medium", "topics": ["Quickstart", "Data Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["pearltrees", "training-data", "rdf", "export"], "related_skills": ["skill_pearl_dataset.md", "skill_synthetic_data.md"], "related_docs": ["scripts/generate_pearl_dataset.py"], "original_answer": "Use `python scripts/generate_pearl_dataset.py` to transform Pearltrees RDF exports into JSONL training data. Basic command: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --output reports/pearltrees_targets.jsonl`. The generated data includes trees (folders), pearls (bookmarks), and their materialized paths for semantic search, folder suggestion models, and bookmark filing. See skill_pearl_dataset.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pearl_dataset_001_q3", "cluster_id": "skill_pearl_dataset_001", "question": "What's the workflow to convert Pearltrees to training data?", "answer": "To convert Pearltrees to training data, run `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --output reports/pearltrees_targets.jsonl`. This workflow transforms RDF exports into JSONL datasets containing trees (folders) and pearls (bookmarks) with materialized paths. For multi-account data, add multiple RDF files: `--rdf data/s243a.rdf data/s243a_groups.rdf --cross-account`. Use query-style options like `--query-style locate` for different formats. The generated training data supports semantic search, folder suggestions, and bookmark filing models.", "question_type": "medium", "topics": ["Quickstart", "Data Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["pearltrees", "training-data", "rdf", "export"], "related_skills": ["skill_pearl_dataset.md", "skill_synthetic_data.md"], "related_docs": ["scripts/generate_pearl_dataset.py"], "original_answer": "Use `python scripts/generate_pearl_dataset.py` to transform Pearltrees RDF exports into JSONL training data. Basic command: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --output reports/pearltrees_targets.jsonl`. The generated data includes trees (folders), pearls (bookmarks), and their materialized paths for semantic search, folder suggestion models, and bookmark filing. See skill_pearl_dataset.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pearl_dataset_002_q0", "cluster_id": "skill_pearl_dataset_002", "question": "What query formats are available for generating training data?", "answer": "Six query formats are available for generating training data from Pearltrees: `raw` (just the title for general embedding), `locate` (Prolog-style `locate_node(\"title\")` queries), `locate_object` (typed queries like `locate_object(tree, \"title\")`), `file` (bookmark filing format `file_bookmark(\"url\", \"title\")`), `similar` (similarity search `find_similar(\"title\")`), and `browse` (navigation queries `browse_folder(\"title\")`). Select your format using the `--query-style` flag when running the generation script. Choose based on your use case: use `file` for bookmark filing assistants, `locate` for Prolog-style queries, `raw` for general semantic embeddings, `similar` for similarity-based searches, `browse` for navigation interfaces, and `locate_object` for typed hierarchical queries.", "question_type": "long", "topics": ["Quickstart", "Data Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["query-styles", "training-data", "formatting"], "related_skills": ["skill_pearl_dataset.md"], "related_docs": ["scripts/generate_pearl_dataset.py"], "original_answer": "Six query styles are available: `raw` (just titles), `locate` (Prolog-style `locate_node()`), `locate_object` (typed queries), `file` (bookmark filing format), `similar` (similarity search), and `browse` (navigation). Use `--query-style` flag to select: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --query-style file --pearls-only --output reports/targets_file.jsonl`. Choose based on your use case\u2014file style for bookmark assistants, locate for Prolog queries, raw for general embedding. See skill_pearl_dataset.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_pearl_dataset_002_q1", "cluster_id": "skill_pearl_dataset_002", "question": "How do I choose the right query style for my dataset?", "answer": "Choose your query style based on your use case: use `raw` for general semantic embeddings, `locate` for Prolog-style queries with `locate_node()`, `locate_object` for typed object queries, `file` for bookmark filing assistants, `similar` for similarity search, and `browse` for folder navigation. Set your choice with the `--query-style` flag when running the dataset generation script. For example, use `--query-style file --pearls-only` for bookmark filing training data, or `--query-style locate` for Prolog-based retrieval.", "question_type": "long", "topics": ["Quickstart", "Data Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["query-styles", "training-data", "formatting"], "related_skills": ["skill_pearl_dataset.md"], "related_docs": ["scripts/generate_pearl_dataset.py"], "original_answer": "Six query styles are available: `raw` (just titles), `locate` (Prolog-style `locate_node()`), `locate_object` (typed queries), `file` (bookmark filing format), `similar` (similarity search), and `browse` (navigation). Use `--query-style` flag to select: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --query-style file --pearls-only --output reports/targets_file.jsonl`. Choose based on your use case\u2014file style for bookmark assistants, locate for Prolog queries, raw for general embedding. See skill_pearl_dataset.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_pearl_dataset_002_q2", "cluster_id": "skill_pearl_dataset_002", "question": "What are the different query formats in dataset generation?", "answer": "Six query formats are available for dataset generation: (1) `raw` - outputs just the title for general embedding; (2) `locate` - produces Prolog-style `locate_node(\"title\")` queries; (3) `locate_object` - generates typed queries like `locate_object(tree, \"title\")`; (4) `file` - formats as `file_bookmark(\"url\", \"title\")` for bookmark filing assistants; (5) `similar` - creates `find_similar(\"title\")` queries for similarity search; (6) `browse` - generates `browse_folder(\"title\")` for navigation queries. Select your format using the `--query-style` flag when running the dataset generation script. Choose based on your use case: file style for bookmark filing models, locate for Prolog-based systems, raw for semantic embeddings.", "question_type": "long", "topics": ["Quickstart", "Data Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["query-styles", "training-data", "formatting"], "related_skills": ["skill_pearl_dataset.md"], "related_docs": ["scripts/generate_pearl_dataset.py"], "original_answer": "Six query styles are available: `raw` (just titles), `locate` (Prolog-style `locate_node()`), `locate_object` (typed queries), `file` (bookmark filing format), `similar` (similarity search), and `browse` (navigation). Use `--query-style` flag to select: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --query-style file --pearls-only --output reports/targets_file.jsonl`. Choose based on your use case\u2014file style for bookmark assistants, locate for Prolog queries, raw for general embedding. See skill_pearl_dataset.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_pearl_dataset_002_q3", "cluster_id": "skill_pearl_dataset_002", "question": "Which query format should I use for bookmark filing?", "answer": "Use the `file` query format for bookmark filing. Run: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --query-style file --pearls-only --output reports/targets_file.jsonl`. This generates queries in the format `file_bookmark(\"url\", \"title\")`, which is optimized for bookmark filing assistant models. The `--pearls-only` flag ensures you only generate training data for bookmarks, not folders.", "question_type": "long", "topics": ["Quickstart", "Data Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["query-styles", "training-data", "formatting"], "related_skills": ["skill_pearl_dataset.md"], "related_docs": ["scripts/generate_pearl_dataset.py"], "original_answer": "Six query styles are available: `raw` (just titles), `locate` (Prolog-style `locate_node()`), `locate_object` (typed queries), `file` (bookmark filing format), `similar` (similarity search), and `browse` (navigation). Use `--query-style` flag to select: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --query-style file --pearls-only --output reports/targets_file.jsonl`. Choose based on your use case\u2014file style for bookmark assistants, locate for Prolog queries, raw for general embedding. See skill_pearl_dataset.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_pearl_dataset_003_q0", "cluster_id": "skill_pearl_dataset_003", "question": "How do I work with multiple Pearltrees accounts?", "answer": "To work with multiple Pearltrees accounts, pass multiple RDF files to the `--rdf` parameter and enable the `--cross-account` flag: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf data/s243a_groups.rdf --output reports/pearltrees_targets_multi.jsonl --cross-account`. This generates training data that includes cross-references between accounts with account boundary notation in target paths. To extract data for a specific account afterward, use: `python scripts/generate_account_training_data.py --input reports/pearltrees_targets_multi.jsonl --account s243a --output reports/pearltrees_targets_s243a.jsonl`.", "question_type": "long", "topics": ["Quickstart", "Data Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["multi-account", "cross-references", "filtering"], "related_skills": ["skill_pearl_dataset.md"], "related_docs": ["scripts/generate_pearl_dataset.py", "scripts/generate_account_training_data.py"], "original_answer": "For multi-account processing, pass multiple RDF files and use `--cross-account` flag: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf data/s243a_groups.rdf --output reports/pearltrees_targets_multi.jsonl --cross-account`. To extract a single account from multi-account data: `python scripts/generate_account_training_data.py --input reports/pearltrees_targets_multi.jsonl --account s243a --output reports/pearltrees_targets_s243a.jsonl`. Cross-references include account boundary notation in target paths. See skill_pearl_dataset.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pearl_dataset_003_q1", "cluster_id": "skill_pearl_dataset_003", "question": "Can I generate training data from multiple accounts?", "answer": "Yes, you can generate training data from multiple accounts. Pass multiple RDF files to the `--rdf` parameter and use the `--cross-account` flag: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf data/s243a_groups.rdf --output reports/pearltrees_targets_multi.jsonl --cross-account`. To extract a single account from the multi-account dataset later, use: `python scripts/generate_account_training_data.py --input reports/pearltrees_targets_multi.jsonl --account s243a --output reports/pearltrees_targets_s243a.jsonl`. Cross-references between accounts are included in the target paths with account boundary notation.", "question_type": "long", "topics": ["Quickstart", "Data Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["multi-account", "cross-references", "filtering"], "related_skills": ["skill_pearl_dataset.md"], "related_docs": ["scripts/generate_pearl_dataset.py", "scripts/generate_account_training_data.py"], "original_answer": "For multi-account processing, pass multiple RDF files and use `--cross-account` flag: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf data/s243a_groups.rdf --output reports/pearltrees_targets_multi.jsonl --cross-account`. To extract a single account from multi-account data: `python scripts/generate_account_training_data.py --input reports/pearltrees_targets_multi.jsonl --account s243a --output reports/pearltrees_targets_s243a.jsonl`. Cross-references include account boundary notation in target paths. See skill_pearl_dataset.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pearl_dataset_003_q2", "cluster_id": "skill_pearl_dataset_003", "question": "How do I handle cross-account references?", "answer": "To handle cross-account references, pass multiple RDF files to the script with the `--cross-account` flag: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf data/s243a_groups.rdf --output reports/pearltrees_targets_multi.jsonl --cross-account`. This processes all accounts and includes cross-references in the output with account boundary notation in target paths. To later extract a single account from the multi-account dataset, use: `python scripts/generate_account_training_data.py --input reports/pearltrees_targets_multi.jsonl --account s243a --output reports/pearltrees_targets_s243a.jsonl`.", "question_type": "long", "topics": ["Quickstart", "Data Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["multi-account", "cross-references", "filtering"], "related_skills": ["skill_pearl_dataset.md"], "related_docs": ["scripts/generate_pearl_dataset.py", "scripts/generate_account_training_data.py"], "original_answer": "For multi-account processing, pass multiple RDF files and use `--cross-account` flag: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf data/s243a_groups.rdf --output reports/pearltrees_targets_multi.jsonl --cross-account`. To extract a single account from multi-account data: `python scripts/generate_account_training_data.py --input reports/pearltrees_targets_multi.jsonl --account s243a --output reports/pearltrees_targets_s243a.jsonl`. Cross-references include account boundary notation in target paths. See skill_pearl_dataset.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pearl_dataset_003_q3", "cluster_id": "skill_pearl_dataset_003", "question": "How do I filter data by account?", "answer": "To filter data by account, use the `--account` flag when generating targets: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --account s243a --output reports/pearltrees_targets_s243a.jsonl`. For multi-account data already generated, use the extraction script: `python scripts/generate_account_training_data.py --input reports/pearltrees_targets_multi.jsonl --account s243a --output reports/pearltrees_targets_s243a.jsonl`. The account name filters nodes and pearls to include only those belonging to the specified account.", "question_type": "long", "topics": ["Quickstart", "Data Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["multi-account", "cross-references", "filtering"], "related_skills": ["skill_pearl_dataset.md"], "related_docs": ["scripts/generate_pearl_dataset.py", "scripts/generate_account_training_data.py"], "original_answer": "For multi-account processing, pass multiple RDF files and use `--cross-account` flag: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf data/s243a_groups.rdf --output reports/pearltrees_targets_multi.jsonl --cross-account`. To extract a single account from multi-account data: `python scripts/generate_account_training_data.py --input reports/pearltrees_targets_multi.jsonl --account s243a --output reports/pearltrees_targets_s243a.jsonl`. Cross-references include account boundary notation in target paths. See skill_pearl_dataset.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "Base answer mentions --account flag and filtering by account name in command options table, but the specific extraction script command appears in the base answer's second sentence. The confidence is moderate because the base answer provides relevant information but mixes two different approaches (filtering during generation vs. extraction from existing data), and I cannot verify if both scripts and their exact syntax exist without checking the codebase."}
{"pair_id": "skill_pearl_dataset_004_q0", "cluster_id": "skill_pearl_dataset_004", "question": "What are RefPearls and how do I generate them?", "answer": "RefPearls are cross-references to other trees or pearls within your Pearltrees hierarchy, enabling semantic relationships between items. Generate them using: `python scripts/generate_tree_refpearls.py --input reports/pearltrees_targets.jsonl --output reports/pearltrees_targets_with_refs.jsonl`. This script infers RefPearls from parent-child relationships by analyzing `cluster_id` fields in your dataset and creates RefPearl records marked with `_source: \"hierarchy_inference\"`. Each RefPearl includes an `alias_target_uri` pointing to its target and displays account boundaries in materialized paths, making them useful for folder suggestion models and bookmark filing assistants.", "question_type": "long", "topics": ["Quickstart", "Data Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["refpearls", "synthetic-data", "relationships"], "related_skills": ["skill_pearl_dataset.md"], "related_docs": ["scripts/generate_tree_refpearls.py"], "original_answer": "RefPearls are cross-references to other trees or items, useful for capturing relationships. Generate them synthetically from parent-child relationships using: `python scripts/generate_tree_refpearls.py --input reports/pearltrees_targets.jsonl --output reports/pearltrees_targets_with_refs.jsonl`. This infers relationships from `cluster_id` fields and creates RefPearl records marked with `_source: \"hierarchy_inference\"`. RefPearls have no URL but include `alias_target_uri` pointing to their target and show account boundaries in paths. See skill_pearl_dataset.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pearl_dataset_004_q1", "cluster_id": "skill_pearl_dataset_004", "question": "How do I create synthetic references in my dataset?", "answer": "To create synthetic references in your dataset, use the `generate_tree_refpearls.py` script which infers RefPearl (cross-reference) records from parent-child relationships in your existing dataset. Run: `python scripts/generate_tree_refpearls.py --input reports/pearltrees_targets.jsonl --output reports/pearltrees_targets_with_refs.jsonl`. This script examines `cluster_id` fields to identify hierarchical relationships and generates RefPearl records marked with `_source: \"hierarchy_inference\"`. These synthetic references capture folder-to-folder and item-to-folder relationships without creating actual URLs, instead using `alias_target_uri` to reference their targets. RefPearls also preserve account boundaries in their materialized paths.", "question_type": "long", "topics": ["Quickstart", "Data Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["refpearls", "synthetic-data", "relationships"], "related_skills": ["skill_pearl_dataset.md"], "related_docs": ["scripts/generate_tree_refpearls.py"], "original_answer": "RefPearls are cross-references to other trees or items, useful for capturing relationships. Generate them synthetically from parent-child relationships using: `python scripts/generate_tree_refpearls.py --input reports/pearltrees_targets.jsonl --output reports/pearltrees_targets_with_refs.jsonl`. This infers relationships from `cluster_id` fields and creates RefPearl records marked with `_source: \"hierarchy_inference\"`. RefPearls have no URL but include `alias_target_uri` pointing to their target and show account boundaries in paths. See skill_pearl_dataset.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pearl_dataset_004_q2", "cluster_id": "skill_pearl_dataset_004", "question": "What's a RefPearl and when should I use it?", "answer": "RefPearls are cross-references to other trees or pearls within your Pearltrees hierarchy. Use them when you want to capture relationships between items - for example, linking a physics article to multiple relevant folders. Generate RefPearls synthetically from your existing hierarchy using: `python scripts/generate_tree_refpearls.py --input reports/pearltrees_targets.jsonl --output reports/pearltrees_targets_with_refs.jsonl`. This command infers parent-child relationships from `cluster_id` fields and creates RefPearl records marked with `_source: \"hierarchy_inference\"`. RefPearls differ from regular pearls in that they have no external URL but include an `alias_target_uri` pointing to their target node, and they display account boundaries in their paths when spanning multiple accounts.", "question_type": "long", "topics": ["Quickstart", "Data Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["refpearls", "synthetic-data", "relationships"], "related_skills": ["skill_pearl_dataset.md"], "related_docs": ["scripts/generate_tree_refpearls.py"], "original_answer": "RefPearls are cross-references to other trees or items, useful for capturing relationships. Generate them synthetically from parent-child relationships using: `python scripts/generate_tree_refpearls.py --input reports/pearltrees_targets.jsonl --output reports/pearltrees_targets_with_refs.jsonl`. This infers relationships from `cluster_id` fields and creates RefPearl records marked with `_source: \"hierarchy_inference\"`. RefPearls have no URL but include `alias_target_uri` pointing to their target and show account boundaries in paths. See skill_pearl_dataset.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pearl_dataset_004_q3", "cluster_id": "skill_pearl_dataset_004", "question": "How do I infer relationships between items?", "answer": "RefPearls are cross-references that capture relationships between items. To infer relationships from your Pearltrees hierarchy, use: `python scripts/generate_tree_refpearls.py --input reports/pearltrees_targets.jsonl --output reports/pearltrees_targets_with_refs.jsonl`. This script analyzes parent-child relationships in your existing targets and creates RefPearl records that represent these connections. Each inferred RefPearl includes an `alias_target_uri` pointing to the related item and is marked with `_source: \"hierarchy_inference\"` to distinguish them from manually-defined references. RefPearls also respect account boundaries, so cross-account relationships are properly tracked in the materialized paths.", "question_type": "long", "topics": ["Quickstart", "Data Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["refpearls", "synthetic-data", "relationships"], "related_skills": ["skill_pearl_dataset.md"], "related_docs": ["scripts/generate_tree_refpearls.py"], "original_answer": "RefPearls are cross-references to other trees or items, useful for capturing relationships. Generate them synthetically from parent-child relationships using: `python scripts/generate_tree_refpearls.py --input reports/pearltrees_targets.jsonl --output reports/pearltrees_targets_with_refs.jsonl`. This infers relationships from `cluster_id` fields and creates RefPearl records marked with `_source: \"hierarchy_inference\"`. RefPearls have no URL but include `alias_target_uri` pointing to their target and show account boundaries in paths. See skill_pearl_dataset.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pearl_dataset_005_q0", "cluster_id": "skill_pearl_dataset_005", "question": "How do I filter my dataset to specific items or paths?", "answer": "Use `--path-filter`, `--trees-only`, and `--pearls-only` flags to subset your dataset. For example, `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --path-filter \"Science\" --output reports/science_targets.jsonl` extracts only the Science subtree. Use `--trees-only` for folders only, `--pearls-only` for bookmarks only, or `--account` to filter by account name. You can combine multiple flags: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --query-style file --pearls-only --output reports/targets_file.jsonl`", "question_type": "long", "topics": ["Quickstart", "Data Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["filtering", "subsetting", "path-filtering"], "related_skills": ["skill_pearl_dataset.md"], "related_docs": ["scripts/generate_pearl_dataset.py"], "original_answer": "Use `--path-filter`, `--trees-only`, and `--pearls-only` options to subset your data. Examples: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --path-filter \"Science\" --output reports/science_targets.jsonl` extracts only the Science subtree. Use `--trees-only` for folders only or `--pearls-only` for bookmarks only. You can also filter by `--account` for multi-account datasets. Combine flags as needed: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --query-style file --pearls-only --output reports/targets_file.jsonl`. See skill_pearl_dataset.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pearl_dataset_005_q1", "cluster_id": "skill_pearl_dataset_005", "question": "Can I extract a subset of my Pearltrees data?", "answer": "Yes, you can extract a subset of your Pearltrees data using filtering options. Use `--path-filter` to extract a specific subtree (e.g., `--path-filter \"Science\"`), `--trees-only` to include only folders, `--pearls-only` to include only bookmarks, or `--account` to filter by account name in multi-account datasets. Example: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --path-filter \"Science\" --output reports/science_targets.jsonl` extracts only the Science subtree. You can combine these flags as needed.", "question_type": "long", "topics": ["Quickstart", "Data Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["filtering", "subsetting", "path-filtering"], "related_skills": ["skill_pearl_dataset.md"], "related_docs": ["scripts/generate_pearl_dataset.py"], "original_answer": "Use `--path-filter`, `--trees-only`, and `--pearls-only` options to subset your data. Examples: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --path-filter \"Science\" --output reports/science_targets.jsonl` extracts only the Science subtree. Use `--trees-only` for folders only or `--pearls-only` for bookmarks only. You can also filter by `--account` for multi-account datasets. Combine flags as needed: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --query-style file --pearls-only --output reports/targets_file.jsonl`. See skill_pearl_dataset.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pearl_dataset_005_q2", "cluster_id": "skill_pearl_dataset_005", "question": "How do I filter by path or item type?", "answer": "Filter your pearl dataset using three main options: `--path-filter` to extract a specific subtree (e.g., `--path-filter \"Science\"`), `--trees-only` to include only folders, and `--pearls-only` to include only bookmarks. You can also filter by `--account` for multi-account datasets. Combine flags as needed: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --path-filter \"Science\" --pearls-only --output reports/science_targets.jsonl` extracts only bookmarks from the Science subtree.", "question_type": "long", "topics": ["Quickstart", "Data Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["filtering", "subsetting", "path-filtering"], "related_skills": ["skill_pearl_dataset.md"], "related_docs": ["scripts/generate_pearl_dataset.py"], "original_answer": "Use `--path-filter`, `--trees-only`, and `--pearls-only` options to subset your data. Examples: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --path-filter \"Science\" --output reports/science_targets.jsonl` extracts only the Science subtree. Use `--trees-only` for folders only or `--pearls-only` for bookmarks only. You can also filter by `--account` for multi-account datasets. Combine flags as needed: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --query-style file --pearls-only --output reports/targets_file.jsonl`. See skill_pearl_dataset.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pearl_dataset_005_q3", "cluster_id": "skill_pearl_dataset_005", "question": "How do I generate data for just trees or just bookmarks?", "answer": "Use the `--trees-only` flag to generate data for just folder/tree nodes, or `--pearls-only` flag to generate data for just bookmarks. Example: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --trees-only --output reports/trees.jsonl` for trees only, or `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --pearls-only --output reports/pearls.jsonl` for bookmarks only. You can combine these with other options like `--query-style` or `--account` to further refine your dataset.", "question_type": "long", "topics": ["Quickstart", "Data Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["filtering", "subsetting", "path-filtering"], "related_skills": ["skill_pearl_dataset.md"], "related_docs": ["scripts/generate_pearl_dataset.py"], "original_answer": "Use `--path-filter`, `--trees-only`, and `--pearls-only` options to subset your data. Examples: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --path-filter \"Science\" --output reports/science_targets.jsonl` extracts only the Science subtree. Use `--trees-only` for folders only or `--pearls-only` for bookmarks only. You can also filter by `--account` for multi-account datasets. Combine flags as needed: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --query-style file --pearls-only --output reports/targets_file.jsonl`. See skill_pearl_dataset.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_pearl_dataset_006_q0", "cluster_id": "skill_pearl_dataset_006", "question": "What's the complete workflow from RDF export to trained model?", "answer": "The complete workflow from RDF export to trained model involves five sequential stages: (1) Export RDF from Pearltrees settings to obtain raw hierarchy data, (2) Parse and generate the base semantic search dataset using `python scripts/generate_pearl_dataset.py` with your exported RDF file and desired query style (e.g., locate, file, or raw), (3) Enrich the dataset with synthetic cross-references using `python scripts/generate_tree_refpearls.py` to create additional training examples, (4) Generate embeddings for all entries with `python scripts/generate_embeddings.py` using a suitable embedding model like nomic-ai/nomic-embed-text-v1.5, and (5) Train your semantic search model using `python scripts/train_pearltrees_federated.py` with the enriched dataset to produce a deployable model artifact. Each stage builds on the previous, transforming raw Pearltrees hierarchy into a trained semantic search system.", "question_type": "medium", "topics": ["Quickstart", "Data Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["workflow", "embeddings", "model-training"], "related_skills": ["skill_pearl_dataset.md", "skill_synthetic_data.md"], "related_docs": ["scripts/generate_pearl_dataset.py", "scripts/generate_tree_refpearls.py", "scripts/train_pearltrees_federated.py"], "original_answer": "The workflow is: (1) Export RDF from Pearltrees settings, (2) Generate base dataset with `python scripts/generate_pearl_dataset.py --rdf data/export.rdf --query-style locate --output reports/base_targets.jsonl`, (3) Add synthetic references with `python scripts/generate_tree_refpearls.py --input reports/base_targets.jsonl --output reports/targets_with_refs.jsonl`, (4) Generate embeddings with `python scripts/generate_embeddings.py --input reports/targets_with_refs.jsonl --output datasets/embeddings.npz --model nomic-ai/nomic-embed-text-v1.5`, (5) Train model with `python scripts/train_pearltrees_federated.py reports/targets_with_refs.jsonl models/federated.pkl`. See skill_pearl_dataset.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pearl_dataset_006_q1", "cluster_id": "skill_pearl_dataset_006", "question": "How do I go from Pearltrees export to a usable model?", "answer": "To go from Pearltrees export to a usable model: (1) Export RDF from Pearltrees settings, (2) Generate base dataset using `python scripts/generate_pearl_dataset.py --rdf data/export.rdf --query-style locate --output reports/base_targets.jsonl`, (3) Enrich with synthetic references via `python scripts/generate_tree_refpearls.py --input reports/base_targets.jsonl --output reports/targets_with_refs.jsonl`, (4) Generate embeddings with `python scripts/generate_embeddings.py --input reports/targets_with_refs.jsonl --output datasets/embeddings.npz --model nomic-ai/nomic-embed-text-v1.5`, (5) Train the model using `python scripts/train_pearltrees_federated.py reports/targets_with_refs.jsonl models/federated.pkl`. This produces an end-to-end pipeline from RDF export to a trained semantic search model.", "question_type": "medium", "topics": ["Quickstart", "Data Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["workflow", "embeddings", "model-training"], "related_skills": ["skill_pearl_dataset.md", "skill_synthetic_data.md"], "related_docs": ["scripts/generate_pearl_dataset.py", "scripts/generate_tree_refpearls.py", "scripts/train_pearltrees_federated.py"], "original_answer": "The workflow is: (1) Export RDF from Pearltrees settings, (2) Generate base dataset with `python scripts/generate_pearl_dataset.py --rdf data/export.rdf --query-style locate --output reports/base_targets.jsonl`, (3) Add synthetic references with `python scripts/generate_tree_refpearls.py --input reports/base_targets.jsonl --output reports/targets_with_refs.jsonl`, (4) Generate embeddings with `python scripts/generate_embeddings.py --input reports/targets_with_refs.jsonl --output datasets/embeddings.npz --model nomic-ai/nomic-embed-text-v1.5`, (5) Train model with `python scripts/train_pearltrees_federated.py reports/targets_with_refs.jsonl models/federated.pkl`. See skill_pearl_dataset.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pearl_dataset_006_q2", "cluster_id": "skill_pearl_dataset_006", "question": "What are the steps to create embeddings and train a model?", "answer": "To create embeddings and train a model: (1) Export RDF from Pearltrees settings, (2) Generate base dataset using `python scripts/generate_pearl_dataset.py --rdf data/export.rdf --query-style locate --output reports/base_targets.jsonl`, (3) Add synthetic references with `python scripts/generate_tree_refpearls.py --input reports/base_targets.jsonl --output reports/targets_with_refs.jsonl`, (4) Generate embeddings with `python scripts/generate_embeddings.py --input reports/targets_with_refs.jsonl --output datasets/embeddings.npz --model nomic-ai/nomic-embed-text-v1.5`, (5) Train the model using `python scripts/train_pearltrees_federated.py reports/targets_with_refs.jsonl models/federated.pkl`.", "question_type": "medium", "topics": ["Quickstart", "Data Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["workflow", "embeddings", "model-training"], "related_skills": ["skill_pearl_dataset.md", "skill_synthetic_data.md"], "related_docs": ["scripts/generate_pearl_dataset.py", "scripts/generate_tree_refpearls.py", "scripts/train_pearltrees_federated.py"], "original_answer": "The workflow is: (1) Export RDF from Pearltrees settings, (2) Generate base dataset with `python scripts/generate_pearl_dataset.py --rdf data/export.rdf --query-style locate --output reports/base_targets.jsonl`, (3) Add synthetic references with `python scripts/generate_tree_refpearls.py --input reports/base_targets.jsonl --output reports/targets_with_refs.jsonl`, (4) Generate embeddings with `python scripts/generate_embeddings.py --input reports/targets_with_refs.jsonl --output datasets/embeddings.npz --model nomic-ai/nomic-embed-text-v1.5`, (5) Train model with `python scripts/train_pearltrees_federated.py reports/targets_with_refs.jsonl models/federated.pkl`. See skill_pearl_dataset.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pearl_dataset_006_q3", "cluster_id": "skill_pearl_dataset_006", "question": "How do I generate embeddings from my training data?", "answer": "To generate embeddings from your training data: (1) Ensure you have a JSONL dataset with `target_text` fields (generate with `python scripts/generate_pearl_dataset.py`), (2) Run `python scripts/generate_embeddings.py --input reports/targets_with_refs.jsonl --output datasets/embeddings.npz --model nomic-ai/nomic-embed-text-v1.5` to create embeddings, (3) The embeddings are stored as NumPy arrays indexed by URI for semantic search. Use the `--model` parameter to specify different embedding models like `all-MiniLM-L6-v2` or `bge-small-en-v1.5`.", "question_type": "medium", "topics": ["Quickstart", "Data Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["workflow", "embeddings", "model-training"], "related_skills": ["skill_pearl_dataset.md", "skill_synthetic_data.md"], "related_docs": ["scripts/generate_pearl_dataset.py", "scripts/generate_tree_refpearls.py", "scripts/train_pearltrees_federated.py"], "original_answer": "The workflow is: (1) Export RDF from Pearltrees settings, (2) Generate base dataset with `python scripts/generate_pearl_dataset.py --rdf data/export.rdf --query-style locate --output reports/base_targets.jsonl`, (3) Add synthetic references with `python scripts/generate_tree_refpearls.py --input reports/base_targets.jsonl --output reports/targets_with_refs.jsonl`, (4) Generate embeddings with `python scripts/generate_embeddings.py --input reports/targets_with_refs.jsonl --output datasets/embeddings.npz --model nomic-ai/nomic-embed-text-v1.5`, (5) Train model with `python scripts/train_pearltrees_federated.py reports/targets_with_refs.jsonl models/federated.pkl`. See skill_pearl_dataset.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "Base answer assumes prior dataset generation and RefPearl synthesis steps. The question specifically asks about embedding generation, which is only one step in the pipeline. Answer extracts the embedding-specific command but lacks details about embedding dimensions, indexing, or downstream usage."}
{"pair_id": "skill_pipe_communication_001_q0", "cluster_id": "skill_pipe_communication_001", "question": "How do I connect different programming languages via Unix pipes?", "answer": "To connect different programming languages via Unix pipes, use the pipe communication module to generate language-specific readers and writers. Generate a reader for the consumer language (e.g., `generate_pipe_reader(python, [name, age], [], Code)`) and a writer for the producer language (e.g., `generate_pipe_writer(go, [name, age], [], Code)`). This produces compatible code that streams data between languages using standard input/output: `go run producer.go | python consumer.py`. The module supports TSV and JSON formats across AWK, Python, Bash, Go, and Rust. See the Pipe Communication skill documentation for language-specific code generation details.", "question_type": "medium", "topics": ["Quickstart", "Pipe Communication"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["pipes", "unix", "data-flow", "interop"], "related_skills": ["skill_pipe_communication.md", "skill_ipc.md"], "related_docs": ["src/unifyweaver/glue/pipe_glue.pl"], "original_answer": "Use the pipe communication module to generate language-specific readers and writers. For example, generate a Python TSV reader with `generate_pipe_reader(python, [name, age], [], Code)` and a Go TSV writer with `generate_pipe_writer(go, [name, age], [], Code)`. This creates compatible code for: `python reader.py | go run writer.go`. See skill_pipe_communication.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pipe_communication_001_q1", "cluster_id": "skill_pipe_communication_001", "question": "How can I pass data between Python and Go in a pipeline?", "answer": "Use the pipe communication module to generate compatible readers and writers for Python and Go. Generate a Python TSV reader with `generate_pipe_reader(python, [field1, field2, ...], [], Code)` to read from stdin, and a Go TSV writer with `generate_pipe_writer(go, [field1, field2, ...], [], Code)` to write to stdout. This creates a pipeline where Python consumes data that Go produces: `go run writer.go | python reader.py`. Both languages support TSV and JSON formats for inter-process communication.", "question_type": "medium", "topics": ["Quickstart", "Pipe Communication"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["pipes", "unix", "data-flow", "interop"], "related_skills": ["skill_pipe_communication.md", "skill_ipc.md"], "related_docs": ["src/unifyweaver/glue/pipe_glue.pl"], "original_answer": "Use the pipe communication module to generate language-specific readers and writers. For example, generate a Python TSV reader with `generate_pipe_reader(python, [name, age], [], Code)` and a Go TSV writer with `generate_pipe_writer(go, [name, age], [], Code)`. This creates compatible code for: `python reader.py | go run writer.go`. See skill_pipe_communication.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pipe_communication_001_q2", "cluster_id": "skill_pipe_communication_001", "question": "What's the best way to create inter-language data flows?", "answer": "Use the pipe communication module to generate language-specific readers and writers that create Unix pipeline-compatible code. For TSV data flows, generate a reader in your consumer language (e.g., `generate_pipe_reader(python, [name, age], [], Code)`) and a writer in your producer language (e.g., `generate_pipe_writer(go, [name, age], [], Code)`). This produces code that pipes seamlessly: `go run producer.go | python consumer.py`. The module supports AWK, Python, Bash, Go, and Rust with both TSV and JSON formats. Choose TSV for simplicity or JSON for structured data with nested fields.", "question_type": "medium", "topics": ["Quickstart", "Pipe Communication"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["pipes", "unix", "data-flow", "interop"], "related_skills": ["skill_pipe_communication.md", "skill_ipc.md"], "related_docs": ["src/unifyweaver/glue/pipe_glue.pl"], "original_answer": "Use the pipe communication module to generate language-specific readers and writers. For example, generate a Python TSV reader with `generate_pipe_reader(python, [name, age], [], Code)` and a Go TSV writer with `generate_pipe_writer(go, [name, age], [], Code)`. This creates compatible code for: `python reader.py | go run writer.go`. See skill_pipe_communication.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pipe_communication_002_q0", "cluster_id": "skill_pipe_communication_002", "question": "How do I build an ETL pipeline with multiple programming languages?", "answer": "To build an ETL pipeline with multiple programming languages, use the Pipe Communication skill to generate language-specific readers and writers for each stage. Generate an extractor in Python using `generate_pipe_reader(python, [id, name, value], [], ExtractCode)`, a transformer in AWK using `generate_pipe_writer(awk, [id, name, value], [], TransformCode)`, and a loader in Go using `generate_pipe_writer(go, [id, name, value], [format(json)], LoadCode)`. Compose them into a Unix pipeline: `python extract.py | awk -f transform.awk | go run load.go`. Each stage reads from stdin and writes to stdout, enabling seamless inter-language data streaming with TSV or JSON formats. Supported languages include Python, AWK, Bash, Go, and Rust.", "question_type": "medium", "topics": ["Quickstart", "Pipe Communication"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["etl", "pipeline", "data-integration", "multi-language"], "related_skills": ["skill_pipe_communication.md"], "related_docs": ["src/unifyweaver/glue/pipe_glue.pl"], "original_answer": "Generate readers and writers for each stage: `generate_pipe_reader(python, [id, name, value], [], ExtractCode)` for extraction, `generate_pipe_writer(awk, [id, name, value], [], TransformCode)` for transformation, and `generate_pipe_writer(go, [id, name, value], [format(json)], LoadCode)` for loading. Compose them as: `python extract.py | awk -f transform.awk | go run load.go`. See skill_pipe_communication.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pipe_communication_002_q1", "cluster_id": "skill_pipe_communication_002", "question": "Can I extract data in Python, transform in AWK, and load in Go?", "answer": "Yes, you can build an ETL pipeline across Python, AWK, and Go. Use `generate_pipe_reader(python, [id, name, value], [], ExtractCode)` to extract data in Python and output TSV to stdout. Then pipe to AWK with `generate_pipe_writer(awk, [id, name, value], [], TransformCode)` to transform the data. Finally, pipe to Go with `generate_pipe_reader(go, [id, name, value], [], LoadCode)` to consume and load the transformed data. Run as: `python extract.py | awk -f transform.awk | go run load.go`. All three targets support TSV read/write operations for seamless piping.", "question_type": "medium", "topics": ["Quickstart", "Pipe Communication"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["etl", "pipeline", "data-integration", "multi-language"], "related_skills": ["skill_pipe_communication.md"], "related_docs": ["src/unifyweaver/glue/pipe_glue.pl"], "original_answer": "Generate readers and writers for each stage: `generate_pipe_reader(python, [id, name, value], [], ExtractCode)` for extraction, `generate_pipe_writer(awk, [id, name, value], [], TransformCode)` for transformation, and `generate_pipe_writer(go, [id, name, value], [format(json)], LoadCode)` for loading. Compose them as: `python extract.py | awk -f transform.awk | go run load.go`. See skill_pipe_communication.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pipe_communication_002_q2", "cluster_id": "skill_pipe_communication_002", "question": "How do I create multi-language ETL workflows?", "answer": "Create multi-language ETL workflows by generating language-specific readers and writers for each pipeline stage. Use `generate_pipe_reader(python, [id, name, value], [], Code)` to extract data, `generate_pipe_writer(awk, [id, name, value], [], Code)` to transform it, and `generate_pipe_writer(go, [id, name, value], [format(json)], Code)` to load the results. Pipe these together: `python extract.py | awk -f transform.awk | go run load.go`. The skill supports TSV and JSON formats across Python, AWK, Bash, Go, and Rust for seamless inter-language data streaming.", "question_type": "medium", "topics": ["Quickstart", "Pipe Communication"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["etl", "pipeline", "data-integration", "multi-language"], "related_skills": ["skill_pipe_communication.md"], "related_docs": ["src/unifyweaver/glue/pipe_glue.pl"], "original_answer": "Generate readers and writers for each stage: `generate_pipe_reader(python, [id, name, value], [], ExtractCode)` for extraction, `generate_pipe_writer(awk, [id, name, value], [], TransformCode)` for transformation, and `generate_pipe_writer(go, [id, name, value], [format(json)], LoadCode)` for loading. Compose them as: `python extract.py | awk -f transform.awk | go run load.go`. See skill_pipe_communication.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pipe_communication_003_q0", "cluster_id": "skill_pipe_communication_003", "question": "How do I generate code to read and write tab-separated data in different languages?", "answer": "Use `generate_tsv_reader(Target, Fields, Code)` and `generate_tsv_writer(Target, Fields, Code)` to generate tab-separated data handlers for awk, python, bash, go, and rust. For example, `generate_tsv_writer(python, [name, age], Code)` produces `print(\"\\t\".join(str(x) for x in [name, age]))`. Pass field names as a list; the predicates automatically generate language-specific parsing or output code. Each target has optimized syntax: awk uses positional fields ($1, $2), python uses split/join, bash uses IFS with read, go uses strings.Split, and rust uses tab-split iterators.", "question_type": "long", "topics": ["Quickstart", "Pipe Communication"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["tsv", "format", "data-reading", "code-generation"], "related_skills": ["skill_pipe_communication.md"], "related_docs": ["src/unifyweaver/glue/pipe_glue.pl"], "original_answer": "Use `generate_tsv_reader(Target, Fields, Code)` and `generate_tsv_writer(Target, Fields, Code)` for supported targets (awk, python, bash, go, rust). For example, `generate_tsv_writer(python, [name, age], Code)` generates: `print(\"\\t\".join(str(x) for x in [name, age]))`. Fields are passed as a list and automatically mapped to language-specific variables. See skill_pipe_communication.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pipe_communication_003_q1", "cluster_id": "skill_pipe_communication_003", "question": "What's the easiest way to handle TSV in multiple programming languages?", "answer": "The easiest way to handle TSV in multiple programming languages is to use the `generate_tsv_reader()` and `generate_tsv_writer()` predicates from the pipe_glue module. These automatically generate language-specific TSV parsing and formatting code for awk, python, bash, go, and rust. For example, `generate_tsv_writer(python, [name, age], Code)` generates `print(\"\\t\".join(str(x) for x in [name, age]))`, while `generate_tsv_reader(python, [name, age], Code)` generates a reader that splits stdin by tabs and assigns fields to named variables. You simply pass your field names as a list, and the predicates handle language-specific syntax automatically.", "question_type": "long", "topics": ["Quickstart", "Pipe Communication"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["tsv", "format", "data-reading", "code-generation"], "related_skills": ["skill_pipe_communication.md"], "related_docs": ["src/unifyweaver/glue/pipe_glue.pl"], "original_answer": "Use `generate_tsv_reader(Target, Fields, Code)` and `generate_tsv_writer(Target, Fields, Code)` for supported targets (awk, python, bash, go, rust). For example, `generate_tsv_writer(python, [name, age], Code)` generates: `print(\"\\t\".join(str(x) for x in [name, age]))`. Fields are passed as a list and automatically mapped to language-specific variables. See skill_pipe_communication.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pipe_communication_003_q2", "cluster_id": "skill_pipe_communication_003", "question": "How do I create compatible TSV readers across languages?", "answer": "To create compatible TSV readers across languages, use `generate_tsv_reader(Target, Fields, Code)` where Target is one of: awk, python, bash, go, or rust. Pass your field names as a list (e.g., `[name, age, score]`). Each language generates the appropriate boilerplate for reading tab-separated stdin: Python uses `sys.stdin` with split on tabs, Bash uses `IFS=$'\\t'` with read loops, AWK accesses fields as `$1`, `$2`, etc., Go uses `bufio.Scanner`, and Rust uses standard input parsing. This ensures field parsing is consistent across all languages while respecting each language's idioms.", "question_type": "long", "topics": ["Quickstart", "Pipe Communication"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["tsv", "format", "data-reading", "code-generation"], "related_skills": ["skill_pipe_communication.md"], "related_docs": ["src/unifyweaver/glue/pipe_glue.pl"], "original_answer": "Use `generate_tsv_reader(Target, Fields, Code)` and `generate_tsv_writer(Target, Fields, Code)` for supported targets (awk, python, bash, go, rust). For example, `generate_tsv_writer(python, [name, age], Code)` generates: `print(\"\\t\".join(str(x) for x in [name, age]))`. Fields are passed as a list and automatically mapped to language-specific variables. See skill_pipe_communication.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_pipe_communication_004_q0", "cluster_id": "skill_pipe_communication_004", "question": "How do I generate code to read and write JSON Lines data across languages?", "answer": "To generate code for reading and writing JSON Lines data across languages, use the `generate_json_reader(Target, Fields, Code)` and `generate_json_writer(Target, Fields, Code)` predicates. For example, `generate_json_writer(python, [id, name, value], Code)` generates Python code that outputs JSON Lines format, while `generate_json_reader(go, [id, name, value], Code)` generates Go code to parse JSON Lines input. Supported targets include Python, Go, Rust, and AWK. You can chain these in Unix pipelines: `python writer.py | go run reader.go`. The generated code handles JSON parsing and field extraction automatically.", "question_type": "long", "topics": ["Quickstart", "Pipe Communication"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["json", "json-lines", "streaming", "format"], "related_skills": ["skill_pipe_communication.md"], "related_docs": ["src/unifyweaver/glue/pipe_glue.pl"], "original_answer": "Use `generate_json_reader(Target, Fields, Code)` or `generate_json_writer(Target, Fields, Code)` with the `format(json)` option. For instance, `generate_json_reader(python, [id, name, value], Code)` generates code to parse JSON lines and extract fields. Supported targets include python, go, rust, awk. Chain them in pipelines: `python writer.py | go run reader.go`. See skill_pipe_communication.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer mentions `format(json)` option but the skill document examples don't show this syntax being used in practice. The truncated skill document may have contained additional details about option syntax that would improve clarity."}
{"pair_id": "skill_pipe_communication_004_q1", "cluster_id": "skill_pipe_communication_004", "question": "How can I work with JSON Lines format in Go and Python?", "answer": "Use `generate_json_reader(Target, Fields, Code)` to read JSON Lines and `generate_json_writer(Target, Fields, Code)` to write JSON Lines. For Python: `generate_json_reader(python, [id, name, value], Code)` generates code that reads JSON objects line-by-line from stdin and extracts fields. For Go: `generate_json_reader(go, [id, name, value], Code)` generates a scanner that parses each JSON line. Similarly, use `generate_json_writer(python, [id, name, value], Code)` or `generate_json_writer(go, [id, name, value], Code)` to output JSON Lines format. Pipe them together: `python writer.py | go run reader.go`.", "question_type": "long", "topics": ["Quickstart", "Pipe Communication"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["json", "json-lines", "streaming", "format"], "related_skills": ["skill_pipe_communication.md"], "related_docs": ["src/unifyweaver/glue/pipe_glue.pl"], "original_answer": "Use `generate_json_reader(Target, Fields, Code)` or `generate_json_writer(Target, Fields, Code)` with the `format(json)` option. For instance, `generate_json_reader(python, [id, name, value], Code)` generates code to parse JSON lines and extract fields. Supported targets include python, go, rust, awk. Chain them in pipelines: `python writer.py | go run reader.go`. See skill_pipe_communication.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pipe_communication_004_q2", "cluster_id": "skill_pipe_communication_004", "question": "What's the best way to handle JSON streaming between different languages?", "answer": "For JSON streaming between languages, use the `generate_json_reader()` and `generate_json_writer()` predicates from the pipe_glue module. Use `generate_json_writer(Target, Fields, Code)` on the producer side to generate JSON line writers (supported in Python, Go, Rust, and AWK), and `generate_json_reader(Target, Fields, Code)` on the consumer side to parse JSON lines and extract fields. Chain them directly in Unix pipelines: `python writer.py | go run reader.go`. This handles JSON streaming natively across language boundaries without requiring intermediate format conversions.", "question_type": "long", "topics": ["Quickstart", "Pipe Communication"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["json", "json-lines", "streaming", "format"], "related_skills": ["skill_pipe_communication.md"], "related_docs": ["src/unifyweaver/glue/pipe_glue.pl"], "original_answer": "Use `generate_json_reader(Target, Fields, Code)` or `generate_json_writer(Target, Fields, Code)` with the `format(json)` option. For instance, `generate_json_reader(python, [id, name, value], Code)` generates code to parse JSON lines and extract fields. Supported targets include python, go, rust, awk. Chain them in pipelines: `python writer.py | go run reader.go`. See skill_pipe_communication.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_pipe_communication_005_q0", "cluster_id": "skill_pipe_communication_005", "question": "How do I orchestrate complex multi-step data pipelines with local and remote processing?", "answer": "Orchestrate multi-step pipelines with `generate_pipeline_script(Steps, Options, Script)`. Define steps as `step(Name, local, Script)` for local processing or `step(Name, remote, Endpoint)` for remote. Options include target language selection. Steps execute sequentially with output piping.", "question_type": "long", "topics": ["Quickstart", "Pipe Communication"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["orchestration", "pipeline", "api-integration", "remote-processing"], "related_skills": ["skill_pipe_communication.md"], "related_docs": ["src/unifyweaver/glue/pipe_glue.pl"], "original_answer": "Use `generate_pipeline_script(Steps, Options, Script)` with step definitions. Each step can be `step(Name, local, Script)` for local processing or `step(Name, remote, URL)` for HTTP calls. Example: `generate_pipeline_script([step(extract, local, 'cat data.tsv'), step(transform, local, 'python transform.py'), step(analyze, remote, 'http://api.example.com/analyze')], [language(bash)], Script)`. See skill_pipe_communication.md for details.", "answer_tailored": true, "confidence": 0.7, "confidence_issues": "Advanced pipeline orchestration options not fully documented", "manually_reviewed": true}
{"pair_id": "skill_pipe_communication_005_q1", "cluster_id": "skill_pipe_communication_005", "question": "Can I combine local scripts with remote API calls in a pipeline?", "answer": "Yes, you can combine local scripts with remote API calls in a pipeline using `generate_pipeline_script(Steps, Options, Script)`. Define each step as either `step(Name, local, Script)` for local processing or `step(Name, remote, URL)` for HTTP API calls. For example: `generate_pipeline_script([step(extract, local, 'cat data.tsv'), step(transform, local, 'python transform.py'), step(analyze, remote, 'http://api.example.com/analyze')], [language(bash)], Script)` generates a bash script that orchestrates the entire pipeline, mixing local execution with remote HTTP calls.", "question_type": "long", "topics": ["Quickstart", "Pipe Communication"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["orchestration", "pipeline", "api-integration", "remote-processing"], "related_skills": ["skill_pipe_communication.md"], "related_docs": ["src/unifyweaver/glue/pipe_glue.pl"], "original_answer": "Use `generate_pipeline_script(Steps, Options, Script)` with step definitions. Each step can be `step(Name, local, Script)` for local processing or `step(Name, remote, URL)` for HTTP calls. Example: `generate_pipeline_script([step(extract, local, 'cat data.tsv'), step(transform, local, 'python transform.py'), step(analyze, remote, 'http://api.example.com/analyze')], [language(bash)], Script)`. See skill_pipe_communication.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "The base answer references `generate_pipeline_script/3` which is not documented in the provided skill document. The skill document covers pipe readers/writers for TSV/JSON data formats, but does not show examples or API details for the `generate_pipeline_script/3` predicate. This creates uncertainty about whether the answer is accurate or if the predicate signature/behavior matches user expectations."}
{"pair_id": "skill_pipe_communication_005_q2", "cluster_id": "skill_pipe_communication_005", "question": "How do I generate pipeline scripts that mix processing steps?", "answer": "To generate pipeline scripts that mix processing steps, use `generate_pipeline_script(Steps, Options, Script)`. Define each step as either `step(Name, local, Script)` for local processing or `step(Name, remote, URL)` for HTTP calls. For example: `generate_pipeline_script([step(extract, local, 'cat data.tsv'), step(transform, local, 'python transform.py'), step(analyze, remote, 'http://api.example.com/analyze')], [language(bash)], Script)` generates a bash pipeline that extracts data, transforms it locally, then sends results to a remote API. Steps execute sequentially with output piping between them.", "question_type": "long", "topics": ["Quickstart", "Pipe Communication"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["orchestration", "pipeline", "api-integration", "remote-processing"], "related_skills": ["skill_pipe_communication.md"], "related_docs": ["src/unifyweaver/glue/pipe_glue.pl"], "original_answer": "Use `generate_pipeline_script(Steps, Options, Script)` with step definitions. Each step can be `step(Name, local, Script)` for local processing or `step(Name, remote, URL)` for HTTP calls. Example: `generate_pipeline_script([step(extract, local, 'cat data.tsv'), step(transform, local, 'python transform.py'), step(analyze, remote, 'http://api.example.com/analyze')], [language(bash)], Script)`. See skill_pipe_communication.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "Base answer lacks specifics on how steps chain together, output format between steps (TSV/JSON), error handling, and whether remote steps receive piped input or make separate requests. The example shows the syntax but not the resulting behavior."}
{"pair_id": "skill_pipe_communication_006_q0", "cluster_id": "skill_pipe_communication_006", "question": "Which programming languages can I use for pipe-based data communication?", "answer": "You can use awk, python, bash, go, and rust for pipe-based TSV data communication. For JSON-based pipes, awk, python, go, and rust are supported (bash does not support JSON). You can compose these languages together in pipelines\u2014for example: `python reader | awk processor | go writer` works across all combinations.", "question_type": "medium", "topics": ["Quickstart", "Pipe Communication"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["language-support", "compatibility", "target-languages"], "related_skills": ["skill_pipe_communication.md"], "related_docs": ["src/unifyweaver/glue/pipe_glue.pl"], "original_answer": "Supported targets for TSV: awk, python, bash, go, rust. All five support both reading and writing TSV. For JSON, awk, python, go, and rust are supported (bash does not support JSON). Build pipelines by composing compatible targets: `python reader | awk processor | go writer` works across all combinations. See skill_pipe_communication.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pipe_communication_006_q1", "cluster_id": "skill_pipe_communication_006", "question": "What languages support TSV and JSON piping?", "answer": "TSV piping is supported by awk, python, bash, go, and rust\u2014all five languages support both reading and writing TSV format. For JSON piping, awk, python, go, and rust are supported, while bash does not support JSON read/write operations. You can compose pipelines across these languages freely, such as `python reader | awk processor | go writer`.", "question_type": "medium", "topics": ["Quickstart", "Pipe Communication"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["language-support", "compatibility", "target-languages"], "related_skills": ["skill_pipe_communication.md"], "related_docs": ["src/unifyweaver/glue/pipe_glue.pl"], "original_answer": "Supported targets for TSV: awk, python, bash, go, rust. All five support both reading and writing TSV. For JSON, awk, python, go, and rust are supported (bash does not support JSON). Build pipelines by composing compatible targets: `python reader | awk processor | go writer` works across all combinations. See skill_pipe_communication.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_pipe_communication_006_q2", "cluster_id": "skill_pipe_communication_006", "question": "Can I use Rust, Go, Python, and AWK in the same pipeline?", "answer": "Yes, you can use Rust, Go, Python, and AWK in the same pipeline. All four languages support both reading and writing TSV format, allowing you to compose them in any order: for example, `python reader | awk processor | go writer | rust consumer` works across all combinations. For JSON pipelines, all four also support both reading and writing. Connect them using standard Unix pipes and ensure each stage outputs the format the next stage expects.", "question_type": "medium", "topics": ["Quickstart", "Pipe Communication"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["language-support", "compatibility", "target-languages"], "related_skills": ["skill_pipe_communication.md"], "related_docs": ["src/unifyweaver/glue/pipe_glue.pl"], "original_answer": "Supported targets for TSV: awk, python, bash, go, rust. All five support both reading and writing TSV. For JSON, awk, python, go, and rust are supported (bash does not support JSON). Build pipelines by composing compatible targets: `python reader | awk processor | go writer` works across all combinations. See skill_pipe_communication.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_python_bridges_001_q0", "cluster_id": "skill_python_bridges_001", "question": "How do I call Python functions from my .NET application?", "answer": "To call Python functions from your .NET application, use Python.NET or CSnakes. Python.NET provides direct CPython embedding with dynamic method invocation through the GIL (Global Interpreter Lock). CSnakes offers a modern source-generated approach with strong typing and improved performance. Use `generate_pythonnet_rpyc_client(Predicates, Code)` to generate a C# bridge class that wraps Python module imports and function calls, or `generate_csnakes_rpyc_client(Predicates, Code)` for the source-generated variant. Both approaches handle the runtime setup and interop marshalling automatically.", "question_type": "medium", "topics": ["Quickstart", "Python Bridges"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["dotnet", "embedding", "interop"], "related_skills": ["skill_python_bridges.md"], "related_docs": ["src/unifyweaver/glue/python_bridges_glue.pl"], "original_answer": "Use Python.NET or CSnakes for .NET embedding. Generate a C# client with `generate_pythonnet_rpyc_client(Predicates, Code)` or `generate_csnakes_rpyc_client(Predicates, Code)`. CSnakes offers modern source-generated interop with strong typing and lower latency. See skill_python_bridges.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_python_bridges_001_q1", "cluster_id": "skill_python_bridges_001", "question": "Can I embed Python in C#?", "answer": "Yes, you can embed Python in C# using two main approaches: Python.NET for CPython embedding in .NET, or CSnakes for modern source-generated Python interop with strong typing and lower latency. Use `generate_pythonnet_rpyc_client(Predicates, Code)` to generate Python.NET client code or `generate_csnakes_rpyc_client(Predicates, Code)` for CSnakes. Both are mature and stable options depending on your latency and type-safety requirements.", "question_type": "medium", "topics": ["Quickstart", "Python Bridges"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["dotnet", "embedding", "interop"], "related_skills": ["skill_python_bridges.md"], "related_docs": ["src/unifyweaver/glue/python_bridges_glue.pl"], "original_answer": "Use Python.NET or CSnakes for .NET embedding. Generate a C# client with `generate_pythonnet_rpyc_client(Predicates, Code)` or `generate_csnakes_rpyc_client(Predicates, Code)`. CSnakes offers modern source-generated interop with strong typing and lower latency. See skill_python_bridges.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_python_bridges_001_q2", "cluster_id": "skill_python_bridges_001", "question": "What's the best way to use Python in a .NET project?", "answer": "For .NET projects, use Python.NET or CSnakes for embedding Python. Python.NET is a mature option that lets you call Python directly from C#. CSnakes is the modern alternative with source-generated interop, offering strong typing and lower latency. To get started, use `generate_pythonnet_rpyc_client(Predicates, Code)` for Python.NET or `generate_csnakes_rpyc_client(Predicates, Code)` for CSnakes to generate client code. Choose CSnakes if you want the latest approach with better type safety.", "question_type": "medium", "topics": ["Quickstart", "Python Bridges"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["dotnet", "embedding", "interop"], "related_skills": ["skill_python_bridges.md"], "related_docs": ["src/unifyweaver/glue/python_bridges_glue.pl"], "original_answer": "Use Python.NET or CSnakes for .NET embedding. Generate a C# client with `generate_pythonnet_rpyc_client(Predicates, Code)` or `generate_csnakes_rpyc_client(Predicates, Code)`. CSnakes offers modern source-generated interop with strong typing and lower latency. See skill_python_bridges.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_python_bridges_002_q0", "cluster_id": "skill_python_bridges_002", "question": "How do I use Python from Java or JVM applications?", "answer": "Use JPype or jpy for JVM-Python integration. Call `auto_select_bridge(jvm, [], Bridge)` to automatically detect the best available bridge on your system, then generate code using `generate_jpype_rpyc_client(Predicates, Code)` for JPype or `generate_jpy_rpyc_client(Predicates, Code)` for jpy. For high-throughput scenarios requiring lower latency, jpy is the recommended choice. Both bridges enable direct Python function calls from Java with minimal overhead.", "question_type": "medium", "topics": ["Quickstart", "Python Bridges"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["jvm", "java", "embedding", "interop"], "related_skills": ["skill_python_bridges.md"], "related_docs": ["src/unifyweaver/glue/python_bridges_glue.pl"], "original_answer": "Use JPype or jpy for JVM-Python integration. Call `auto_select_bridge(jvm, [], Bridge)` to detect the best available option, then generate code with `generate_jpype_rpyc_client(Predicates, Code)` or `generate_jpy_rpyc_client(Predicates, Code)`. jpy offers lower latency and better performance for high-throughput scenarios. See skill_python_bridges.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_python_bridges_002_q1", "cluster_id": "skill_python_bridges_002", "question": "Can I call Python from Java?", "answer": "Yes, you can call Python from Java using JPype or jpy. Use `auto_select_bridge(jvm, [], Bridge)` to detect the best available bridge for your system. JPype provides direct Python integration with mature support, while jpy offers bidirectional interoperability and lower latency for high-throughput scenarios. Generate integration code using `generate_jpype_rpyc_client(Predicates, Code)` or `generate_jpy_rpyc_client(Predicates, Code)`. See the Python Bridges skill documentation for detailed implementation steps.", "question_type": "medium", "topics": ["Quickstart", "Python Bridges"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["jvm", "java", "embedding", "interop"], "related_skills": ["skill_python_bridges.md"], "related_docs": ["src/unifyweaver/glue/python_bridges_glue.pl"], "original_answer": "Use JPype or jpy for JVM-Python integration. Call `auto_select_bridge(jvm, [], Bridge)` to detect the best available option, then generate code with `generate_jpype_rpyc_client(Predicates, Code)` or `generate_jpy_rpyc_client(Predicates, Code)`. jpy offers lower latency and better performance for high-throughput scenarios. See skill_python_bridges.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_python_bridges_002_q2", "cluster_id": "skill_python_bridges_002", "question": "What's the fastest way to integrate Python with JVM?", "answer": "For JVM-Python integration, use JPype or jpy. Call `auto_select_bridge(jvm, [], Bridge)` to automatically detect the fastest available bridge on your system. For high-throughput scenarios, jpy typically offers lower latency. Generate integration code with `generate_jpype_rpyc_client(Predicates, Code)` or `generate_jpy_rpyc_client(Predicates, Code)`. jpy is recommended as the fastest option when available.", "question_type": "medium", "topics": ["Quickstart", "Python Bridges"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["jvm", "java", "embedding", "interop"], "related_skills": ["skill_python_bridges.md"], "related_docs": ["src/unifyweaver/glue/python_bridges_glue.pl"], "original_answer": "Use JPype or jpy for JVM-Python integration. Call `auto_select_bridge(jvm, [], Bridge)` to detect the best available option, then generate code with `generate_jpype_rpyc_client(Predicates, Code)` or `generate_jpy_rpyc_client(Predicates, Code)`. jpy offers lower latency and better performance for high-throughput scenarios. See skill_python_bridges.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_python_bridges_003_q0", "cluster_id": "skill_python_bridges_003", "question": "What's the best way to integrate Python with Rust?", "answer": "Use PyO3 for Rust-Python integration. PyO3 provides direct Python bindings with strong typing and high performance through Rust's memory safety guarantees. Call `generate_pyo3_rpyc_client(Predicates, RustCode)` to auto-generate Rust code that lets you call Python functions with low latency. PyO3 is the mature, recommended bridge for embedding Python in Rust applications.", "question_type": "medium", "topics": ["Quickstart", "Python Bridges"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["rust", "embedding", "interop", "ffi"], "related_skills": ["skill_python_bridges.md"], "related_docs": ["src/unifyweaver/glue/python_bridges_glue.pl"], "original_answer": "Use PyO3 for Rust-Python integration. Call `generate_pyo3_rpyc_client(Predicates, Code)` to generate Rust bindings that let you call Python functions with low latency. PyO3 provides strong typing and high performance through Rust's memory safety guarantees. See skill_python_bridges.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_python_bridges_003_q1", "cluster_id": "skill_python_bridges_003", "question": "How do I call Python from Rust?", "answer": "Use PyO3 to call Python from Rust. PyO3 provides native Rust bindings for Python with strong typing and high performance. Call `generate_pyo3_rpyc_client(Predicates, Code)` to generate Rust code that integrates with Python functions. PyO3 leverages Rust's memory safety guarantees for low-latency cross-runtime communication.", "question_type": "medium", "topics": ["Quickstart", "Python Bridges"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["rust", "embedding", "interop", "ffi"], "related_skills": ["skill_python_bridges.md"], "related_docs": ["src/unifyweaver/glue/python_bridges_glue.pl"], "original_answer": "Use PyO3 for Rust-Python integration. Call `generate_pyo3_rpyc_client(Predicates, Code)` to generate Rust bindings that let you call Python functions with low latency. PyO3 provides strong typing and high performance through Rust's memory safety guarantees. See skill_python_bridges.md for details.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null}
{"pair_id": "skill_python_bridges_003_q2", "cluster_id": "skill_python_bridges_003", "question": "Can I embed Python in Rust code?", "answer": "Yes, you can embed Python in Rust using PyO3. PyO3 is a mature Rust bridge that provides strong typing and high-performance Python integration through Rust's memory safety guarantees. You can use `generate_pyo3_rpyc_client(Predicates, Code)` to automatically generate Rust bindings that allow you to call Python functions with low latency. For more details, see the Python Bridges skill documentation.", "question_type": "medium", "topics": ["Quickstart", "Python Bridges"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["rust", "embedding", "interop", "ffi"], "related_skills": ["skill_python_bridges.md"], "related_docs": ["src/unifyweaver/glue/python_bridges_glue.pl"], "original_answer": "Use PyO3 for Rust-Python integration. Call `generate_pyo3_rpyc_client(Predicates, Code)` to generate Rust bindings that let you call Python functions with low latency. PyO3 provides strong typing and high performance through Rust's memory safety guarantees. See skill_python_bridges.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_python_bridges_004_q0", "cluster_id": "skill_python_bridges_004", "question": "How do I call Python from Go or Node.js?", "answer": "Use FFI (Foreign Function Interface) bridges to call Python from Go or Node.js. For Go, generate a Rust FFI bridge with `generate_rust_ffi_bridge(Predicates, Code)` then call it from Go using `generate_go_ffi_client(Predicates, Code)`. For Node.js, use either `generate_node_koffi_client(Predicates, Code)` for modern FFI or `generate_node_ffi_napi_client(Predicates, Code)` for N-API based FFI. This approach provides the lowest-latency Python integration when direct bindings aren't available.", "question_type": "medium", "topics": ["Quickstart", "Python Bridges"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["ffi", "go", "node.js", "polyglot", "interop"], "related_skills": ["skill_python_bridges.md"], "related_docs": ["src/unifyweaver/glue/python_bridges_glue.pl"], "original_answer": "Use FFI (Foreign Function Interface) bridges. Generate a Rust FFI bridge with `generate_rust_ffi_bridge(Predicates, Code)`, then call it from Go with `generate_go_ffi_client(Predicates, Code)` or from Node.js with `generate_node_koffi_client(Predicates, Code)` or `generate_node_ffi_napi_client(Predicates, Code)`. This approach works for languages without direct Python bindings. See skill_python_bridges.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "Base answer mentions Rust FFI bridge generation, but the skill document shows FFI targets (Go/Node.js) but doesn't explicitly document the Rust bridge generation functions. The answer assumes these predicates exist based on the skill's architecture."}
{"pair_id": "skill_python_bridges_004_q1", "cluster_id": "skill_python_bridges_004", "question": "Can I use Python in a Go application?", "answer": "Yes, you can use Python in a Go application using FFI (Foreign Function Interface) bridges. Generate a Rust FFI bridge with `generate_rust_ffi_bridge(Predicates, Code)`, then call it from Go using `generate_go_ffi_client(Predicates, Code)`. Alternatively, you can use Go's cgo to create C FFI bindings to Python. This approach enables Python integration in languages without direct Python bindings.", "question_type": "medium", "topics": ["Quickstart", "Python Bridges"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["ffi", "go", "node.js", "polyglot", "interop"], "related_skills": ["skill_python_bridges.md"], "related_docs": ["src/unifyweaver/glue/python_bridges_glue.pl"], "original_answer": "Use FFI (Foreign Function Interface) bridges. Generate a Rust FFI bridge with `generate_rust_ffi_bridge(Predicates, Code)`, then call it from Go with `generate_go_ffi_client(Predicates, Code)` or from Node.js with `generate_node_koffi_client(Predicates, Code)` or `generate_node_ffi_napi_client(Predicates, Code)`. This approach works for languages without direct Python bindings. See skill_python_bridges.md for details.", "answer_tailored": true, "confidence": 0.75, "confidence_issues": "The base answer mentions Node.js code generation functions that aren't directly applicable to Go. The tailored answer focuses on Go-specific approaches (cgo and Rust FFI bridge pattern) but the skill document doesn't explicitly show Go FFI code generation examples, only mentions it exists."}
{"pair_id": "skill_python_bridges_004_q2", "cluster_id": "skill_python_bridges_004", "question": "What's the best way to integrate Python with Node.js?", "answer": "Use FFI (Foreign Function Interface) bridges for Node.js integration. Node.js provides two FFI options: koffi (modern FFI library) or ffi-napi (N-API based). You can call Python functions through these FFI bridges without requiring direct Python bindings. Generate client code using `generate_node_koffi_client(Predicates, Code)` or `generate_node_ffi_napi_client(Predicates, Code)` depending on your performance and compatibility needs. See skill_python_bridges.md for implementation details.", "question_type": "medium", "topics": ["Quickstart", "Python Bridges"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["ffi", "go", "node.js", "polyglot", "interop"], "related_skills": ["skill_python_bridges.md"], "related_docs": ["src/unifyweaver/glue/python_bridges_glue.pl"], "original_answer": "Use FFI (Foreign Function Interface) bridges. Generate a Rust FFI bridge with `generate_rust_ffi_bridge(Predicates, Code)`, then call it from Go with `generate_go_ffi_client(Predicates, Code)` or from Node.js with `generate_node_koffi_client(Predicates, Code)` or `generate_node_ffi_napi_client(Predicates, Code)`. This approach works for languages without direct Python bindings. See skill_python_bridges.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_python_bridges_005_q0", "cluster_id": "skill_python_bridges_005", "question": "How do I choose the best Python bridge for my runtime environment?", "answer": "Use `detect_all_bridges(Bridges)` to identify which Python bridges are available on your system. Then call `auto_select_bridge(RuntimeEnv, Preferences, Bridge)` where RuntimeEnv is your target runtime (dotnet, jvm, rust, ruby, go, or nodejs). The function automatically selects the best bridge based on what's installed and available. You can control the selection by adding preferences: use `prefer(BridgeName)` to favor a specific bridge or `avoid(BridgeName)` to exclude one. For example, `auto_select_bridge(jvm, [prefer(jpype)], Bridge)` would select JPype for Java if available.", "question_type": "medium", "topics": ["Quickstart", "Python Bridges"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["bridge-selection", "auto-detection", "configuration"], "related_skills": ["skill_python_bridges.md"], "related_docs": ["src/unifyweaver/glue/python_bridges_glue.pl"], "original_answer": "Call `detect_all_bridges(Bridges)` to see available bridges on your system, then use `auto_select_bridge(RuntimeEnv, Preferences, Bridge)` to automatically select the best option for your runtime (.NET, JVM, Rust, Ruby, Go, Node.js). Add preferences with `prefer(BridgeName)` or `avoid(BridgeName)` to control selection. See skill_python_bridges.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_python_bridges_005_q1", "cluster_id": "skill_python_bridges_005", "question": "Which Python bridge should I use?", "answer": "Call `detect_all_bridges(Bridges)` to see available bridges on your system, then use `auto_select_bridge(RuntimeEnv, Preferences, Bridge)` to automatically select the best option for your runtime (.NET, JVM, Rust, Ruby, Go, Node.js). You can control selection by adding `prefer(BridgeName)` or `avoid(BridgeName)` to the preferences list. For .NET use Python.NET or CSnakes, for JVM use JPype or jpy, for Rust use PyO3, for Ruby use PyCall.rb, and for Go/Node.js use FFI libraries like cgo or koffi.", "question_type": "medium", "topics": ["Quickstart", "Python Bridges"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["bridge-selection", "auto-detection", "configuration"], "related_skills": ["skill_python_bridges.md"], "related_docs": ["src/unifyweaver/glue/python_bridges_glue.pl"], "original_answer": "Call `detect_all_bridges(Bridges)` to see available bridges on your system, then use `auto_select_bridge(RuntimeEnv, Preferences, Bridge)` to automatically select the best option for your runtime (.NET, JVM, Rust, Ruby, Go, Node.js). Add preferences with `prefer(BridgeName)` or `avoid(BridgeName)` to control selection. See skill_python_bridges.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_python_bridges_005_q2", "cluster_id": "skill_python_bridges_005", "question": "How do I auto-detect available Python bridges?", "answer": "Use `detect_all_bridges(Bridges)` to get a list of all available Python bridges installed on your system. Then call `auto_select_bridge(RuntimeEnv, Preferences, Bridge)` to automatically select the best bridge for your target runtime (.NET, JVM, Rust, Ruby, Go, or Node.js). You can optionally pass preferences like `prefer(BridgeName)` or `avoid(BridgeName)` to influence the selection. This approach detects what's actually available and picks the most suitable option for your environment.", "question_type": "medium", "topics": ["Quickstart", "Python Bridges"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["bridge-selection", "auto-detection", "configuration"], "related_skills": ["skill_python_bridges.md"], "related_docs": ["src/unifyweaver/glue/python_bridges_glue.pl"], "original_answer": "Call `detect_all_bridges(Bridges)` to see available bridges on your system, then use `auto_select_bridge(RuntimeEnv, Preferences, Bridge)` to automatically select the best option for your runtime (.NET, JVM, Rust, Ruby, Go, Node.js). Add preferences with `prefer(BridgeName)` or `avoid(BridgeName)` to control selection. See skill_python_bridges.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_python_bridges_006_q0", "cluster_id": "skill_python_bridges_006", "question": "Can I use Python bridges with UnifyWeaver's security firewall?", "answer": "Yes, Python bridges integrate with UnifyWeaver's firewall system. Use `validate_bridge(Bridge, Firewall)` to verify if a bridge meets your security requirements. For automatic firewall-compliant bridge selection, pass firewall constraints to `auto_select_bridge(Env, [firewall(Firewall)], Bridge)`. This ensures your Python integration respects configured security policies without requiring manual validation.", "question_type": "medium", "topics": ["Quickstart", "Python Bridges"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["security", "firewall", "validation", "constraints"], "related_skills": ["skill_python_bridges.md"], "related_docs": ["src/unifyweaver/glue/python_bridges_glue.pl"], "original_answer": "Yes, bridges integrate with UnifyWeaver's firewall system. Use `validate_bridge(Bridge, Firewall)` to check if a bridge is allowed, and pass firewall constraints to `auto_select_bridge(Env, [firewall(Firewall)], Bridge)` to auto-select only firewall-compliant bridges. This ensures Python integration respects your security policies. See skill_python_bridges.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer references 'skill_python_bridges.md' which may not exist or be accurate. Answer assumes firewall integration exists as described but cannot verify actual implementation without seeing the codebase."}
{"pair_id": "skill_python_bridges_006_q1", "cluster_id": "skill_python_bridges_006", "question": "How do I enforce firewall policies on Python bridges?", "answer": "To enforce firewall policies on Python bridges, use the `validate_bridge(Bridge, Firewall)` predicate to verify that a bridge complies with your security policies. For automatic selection of firewall-compliant bridges, pass firewall constraints to `auto_select_bridge(Env, [firewall(Firewall)], Bridge)`, which will only select bridges that respect your configured firewall rules. This integration with UnifyWeaver's firewall system ensures Python integration adheres to your security requirements.", "question_type": "medium", "topics": ["Quickstart", "Python Bridges"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["security", "firewall", "validation", "constraints"], "related_skills": ["skill_python_bridges.md"], "related_docs": ["src/unifyweaver/glue/python_bridges_glue.pl"], "original_answer": "Yes, bridges integrate with UnifyWeaver's firewall system. Use `validate_bridge(Bridge, Firewall)` to check if a bridge is allowed, and pass firewall constraints to `auto_select_bridge(Env, [firewall(Firewall)], Bridge)` to auto-select only firewall-compliant bridges. This ensures Python integration respects your security policies. See skill_python_bridges.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "The base answer references 'skill_python_bridges.md for details' but the skill document provided does not show firewall validation predicates or examples. The answer makes reasonable inferences about the firewall API based on the pattern of other predicates, but lacks concrete implementation examples or documentation support."}
{"pair_id": "skill_python_bridges_006_q2", "cluster_id": "skill_python_bridges_006", "question": "Are there security constraints for Python integration?", "answer": "Yes, Python bridges integrate with UnifyWeaver's firewall system for security. Use `validate_bridge(Bridge, Firewall)` to verify if a bridge meets your security policies. When auto-selecting a bridge, pass firewall constraints via `auto_select_bridge(Env, [firewall(Firewall)], Bridge)` to ensure only firewall-compliant bridges are selected. This enforces security policies across all Python integration scenarios.", "question_type": "medium", "topics": ["Quickstart", "Python Bridges"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["security", "firewall", "validation", "constraints"], "related_skills": ["skill_python_bridges.md"], "related_docs": ["src/unifyweaver/glue/python_bridges_glue.pl"], "original_answer": "Yes, bridges integrate with UnifyWeaver's firewall system. Use `validate_bridge(Bridge, Firewall)` to check if a bridge is allowed, and pass firewall constraints to `auto_select_bridge(Env, [firewall(Firewall)], Bridge)` to auto-select only firewall-compliant bridges. This ensures Python integration respects your security policies. See skill_python_bridges.md for details.", "answer_tailored": true, "confidence": 0.75, "confidence_issues": "The base answer references 'skill_python_bridges.md' for details, but the truncated skill document doesn't show a dedicated security section. The confidence is moderate because the answer relies on the firewall integration claim being accurate and implemented as described."}
{"pair_id": "skill_qa_generation_001_q0", "cluster_id": "skill_qa_generation_001", "question": "How do I create question-answer training data from my skill files?", "answer": "Use `generate_qa_from_skills.py` to create Q&A training data from skill markdown files. Run `python training-data/scripts/generate_qa_from_skills.py --skill skill_mindmap_linking.md` for a single skill, or `--all` to process all skill_*.md files. The script extracts the \"When to Use\" section for question ideas and commands/examples for answers, then uses an LLM to generate Q&A pairs. Output is structured JSONL saved to `by-topic/<topic>/skills-generated.jsonl`. You can customize the LLM provider and model with `--provider` and `--model` flags, and control the number of pairs per skill with `--pairs`.", "question_type": "medium", "topics": ["Quickstart", "Q&A Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["training-data", "Q&A", "skills", "generation"], "related_skills": ["skill_qa_generation.md", "skill_synthetic_data.md"], "related_docs": ["training-data/scripts/generate_qa_from_skills.py"], "original_answer": "Use `generate_qa_from_skills.py` to generate Q&A pairs from skill markdown files. Basic usage: `python training-data/scripts/generate_qa_from_skills.py --skill skill_mindmap_linking.md` for a single skill, or `--all` to process all skill_*.md files. The tool reads your \"When to Use\" sections and examples to generate structured JSONL output. Outputs to `by-topic/<topic>/skills-generated.jsonl`. See skill_qa_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_qa_generation_001_q1", "cluster_id": "skill_qa_generation_001", "question": "What's the best way to generate Q&A pairs from documentation?", "answer": "Use `generate_qa_from_skills.py` to generate Q&A pairs from skill markdown files. Run `python training-data/scripts/generate_qa_from_skills.py --skill skill_mindmap_linking.md` for a single skill, or `--all` to process all skill_*.md files in batch. The tool extracts your \"When to Use\" sections and code examples to automatically generate structured JSONL training pairs. Output goes to `by-topic/<topic>/skills-generated.jsonl`. Alternatively, use `generate_quickstart_qa.py` with SOURCE_MAPPING.md for capability-based Q&A pairs instead of task-oriented ones.", "question_type": "medium", "topics": ["Quickstart", "Q&A Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["training-data", "Q&A", "skills", "generation"], "related_skills": ["skill_qa_generation.md", "skill_synthetic_data.md"], "related_docs": ["training-data/scripts/generate_qa_from_skills.py"], "original_answer": "Use `generate_qa_from_skills.py` to generate Q&A pairs from skill markdown files. Basic usage: `python training-data/scripts/generate_qa_from_skills.py --skill skill_mindmap_linking.md` for a single skill, or `--all` to process all skill_*.md files. The tool reads your \"When to Use\" sections and examples to generate structured JSONL output. Outputs to `by-topic/<topic>/skills-generated.jsonl`. See skill_qa_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_qa_generation_001_q2", "cluster_id": "skill_qa_generation_001", "question": "Can I automatically create training data from my skills?", "answer": "Yes, you can automatically create training data from your skills using `generate_qa_from_skills.py`. Run `python training-data/scripts/generate_qa_from_skills.py --skill skill_mindmap_linking.md` for a single skill, or use `--all` to process all skill_*.md files at once. The script extracts your \"When to Use\" sections and code examples, uses an LLM to generate Q&A pairs, and outputs them as JSONL to `by-topic/<topic>/skills-generated.jsonl`. You can customize the LLM provider/model and number of pairs with `--provider`, `--model`, and `--pairs` options.", "question_type": "medium", "topics": ["Quickstart", "Q&A Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["training-data", "Q&A", "skills", "generation"], "related_skills": ["skill_qa_generation.md", "skill_synthetic_data.md"], "related_docs": ["training-data/scripts/generate_qa_from_skills.py"], "original_answer": "Use `generate_qa_from_skills.py` to generate Q&A pairs from skill markdown files. Basic usage: `python training-data/scripts/generate_qa_from_skills.py --skill skill_mindmap_linking.md` for a single skill, or `--all` to process all skill_*.md files. The tool reads your \"When to Use\" sections and examples to generate structured JSONL output. Outputs to `by-topic/<topic>/skills-generated.jsonl`. See skill_qa_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_qa_generation_002_q0", "cluster_id": "skill_qa_generation_002", "question": "How can I generate training data from SOURCE_MAPPING.md?", "answer": "Use `generate_quickstart_qa.py` to generate training data from SOURCE_MAPPING.md. Run `python training-data/scripts/generate_quickstart_qa.py --topic compilation` for a specific topic or `--all` for all topics. The script reads source file references in SOURCE_MAPPING.md, extracts content, and generates capability-based Q&A pairs with level tags. Output is saved to `by-topic/<topic>/<topic>-generated.jsonl`.", "question_type": "medium", "topics": ["Quickstart", "Q&A Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["training-data", "Q&A", "quickstart", "source-mapping"], "related_skills": ["skill_qa_generation.md", "skill_synthetic_data.md"], "related_docs": ["training-data/scripts/generate_quickstart_qa.py", "training-data/by-topic/SOURCE_MAPPING.md"], "original_answer": "Use `generate_quickstart_qa.py` to generate Q&A from SOURCE_MAPPING.md. Run: `python training-data/scripts/generate_quickstart_qa.py --topic compilation` for a specific topic or `--all` for all topics. The tool reads source file references in SOURCE_MAPPING.md, extracts content, and generates capability-based Q&A pairs with appropriate level tags. Output is saved to `by-topic/<topic>/<topic>-generated.jsonl`. See skill_qa_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_qa_generation_002_q1", "cluster_id": "skill_qa_generation_002", "question": "What tool creates Q&A pairs from capability mappings?", "answer": "Use `generate_quickstart_qa.py` to create Q&A pairs from capability mappings in SOURCE_MAPPING.md. Run `python training-data/scripts/generate_quickstart_qa.py --topic <topic>` for a specific topic or `--all` for all topics. The tool extracts source file references and generates capability-based Q&A pairs, outputting to `by-topic/<topic>/<topic>-generated.jsonl`.", "question_type": "medium", "topics": ["Quickstart", "Q&A Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["training-data", "Q&A", "quickstart", "source-mapping"], "related_skills": ["skill_qa_generation.md", "skill_synthetic_data.md"], "related_docs": ["training-data/scripts/generate_quickstart_qa.py", "training-data/by-topic/SOURCE_MAPPING.md"], "original_answer": "Use `generate_quickstart_qa.py` to generate Q&A from SOURCE_MAPPING.md. Run: `python training-data/scripts/generate_quickstart_qa.py --topic compilation` for a specific topic or `--all` for all topics. The tool reads source file references in SOURCE_MAPPING.md, extracts content, and generates capability-based Q&A pairs with appropriate level tags. Output is saved to `by-topic/<topic>/<topic>-generated.jsonl`. See skill_qa_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_qa_generation_002_q2", "cluster_id": "skill_qa_generation_002", "question": "How do I generate quickstart Q&A from source files?", "answer": "Use `generate_quickstart_qa.py` to generate Q&A from SOURCE_MAPPING.md. Run `python training-data/scripts/generate_quickstart_qa.py --topic compilation` for a specific topic or `--all` for all topics. The tool extracts source file references from SOURCE_MAPPING.md, generates capability-based Q&A pairs with level tags, and saves output to `by-topic/<topic>/<topic>-generated.jsonl`. You can customize the LLM provider with `--provider gemini` or model with `--model gemini-2.5-flash-preview`, and control pairs per section with `--pairs N`.", "question_type": "medium", "topics": ["Quickstart", "Q&A Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["training-data", "Q&A", "quickstart", "source-mapping"], "related_skills": ["skill_qa_generation.md", "skill_synthetic_data.md"], "related_docs": ["training-data/scripts/generate_quickstart_qa.py", "training-data/by-topic/SOURCE_MAPPING.md"], "original_answer": "Use `generate_quickstart_qa.py` to generate Q&A from SOURCE_MAPPING.md. Run: `python training-data/scripts/generate_quickstart_qa.py --topic compilation` for a specific topic or `--all` for all topics. The tool reads source file references in SOURCE_MAPPING.md, extracts content, and generates capability-based Q&A pairs with appropriate level tags. Output is saved to `by-topic/<topic>/<topic>-generated.jsonl`. See skill_qa_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_qa_generation_003_q0", "cluster_id": "skill_qa_generation_003", "question": "What options are available when generating Q&A data?", "answer": "Both Q&A generation tools support several key options: `--provider` (claude or gemini) specifies the LLM provider, `--model` (e.g., sonnet, gemini-2.5-flash-preview) selects the specific model, `--pairs` (default 4 for skills, 3 for quickstart) controls how many Q&A pairs are generated per source, and `--output` sets the output directory. For example: `python training-data/scripts/generate_qa_from_skills.py --all --provider gemini --model gemini-2.5-flash-preview --pairs 6`. Use haiku for faster generation, opus or sonnet for higher quality answers. The tools output structured JSONL data organized by topic.", "question_type": "long", "topics": ["Quickstart", "Q&A Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["training-data", "Q&A", "customization", "LLM"], "related_skills": ["skill_qa_generation.md"], "related_docs": ["training-data/scripts/generate_qa_from_skills.py", "training-data/scripts/generate_quickstart_qa.py"], "original_answer": "Both generation tools support: `--provider` (claude or gemini), `--model` (e.g., sonnet, gemini-2.5-flash-preview), `--pairs` (default 4 for skills, 3 for quickstart), and `--output` directory. Example: `python training-data/scripts/generate_qa_from_skills.py --all --provider gemini --model gemini-2.5-flash-preview --pairs 6`. Use haiku for speed, opus/sonnet for quality. Configure output directory with `--output`. See skill_qa_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_qa_generation_003_q1", "cluster_id": "skill_qa_generation_003", "question": "Can I use different LLM providers for Q&A generation?", "answer": "Yes, both `generate_qa_from_skills.py` and `generate_quickstart_qa.py` support different LLM providers through the `--provider` flag (claude or gemini) and `--model` flag to specify the model name. For example: `python training-data/scripts/generate_qa_from_skills.py --all --provider gemini --model gemini-2.5-flash-preview`. You can also adjust `--pairs` (default 4 for skills, 3 for quickstart) and `--output` directory as needed.", "question_type": "long", "topics": ["Quickstart", "Q&A Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["training-data", "Q&A", "customization", "LLM"], "related_skills": ["skill_qa_generation.md"], "related_docs": ["training-data/scripts/generate_qa_from_skills.py", "training-data/scripts/generate_quickstart_qa.py"], "original_answer": "Both generation tools support: `--provider` (claude or gemini), `--model` (e.g., sonnet, gemini-2.5-flash-preview), `--pairs` (default 4 for skills, 3 for quickstart), and `--output` directory. Example: `python training-data/scripts/generate_qa_from_skills.py --all --provider gemini --model gemini-2.5-flash-preview --pairs 6`. Use haiku for speed, opus/sonnet for quality. Configure output directory with `--output`. See skill_qa_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_qa_generation_003_q2", "cluster_id": "skill_qa_generation_003", "question": "How do I customize the number of question pairs?", "answer": "Both `generate_qa_from_skills.py` and `generate_quickstart_qa.py` support the `--pairs` option to customize the number of question pairs generated. Use `--pairs N` where N is the desired number (default is 4 for skills, 3 for quickstart). Example: `python training-data/scripts/generate_qa_from_skills.py --all --pairs 6` generates 6 Q&A pairs per skill.", "question_type": "long", "topics": ["Quickstart", "Q&A Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["training-data", "Q&A", "customization", "LLM"], "related_skills": ["skill_qa_generation.md"], "related_docs": ["training-data/scripts/generate_qa_from_skills.py", "training-data/scripts/generate_quickstart_qa.py"], "original_answer": "Both generation tools support: `--provider` (claude or gemini), `--model` (e.g., sonnet, gemini-2.5-flash-preview), `--pairs` (default 4 for skills, 3 for quickstart), and `--output` directory. Example: `python training-data/scripts/generate_qa_from_skills.py --all --provider gemini --model gemini-2.5-flash-preview --pairs 6`. Use haiku for speed, opus/sonnet for quality. Configure output directory with `--output`. See skill_qa_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_qa_generation_004_q0", "cluster_id": "skill_qa_generation_004", "question": "How do I check which skills are missing or have coverage gaps?", "answer": "Run `python training-data/scripts/generate_qa_from_skills.py --coverage` to analyze skill coverage gaps. This command shows existing skills with checkmarks, identifies missing skills (capability tree items without corresponding skill files), and suggests new skills to create.", "question_type": "medium", "topics": ["Quickstart", "Q&A Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["training-data", "Q&A", "coverage", "analysis"], "related_skills": ["skill_qa_generation.md", "skill_synthetic_data.md"], "related_docs": ["training-data/scripts/generate_qa_from_skills.py"], "original_answer": "Run `python training-data/scripts/generate_qa_from_skills.py --coverage` to analyze skill coverage gaps. The command outputs existing skills with checkmarks, identifies missing skills (capability tree items without corresponding skill files), and suggests new skills to create. This helps ensure you have training data for all important capabilities before generating Q&A pairs. See skill_qa_generation.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_qa_generation_004_q1", "cluster_id": "skill_qa_generation_004", "question": "Can I analyze what Q&A training data I'm missing?", "answer": "Yes. Run `python training-data/scripts/generate_qa_from_skills.py --coverage` to analyze what Q&A training data you're missing. This command identifies missing skills (capability tree items without corresponding skill files), shows existing skills with checkmarks, and suggests new skills to create. This helps ensure you have training data coverage for all important capabilities before generating Q&A pairs.", "question_type": "medium", "topics": ["Quickstart", "Q&A Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["training-data", "Q&A", "coverage", "analysis"], "related_skills": ["skill_qa_generation.md", "skill_synthetic_data.md"], "related_docs": ["training-data/scripts/generate_qa_from_skills.py"], "original_answer": "Run `python training-data/scripts/generate_qa_from_skills.py --coverage` to analyze skill coverage gaps. The command outputs existing skills with checkmarks, identifies missing skills (capability tree items without corresponding skill files), and suggests new skills to create. This helps ensure you have training data for all important capabilities before generating Q&A pairs. See skill_qa_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_qa_generation_004_q2", "cluster_id": "skill_qa_generation_004", "question": "How do I identify gaps in my skill documentation?", "answer": "Run `python training-data/scripts/generate_qa_from_skills.py --coverage` to analyze skill coverage gaps. This command outputs existing skills with checkmarks, identifies missing skills (capability tree items without corresponding skill files), and suggests new skills to create. This helps ensure you have training data for all important capabilities before generating Q&A pairs.", "question_type": "medium", "topics": ["Quickstart", "Q&A Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["training-data", "Q&A", "coverage", "analysis"], "related_skills": ["skill_qa_generation.md", "skill_synthetic_data.md"], "related_docs": ["training-data/scripts/generate_qa_from_skills.py"], "original_answer": "Run `python training-data/scripts/generate_qa_from_skills.py --coverage` to analyze skill coverage gaps. The command outputs existing skills with checkmarks, identifies missing skills (capability tree items without corresponding skill files), and suggests new skills to create. This helps ensure you have training data for all important capabilities before generating Q&A pairs. See skill_qa_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_qa_generation_005_q0", "cluster_id": "skill_qa_generation_005", "question": "What's the best practice for writing questions users would actually ask?", "answer": "Write questions from a new user's perspective based on the \"When to Use\" section of skills. Don't mention skill names\u2014users won't know them. Include 2-3 question variants for training diversity. Questions at level 2 should be general tasks (\"How do I organize mindmaps?\") while level 3 is specific tasks (\"How do I use MST clustering?\"). Keep answers concise with key commands and reference paths like \"See education/book-02-bash-target/\" for learning more.", "question_type": "medium", "topics": ["Quickstart", "Q&A Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["training-data", "Q&A", "best-practices", "user-centered"], "related_skills": ["skill_qa_generation.md"], "related_docs": [], "original_answer": "Write questions from a new user's perspective based on the \"When to Use\" section of skills. Don't mention skill names\u2014users won't know them. Include 2-3 question variants for training diversity. Questions at level 2 should be general tasks (\"How do I organize mindmaps?\") while level 3 is specific tasks (\"How do I use MST clustering?\"). Keep answers concise with key commands and reference paths like \"See education/book-02-bash-target/\" for learning more. See skill_qa_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_qa_generation_005_q1", "cluster_id": "skill_qa_generation_005", "question": "How should I phrase Q&A for a quickstart agent?", "answer": "Phrase Q&A for quickstart agents from a new user's perspective using the 'When to Use' section as your guide. Don't reference skill names\u2014users won't know them. Generate 2-3 question variants per answer for training diversity. Use general tasks for level 2 questions (e.g., 'How do I organize mindmaps?') and specific tasks for level 3 (e.g., 'How do I use MST clustering?'). Keep answers concise with essential commands and reference paths like 'See education/book-02-bash-target/' for deeper learning.", "question_type": "medium", "topics": ["Quickstart", "Q&A Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["training-data", "Q&A", "best-practices", "user-centered"], "related_skills": ["skill_qa_generation.md"], "related_docs": [], "original_answer": "Write questions from a new user's perspective based on the \"When to Use\" section of skills. Don't mention skill names\u2014users won't know them. Include 2-3 question variants for training diversity. Questions at level 2 should be general tasks (\"How do I organize mindmaps?\") while level 3 is specific tasks (\"How do I use MST clustering?\"). Keep answers concise with key commands and reference paths like \"See education/book-02-bash-target/\" for learning more. See skill_qa_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_qa_generation_005_q2", "cluster_id": "skill_qa_generation_005", "question": "What makes a good training question for a new user?", "answer": "Write questions from a new user's perspective, focusing on real tasks they want to accomplish rather than tool or skill names. Users don't know skill terminology\u2014they think in terms of goals like 'How do I organize mindmaps?' or 'How do I cluster data?'. Generate 2-3 question variants per topic for training diversity. Level 2 questions should be broad and general ('How do I X?'), while level 3 questions are specific and technical ('How do I use X algorithm for Y?'). Keep answers concise, leading with the key command or approach, then reference source locations (like 'See education/book-02-bash-target/' or specific file paths) for deeper learning. Avoid mentioning skill or capability names\u2014instead reference the actual functionality or outcome users care about.", "question_type": "medium", "topics": ["Quickstart", "Q&A Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["training-data", "Q&A", "best-practices", "user-centered"], "related_skills": ["skill_qa_generation.md"], "related_docs": [], "original_answer": "Write questions from a new user's perspective based on the \"When to Use\" section of skills. Don't mention skill names\u2014users won't know them. Include 2-3 question variants for training diversity. Questions at level 2 should be general tasks (\"How do I organize mindmaps?\") while level 3 is specific tasks (\"How do I use MST clustering?\"). Keep answers concise with key commands and reference paths like \"See education/book-02-bash-target/\" for learning more. See skill_qa_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_qa_generation_006_q0", "cluster_id": "skill_qa_generation_006", "question": "What's the output format for generated Q&A data and what does each field mean?", "answer": "Generated Q&A pairs use JSONL format with these fields: `id` (unique identifier), `question` (primary question), `question_variants` (2-3 alternative phrasings), `level` (0-4 scale from identity/recall through specific tasks to details), `tree_path` (hierarchical location), `answer` (the response content), `related_skills` (linked skill files), `related_docs` (documentation references), and `tags` (topic categorization). Level 0 is identity/recall questions, level 1 covers capabilities, level 2 addresses general tasks, level 3 tackles specific task variations, and level 4 handles detailed technical information. For example, a level 2 question might be \"How do I organize mindmaps?\" while level 3 could be \"How do I use MST clustering in mindmap linking?\". Answers should be concise with practical examples.", "question_type": "long", "topics": ["Quickstart", "Q&A Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["training-data", "Q&A", "JSONL", "format"], "related_skills": ["skill_qa_generation.md"], "related_docs": [], "original_answer": "Generated Q&A pairs are JSONL formatted with: `id` (unique identifier), `question`, `question_variants` (2-3 alternatives), `level` (0-4: identity, capabilities, general task, specific task, details), `tree_path`, `answer`, `related_skills`, `related_docs`, and `tags`. Example: level 2 = \"How do I organize mindmaps?\", level 3 = \"How do I use MST clustering?\". Answers should be concise with examples and end with \"See skill_qa_generation.md for details.\" See skill_qa_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_qa_generation_006_q1", "cluster_id": "skill_qa_generation_006", "question": "How is Q&A training data structured in JSONL?", "answer": "Q&A training data is structured in JSONL format with the following fields: `id` (unique identifier), `question` (the main question), `question_variants` (2-3 alternative phrasings), `level` (0-4 scale: 0=identity, 1=capabilities, 2=general task, 3=specific task, 4=details), `tree_path` (hierarchical location), `answer` (concise response with examples), `related_skills` (linked skill references), `related_docs` (documentation references), and `tags` (categorical labels). For example, a level 2 question might be 'How do I organize mindmaps?' while level 3 asks 'How do I use MST clustering?' for the same topic.", "question_type": "long", "topics": ["Quickstart", "Q&A Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["training-data", "Q&A", "JSONL", "format"], "related_skills": ["skill_qa_generation.md"], "related_docs": [], "original_answer": "Generated Q&A pairs are JSONL formatted with: `id` (unique identifier), `question`, `question_variants` (2-3 alternatives), `level` (0-4: identity, capabilities, general task, specific task, details), `tree_path`, `answer`, `related_skills`, `related_docs`, and `tags`. Example: level 2 = \"How do I organize mindmaps?\", level 3 = \"How do I use MST clustering?\". Answers should be concise with examples and end with \"See skill_qa_generation.md for details.\" See skill_qa_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_qa_generation_006_q2", "cluster_id": "skill_qa_generation_006", "question": "What fields are in the generated training pairs?", "answer": "Generated Q&A pairs are JSONL formatted with these fields: `id` (unique identifier), `question`, `question_variants` (2-3 alternative phrasings), `level` (0-4 scale indicating question specificity: 0=identity, 1=capabilities, 2=general task, 3=specific task, 4=details), `tree_path`, `answer`, `related_skills`, `related_docs`, and `tags`. For example, level 2 questions ask \"How do I organize mindmaps?\" while level 3 asks \"How do I use MST clustering?\"", "question_type": "long", "topics": ["Quickstart", "Q&A Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["training-data", "Q&A", "JSONL", "format"], "related_skills": ["skill_qa_generation.md"], "related_docs": [], "original_answer": "Generated Q&A pairs are JSONL formatted with: `id` (unique identifier), `question`, `question_variants` (2-3 alternatives), `level` (0-4: identity, capabilities, general task, specific task, details), `tree_path`, `answer`, `related_skills`, `related_docs`, and `tags`. Example: level 2 = \"How do I organize mindmaps?\", level 3 = \"How do I use MST clustering?\". Answers should be concise with examples and end with \"See skill_qa_generation.md for details.\" See skill_qa_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_query_patterns_001_q0", "cluster_id": "skill_query_patterns_001", "question": "How do I aggregate data from multiple records into summaries?", "answer": "To aggregate data from multiple records into summaries, use aggregation operators that reduce many values into fewer meaningful values. Choose your approach based on where the aggregation happens:\n\n**SQL (SQLite, PostgreSQL, MySQL)**: Use `GROUP BY` with standard operators like `COUNT(*)`, `SUM(col)`, `AVG(col)`, `MIN(col)`, `MAX(col)`. Example: `group_by(Dept, employee(_, Dept, _), count, Count)` compiles to `SELECT dept, COUNT(*) FROM employee GROUP BY dept`. Add conditions with `HAVING` clauses after grouping.\n\n**Runtime Aggregation (Go, C#, Perl, Ruby)**: Use `aggregate_all(operator, pattern, key, result)` to accumulate values across a data stream. Example: `aggregate_all(sum(Amount), sale(Region, _, Amount), Region, Total)` sums sales amounts by region during code execution.\n\n**Score Blending (Fuzzy Logic)**: Combine multiple ranking sources using weighted aggregation. Example: `blend_scores(0.7, SemanticScores, KeywordScores, Combined)` merges semantic and keyword search scores at 70%/30% weights.\n\nStandard operators supported across paradigms: `count`, `sum(V)`, `avg(V)`, `min(V)`, `max(V)`, plus stream-only `set(V)` for unique values and `bag(V)` for all values with duplicates.", "question_type": "medium", "topics": ["Quickstart", "Query Patterns (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["aggregation", "sql", "stream", "grouping"], "related_skills": ["skill_query_patterns.md", "skill_sql_target.md", "skill_stream_aggregation.md", "skill_aggregation_patterns.md", "skill_fuzzy_search.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl", "src/unifyweaver/targets/go_target.pl", "src/unifyweaver/targets/csharp_target.pl", "scripts/experiment_ensemble_blend.py"], "original_answer": "Use aggregation operators to reduce multiple values into summaries. Choose based on your output target:\n- **SQL**: Use `GROUP BY` with operators like `COUNT(*)`, `SUM()`, `AVG()`. Example: `group_by(Dept, employee(_, Dept, _), count, Count)` compiles to `SELECT dept, COUNT(*) FROM employee GROUP BY dept`\n- **Stream (Go/C#/Perl/Ruby)**: Use `aggregate_all(sum(Amount), sale(Region, _, Amount), Region, Total)` for runtime aggregation\n- **Fuzzy logic**: Use `blend_scores(0.7, SemanticScores, KeywordScores, Combined)` for weighted score combination\nSee skill_query_patterns.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_query_patterns_001_q1", "cluster_id": "skill_query_patterns_001", "question": "How do I group data and calculate totals?", "answer": "To group data and calculate totals, use aggregation operators to reduce multiple values into summaries. Choose your approach based on your output target:\n\n**SQL**: Use `GROUP BY` with aggregation functions. For example, `group_by(Dept, employee(_, Dept, _), count, Count)` compiles to `SELECT dept, COUNT(*) FROM employee GROUP BY dept`. For totals specifically, use `SUM()`: `group_by(Region, sale(Region, _, Amount), sum(Amount), Total)` compiles to `SELECT region, SUM(amount) FROM sale GROUP BY region`.\n\n**Stream (Go/C#/Perl/Ruby)**: Use `aggregate_all(sum(Amount), sale(Region, _, Amount), Region, Total)` to accumulate totals at runtime across data streams.\n\n**Fuzzy Logic**: For combining multiple score sources, use `blend_scores(0.7, SemanticScores, KeywordScores, Combined)` to weight and merge rankings.\n\nAll approaches reduce many input values to fewer output values while preserving meaningful aggregate information.", "question_type": "medium", "topics": ["Quickstart", "Query Patterns (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["aggregation", "sql", "stream", "grouping"], "related_skills": ["skill_query_patterns.md", "skill_sql_target.md", "skill_stream_aggregation.md", "skill_aggregation_patterns.md", "skill_fuzzy_search.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl", "src/unifyweaver/targets/go_target.pl", "src/unifyweaver/targets/csharp_target.pl", "scripts/experiment_ensemble_blend.py"], "original_answer": "Use aggregation operators to reduce multiple values into summaries. Choose based on your output target:\n- **SQL**: Use `GROUP BY` with operators like `COUNT(*)`, `SUM()`, `AVG()`. Example: `group_by(Dept, employee(_, Dept, _), count, Count)` compiles to `SELECT dept, COUNT(*) FROM employee GROUP BY dept`\n- **Stream (Go/C#/Perl/Ruby)**: Use `aggregate_all(sum(Amount), sale(Region, _, Amount), Region, Total)` for runtime aggregation\n- **Fuzzy logic**: Use `blend_scores(0.7, SemanticScores, KeywordScores, Combined)` for weighted score combination\nSee skill_query_patterns.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_query_patterns_001_q2", "cluster_id": "skill_query_patterns_001", "question": "What's the best way to combine many values into fewer summaries?", "answer": "The best way to combine many values into fewer summaries is to use aggregation operators, which reduce multiple values while preserving meaningful information. Choose your approach based on where the aggregation happens: Use SQL `GROUP BY` with operators like `COUNT(*)`, `SUM()`, `AVG()`, `MIN()`, `MAX()` for database-level aggregation. Use `aggregate_all()` for runtime aggregation in Go, C#, Perl, or Ruby when processing data streams. Use `blend_scores()` for fuzzy logic scenarios where you're combining multiple score sources (e.g., 70% semantic + 30% keyword scores). The key principle across all paradigms is the same: reduce many input values to fewer output values through aggregation operators.", "question_type": "medium", "topics": ["Quickstart", "Query Patterns (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["aggregation", "sql", "stream", "grouping"], "related_skills": ["skill_query_patterns.md", "skill_sql_target.md", "skill_stream_aggregation.md", "skill_aggregation_patterns.md", "skill_fuzzy_search.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl", "src/unifyweaver/targets/go_target.pl", "src/unifyweaver/targets/csharp_target.pl", "scripts/experiment_ensemble_blend.py"], "original_answer": "Use aggregation operators to reduce multiple values into summaries. Choose based on your output target:\n- **SQL**: Use `GROUP BY` with operators like `COUNT(*)`, `SUM()`, `AVG()`. Example: `group_by(Dept, employee(_, Dept, _), count, Count)` compiles to `SELECT dept, COUNT(*) FROM employee GROUP BY dept`\n- **Stream (Go/C#/Perl/Ruby)**: Use `aggregate_all(sum(Amount), sale(Region, _, Amount), Region, Total)` for runtime aggregation\n- **Fuzzy logic**: Use `blend_scores(0.7, SemanticScores, KeywordScores, Combined)` for weighted score combination\nSee skill_query_patterns.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_query_patterns_002_q0", "cluster_id": "skill_query_patterns_002", "question": "How do I generate SQL GROUP BY queries with filters and conditions?", "answer": "To generate SQL GROUP BY queries with filters and conditions, combine WHERE filtering with GROUP BY and HAVING clauses. Start with a predicate that filters your data using unification (WHERE clause), then use `group_by/4` to aggregate, and add HAVING conditions as Prolog constraints:\n\n```prolog\nactive_large_depts(Dept, Count) :-\n    employee(Name, Dept, Status),\n    Status = active,\n    group_by(Dept, employee(Name, Dept, active), count, Count),\n    Count >= 10.\n```\n\nThis filters to active employees, groups by department, and returns only departments with 10+ employees. Compile with: `compile_predicate_to_sql(active_large_depts/2, [dialect(postgres)], SQL)`.\n\nFor more complex scenarios with multiple aggregation operators (SUM, AVG, MIN, MAX) or window functions in PostgreSQL, see skill_query_patterns.md.", "question_type": "long", "topics": ["Quickstart", "Query Patterns (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sql", "where", "having", "filtering", "group-by"], "related_skills": ["skill_query_patterns.md", "skill_sql_target.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl"], "original_answer": "Combine WHERE filtering with GROUP BY and HAVING clauses:\n```prolog\nactive_large_depts(Dept, Count) :-\n    employee(Name, Dept, Status),\n    Status = active,\n    group_by(Dept, employee(Name, Dept, active), count, Count),\n    Count >= 10.\n```\nThis filters to active employees, groups by department, and only returns departments with 10+ employees. Compile with `compile_predicate_to_sql(active_large_depts/2, [dialect(postgres)], SQL)`. See skill_query_patterns.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_query_patterns_002_q1", "cluster_id": "skill_query_patterns_002", "question": "How do I use GROUP BY with WHERE and HAVING clauses?", "answer": "To use GROUP BY with WHERE and HAVING clauses, apply filtering at the correct stage:\n\n1. **WHERE clause** - Filters individual rows BEFORE grouping\n2. **GROUP BY** - Groups the filtered rows\n3. **HAVING clause** - Filters the grouped results\n\nExample in Prolog:\n```prolog\nactive_large_depts(Dept, Count) :-\n    employee(Name, Dept, Status),\n    Status = active,\n    group_by(Dept, employee(Name, Dept, active), count, Count),\n    Count >= 10.\n```\n\nThis pattern:\n- Filters to active employees (WHERE equivalent)\n- Groups by department (GROUP BY)\n- Only returns departments with 10+ employees (HAVING equivalent)\n\nCompile with: `compile_predicate_to_sql(active_large_depts/2, [dialect(postgres)], SQL)`\n\nThe generated SQL will be:\n```sql\nSELECT dept, COUNT(*) AS count\nFROM employee\nWHERE status = 'active'\nGROUP BY dept\nHAVING COUNT(*) >= 10\n```", "question_type": "long", "topics": ["Quickstart", "Query Patterns (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sql", "where", "having", "filtering", "group-by"], "related_skills": ["skill_query_patterns.md", "skill_sql_target.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl"], "original_answer": "Combine WHERE filtering with GROUP BY and HAVING clauses:\n```prolog\nactive_large_depts(Dept, Count) :-\n    employee(Name, Dept, Status),\n    Status = active,\n    group_by(Dept, employee(Name, Dept, active), count, Count),\n    Count >= 10.\n```\nThis filters to active employees, groups by department, and only returns departments with 10+ employees. Compile with `compile_predicate_to_sql(active_large_depts/2, [dialect(postgres)], SQL)`. See skill_query_patterns.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_query_patterns_002_q2", "cluster_id": "skill_query_patterns_002", "question": "How do I filter data before and after grouping?", "answer": "Filter data before and after grouping using WHERE and HAVING clauses:\n\n**Before grouping (WHERE):** Filter individual rows before GROUP BY\n```prolog\nactive_large_depts(Dept, Count) :-\n    employee(Name, Dept, Status),\n    Status = active,\n    group_by(Dept, employee(Name, Dept, active), count, Count),\n    Count >= 10.\n```\n\nThe `Status = active` condition filters to active employees before grouping by department.\n\n**After grouping (HAVING):** Filter grouped results using aggregation conditions like `Count >= 10`, which returns only departments with 10+ active employees.\n\nWHERE operates on rows; HAVING operates on group summaries. Both work together to narrow results at different stages of aggregation.", "question_type": "long", "topics": ["Quickstart", "Query Patterns (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sql", "where", "having", "filtering", "group-by"], "related_skills": ["skill_query_patterns.md", "skill_sql_target.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl"], "original_answer": "Combine WHERE filtering with GROUP BY and HAVING clauses:\n```prolog\nactive_large_depts(Dept, Count) :-\n    employee(Name, Dept, Status),\n    Status = active,\n    group_by(Dept, employee(Name, Dept, active), count, Count),\n    Count >= 10.\n```\nThis filters to active employees, groups by department, and only returns departments with 10+ employees. Compile with `compile_predicate_to_sql(active_large_depts/2, [dialect(postgres)], SQL)`. See skill_query_patterns.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_query_patterns_003_q0", "cluster_id": "skill_query_patterns_003", "question": "How do I combine multiple ranking scores from different models?", "answer": "To combine multiple ranking scores from different models, use score blending for compatible scales or rank fusion for incompatible scales. For compatible scales (e.g., both normalized 0-1), use `blend_scores(0.7, SemanticScores, KeywordScores, Combined)` to create a weighted combination with your desired weights. For incompatible scales (e.g., raw model scores on different ranges), use `rrf_blend_scores([bge_scores, minilm_scores, nomic_scores])` which applies Reciprocal Rank Fusion: `\u03a3 1/(k + rank)`. In Python, import from `scripts.experiment_ensemble_blend import blend_scores, rrf_blend_scores`.", "question_type": "long", "topics": ["Quickstart", "Query Patterns (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["fuzzy-logic", "score-blending", "ensemble", "ranking"], "related_skills": ["skill_query_patterns.md", "skill_fuzzy_search.md"], "related_docs": ["scripts/experiment_ensemble_blend.py"], "original_answer": "Use score blending for compatible scales or rank fusion for incompatible scales:\n- **Score blending (compatible scales)**: `blend_scores(0.7, SemanticScores, KeywordScores, Combined)` creates a weighted combination (70% semantic, 30% keyword)\n- **Rank fusion (incompatible scales)**: `rrf_blend_scores([bge_scores, minilm_scores, nomic_scores])` uses Reciprocal Rank Fusion formula: `\u03a3 1/(k + rank)`\nIn Python: `from scripts.experiment_ensemble_blend import blend_scores, rrf_blend_scores`. See skill_query_patterns.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_query_patterns_003_q1", "cluster_id": "skill_query_patterns_003", "question": "How do I blend semantic and keyword search scores?", "answer": "Use score blending for compatible scales or rank fusion for incompatible scales:\n\n**Score blending (compatible scales)**: Apply weighted combination using `blend_scores(0.7, SemanticScores, KeywordScores, Combined)` to create 70% semantic + 30% keyword blend.\n\n**Rank fusion (incompatible scales)**: Use `rrf_blend_scores([bge_scores, minilm_scores, nomic_scores])` which applies Reciprocal Rank Fusion: `\u03a3 1/(k + rank)` across multiple ranking sources.\n\nIn Python, import from `scripts.experiment_ensemble_blend`: `from scripts.experiment_ensemble_blend import blend_scores, rrf_blend_scores`. For Prolog-based implementation, see skill_query_patterns.md and skill_fuzzy_search.md.", "question_type": "long", "topics": ["Quickstart", "Query Patterns (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["fuzzy-logic", "score-blending", "ensemble", "ranking"], "related_skills": ["skill_query_patterns.md", "skill_fuzzy_search.md"], "related_docs": ["scripts/experiment_ensemble_blend.py"], "original_answer": "Use score blending for compatible scales or rank fusion for incompatible scales:\n- **Score blending (compatible scales)**: `blend_scores(0.7, SemanticScores, KeywordScores, Combined)` creates a weighted combination (70% semantic, 30% keyword)\n- **Rank fusion (incompatible scales)**: `rrf_blend_scores([bge_scores, minilm_scores, nomic_scores])` uses Reciprocal Rank Fusion formula: `\u03a3 1/(k + rank)`\nIn Python: `from scripts.experiment_ensemble_blend import blend_scores, rrf_blend_scores`. See skill_query_patterns.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_query_patterns_003_q2", "cluster_id": "skill_query_patterns_003", "question": "How do I fuse rankings from incompatible score scales?", "answer": "Use Reciprocal Rank Fusion (RRF) for incompatible score scales. Apply `rrf_blend_scores([bge_scores, minilm_scores, nomic_scores])` which converts each ranking to a unified score using the formula: `\u03a3 1/(k + rank)`. This works across different models with incompatible scales. For compatible scales where direct weighting is possible, use `blend_scores(0.7, SemanticScores, KeywordScores, Combined)` instead. Import from `scripts.experiment_ensemble_blend` in Python.", "question_type": "long", "topics": ["Quickstart", "Query Patterns (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["fuzzy-logic", "score-blending", "ensemble", "ranking"], "related_skills": ["skill_query_patterns.md", "skill_fuzzy_search.md"], "related_docs": ["scripts/experiment_ensemble_blend.py"], "original_answer": "Use score blending for compatible scales or rank fusion for incompatible scales:\n- **Score blending (compatible scales)**: `blend_scores(0.7, SemanticScores, KeywordScores, Combined)` creates a weighted combination (70% semantic, 30% keyword)\n- **Rank fusion (incompatible scales)**: `rrf_blend_scores([bge_scores, minilm_scores, nomic_scores])` uses Reciprocal Rank Fusion formula: `\u03a3 1/(k + rank)`\nIn Python: `from scripts.experiment_ensemble_blend import blend_scores, rrf_blend_scores`. See skill_query_patterns.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "Base answer mentions both compatible and incompatible approaches, but question specifically asks about incompatible scales. The tailored answer prioritizes RRF but still acknowledges the compatible scale alternative for context. Confidence is moderate because the skill document truncates the detailed RRF formula explanation."}
{"pair_id": "skill_query_patterns_004_q0", "cluster_id": "skill_query_patterns_004", "question": "Should I use SQL generation or stream aggregation for processing data?", "answer": "Choose based on your deployment context:\n\n**Use SQL Generation when:**\n- Output is a database view/query\n- You need complex joins across tables\n- Your target is external PostgreSQL, MySQL, or SQLite\n- You want pure SQL without generated code overhead\n- Example: `compile_predicate_to_sql(report/3, [dialect(postgres), format(view)], SQL)`\n\n**Use Stream Aggregation when:**\n- Processing data streams in generated Go, C#, Perl, or Ruby code\n- You need custom runtime logic that SQL can't express\n- Working with embedded databases (BBolt, Redb, LiteDB)\n- Data arrives incrementally and must be aggregated in-memory\n- Example: `aggregate_all(avg(Score), item(_, Score), Average)`\n\n**Use Fuzzy Logic when:**\n- Combining multiple ranking signals (semantic + keyword scores)\n- Scores have different scales that need normalization\n- Building ensemble search systems\n- Example: `blend_scores(0.7, SemanticScores, KeywordScores, Combined)`\n\nIf unsure, start with SQL for structured data queries, stream aggregation for real-time processing, and fuzzy logic for search ranking.", "question_type": "medium", "topics": ["Quickstart", "Query Patterns (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sql", "stream", "aggregation", "choice", "decision"], "related_skills": ["skill_query_patterns.md", "skill_sql_target.md", "skill_stream_aggregation.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl", "src/unifyweaver/targets/go_target.pl", "src/unifyweaver/targets/csharp_target.pl"], "original_answer": "Choose based on your deployment context:\n- **SQL Target**: Output is a database view/query, need complex joins, target is external PostgreSQL/MySQL, or want pure SQL (no generated code)\n- **Stream Aggregation**: Processing data streams in generated Go/C#/Perl/Ruby code, need custom runtime logic, or working with embedded databases (BBolt, Redb, LiteDB)\n- **Fuzzy Logic**: Combining multiple ranking signals, scores have different scales, or building ensemble search systems\nSQL example: `compile_predicate_to_sql(report/3, [dialect(postgres), format(view)], SQL)`. Stream example: `aggregate_all(avg(Score), item(_, Score), Average)`. See skill_query_patterns.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_query_patterns_004_q1", "cluster_id": "skill_query_patterns_004", "question": "When do I generate SQL vs write runtime aggregation code?", "answer": "Choose SQL generation when your output is a database view/query, you need complex joins, your target is an external database (PostgreSQL/MySQL), or you prefer pure SQL without generated code. Use stream aggregation when processing data in generated Go/C#/Perl/Ruby code, you need custom runtime logic, or you're working with embedded databases (BBolt, Redb, LiteDB). Use fuzzy logic when combining multiple ranking signals with different scales or building ensemble search systems. Example: `compile_predicate_to_sql(report/3, [dialect(postgres), format(view)], SQL)` for SQL, or `aggregate_all(avg(Score), item(_, Score), Average)` for stream aggregation.", "question_type": "medium", "topics": ["Quickstart", "Query Patterns (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sql", "stream", "aggregation", "choice", "decision"], "related_skills": ["skill_query_patterns.md", "skill_sql_target.md", "skill_stream_aggregation.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl", "src/unifyweaver/targets/go_target.pl", "src/unifyweaver/targets/csharp_target.pl"], "original_answer": "Choose based on your deployment context:\n- **SQL Target**: Output is a database view/query, need complex joins, target is external PostgreSQL/MySQL, or want pure SQL (no generated code)\n- **Stream Aggregation**: Processing data streams in generated Go/C#/Perl/Ruby code, need custom runtime logic, or working with embedded databases (BBolt, Redb, LiteDB)\n- **Fuzzy Logic**: Combining multiple ranking signals, scores have different scales, or building ensemble search systems\nSQL example: `compile_predicate_to_sql(report/3, [dialect(postgres), format(view)], SQL)`. Stream example: `aggregate_all(avg(Score), item(_, Score), Average)`. See skill_query_patterns.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_query_patterns_004_q2", "cluster_id": "skill_query_patterns_004", "question": "Should I use a database view or runtime processing?", "answer": "Choose based on your deployment context: Use SQL Target if your output needs to be a database view/query, you're doing complex joins, targeting external PostgreSQL/MySQL, or prefer pure SQL without generated code. Use Stream Aggregation if you're processing data streams in generated Go/C#/Perl/Ruby code, need custom runtime logic, or working with embedded databases like BBolt or Redb. Use Fuzzy Logic if you're combining multiple ranking signals with different scales or building ensemble search systems. SQL example: `compile_predicate_to_sql(report/3, [dialect(postgres), format(view)], SQL)`. Stream example: `aggregate_all(avg(Score), item(_, Score), Average)`.", "question_type": "medium", "topics": ["Quickstart", "Query Patterns (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sql", "stream", "aggregation", "choice", "decision"], "related_skills": ["skill_query_patterns.md", "skill_sql_target.md", "skill_stream_aggregation.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl", "src/unifyweaver/targets/go_target.pl", "src/unifyweaver/targets/csharp_target.pl"], "original_answer": "Choose based on your deployment context:\n- **SQL Target**: Output is a database view/query, need complex joins, target is external PostgreSQL/MySQL, or want pure SQL (no generated code)\n- **Stream Aggregation**: Processing data streams in generated Go/C#/Perl/Ruby code, need custom runtime logic, or working with embedded databases (BBolt, Redb, LiteDB)\n- **Fuzzy Logic**: Combining multiple ranking signals, scores have different scales, or building ensemble search systems\nSQL example: `compile_predicate_to_sql(report/3, [dialect(postgres), format(view)], SQL)`. Stream example: `aggregate_all(avg(Score), item(_, Score), Average)`. See skill_query_patterns.md for details.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null}
{"pair_id": "skill_query_patterns_005_q0", "cluster_id": "skill_query_patterns_005", "question": "How do I perform hierarchical or multi-level aggregation?", "answer": "To perform hierarchical or multi-level aggregation, use nested GROUP BY clauses or two-pass aggregation depending on your context:\n\n**SQL Approach**: Use nested grouping with multiple columns: `group_by([Region, Category], sale(Region, Category, Amount), sum(Amount), Total)` generates a predicate that groups by both region and category, creating summaries at each level. Compile with `compile_predicate_to_sql(regional_summary/3, [dialect(postgres)], SQL)` to produce SQL like `SELECT region, category, SUM(amount) FROM sale GROUP BY region, category`.\n\n**Stream Approach**: Use two-pass aggregation: first collect all values with `findall(Amount, sale(Region, Category, Amount), Amounts)`, then aggregate with operators like `sum_list(Amounts, Total)`. This works at runtime in Go, C#, Perl, or Ruby when SQL isn't available.\n\n**Multi-level Strategy**: For deeper hierarchies (e.g., Region \u2192 Category \u2192 Subcategory), extend the GROUP BY column list or chain multiple two-pass aggregations. Each level reduces cardinality while preserving grouping information.", "question_type": "long", "topics": ["Quickstart", "Query Patterns (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["aggregation", "hierarchical", "multi-level", "group-by", "nested"], "related_skills": ["skill_query_patterns.md", "skill_sql_target.md", "skill_stream_aggregation.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl", "src/unifyweaver/targets/go_target.pl"], "original_answer": "Use nested GROUP BY or two-pass aggregation:\n- **SQL nested GROUP BY**: `group_by([Region, Category], sale(Region, Category, Amount), sum(Amount), Total)` creates a regional_summary(Region, Category, Total) predicate\n- **Stream two-pass**: Use findall to collect all values, then aggregate with sum_list or similar: `findall(Amount, sale(_, Category, Amount), Amounts), sum_list(Amounts, Total)`\nCompile SQL with `compile_predicate_to_sql(regional_summary/3, [dialect(postgres)], SQL)`. See skill_query_patterns.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer assumes Prolog/UnifyWeaver syntax which may not be universally clear. The answer uses this syntax as-is since it matches the skill document context, but generalization beyond SQL GROUP BY and stream aggregation isn't explicitly covered in the provided skill content."}
{"pair_id": "skill_query_patterns_005_q1", "cluster_id": "skill_query_patterns_005", "question": "How do I aggregate data by multiple dimensions?", "answer": "To aggregate data by multiple dimensions, use GROUP BY with multiple columns. In SQL: `SELECT Region, Category, SUM(Amount) FROM sales GROUP BY Region, Category` groups by both Region and Category. In Prolog with stream aggregation: `aggregate_all(sum(Amount), sale(Region, Category, Amount), [Region, Category], Total)` aggregates across both dimensions. For nested aggregations, use two-pass aggregation: first collect all matching values with findall, then apply aggregation functions like sum_list or max_list. Use `compile_predicate_to_sql(regional_summary/3, [dialect(postgres)], SQL)` to generate SQL from Prolog predicates.", "question_type": "long", "topics": ["Quickstart", "Query Patterns (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["aggregation", "hierarchical", "multi-level", "group-by", "nested"], "related_skills": ["skill_query_patterns.md", "skill_sql_target.md", "skill_stream_aggregation.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl", "src/unifyweaver/targets/go_target.pl"], "original_answer": "Use nested GROUP BY or two-pass aggregation:\n- **SQL nested GROUP BY**: `group_by([Region, Category], sale(Region, Category, Amount), sum(Amount), Total)` creates a regional_summary(Region, Category, Total) predicate\n- **Stream two-pass**: Use findall to collect all values, then aggregate with sum_list or similar: `findall(Amount, sale(_, Category, Amount), Amounts), sum_list(Amounts, Total)`\nCompile SQL with `compile_predicate_to_sql(regional_summary/3, [dialect(postgres)], SQL)`. See skill_query_patterns.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer's Prolog syntax for nested GROUP BY may not be standard\u2014the actual API might differ. Stream aggregation example assumes specific predicate arity conventions."}
{"pair_id": "skill_query_patterns_005_q2", "cluster_id": "skill_query_patterns_005", "question": "How do I group by region AND category?", "answer": "To group by both region AND category, use `group_by([Region, Category], sale(Region, Category, Amount), sum(Amount), Total)` which creates a regional_summary(Region, Category, Total) predicate. This treats the region-category pair as a composite grouping key. For SQL, compile with `compile_predicate_to_sql(regional_summary/3, [dialect(postgres)], SQL)` to generate `SELECT region, category, SUM(amount) FROM sale GROUP BY region, category`. For stream-based aggregation, use findall to collect matching records, then aggregate by region-category pairs using sum_list or similar operations.", "question_type": "long", "topics": ["Quickstart", "Query Patterns (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["aggregation", "hierarchical", "multi-level", "group-by", "nested"], "related_skills": ["skill_query_patterns.md", "skill_sql_target.md", "skill_stream_aggregation.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl", "src/unifyweaver/targets/go_target.pl"], "original_answer": "Use nested GROUP BY or two-pass aggregation:\n- **SQL nested GROUP BY**: `group_by([Region, Category], sale(Region, Category, Amount), sum(Amount), Total)` creates a regional_summary(Region, Category, Total) predicate\n- **Stream two-pass**: Use findall to collect all values, then aggregate with sum_list or similar: `findall(Amount, sale(_, Category, Amount), Amounts), sum_list(Amounts, Total)`\nCompile SQL with `compile_predicate_to_sql(regional_summary/3, [dialect(postgres)], SQL)`. See skill_query_patterns.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer mentions 'nested GROUP BY' and 'two-pass aggregation' but the actual technique shown is a multi-column GROUP BY, not nested groups. The terminology could be clearer. Also, the stream aggregation example is vague about the actual implementation details for grouping by multiple keys."}
{"pair_id": "skill_query_patterns_006_q0", "cluster_id": "skill_query_patterns_006", "question": "What aggregation operators are available and which databases support them?", "answer": "Standard aggregation operators (COUNT, SUM, AVG, MIN, MAX) are supported across all SQL dialects (SQLite, PostgreSQL, MySQL) and stream languages (Go, C#, Perl, Ruby). Advanced SQL features include GROUP BY, HAVING, CTEs, UNION/INTERSECT/EXCEPT on all three databases, with PostgreSQL offering full window functions and MySQL 8.0+ adding window functions and CTEs. Stream-only operators include set(V) for unique values and bag(V) for all values with duplicates. Go and C# have full aggregate_all/3 and aggregate_all/4 support, while Perl and Ruby have basic or partial support. For fuzzy logic, available operators are f_and (product), f_or (probabilistic sum), blend_scores (weighted combination), and rrf_blend (rank reciprocal fusion).", "question_type": "medium", "topics": ["Quickstart", "Query Patterns (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["operators", "support-matrix", "database", "language", "features"], "related_skills": ["skill_query_patterns.md", "skill_sql_target.md", "skill_stream_aggregation.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl", "src/unifyweaver/targets/go_target.pl", "src/unifyweaver/targets/csharp_target.pl"], "original_answer": "Standard operators (`COUNT`, `SUM`, `AVG`, `MIN`, `MAX`) work across all SQL dialects and stream languages (Go, C#, Perl, Ruby). Advanced features vary:\n- **SQL**: SQLite/PostgreSQL/MySQL all support GROUP BY, HAVING, CTEs, UNION/INTERSECT/EXCEPT. PostgreSQL has full window functions; MySQL 8.0+ adds window functions and CTEs\n- **Stream**: Go and C# support full aggregate_all/3 and aggregate_all/4; Perl and Ruby have basic or partial support\n- **Stream-only**: `set(V)` for unique values, `bag(V)` for all values with duplicates\n- **Fuzzy**: `f_and` (product), `f_or` (probabilistic sum), `blend_scores` (weighted), `rrf_blend` (rank fusion)\nSee skill_query_patterns.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_query_patterns_006_q1", "cluster_id": "skill_query_patterns_006", "question": "Which aggregation functions work in PostgreSQL vs MySQL vs SQLite?", "answer": "Standard aggregation functions (`COUNT`, `SUM`, `AVG`, `MIN`, `MAX`) work across all three SQL dialects. PostgreSQL and MySQL 8.0+ support window functions, while SQLite has limited window function support. All three support GROUP BY, HAVING, and CTEs (MySQL 8.0+, PostgreSQL, SQLite). For advanced features: PostgreSQL offers full window function capabilities; MySQL 8.0+ added window functions and CTEs; SQLite supports basic window functions but with fewer options. UNION, INTERSECT, and EXCEPT are supported in all three dialects.", "question_type": "medium", "topics": ["Quickstart", "Query Patterns (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["operators", "support-matrix", "database", "language", "features"], "related_skills": ["skill_query_patterns.md", "skill_sql_target.md", "skill_stream_aggregation.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl", "src/unifyweaver/targets/go_target.pl", "src/unifyweaver/targets/csharp_target.pl"], "original_answer": "Standard operators (`COUNT`, `SUM`, `AVG`, `MIN`, `MAX`) work across all SQL dialects and stream languages (Go, C#, Perl, Ruby). Advanced features vary:\n- **SQL**: SQLite/PostgreSQL/MySQL all support GROUP BY, HAVING, CTEs, UNION/INTERSECT/EXCEPT. PostgreSQL has full window functions; MySQL 8.0+ adds window functions and CTEs\n- **Stream**: Go and C# support full aggregate_all/3 and aggregate_all/4; Perl and Ruby have basic or partial support\n- **Stream-only**: `set(V)` for unique values, `bag(V)` for all values with duplicates\n- **Fuzzy**: `f_and` (product), `f_or` (probabilistic sum), `blend_scores` (weighted), `rrf_blend` (rank fusion)\nSee skill_query_patterns.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_query_patterns_006_q2", "cluster_id": "skill_query_patterns_006", "question": "Does my target language support window functions and CTEs?", "answer": "Yes, support varies by target language. SQL dialects (SQLite, PostgreSQL, MySQL) all support window functions\u2014PostgreSQL has full support, while MySQL added window functions in version 8.0+. CTEs (Common Table Expressions) are supported in PostgreSQL and MySQL 8.0+, with limited or no support in SQLite. For stream languages (Go, C#, Perl, Ruby), window functions and CTEs are not natively supported; use aggregate_all/3 or aggregate_all/4 instead. Check the specific dialect or language version before relying on these advanced features.", "question_type": "medium", "topics": ["Quickstart", "Query Patterns (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["operators", "support-matrix", "database", "language", "features"], "related_skills": ["skill_query_patterns.md", "skill_sql_target.md", "skill_stream_aggregation.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl", "src/unifyweaver/targets/go_target.pl", "src/unifyweaver/targets/csharp_target.pl"], "original_answer": "Standard operators (`COUNT`, `SUM`, `AVG`, `MIN`, `MAX`) work across all SQL dialects and stream languages (Go, C#, Perl, Ruby). Advanced features vary:\n- **SQL**: SQLite/PostgreSQL/MySQL all support GROUP BY, HAVING, CTEs, UNION/INTERSECT/EXCEPT. PostgreSQL has full window functions; MySQL 8.0+ adds window functions and CTEs\n- **Stream**: Go and C# support full aggregate_all/3 and aggregate_all/4; Perl and Ruby have basic or partial support\n- **Stream-only**: `set(V)` for unique values, `bag(V)` for all values with duplicates\n- **Fuzzy**: `f_and` (product), `f_or` (probabilistic sum), `blend_scores` (weighted), `rrf_blend` (rank fusion)\nSee skill_query_patterns.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer provides correct information but is dense and uses specialized terminology. SQLite's CTE support is understated\u2014it does support basic CTEs but not all advanced features. The stream language section could be clearer that window functions require a different aggregation approach."}
{"pair_id": "skill_responsive_design_001_q0", "cluster_id": "skill_responsive_design_001", "question": "How do I make my layouts responsive across different screen sizes?", "answer": "To make layouts responsive across different screen sizes, use the `responsive_layout/2` predicate with breakpoint variants. Define a base layout with `default([strategy(grid), columns([\"1fr\"])])` for mobile, then add responsive variants at different breakpoints: `at(sm, [...])`, `at(md, [...])`, `at(lg, [...])`, etc. Use standard breakpoints like `sm` (576px), `md` (768px), `lg` (992px), and `xl` (1200px), or choose a strategy with `set_responsive_strategy(mobile_first)` or `set_responsive_strategy(desktop_first)`. Specify grid columns dynamically: `columns([\"repeat(2, 1fr)\"])` for 2 columns, `columns([\"repeat(4, 1fr)\"])` for 4 columns. Generate CSS with `generate_responsive_css(LayoutName, CSS)`. This approach handles layout adaptation across phones, tablets, and desktops automatically.", "question_type": "medium", "topics": ["Quickstart", "Responsive Design"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["responsive", "breakpoints", "layout", "mobile-first"], "related_skills": ["skill_responsive_design.md"], "related_docs": ["src/unifyweaver/glue/responsive_generator.pl"], "original_answer": "Use responsive layouts with breakpoints. Define a layout with `responsive_layout(name, [default([...]), at(breakpoint, [...])])` and specify grid or flex strategies. Start with mobile-first (default strategy) or use `set_responsive_strategy(desktop_first)` for desktop-first. Standard breakpoints include `sm` (576px), `md` (768px), `lg` (992px), and `xl` (1200px). Example: `responsive_layout(card_grid, [default([strategy(grid), columns([\"1fr\"])]), at(md, [columns([\"repeat(3, 1fr)\"])])])`. See skill_responsive_design.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_responsive_design_001_q1", "cluster_id": "skill_responsive_design_001", "question": "How do I create layouts that work on mobile and desktop?", "answer": "Create layouts for mobile and desktop using responsive breakpoints: `responsive_layout(name, [default([...]), breakpoint(768, [...])], Options)`. Define different layouts per breakpoint. Use `generate_breakpoint_styles/2` to create the CSS media queries.", "question_type": "medium", "topics": ["Quickstart", "Responsive Design"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["responsive", "breakpoints", "layout", "mobile-first"], "related_skills": ["skill_responsive_design.md"], "related_docs": ["src/unifyweaver/glue/responsive_generator.pl"], "original_answer": "Use responsive layouts with breakpoints. Define a layout with `responsive_layout(name, [default([...]), at(breakpoint, [...])])` and specify grid or flex strategies. Start with mobile-first (default strategy) or use `set_responsive_strategy(desktop_first)` for desktop-first. Standard breakpoints include `sm` (576px), `md` (768px), `lg` (992px), and `xl` (1200px). Example: `responsive_layout(card_grid, [default([strategy(grid), columns([\"1fr\"])]), at(md, [columns([\"repeat(3, 1fr)\"])])])`. See skill_responsive_design.md for details.", "answer_tailored": true, "confidence": 0.8, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_responsive_design_001_q2", "cluster_id": "skill_responsive_design_001", "question": "What's the best way to support multiple devices?", "answer": "Support multiple devices with responsive layouts and breakpoints. Define layouts using `responsive_layout(name, [default([...]), breakpoint(768, tablet), breakpoint(1024, desktop)], Options)`. Generate CSS with `generate_breakpoint_styles/2` for media queries.", "question_type": "medium", "topics": ["Quickstart", "Responsive Design"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["responsive", "breakpoints", "layout", "mobile-first"], "related_skills": ["skill_responsive_design.md"], "related_docs": ["src/unifyweaver/glue/responsive_generator.pl"], "original_answer": "Use responsive layouts with breakpoints. Define a layout with `responsive_layout(name, [default([...]), at(breakpoint, [...])])` and specify grid or flex strategies. Start with mobile-first (default strategy) or use `set_responsive_strategy(desktop_first)` for desktop-first. Standard breakpoints include `sm` (576px), `md` (768px), `lg` (992px), and `xl` (1200px). Example: `responsive_layout(card_grid, [default([strategy(grid), columns([\"1fr\"])]), at(md, [columns([\"repeat(3, 1fr)\"])])])`. See skill_responsive_design.md for details.", "answer_tailored": true, "confidence": 0.8, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_responsive_design_002_q0", "cluster_id": "skill_responsive_design_002", "question": "What are the standard breakpoints for different devices?", "answer": "Standard breakpoints for different devices are: `xs` (\u2264575px), `sm` (\u2265576px), `md` (\u2265768px), `lg` (\u2265992px), `xl` (\u22651200px), and `xxl` (\u22651400px). Semantic alternatives include `mobile` (\u2264767px), `tablet` (768-1023px), and `desktop` (\u22651024px). Device-specific breakpoints are `phone_portrait` (\u2264480px), `phone_landscape` (481-767px), `tablet_portrait` (768-1024px), and `tablet_landscape` (1025-1279px).", "question_type": "medium", "topics": ["Quickstart", "Responsive Design"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["breakpoints", "device-sizes", "mobile", "tablet", "desktop"], "related_skills": ["skill_responsive_design.md"], "related_docs": ["src/unifyweaver/glue/responsive_generator.pl"], "original_answer": "Standard breakpoints are: `xs` (\u2264575px), `sm` (\u2265576px), `md` (\u2265768px), `lg` (\u2265992px), `xl` (\u22651200px), and `xxl` (\u22651400px). Use semantic names like `mobile` (\u2264767px), `tablet` (768-1023px), or `desktop` (\u22651024px). Device-specific names include `phone_portrait` (\u2264480px), `phone_landscape` (481-767px), `tablet_portrait` (768-1024px), and `tablet_landscape` (1025-1279px). Mobile-first approach uses `min_width` conditions; desktop-first uses `max_width`. See skill_responsive_design.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_responsive_design_002_q1", "cluster_id": "skill_responsive_design_002", "question": "Which breakpoints should I use for phones, tablets, and desktops?", "answer": "For phones, tablets, and desktops, use semantic breakpoints: `mobile` (\u2264767px) for phones, `tablet` (768-1023px) for tablets, and `desktop` (\u22651024px) for desktops. Alternatively, use size-based breakpoints: `xs`-`sm` for phones, `md` for tablets, and `lg`+ for desktops. For mobile-first design, use `min_width` conditions (e.g., `at(sm, ...)` for \u2265576px); for desktop-first, use `max_width`. Device-specific options include `phone_portrait` (\u2264480px), `phone_landscape` (481-767px), `tablet_portrait` (768-1024px), and `tablet_landscape` (1025-1279px).", "question_type": "medium", "topics": ["Quickstart", "Responsive Design"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["breakpoints", "device-sizes", "mobile", "tablet", "desktop"], "related_skills": ["skill_responsive_design.md"], "related_docs": ["src/unifyweaver/glue/responsive_generator.pl"], "original_answer": "Standard breakpoints are: `xs` (\u2264575px), `sm` (\u2265576px), `md` (\u2265768px), `lg` (\u2265992px), `xl` (\u22651200px), and `xxl` (\u22651400px). Use semantic names like `mobile` (\u2264767px), `tablet` (768-1023px), or `desktop` (\u22651024px). Device-specific names include `phone_portrait` (\u2264480px), `phone_landscape` (481-767px), `tablet_portrait` (768-1024px), and `tablet_landscape` (1025-1279px). Mobile-first approach uses `min_width` conditions; desktop-first uses `max_width`. See skill_responsive_design.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_responsive_design_002_q2", "cluster_id": "skill_responsive_design_002", "question": "What pixel widths define mobile and tablet sizes?", "answer": "Mobile sizes are defined as \u2264767px (or \u2264575px for `xs` breakpoint), while tablet sizes range from 768-1023px. Alternatively, use device-specific breakpoints: `phone_portrait` (\u2264480px), `phone_landscape` (481-767px), `tablet_portrait` (768-1024px), and `tablet_landscape` (1025-1279px). The `sm` breakpoint starts at 576px, `md` at 768px, and `lg` at 992px.", "question_type": "medium", "topics": ["Quickstart", "Responsive Design"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["breakpoints", "device-sizes", "mobile", "tablet", "desktop"], "related_skills": ["skill_responsive_design.md"], "related_docs": ["src/unifyweaver/glue/responsive_generator.pl"], "original_answer": "Standard breakpoints are: `xs` (\u2264575px), `sm` (\u2265576px), `md` (\u2265768px), `lg` (\u2265992px), `xl` (\u22651200px), and `xxl` (\u22651400px). Use semantic names like `mobile` (\u2264767px), `tablet` (768-1023px), or `desktop` (\u22651024px). Device-specific names include `phone_portrait` (\u2264480px), `phone_landscape` (481-767px), `tablet_portrait` (768-1024px), and `tablet_landscape` (1025-1279px). Mobile-first approach uses `min_width` conditions; desktop-first uses `max_width`. See skill_responsive_design.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_responsive_design_003_q0", "cluster_id": "skill_responsive_design_003", "question": "How do I create a grid layout that changes columns on different screen sizes?", "answer": "Define a responsive layout using the grid strategy with column specifications at different breakpoints. Use `responsive_layout(card_grid, [default([strategy(grid), columns([\"1fr\"]), gap(\"1rem\")]), at(sm, [columns([\"repeat(2, 1fr)\"])]), at(md, [columns([\"repeat(3, 1fr)\"])]), at(lg, [columns([\"repeat(4, 1fr)\"])])])` to create a grid that adapts: 1 column on mobile, 2 columns at sm breakpoint (\u2265576px), 3 columns at md breakpoint (\u2265768px), and 4 columns at lg breakpoint (\u2265992px). The `gap()` parameter controls spacing between grid items.", "question_type": "long", "topics": ["Quickstart", "Responsive Design"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["grid", "columns", "responsive-layout", "card-grid"], "related_skills": ["skill_responsive_design.md"], "related_docs": ["src/unifyweaver/glue/responsive_generator.pl"], "original_answer": "Define a responsive layout with grid strategy and specify columns at different breakpoints. Example: `responsive_layout(card_grid, [default([strategy(grid), columns([\"1fr\"]), gap(\"1rem\")]), at(sm, [columns([\"repeat(2, 1fr)\"])]), at(md, [columns([\"repeat(3, 1fr)\"])]), at(lg, [columns([\"repeat(4, 1fr)\"])])])`. This creates 1 column on mobile, 2 on small screens, 3 on medium, and 4 on large screens. Use `gap()` to control spacing between items. See skill_responsive_design.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_responsive_design_003_q1", "cluster_id": "skill_responsive_design_003", "question": "How do I make a card grid responsive?", "answer": "To make a card grid responsive, use the `responsive_layout` predicate with a grid strategy and define column counts at different breakpoints. Example: `responsive_layout(card_grid, [default([strategy(grid), columns([\"1fr\"]), gap(\"1rem\")]), at(sm, [columns([\"repeat(2, 1fr)\"])]), at(md, [columns([\"repeat(3, 1fr)\"])]), at(lg, [columns([\"repeat(4, 1fr)\"])])])`. This creates 1 column on mobile, 2 on small screens (\u2265576px), 3 on medium (\u2265768px), and 4 on large screens (\u2265992px). The `gap()` property controls spacing between cards. Generate CSS using `generate_responsive_css(card_grid, CSS)`.", "question_type": "long", "topics": ["Quickstart", "Responsive Design"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["grid", "columns", "responsive-layout", "card-grid"], "related_skills": ["skill_responsive_design.md"], "related_docs": ["src/unifyweaver/glue/responsive_generator.pl"], "original_answer": "Define a responsive layout with grid strategy and specify columns at different breakpoints. Example: `responsive_layout(card_grid, [default([strategy(grid), columns([\"1fr\"]), gap(\"1rem\")]), at(sm, [columns([\"repeat(2, 1fr)\"])]), at(md, [columns([\"repeat(3, 1fr)\"])]), at(lg, [columns([\"repeat(4, 1fr)\"])])])`. This creates 1 column on mobile, 2 on small screens, 3 on medium, and 4 on large screens. Use `gap()` to control spacing between items. See skill_responsive_design.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_responsive_design_003_q2", "cluster_id": "skill_responsive_design_003", "question": "How do I adjust grid columns for mobile vs desktop?", "answer": "Use the responsive_layout predicate with grid strategy to define columns at different breakpoints. Define a base layout with single-column grid, then add breakpoint-specific variants using `at()` to increase columns: `responsive_layout(card_grid, [default([strategy(grid), columns([\"1fr\"]), gap(\"1rem\")]), at(sm, [columns([\"repeat(2, 1fr)\"])]), at(md, [columns([\"repeat(3, 1fr)\"])]), at(lg, [columns([\"repeat(4, 1fr)\"])])])`. This creates a 1-column mobile layout that expands to 2 columns at 576px, 3 columns at 768px, and 4 columns at 992px. Use the `gap()` option to control spacing between grid items.", "question_type": "long", "topics": ["Quickstart", "Responsive Design"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["grid", "columns", "responsive-layout", "card-grid"], "related_skills": ["skill_responsive_design.md"], "related_docs": ["src/unifyweaver/glue/responsive_generator.pl"], "original_answer": "Define a responsive layout with grid strategy and specify columns at different breakpoints. Example: `responsive_layout(card_grid, [default([strategy(grid), columns([\"1fr\"]), gap(\"1rem\")]), at(sm, [columns([\"repeat(2, 1fr)\"])]), at(md, [columns([\"repeat(3, 1fr)\"])]), at(lg, [columns([\"repeat(4, 1fr)\"])])])`. This creates 1 column on mobile, 2 on small screens, 3 on medium, and 4 on large screens. Use `gap()` to control spacing between items. See skill_responsive_design.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_responsive_design_004_q0", "cluster_id": "skill_responsive_design_004", "question": "How do I hide or show content on specific screen sizes?", "answer": "Use `generate_visibility_utilities(CSS)` to create show/hide classes for each breakpoint, generating classes like `.hidden-mobile`, `.visible-mobile`, `.hidden-tablet`, etc. that automatically apply the correct media queries. Alternatively, use responsive layout areas with different `areas([...])` values at different breakpoints to reorganize content visibility. For example: `responsive_layout(layout, [default([areas([['sidebar', 'main']])]), at(mobile, [areas([['main'], ['sidebar']])])])` will reorder elements across breakpoints.", "question_type": "long", "topics": ["Quickstart", "Responsive Design"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["visibility", "show-hide", "responsive-utilities", "media-queries"], "related_skills": ["skill_responsive_design.md"], "related_docs": ["src/unifyweaver/glue/responsive_generator.pl"], "original_answer": "Generate visibility utilities with `generate_visibility_utilities(CSS)` to create show/hide classes for each breakpoint. This generates classes like `.hidden-mobile`, `.visible-mobile`, `.hidden-tablet`, etc., that automatically apply the correct media queries. Alternatively, use responsive layout areas: define different `areas([...])` values at different breakpoints to reorganize layout grids. Example: `responsive_layout(layout, [default([areas([[\"sidebar\", \"main\"]])]), at(mobile, [areas([[\"main\"], [\"sidebar\"]])])])`. See skill_responsive_design.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_responsive_design_004_q1", "cluster_id": "skill_responsive_design_004", "question": "How do I use show/hide classes for different breakpoints?", "answer": "Use `generate_visibility_utilities(CSS)` to create show/hide classes for each breakpoint (e.g., `.hidden-mobile`, `.visible-mobile`, `.hidden-tablet`, `.visible-tablet`). These classes automatically apply the correct media queries for displaying or hiding content at specific breakpoints. Alternatively, use responsive layout areas by defining different `areas([...])` values at different breakpoints to reorganize which elements are visible. Example: `responsive_layout(layout, [default([areas([['sidebar', 'main']])]), at(mobile, [areas([['main'], ['sidebar']])])])`. See skill_responsive_design.md for complete breakpoint reference and options.", "question_type": "long", "topics": ["Quickstart", "Responsive Design"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["visibility", "show-hide", "responsive-utilities", "media-queries"], "related_skills": ["skill_responsive_design.md"], "related_docs": ["src/unifyweaver/glue/responsive_generator.pl"], "original_answer": "Generate visibility utilities with `generate_visibility_utilities(CSS)` to create show/hide classes for each breakpoint. This generates classes like `.hidden-mobile`, `.visible-mobile`, `.hidden-tablet`, etc., that automatically apply the correct media queries. Alternatively, use responsive layout areas: define different `areas([...])` values at different breakpoints to reorganize layout grids. Example: `responsive_layout(layout, [default([areas([[\"sidebar\", \"main\"]])]), at(mobile, [areas([[\"main\"], [\"sidebar\"]])])])`. See skill_responsive_design.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_responsive_design_004_q2", "cluster_id": "skill_responsive_design_004", "question": "How do I make elements visible only on mobile or desktop?", "answer": "Make elements visible only on certain devices using `generate_visibility_utilities(CSS)`. This creates classes like `.hidden-mobile`, `.hidden-desktop`, `.show-mobile`, `.show-desktop` for each breakpoint. Apply these classes to control element visibility.", "question_type": "long", "topics": ["Quickstart", "Responsive Design"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["visibility", "show-hide", "responsive-utilities", "media-queries"], "related_skills": ["skill_responsive_design.md"], "related_docs": ["src/unifyweaver/glue/responsive_generator.pl"], "original_answer": "Generate visibility utilities with `generate_visibility_utilities(CSS)` to create show/hide classes for each breakpoint. This generates classes like `.hidden-mobile`, `.visible-mobile`, `.hidden-tablet`, etc., that automatically apply the correct media queries. Alternatively, use responsive layout areas: define different `areas([...])` values at different breakpoints to reorganize layout grids. Example: `responsive_layout(layout, [default([areas([[\"sidebar\", \"main\"]])]), at(mobile, [areas([[\"main\"], [\"sidebar\"]])])])`. See skill_responsive_design.md for details.", "answer_tailored": true, "confidence": 0.8, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_responsive_design_005_q0", "cluster_id": "skill_responsive_design_005", "question": "What are container queries and when should I use them instead of media queries?", "answer": "Container queries allow components to respond to their container's size rather than the viewport size, defined with `container(name, [type(inline_size), breakpoints([at(small, max_width(400)), at(large, min_width(801))])])` and generated via `generate_container_css(container_name, CSS)`. Use container queries instead of media queries when the same component needs different layouts depending on its context\u2014for example, a card that appears both in a narrow sidebar and full-width area. This provides component-level responsiveness that's independent of viewport size, making components more reusable and self-contained.", "question_type": "long", "topics": ["Quickstart", "Responsive Design"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["container-queries", "inline-size", "component-responsive"], "related_skills": ["skill_responsive_design.md"], "related_docs": ["src/unifyweaver/glue/responsive_generator.pl"], "original_answer": "Container queries make components respond to their container size instead of viewport size. Define with `container(name, [type(inline_size), breakpoints([at(small, max_width(400)), at(large, min_width(801))])])`. This is useful when the same component appears in different contexts (narrow sidebar vs full width). Generate CSS with `generate_container_css(container_name, CSS)`. Modern approach: use when you need component-level responsiveness independent of viewport size. See skill_responsive_design.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer assumes familiarity with the Prolog-based system (use_module, syntax) which may not be universal. The answer covers the 'what' and 'when' well but could benefit from a clearer contrast example showing media queries failing where container queries succeed."}
{"pair_id": "skill_responsive_design_005_q1", "cluster_id": "skill_responsive_design_005", "question": "How do I use container queries for responsive design?", "answer": "Container queries enable components to respond to their container size rather than viewport size. Define them using `container(name, [type(inline_size), breakpoints([at(small, max_width(400)), at(large, min_width(801))])])`. This is essential when the same component appears in different layout contexts\u2014such as a narrow sidebar versus full width\u2014and needs to adapt independently of viewport breakpoints. Generate the resulting CSS with `generate_container_css(container_name, CSS)`. Container queries represent the modern approach for component-level responsiveness, allowing true component encapsulation where styling adapts based on available container space rather than global viewport dimensions.", "question_type": "long", "topics": ["Quickstart", "Responsive Design"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["container-queries", "inline-size", "component-responsive"], "related_skills": ["skill_responsive_design.md"], "related_docs": ["src/unifyweaver/glue/responsive_generator.pl"], "original_answer": "Container queries make components respond to their container size instead of viewport size. Define with `container(name, [type(inline_size), breakpoints([at(small, max_width(400)), at(large, min_width(801))])])`. This is useful when the same component appears in different contexts (narrow sidebar vs full width). Generate CSS with `generate_container_css(container_name, CSS)`. Modern approach: use when you need component-level responsiveness independent of viewport size. See skill_responsive_design.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer doesn't explicitly clarify that container queries complement (rather than replace) media queries, or mention the CSS Containment requirement. The syntax example could be more concrete with actual property values."}
{"pair_id": "skill_responsive_design_005_q2", "cluster_id": "skill_responsive_design_005", "question": "When do I use container-based responsiveness?", "answer": "Use container queries when you need components to respond to their own container size rather than the viewport size. This is essential when the same component appears in different contexts\u2014like a card in a narrow sidebar versus full-width layout. Container queries let you define breakpoints based on container dimensions using `container(name, [type(inline_size), breakpoints([at(small, max_width(400)), at(large, min_width(801))])])`. Generate CSS with `generate_container_css(container_name, CSS)`. This modern approach provides true component-level responsiveness independent of viewport size.", "question_type": "long", "topics": ["Quickstart", "Responsive Design"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["container-queries", "inline-size", "component-responsive"], "related_skills": ["skill_responsive_design.md"], "related_docs": ["src/unifyweaver/glue/responsive_generator.pl"], "original_answer": "Container queries make components respond to their container size instead of viewport size. Define with `container(name, [type(inline_size), breakpoints([at(small, max_width(400)), at(large, min_width(801))])])`. This is useful when the same component appears in different contexts (narrow sidebar vs full width). Generate CSS with `generate_container_css(container_name, CSS)`. Modern approach: use when you need component-level responsiveness independent of viewport size. See skill_responsive_design.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_responsive_design_006_q0", "cluster_id": "skill_responsive_design_006", "question": "Should I use mobile-first or desktop-first strategy for my responsive design?", "answer": "Mobile-first (default) is generally recommended\u2014it starts with mobile styles and progressively enhances for larger screens using `min_width` conditions, which improves performance and accessibility. Desktop-first is an alternative that starts with desktop styles and simplifies for smaller screens using `max_width` conditions. Choose mobile-first if you prioritize performance and progressive enhancement, or desktop-first if your team prefers designing from larger screens down. Set your strategy with `set_responsive_strategy(mobile_first)` or `set_responsive_strategy(desktop_first)`, and check the current strategy with `is_mobile_first`.", "question_type": "medium", "topics": ["Quickstart", "Responsive Design"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["mobile-first", "desktop-first", "strategy", "responsive-approach"], "related_skills": ["skill_responsive_design.md"], "related_docs": ["src/unifyweaver/glue/responsive_generator.pl"], "original_answer": "Mobile-first (default) starts with mobile styles and adds complexity for larger screens using `min_width` conditions\u2014best for progressive enhancement. Desktop-first starts with desktop styles and simplifies for smaller screens using `max_width` conditions. Set strategy with `set_responsive_strategy(mobile_first)` or `set_responsive_strategy(desktop_first)`. Mobile-first is generally recommended for better performance and accessibility. Check current strategy with `is_mobile_first`. Choose based on your target audience and workflow preferences. See skill_responsive_design.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_responsive_design_006_q1", "cluster_id": "skill_responsive_design_006", "question": "What's the difference between mobile-first and desktop-first?", "answer": "Mobile-first (default) uses `min_width` conditions to start with mobile styles and progressively add complexity for larger screens\u2014best for progressive enhancement and performance. Desktop-first uses `max_width` conditions to start with desktop styles and simplify for smaller screens. Set your strategy with `set_responsive_strategy(mobile_first)` or `set_responsive_strategy(desktop_first)`. Mobile-first is generally recommended due to better performance and accessibility. Check your current strategy with `is_mobile_first`. Choose based on your target audience and workflow preferences.", "question_type": "medium", "topics": ["Quickstart", "Responsive Design"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["mobile-first", "desktop-first", "strategy", "responsive-approach"], "related_skills": ["skill_responsive_design.md"], "related_docs": ["src/unifyweaver/glue/responsive_generator.pl"], "original_answer": "Mobile-first (default) starts with mobile styles and adds complexity for larger screens using `min_width` conditions\u2014best for progressive enhancement. Desktop-first starts with desktop styles and simplifies for smaller screens using `max_width` conditions. Set strategy with `set_responsive_strategy(mobile_first)` or `set_responsive_strategy(desktop_first)`. Mobile-first is generally recommended for better performance and accessibility. Check current strategy with `is_mobile_first`. Choose based on your target audience and workflow preferences. See skill_responsive_design.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_responsive_design_006_q2", "cluster_id": "skill_responsive_design_006", "question": "Which responsive strategy should I choose?", "answer": "Choose mobile-first (default) if you're building for mobile users first or want progressive enhancement\u2014it starts with mobile styles and uses `min_width` conditions to add complexity for larger screens, which typically improves performance and accessibility. Choose desktop-first if your primary audience is desktop users\u2014it starts with desktop styles and uses `max_width` conditions to simplify for smaller screens. Set your strategy with `set_responsive_strategy(mobile_first)` or `set_responsive_strategy(desktop_first)`, and check the current strategy with `is_mobile_first`. Mobile-first is generally recommended unless your project has specific desktop-focused requirements.", "question_type": "medium", "topics": ["Quickstart", "Responsive Design"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["mobile-first", "desktop-first", "strategy", "responsive-approach"], "related_skills": ["skill_responsive_design.md"], "related_docs": ["src/unifyweaver/glue/responsive_generator.pl"], "original_answer": "Mobile-first (default) starts with mobile styles and adds complexity for larger screens using `min_width` conditions\u2014best for progressive enhancement. Desktop-first starts with desktop styles and simplifies for smaller screens using `max_width` conditions. Set strategy with `set_responsive_strategy(mobile_first)` or `set_responsive_strategy(desktop_first)`. Mobile-first is generally recommended for better performance and accessibility. Check current strategy with `is_mobile_first`. Choose based on your target audience and workflow preferences. See skill_responsive_design.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_rpyc_001_q0", "cluster_id": "skill_rpyc_001", "question": "How do I call Python functions from Prolog over a network?", "answer": "Use RPyC to call Python functions from Prolog over a network. Connect with `rpyc_connect('localhost', [security(unsecured), acknowledge_risk(true)], Proxy)`, then call functions using `rpyc_call(Proxy, module_name, function_name, [args], Result)`. For example: `rpyc_call(Proxy, math, sqrt, [16], R)` returns `R = 4.0`. For automatic connection cleanup, use `rpyc_with_connection/3`. Disconnect when done with `rpyc_disconnect(Proxy)`. Remote connections can use SSH or SSL security modes for production environments.", "question_type": "medium", "topics": ["Quickstart", "RPyC (Remote Python Call)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["remote-execution", "python-bridge", "networking"], "related_skills": ["skill_rpyc.md"], "related_docs": ["src/unifyweaver/glue/rpyc_glue.pl", "src/unifyweaver/glue/rpyc_security.pl"], "original_answer": "Use RPyC to establish a network connection and call Python functions. First connect: `rpyc_connect('localhost', [security(unsecured), acknowledge_risk(true)], Proxy)`. Then call functions: `rpyc_call(Proxy, math, sqrt, [16], R)`. Finally disconnect: `rpyc_disconnect(Proxy)`. For automatic cleanup, use `rpyc_with_connection/3`. See skill_rpyc.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_rpyc_001_q1", "cluster_id": "skill_rpyc_001", "question": "Can I execute Python code remotely from Prolog?", "answer": "Yes, you can execute Python code remotely from Prolog using RPyC. Connect to a remote Python service with `rpyc_connect('localhost', [security(unsecured), acknowledge_risk(true)], Proxy)`, then execute functions using `rpyc_call(Proxy, module_name, function_name, [args], Result)`. For example: `rpyc_call(Proxy, math, sqrt, [16], R)` returns `R = 4.0`. Use `rpyc_disconnect(Proxy)` to close the connection, or `rpyc_with_connection/3` for automatic cleanup. Supports synchronous calls, asynchronous calls with `rpyc_async_call/4`, and multiple security modes (SSH, SSL, unsecured).", "question_type": "medium", "topics": ["Quickstart", "RPyC (Remote Python Call)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["remote-execution", "python-bridge", "networking"], "related_skills": ["skill_rpyc.md"], "related_docs": ["src/unifyweaver/glue/rpyc_glue.pl", "src/unifyweaver/glue/rpyc_security.pl"], "original_answer": "Use RPyC to establish a network connection and call Python functions. First connect: `rpyc_connect('localhost', [security(unsecured), acknowledge_risk(true)], Proxy)`. Then call functions: `rpyc_call(Proxy, math, sqrt, [16], R)`. Finally disconnect: `rpyc_disconnect(Proxy)`. For automatic cleanup, use `rpyc_with_connection/3`. See skill_rpyc.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_rpyc_001_q2", "cluster_id": "skill_rpyc_001", "question": "How do I connect Prolog to a Python service?", "answer": "Use RPyC to connect Prolog to a Python service. Call `rpyc_connect('localhost', [security(unsecured), acknowledge_risk(true)], Proxy)` to establish a connection, then use `rpyc_call(Proxy, module_name, function_name, [args], Result)` to call Python functions remotely. For secure connections, use `security(ssh)` or `security(ssl)` with appropriate credentials. Use `rpyc_disconnect(Proxy)` to close the connection, or `rpyc_with_connection/3` for automatic cleanup. Async calls are available via `rpyc_async_call/5` and `rpyc_await/2`.", "question_type": "medium", "topics": ["Quickstart", "RPyC (Remote Python Call)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["remote-execution", "python-bridge", "networking"], "related_skills": ["skill_rpyc.md"], "related_docs": ["src/unifyweaver/glue/rpyc_glue.pl", "src/unifyweaver/glue/rpyc_security.pl"], "original_answer": "Use RPyC to establish a network connection and call Python functions. First connect: `rpyc_connect('localhost', [security(unsecured), acknowledge_risk(true)], Proxy)`. Then call functions: `rpyc_call(Proxy, math, sqrt, [16], R)`. Finally disconnect: `rpyc_disconnect(Proxy)`. For automatic cleanup, use `rpyc_with_connection/3`. See skill_rpyc.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_rpyc_002_q0", "cluster_id": "skill_rpyc_002", "question": "How do I secure my connection between Prolog and Python?", "answer": "RPyC provides three security modes for Prolog-Python connections. For production, use `security(ssh)` with SSH tunneling\u2014configure with `ssh_user(User)`, `ssh_key(Path)`, and optionally `ssh_port(Port)`. Alternatively, use `security(ssl)` with `certfile(Path)`, `keyfile(Path)`, and `ca_certs(Path)` for SSL/TLS encryption. For local development only, use `security(unsecured)` with `acknowledge_risk(true)`. Example: `rpyc_connect('server.example.com', [security(ssh), ssh_user(admin), ssh_key('/home/user/.ssh/id_rsa'), remote_port(18812)], Proxy).`", "question_type": "medium", "topics": ["Quickstart", "RPyC (Remote Python Call)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["security", "encryption", "ssh", "ssl"], "related_skills": ["skill_rpyc.md"], "related_docs": ["src/unifyweaver/glue/rpyc_security.pl"], "original_answer": "RPyC supports three security modes. Use `security(ssh)` with SSH tunneling and `ssh_key(Path)`, `ssh_user(User)` for SSH-based security. Use `security(ssl)` with `certfile(Path)`, `keyfile(Path)`, and `ca_certs(Path)` for SSL/TLS encryption. For development, use `security(unsecured)` with `acknowledge_risk(true)`. Choose based on your deployment environment and security requirements. See skill_rpyc.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_rpyc_002_q1", "cluster_id": "skill_rpyc_002", "question": "What security options are available for remote Python calls?", "answer": "RPyC provides three security modes for remote Python calls: (1) `security(ssh)` with SSH tunneling using `ssh_user(User)`, `ssh_key(Path)`, and optional `ssh_port(Port)` for secure connections over SSH; (2) `security(ssl)` with SSL/TLS encryption using `certfile(Path)`, `keyfile(Path)`, and `ca_certs(Path)` for certificate-based security; (3) `security(unsecured)` for local development, requiring `acknowledge_risk(true)` to acknowledge the unencrypted connection. Choose based on your deployment environment\u2014SSH for server access, SSL for API endpoints, and unsecured only for local testing.", "question_type": "medium", "topics": ["Quickstart", "RPyC (Remote Python Call)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["security", "encryption", "ssh", "ssl"], "related_skills": ["skill_rpyc.md"], "related_docs": ["src/unifyweaver/glue/rpyc_security.pl"], "original_answer": "RPyC supports three security modes. Use `security(ssh)` with SSH tunneling and `ssh_key(Path)`, `ssh_user(User)` for SSH-based security. Use `security(ssl)` with `certfile(Path)`, `keyfile(Path)`, and `ca_certs(Path)` for SSL/TLS encryption. For development, use `security(unsecured)` with `acknowledge_risk(true)`. Choose based on your deployment environment and security requirements. See skill_rpyc.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_rpyc_002_q2", "cluster_id": "skill_rpyc_002", "question": "How do I encrypt communication with a Python service?", "answer": "RPyC provides two encryption options for secure communication with a Python service: (1) SSH tunneling via `security(ssh)` with `ssh_user(User)`, `ssh_key(Path)`, and optionally `ssh_port(Port)` - this encrypts all traffic through an SSH tunnel; (2) SSL/TLS via `security(ssl)` with `certfile(Path)`, `keyfile(Path)`, and `ca_certs(Path)` - this uses certificate-based encryption. Example with SSH: `rpyc_connect('server.example.com', [security(ssh), ssh_user(admin), ssh_key('/path/to/key')], Proxy)`. Example with SSL: `rpyc_connect('api.example.com', [security(ssl), certfile('/certs/client.pem'), keyfile('/certs/client.key'), ca_certs('/certs/ca.pem')], Proxy)`. Choose SSH for tunneled connections or SSL for direct encrypted connections based on your deployment needs.", "question_type": "medium", "topics": ["Quickstart", "RPyC (Remote Python Call)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["security", "encryption", "ssh", "ssl"], "related_skills": ["skill_rpyc.md"], "related_docs": ["src/unifyweaver/glue/rpyc_security.pl"], "original_answer": "RPyC supports three security modes. Use `security(ssh)` with SSH tunneling and `ssh_key(Path)`, `ssh_user(User)` for SSH-based security. Use `security(ssl)` with `certfile(Path)`, `keyfile(Path)`, and `ca_certs(Path)` for SSL/TLS encryption. For development, use `security(unsecured)` with `acknowledge_risk(true)`. Choose based on your deployment environment and security requirements. See skill_rpyc.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_rpyc_003_q0", "cluster_id": "skill_rpyc_003", "question": "How do I run long-running Python computations without blocking Prolog?", "answer": "Use asynchronous calls with `rpyc_async_call(Proxy, Module, Function, Args, AsyncResult)` to start long-running Python computations without blocking Prolog. While the computation runs, you can perform other work in Prolog. Use `rpyc_ready(AsyncResult)` to check if the result is ready, and `rpyc_await(AsyncResult, Result)` to retrieve the result when needed. This pattern allows Prolog to continue executing other tasks instead of waiting for the Python computation to complete.", "question_type": "medium", "topics": ["Quickstart", "RPyC (Remote Python Call)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["async", "non-blocking", "concurrency"], "related_skills": ["skill_rpyc.md"], "related_docs": ["src/unifyweaver/glue/rpyc_glue.pl"], "original_answer": "Use asynchronous calls for non-blocking execution. Start a computation with: `rpyc_async_call(Proxy, scipy, optimize, [func, x0], AsyncResult)`. Do other work while it runs. Check if ready with: `rpyc_ready(AsyncResult)`. Wait for the result when needed: `rpyc_await(AsyncResult, Result)`. This allows Prolog to continue without blocking on long computations. See skill_rpyc.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_rpyc_003_q1", "cluster_id": "skill_rpyc_003", "question": "Can I execute Python asynchronously from Prolog?", "answer": "Yes, you can execute Python asynchronously from Prolog using RPyC. Use `rpyc_async_call(Proxy, Module, Function, Args, AsyncResult)` to start a non-blocking computation. Check if the result is ready with `rpyc_ready(AsyncResult)`, which allows Prolog to continue other work while Python executes. When you need the result, call `rpyc_await(AsyncResult, Result)` to retrieve it. This enables long-running Python computations without blocking Prolog execution.", "question_type": "medium", "topics": ["Quickstart", "RPyC (Remote Python Call)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["async", "non-blocking", "concurrency"], "related_skills": ["skill_rpyc.md"], "related_docs": ["src/unifyweaver/glue/rpyc_glue.pl"], "original_answer": "Use asynchronous calls for non-blocking execution. Start a computation with: `rpyc_async_call(Proxy, scipy, optimize, [func, x0], AsyncResult)`. Do other work while it runs. Check if ready with: `rpyc_ready(AsyncResult)`. Wait for the result when needed: `rpyc_await(AsyncResult, Result)`. This allows Prolog to continue without blocking on long computations. See skill_rpyc.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_rpyc_003_q2", "cluster_id": "skill_rpyc_003", "question": "How do I handle background Python tasks?", "answer": "Use asynchronous calls for non-blocking background execution in Python. Start a computation with `rpyc_async_call(Proxy, Module, Function, Args, AsyncResult)` to initiate the task without waiting. Check progress with `rpyc_ready(AsyncResult)` to test if the task has completed. Retrieve the result with `rpyc_await(AsyncResult, Result)` when you need it. This pattern allows Prolog to continue executing other code while Python processes run in the background. Example: `rpyc_async_call(Proxy, scipy, optimize, [func, x0], AsyncResult)` starts an optimization task, then you can do other work and call `rpyc_await(AsyncResult, Result)` later to get the answer.", "question_type": "medium", "topics": ["Quickstart", "RPyC (Remote Python Call)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["async", "non-blocking", "concurrency"], "related_skills": ["skill_rpyc.md"], "related_docs": ["src/unifyweaver/glue/rpyc_glue.pl"], "original_answer": "Use asynchronous calls for non-blocking execution. Start a computation with: `rpyc_async_call(Proxy, scipy, optimize, [func, x0], AsyncResult)`. Do other work while it runs. Check if ready with: `rpyc_ready(AsyncResult)`. Wait for the result when needed: `rpyc_await(AsyncResult, Result)`. This allows Prolog to continue without blocking on long computations. See skill_rpyc.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_rpyc_004_q0", "cluster_id": "skill_rpyc_004", "question": "How do I import and use Python modules like NumPy or SciPy from Prolog?", "answer": "Import and call Python modules directly using rpyc_call. For standard modules like NumPy: `rpyc_call(Proxy, numpy, mean, [[1,2,3,4,5]], R)` returns the mean (3.0). For nested modules like SciPy: `rpyc_get_module(Proxy, 'scipy.optimize', ModuleRef)` retrieves the module reference. For complex imports or custom initialization: `rpyc_exec(Proxy, \"import numpy as np\\nimport scipy\\nresult = np.array([1,2,3]) * 2\", Namespace)` executes arbitrary Python code and stores results in Namespace. After connecting with rpyc_connect, you can call any module's functions with rpyc_call(Proxy, ModuleName, FunctionName, Arguments, Result).", "question_type": "long", "topics": ["Quickstart", "RPyC (Remote Python Call)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["modules", "libraries", "numpy", "scipy"], "related_skills": ["skill_rpyc.md"], "related_docs": ["src/unifyweaver/glue/rpyc_glue.pl"], "original_answer": "Import modules and call their functions directly. For standard modules: `rpyc_call(Proxy, numpy, mean, [[1,2,3,4,5]], R)`. For nested modules, use: `rpyc_get_module(Proxy, 'scipy.optimize', ModuleRef)`. You can also execute arbitrary Python code: `rpyc_exec(Proxy, \"import numpy as np\\nresult = np.array([1,2,3]) * 2\", Namespace)`. See skill_rpyc.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_rpyc_004_q1", "cluster_id": "skill_rpyc_004", "question": "Can I access external Python libraries from Prolog?", "answer": "Yes, you can access external Python libraries from Prolog through RPyC. For standard libraries like NumPy, call functions directly: `rpyc_call(Proxy, numpy, mean, [[1,2,3,4,5]], R)`. For nested modules like scipy.optimize, use: `rpyc_get_module(Proxy, 'scipy.optimize', ModuleRef)`. You can also execute arbitrary Python code with imports: `rpyc_exec(Proxy, \"import numpy as np\\nresult = np.array([1,2,3]) * 2\", Namespace)`. This allows seamless access to any installed Python package from your Prolog code.", "question_type": "long", "topics": ["Quickstart", "RPyC (Remote Python Call)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["modules", "libraries", "numpy", "scipy"], "related_skills": ["skill_rpyc.md"], "related_docs": ["src/unifyweaver/glue/rpyc_glue.pl"], "original_answer": "Import modules and call their functions directly. For standard modules: `rpyc_call(Proxy, numpy, mean, [[1,2,3,4,5]], R)`. For nested modules, use: `rpyc_get_module(Proxy, 'scipy.optimize', ModuleRef)`. You can also execute arbitrary Python code: `rpyc_exec(Proxy, \"import numpy as np\\nresult = np.array([1,2,3]) * 2\", Namespace)`. See skill_rpyc.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_rpyc_004_q2", "cluster_id": "skill_rpyc_004", "question": "How do I call NumPy functions remotely?", "answer": "To call NumPy functions remotely using RPyC, use `rpyc_call(Proxy, numpy, function_name, [args], Result)`. For example: `rpyc_call(Proxy, numpy, mean, [[1,2,3,4,5]], R)` computes the mean, `rpyc_call(Proxy, numpy, std, [[1,2,3,4,5]], R)` computes standard deviation. For nested NumPy submodules, use `rpyc_get_module(Proxy, 'numpy.linalg', ModuleRef)` first, then call functions on that reference. Alternatively, execute arbitrary NumPy code directly with `rpyc_exec(Proxy, \"import numpy as np\\nresult = np.array([1,2,3]) * 2\", Namespace)`.", "question_type": "long", "topics": ["Quickstart", "RPyC (Remote Python Call)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["modules", "libraries", "numpy", "scipy"], "related_skills": ["skill_rpyc.md"], "related_docs": ["src/unifyweaver/glue/rpyc_glue.pl"], "original_answer": "Import modules and call their functions directly. For standard modules: `rpyc_call(Proxy, numpy, mean, [[1,2,3,4,5]], R)`. For nested modules, use: `rpyc_get_module(Proxy, 'scipy.optimize', ModuleRef)`. You can also execute arbitrary Python code: `rpyc_exec(Proxy, \"import numpy as np\\nresult = np.array([1,2,3]) * 2\", Namespace)`. See skill_rpyc.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_rpyc_005_q0", "cluster_id": "skill_rpyc_005", "question": "What should I do when a remote Python call fails?", "answer": "Wrap RPyC calls in catch/3 to handle failures. For connection errors: `catch(rpyc_connect(Host, Options, Proxy), Error, handle_connection_error(Error))`. For execution errors: `catch(rpyc_call(Proxy, Module, Function, Args, Result), Error, handle_call_error(Error))`. Common failures include unavailable servers (check server status before connecting), incorrect function names (verify function exists in target module), type mismatches in arguments, and network timeouts. Always validate that the remote server is running and accessible, confirm the module and function names exist, and check network connectivity. Use rpyc_ready/1 with async calls to test result availability before awaiting.", "question_type": "long", "topics": ["Quickstart", "RPyC (Remote Python Call)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["error-handling", "debugging", "troubleshooting"], "related_skills": ["skill_rpyc.md"], "related_docs": ["src/unifyweaver/glue/rpyc_glue.pl"], "original_answer": "Wrap RPyC calls in catch/3 to handle errors. Catch connection errors: `catch(rpyc_connect(...), Error, handle_error(Error))`. Catch execution errors: `catch(rpyc_call(Proxy, module, func, [], R), Error, (format('Call failed: ~w~n', [Error]), R = error))`. Common issues include unavailable servers, incorrect function names, and network problems. Always check server availability and function signatures before deployment. See skill_rpyc.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_rpyc_005_q1", "cluster_id": "skill_rpyc_005", "question": "How do I handle errors in RPyC calls?", "answer": "Wrap RPyC calls in catch/3 to handle errors. For connection errors, use: `catch(rpyc_connect(Host, Options, Proxy), Error, handle_error(Error))`. For execution errors: `catch(rpyc_call(Proxy, Module, Function, Args, Result), Error, (format('Call failed: ~w~n', [Error]), Result = error))`. Common errors include unavailable servers, incorrect function names, and network timeouts. Always verify server availability and validate function signatures before calling. For async calls, wrap both `rpyc_async_call/5` and `rpyc_await/2` in catch/3 to handle both submission and result retrieval failures.", "question_type": "long", "topics": ["Quickstart", "RPyC (Remote Python Call)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["error-handling", "debugging", "troubleshooting"], "related_skills": ["skill_rpyc.md"], "related_docs": ["src/unifyweaver/glue/rpyc_glue.pl"], "original_answer": "Wrap RPyC calls in catch/3 to handle errors. Catch connection errors: `catch(rpyc_connect(...), Error, handle_error(Error))`. Catch execution errors: `catch(rpyc_call(Proxy, module, func, [], R), Error, (format('Call failed: ~w~n', [Error]), R = error))`. Common issues include unavailable servers, incorrect function names, and network problems. Always check server availability and function signatures before deployment. See skill_rpyc.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_rpyc_005_q2", "cluster_id": "skill_rpyc_005", "question": "What happens if the Python server is unavailable?", "answer": "When the Python server is unavailable, RPyC connection attempts will fail. Use catch/3 to handle connection errors: `catch(rpyc_connect(Host, Options, Proxy), Error, handle_connection_error(Error))`. This catches exceptions when the server cannot be reached. For robustness, check server availability before attempting connections, and consider implementing reconnection logic or timeouts. Network problems, incorrect host/port configurations, and server crashes will all trigger these errors.", "question_type": "long", "topics": ["Quickstart", "RPyC (Remote Python Call)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["error-handling", "debugging", "troubleshooting"], "related_skills": ["skill_rpyc.md"], "related_docs": ["src/unifyweaver/glue/rpyc_glue.pl"], "original_answer": "Wrap RPyC calls in catch/3 to handle errors. Catch connection errors: `catch(rpyc_connect(...), Error, handle_error(Error))`. Catch execution errors: `catch(rpyc_call(Proxy, module, func, [], R), Error, (format('Call failed: ~w~n', [Error]), R = error))`. Common issues include unavailable servers, incorrect function names, and network problems. Always check server availability and function signatures before deployment. See skill_rpyc.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "Base answer mentions multiple error types but doesn't explicitly state that unavailability causes connection failure exceptions. The answer infers this from the error handling guidance provided."}
{"pair_id": "skill_rpyc_006_q0", "cluster_id": "skill_rpyc_006", "question": "How do I generate Prolog code that automatically calls remote Python functions?", "answer": "Use code generation predicates to automatically create Prolog code that calls remote Python functions. Use `generate_rpyc_client(Predicates, Options, Code)` to generate client predicates that wrap rpyc_call invocations for specified functions. Use `generate_rpyc_service(Predicates, Options, ServiceCode)` to generate the corresponding Python RPyC service that exposes those functions. Use `generate_rpyc_server(Options, ServerScript)` to generate a complete standalone server script. These predicates automate boilerplate generation and ensure consistency between Prolog client code and Python server implementations.", "question_type": "long", "topics": ["Quickstart", "RPyC (Remote Python Call)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["code-generation", "automation", "server-setup"], "related_skills": ["skill_rpyc.md"], "related_docs": ["src/unifyweaver/glue/rpyc_glue.pl"], "original_answer": "Use code generation predicates to create client and server code. Generate Python client code with: `generate_rpyc_client(Predicates, Options, Code)`. Generate a Python RPyC service with: `generate_rpyc_service(Predicates, Options, ServiceCode)`. Generate a standalone server script with: `generate_rpyc_server(Options, ServerScript)`. This automates boilerplate and ensures consistency between client and server. See skill_rpyc.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "The base answer references specific predicates (generate_rpyc_client, generate_rpyc_service, generate_rpyc_server) that are not documented in the provided skill document excerpt. The answer assumes these predicates exist but provides no usage examples or detailed parameter documentation. Cannot fully validate answer accuracy against the provided skill reference material."}
{"pair_id": "skill_rpyc_006_q1", "cluster_id": "skill_rpyc_006", "question": "Can I auto-generate RPyC client code?", "answer": "Yes, you can auto-generate RPyC client code using the code generation predicates. Use `generate_rpyc_client(Predicates, Options, Code)` to create Python client code, `generate_rpyc_service(Predicates, Options, ServiceCode)` to generate a Python RPyC service, and `generate_rpyc_server(Options, ServerScript)` to create a standalone server script. This automation reduces boilerplate and ensures consistency between client and server implementations.", "question_type": "long", "topics": ["Quickstart", "RPyC (Remote Python Call)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["code-generation", "automation", "server-setup"], "related_skills": ["skill_rpyc.md"], "related_docs": ["src/unifyweaver/glue/rpyc_glue.pl"], "original_answer": "Use code generation predicates to create client and server code. Generate Python client code with: `generate_rpyc_client(Predicates, Options, Code)`. Generate a Python RPyC service with: `generate_rpyc_service(Predicates, Options, ServiceCode)`. Generate a standalone server script with: `generate_rpyc_server(Options, ServerScript)`. This automates boilerplate and ensures consistency between client and server. See skill_rpyc.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "The base answer references 'skill_rpyc.md' for details, but the provided skill document does not contain documentation for these code generation predicates. The confidence is moderate because the predicates are mentioned in the base answer but lack implementation examples or detailed parameter documentation in the available reference material."}
{"pair_id": "skill_rpyc_006_q2", "cluster_id": "skill_rpyc_006", "question": "How do I create a Python service wrapper in Prolog?", "answer": "Use code generation predicates to create Python service wrappers. Generate a Python RPyC service with `generate_rpyc_service(Predicates, Options, ServiceCode)` to automatically create server code from Prolog predicates. Generate a Python client wrapper with `generate_rpyc_client(Predicates, Options, Code)` for calling Prolog from Python. For a complete standalone server, use `generate_rpyc_server(Options, ServerScript)`. These predicates automate boilerplate code and ensure the client and server implementations stay synchronized.", "question_type": "long", "topics": ["Quickstart", "RPyC (Remote Python Call)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["code-generation", "automation", "server-setup"], "related_skills": ["skill_rpyc.md"], "related_docs": ["src/unifyweaver/glue/rpyc_glue.pl"], "original_answer": "Use code generation predicates to create client and server code. Generate Python client code with: `generate_rpyc_client(Predicates, Options, Code)`. Generate a Python RPyC service with: `generate_rpyc_service(Predicates, Options, ServiceCode)`. Generate a standalone server script with: `generate_rpyc_server(Options, ServerScript)`. This automates boilerplate and ensures consistency between client and server. See skill_rpyc.md for details.", "answer_tailored": true, "confidence": 0.75, "confidence_issues": "The base answer references skill_rpyc.md for details, but the provided skill document doesn't include these code generation predicates or their full specifications. The answer is inferred from the base text but lacks concrete examples of what the generated code looks like or how to use it."}
{"pair_id": "skill_semantic_inference_001_q0", "cluster_id": "skill_semantic_inference_001", "question": "How do I find where to file a bookmark in my collection?", "answer": "Use the bookmark filing assistant to automatically suggest the best folders for your bookmark:\n\n```bash\npython3 scripts/bookmark_filing_assistant.py \\\n  --model models/pearltrees_federated.pkl \\\n  --bookmark \"https://example.com/article\" \\\n  --title \"Interesting Article\" \\\n  --suggest-folders 5\n```\n\nThis analyzes your bookmark's content and returns the top matching folders from your collection hierarchy, ranked by similarity score. Adjust `--suggest-folders` to get more or fewer suggestions.", "question_type": "medium", "topics": ["Quickstart", "Semantic Inference"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["bookmark", "filing", "semantic", "suggestion"], "related_skills": ["skill_semantic_inference.md", "skill_train_model.md", "skill_bookmark_filing.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "docs/QUICKSTART_MINDMAP_LINKING.md", "education/book-13-semantic-search/16_bookmark_filing.md"], "original_answer": "Use the bookmark filing assistant to automatically suggest folders based on bookmark content:\n\n```bash\npython3 scripts/bookmark_filing_assistant.py \\\n  --model models/pearltrees_federated.pkl \\\n  --bookmark \"https://example.com/article\" \\\n  --title \"Interesting Article\" \\\n  --suggest-folders 5\n```\n\nThis analyzes your bookmark and returns the most relevant folders from your hierarchy with similarity scores. See skill_semantic_inference.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_semantic_inference_001_q1", "cluster_id": "skill_semantic_inference_001", "question": "Where should I file this bookmark?", "answer": "Use the bookmark filing assistant to automatically suggest folders based on your bookmark's content and metadata:\n\n```bash\npython3 scripts/bookmark_filing_assistant.py \\\n  --model models/pearltrees_federated.pkl \\\n  --bookmark \"https://your-bookmark-url\" \\\n  --title \"Your Bookmark Title\" \\\n  --suggest-folders 5\n```\n\nThe tool analyzes your bookmark and returns the top 5 most relevant folders from your hierarchy, ranked by similarity score. This helps you find the best location in your folder structure for organizing the bookmark.", "question_type": "medium", "topics": ["Quickstart", "Semantic Inference"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["bookmark", "filing", "semantic", "suggestion"], "related_skills": ["skill_semantic_inference.md", "skill_train_model.md", "skill_bookmark_filing.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "docs/QUICKSTART_MINDMAP_LINKING.md", "education/book-13-semantic-search/16_bookmark_filing.md"], "original_answer": "Use the bookmark filing assistant to automatically suggest folders based on bookmark content:\n\n```bash\npython3 scripts/bookmark_filing_assistant.py \\\n  --model models/pearltrees_federated.pkl \\\n  --bookmark \"https://example.com/article\" \\\n  --title \"Interesting Article\" \\\n  --suggest-folders 5\n```\n\nThis analyzes your bookmark and returns the most relevant folders from your hierarchy with similarity scores. See skill_semantic_inference.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_semantic_inference_001_q2", "cluster_id": "skill_semantic_inference_001", "question": "How can I suggest folders for a bookmark?", "answer": "Use the bookmark filing assistant to suggest folders for a bookmark:\n\n```bash\npython3 scripts/bookmark_filing_assistant.py \\\n  --model models/pearltrees_federated.pkl \\\n  --bookmark \"https://example.com/article\" \\\n  --title \"Interesting Article\" \\\n  --suggest-folders 5\n```\n\nThis analyzes your bookmark URL and title, then returns the top 5 most relevant folders from your hierarchy with similarity scores. The tool uses your trained federated model to match bookmark content against your folder structure.", "question_type": "medium", "topics": ["Quickstart", "Semantic Inference"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["bookmark", "filing", "semantic", "suggestion"], "related_skills": ["skill_semantic_inference.md", "skill_train_model.md", "skill_bookmark_filing.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "docs/QUICKSTART_MINDMAP_LINKING.md", "education/book-13-semantic-search/16_bookmark_filing.md"], "original_answer": "Use the bookmark filing assistant to automatically suggest folders based on bookmark content:\n\n```bash\npython3 scripts/bookmark_filing_assistant.py \\\n  --model models/pearltrees_federated.pkl \\\n  --bookmark \"https://example.com/article\" \\\n  --title \"Interesting Article\" \\\n  --suggest-folders 5\n```\n\nThis analyzes your bookmark and returns the most relevant folders from your hierarchy with similarity scores. See skill_semantic_inference.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_semantic_inference_001_q3", "cluster_id": "skill_semantic_inference_001", "question": "How do I organize bookmarks automatically?", "answer": "Use the bookmark filing assistant to automatically suggest folders based on bookmark content. Run `python3 scripts/bookmark_filing_assistant.py --model models/pearltrees_federated.pkl --bookmark \"https://example.com/article\" --title \"Interesting Article\" --suggest-folders 5`. This analyzes your bookmark and returns the most relevant folders from your hierarchy with similarity scores, letting you file bookmarks without manually navigating your folder structure.", "question_type": "medium", "topics": ["Quickstart", "Semantic Inference"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["bookmark", "filing", "semantic", "suggestion"], "related_skills": ["skill_semantic_inference.md", "skill_train_model.md", "skill_bookmark_filing.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "docs/QUICKSTART_MINDMAP_LINKING.md", "education/book-13-semantic-search/16_bookmark_filing.md"], "original_answer": "Use the bookmark filing assistant to automatically suggest folders based on bookmark content:\n\n```bash\npython3 scripts/bookmark_filing_assistant.py \\\n  --model models/pearltrees_federated.pkl \\\n  --bookmark \"https://example.com/article\" \\\n  --title \"Interesting Article\" \\\n  --suggest-folders 5\n```\n\nThis analyzes your bookmark and returns the most relevant folders from your hierarchy with similarity scores. See skill_semantic_inference.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_semantic_inference_002_q0", "cluster_id": "skill_semantic_inference_002", "question": "How do I search my data semantically to find similar documents?", "answer": "Use semantic inference to search your data for similar documents:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --query \"your search text here\" \\\n  --top-k 5\n```\n\nThis returns the top 5 most similar documents/folders with relevance scores. For batch processing multiple queries, use `--input queries.txt --output results.jsonl`. You can also filter results with `--threshold` to set a minimum similarity score. For more options, run with `--help` or see skill_semantic_inference.md.", "question_type": "medium", "topics": ["Quickstart", "Semantic Inference"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["semantic", "search", "similarity", "inference"], "related_skills": ["skill_semantic_inference.md", "skill_embedding_models.md", "skill_density_explorer.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "education/book-13-semantic-search/02_graph_rag.md", "education/book-13-semantic-search/07_density_scoring.md"], "original_answer": "Use semantic inference to find similar folders and documents:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --query \"quantum computing basics\" \\\n  --top-k 5\n```\n\nThis returns the top 5 most similar paths with scores. Use `--threshold` to filter by minimum similarity score. See skill_semantic_inference.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_semantic_inference_002_q1", "cluster_id": "skill_semantic_inference_002", "question": "How can I find documents similar to a query?", "answer": "Use the semantic inference script to find documents similar to your query:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --query \"your search query here\" \\\n  --top-k 5\n```\n\nThis returns the top 5 most similar documents/folders ranked by similarity score (0-1). Adjust `--top-k` for more results, or use `--threshold` to only show matches above a minimum score.", "question_type": "medium", "topics": ["Quickstart", "Semantic Inference"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["semantic", "search", "similarity", "inference"], "related_skills": ["skill_semantic_inference.md", "skill_embedding_models.md", "skill_density_explorer.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "education/book-13-semantic-search/02_graph_rag.md", "education/book-13-semantic-search/07_density_scoring.md"], "original_answer": "Use semantic inference to find similar folders and documents:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --query \"quantum computing basics\" \\\n  --top-k 5\n```\n\nThis returns the top 5 most similar paths with scores. Use `--threshold` to filter by minimum similarity score. See skill_semantic_inference.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_semantic_inference_002_q2", "cluster_id": "skill_semantic_inference_002", "question": "How do I run semantic search on my collection?", "answer": "To run semantic search on your collection, use the semantic inference script with your query:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --query \"your search query here\" \\\n  --top-k 5\n```\n\nThis searches your collection and returns the top 5 most similar folders/documents with relevance scores. Customize `--top-k` for more/fewer results, and use `--threshold` to filter by minimum similarity score. For batch searching multiple queries from a file, use `--input queries.txt --output results.jsonl` instead of `--query`.", "question_type": "medium", "topics": ["Quickstart", "Semantic Inference"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["semantic", "search", "similarity", "inference"], "related_skills": ["skill_semantic_inference.md", "skill_embedding_models.md", "skill_density_explorer.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "education/book-13-semantic-search/02_graph_rag.md", "education/book-13-semantic-search/07_density_scoring.md"], "original_answer": "Use semantic inference to find similar folders and documents:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --query \"quantum computing basics\" \\\n  --top-k 5\n```\n\nThis returns the top 5 most similar paths with scores. Use `--threshold` to filter by minimum similarity score. See skill_semantic_inference.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_semantic_inference_002_q3", "cluster_id": "skill_semantic_inference_002", "question": "How do I find related folders or documents?", "answer": "Use semantic inference with the federated model to find related folders and documents. Run: `python3 scripts/infer_pearltrees_federated.py --model models/pearltrees_federated.pkl --query \"your search text\" --top-k 5`. This returns the top matching paths with similarity scores. Adjust `--top-k` for more results, or use `--threshold` to set a minimum similarity score filter. For batch processing multiple queries, use `--input queries.txt --output results.jsonl`.", "question_type": "medium", "topics": ["Quickstart", "Semantic Inference"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["semantic", "search", "similarity", "inference"], "related_skills": ["skill_semantic_inference.md", "skill_embedding_models.md", "skill_density_explorer.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "education/book-13-semantic-search/02_graph_rag.md", "education/book-13-semantic-search/07_density_scoring.md"], "original_answer": "Use semantic inference to find similar folders and documents:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --query \"quantum computing basics\" \\\n  --top-k 5\n```\n\nThis returns the top 5 most similar paths with scores. Use `--threshold` to filter by minimum similarity score. See skill_semantic_inference.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_semantic_inference_003_q0", "cluster_id": "skill_semantic_inference_003", "question": "How do I process multiple queries at once?", "answer": "Use batch mode to process multiple queries at once:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --input queries.txt \\\n  --output results.jsonl\n```\n\nPrepare a text file with one query per line, and the script will process all queries and write results to a JSONL file containing paths, similarity scores, and cluster information for each query.", "question_type": "long", "topics": ["Quickstart", "Semantic Inference"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["batch", "inference", "automation", "processing"], "related_skills": ["skill_semantic_inference.md", "skill_train_model.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "education/book-13-semantic-search/06_distributed_search.md"], "original_answer": "Use batch mode to process multiple queries from a file:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --input queries.txt \\\n  --output results.jsonl\n```\n\nThe input file should contain one query per line. Results are written to the output file in JSONL format with paths, scores, and cluster information. See skill_semantic_inference.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_semantic_inference_003_q1", "cluster_id": "skill_semantic_inference_003", "question": "How do I batch process queries?", "answer": "Use batch mode to process multiple queries from a file:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --input queries.txt \\\n  --output results.jsonl\n```\n\nPrepare your input file with one query per line. Results will be written to the output file in JSONL format, with each result containing the matched path, similarity score, and cluster assignment.", "question_type": "long", "topics": ["Quickstart", "Semantic Inference"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["batch", "inference", "automation", "processing"], "related_skills": ["skill_semantic_inference.md", "skill_train_model.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "education/book-13-semantic-search/06_distributed_search.md"], "original_answer": "Use batch mode to process multiple queries from a file:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --input queries.txt \\\n  --output results.jsonl\n```\n\nThe input file should contain one query per line. Results are written to the output file in JSONL format with paths, scores, and cluster information. See skill_semantic_inference.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_semantic_inference_003_q2", "cluster_id": "skill_semantic_inference_003", "question": "Can I inference on a file of queries?", "answer": "Yes, you can run inference on a file of queries using batch mode. Use the `--input` parameter to specify your query file and `--output` to save results:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --input queries.txt \\\n  --output results.jsonl\n```\n\nFormat your input file with one query per line. Results are written to the output file in JSONL format, with each result containing the path, similarity score, and cluster assignment.", "question_type": "long", "topics": ["Quickstart", "Semantic Inference"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["batch", "inference", "automation", "processing"], "related_skills": ["skill_semantic_inference.md", "skill_train_model.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "education/book-13-semantic-search/06_distributed_search.md"], "original_answer": "Use batch mode to process multiple queries from a file:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --input queries.txt \\\n  --output results.jsonl\n```\n\nThe input file should contain one query per line. Results are written to the output file in JSONL format with paths, scores, and cluster information. See skill_semantic_inference.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_semantic_inference_003_q3", "cluster_id": "skill_semantic_inference_003", "question": "How do I analyze many queries in one go?", "answer": "Use batch mode to process multiple queries from a file:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --input queries.txt \\\n  --output results.jsonl\n```\n\nPut one query per line in your input file. Results are written to the output file in JSONL format, with each result containing the path, similarity score, and cluster information for easy analysis of all queries at once.", "question_type": "long", "topics": ["Quickstart", "Semantic Inference"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["batch", "inference", "automation", "processing"], "related_skills": ["skill_semantic_inference.md", "skill_train_model.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "education/book-13-semantic-search/06_distributed_search.md"], "original_answer": "Use batch mode to process multiple queries from a file:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --input queries.txt \\\n  --output results.jsonl\n```\n\nThe input file should contain one query per line. Results are written to the output file in JSONL format with paths, scores, and cluster information. See skill_semantic_inference.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_semantic_inference_004_q0", "cluster_id": "skill_semantic_inference_004", "question": "How do I restrict inference results to a specific cluster or category?", "answer": "Use the `--cluster` parameter to restrict inference results to a specific cluster:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --query \"quantum computing basics\" \\\n  --cluster science\n```\n\nThis filters results to only the specified cluster (e.g., \"science\", \"technology\"). Combine with `--top-k` to limit the number of results returned.", "question_type": "long", "topics": ["Quickstart", "Semantic Inference"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["cluster", "filtering", "category", "inference"], "related_skills": ["skill_semantic_inference.md", "skill_embedding_models.md", "skill_hierarchy_objective.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "education/book-13-semantic-search/13_advanced_routing.md"], "original_answer": "Use the `--cluster` parameter to restrict inference to a specific category:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --query \"quantum computing basics\" \\\n  --cluster science\n```\n\nThis returns only results from the specified cluster. Combine with `--top-k` to control result count. See skill_semantic_inference.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_semantic_inference_004_q1", "cluster_id": "skill_semantic_inference_004", "question": "Can I search within a specific cluster?", "answer": "Yes, you can search within a specific cluster using the `--cluster` parameter. For example:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --query \"quantum computing basics\" \\\n  --cluster science\n```\n\nThis restricts results to only the specified cluster. You can combine this with `--top-k` to control how many results are returned from that cluster.", "question_type": "long", "topics": ["Quickstart", "Semantic Inference"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["cluster", "filtering", "category", "inference"], "related_skills": ["skill_semantic_inference.md", "skill_embedding_models.md", "skill_hierarchy_objective.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "education/book-13-semantic-search/13_advanced_routing.md"], "original_answer": "Use the `--cluster` parameter to restrict inference to a specific category:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --query \"quantum computing basics\" \\\n  --cluster science\n```\n\nThis returns only results from the specified cluster. Combine with `--top-k` to control result count. See skill_semantic_inference.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_semantic_inference_004_q2", "cluster_id": "skill_semantic_inference_004", "question": "How do I limit results to one category?", "answer": "Use the `--cluster` parameter to restrict inference to a specific category:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --query \"quantum computing basics\" \\\n  --cluster science\n```\n\nThis returns only results from the specified cluster. You can combine it with `--top-k` to control how many results you get back from that category.", "question_type": "long", "topics": ["Quickstart", "Semantic Inference"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["cluster", "filtering", "category", "inference"], "related_skills": ["skill_semantic_inference.md", "skill_embedding_models.md", "skill_hierarchy_objective.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "education/book-13-semantic-search/13_advanced_routing.md"], "original_answer": "Use the `--cluster` parameter to restrict inference to a specific category:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --query \"quantum computing basics\" \\\n  --cluster science\n```\n\nThis returns only results from the specified cluster. Combine with `--top-k` to control result count. See skill_semantic_inference.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_semantic_inference_004_q3", "cluster_id": "skill_semantic_inference_004", "question": "How do I filter inference by cluster?", "answer": "Use the `--cluster` parameter to restrict inference results to a specific cluster:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --query \"quantum computing basics\" \\\n  --cluster science\n```\n\nThis filters results to only the specified cluster (e.g., `science`, `technology`). You can combine it with `--top-k` to limit the number of results returned from that cluster.", "question_type": "long", "topics": ["Quickstart", "Semantic Inference"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["cluster", "filtering", "category", "inference"], "related_skills": ["skill_semantic_inference.md", "skill_embedding_models.md", "skill_hierarchy_objective.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "education/book-13-semantic-search/13_advanced_routing.md"], "original_answer": "Use the `--cluster` parameter to restrict inference to a specific category:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --query \"quantum computing basics\" \\\n  --cluster science\n```\n\nThis returns only results from the specified cluster. Combine with `--top-k` to control result count. See skill_semantic_inference.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_semantic_inference_005_q0", "cluster_id": "skill_semantic_inference_005", "question": "What different inference modes are available?", "answer": "UnifyWeaver's semantic inference system supports four different modes:\n\n- **single**: Run one query at a time (default mode)\n- **batch**: Process multiple queries from a file\n- **interactive**: REPL environment for testing multiple queries interactively\n- **server**: HTTP API endpoint for integration with other applications\n\nYou can select a mode when running the inference script. Use `python3 scripts/infer_pearltrees_federated.py --help` to see all available options and parameters for each mode.", "question_type": "medium", "topics": ["Quickstart", "Semantic Inference"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["inference", "modes", "workflow", "api"], "related_skills": ["skill_semantic_inference.md", "skill_train_model.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "education/book-13-semantic-search/06_distributed_search.md"], "original_answer": "Several inference modes are available:\n\n- **single**: One query at a time (default)\n- **batch**: Process a file of queries\n- **interactive**: REPL for testing multiple queries\n- **server**: HTTP API endpoint for integration\n\nUse `--help` to see all options:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py --help\n```\n\nChoose the mode that best fits your workflow. See skill_semantic_inference.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_semantic_inference_005_q1", "cluster_id": "skill_semantic_inference_005", "question": "How do I use interactive inference?", "answer": "Use interactive inference by running the inference script without the `--query` parameter. This enters a REPL mode for testing queries interactively. Type queries at the prompt and see results immediately. Exit with `quit` or Ctrl+D.", "question_type": "medium", "topics": ["Quickstart", "Semantic Inference"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["inference", "modes", "workflow", "api"], "related_skills": ["skill_semantic_inference.md", "skill_train_model.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "education/book-13-semantic-search/06_distributed_search.md"], "original_answer": "Several inference modes are available:\n\n- **single**: One query at a time (default)\n- **batch**: Process a file of queries\n- **interactive**: REPL for testing multiple queries\n- **server**: HTTP API endpoint for integration\n\nUse `--help` to see all options:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py --help\n```\n\nChoose the mode that best fits your workflow. See skill_semantic_inference.md for details.", "answer_tailored": true, "confidence": 0.8, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_semantic_inference_005_q2", "cluster_id": "skill_semantic_inference_005", "question": "Can I run inference as an API?", "answer": "Yes, you can run inference as an API using the **server** mode. The inference script supports multiple modes including a server mode that provides an HTTP API endpoint for integration. Use `python3 scripts/infer_pearltrees_federated.py --help` to see all available options and configuration details for running the API server.", "question_type": "medium", "topics": ["Quickstart", "Semantic Inference"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["inference", "modes", "workflow", "api"], "related_skills": ["skill_semantic_inference.md", "skill_train_model.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "education/book-13-semantic-search/06_distributed_search.md"], "original_answer": "Several inference modes are available:\n\n- **single**: One query at a time (default)\n- **batch**: Process a file of queries\n- **interactive**: REPL for testing multiple queries\n- **server**: HTTP API endpoint for integration\n\nUse `--help` to see all options:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py --help\n```\n\nChoose the mode that best fits your workflow. See skill_semantic_inference.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_semantic_inference_005_q3", "cluster_id": "skill_semantic_inference_005", "question": "What are the different ways to run inference?", "answer": "UnifyWeaver supports four inference modes for running semantic search and predictions:\n\n1. **single** - Run one query at a time (default mode)\n2. **batch** - Process multiple queries from a file using `--input queries.txt --output results.jsonl`\n3. **interactive** - REPL mode for testing multiple queries iteratively\n4. **server** - HTTP API endpoint for integrating inference into applications\n\nUse the single mode for quick one-off queries:\n```bash\npython3 scripts/infer_pearltrees_federated.py --model models/pearltrees_federated.pkl --query \"your query\"\n```\n\nUse batch mode for processing many queries at once:\n```bash\npython3 scripts/infer_pearltrees_federated.py --model models/pearltrees_federated.pkl --input queries.txt --output results.jsonl\n```\n\nRun `--help` to see all available options and parameters for each mode.", "question_type": "medium", "topics": ["Quickstart", "Semantic Inference"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["inference", "modes", "workflow", "api"], "related_skills": ["skill_semantic_inference.md", "skill_train_model.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md", "education/book-13-semantic-search/06_distributed_search.md"], "original_answer": "Several inference modes are available:\n\n- **single**: One query at a time (default)\n- **batch**: Process a file of queries\n- **interactive**: REPL for testing multiple queries\n- **server**: HTTP API endpoint for integration\n\nUse `--help` to see all options:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py --help\n```\n\nChoose the mode that best fits your workflow. See skill_semantic_inference.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_semantic_inference_006_q0", "cluster_id": "skill_semantic_inference_006", "question": "How do I set the similarity threshold for results?", "answer": "Use the `--threshold` parameter when running inference to set the minimum similarity score for results:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --query \"quantum computing\" \\\n  --threshold 0.75\n```\n\nOnly results scoring 0.75 or higher will be returned. The default threshold is 0.0 (no filtering). You can combine this with `--top-k` to both filter by score and limit the number of results returned.", "question_type": "long", "topics": ["Quickstart", "Semantic Inference"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["threshold", "filtering", "scoring", "quality"], "related_skills": ["skill_semantic_inference.md", "skill_density_explorer.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "education/book-13-semantic-search/07_density_scoring.md"], "original_answer": "Use the `--threshold` parameter to filter results by minimum similarity score:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --query \"quantum computing\" \\\n  --threshold 0.75\n```\n\nOnly results with scores of 0.75 or higher will be returned. Combine with `--top-k` to limit result count. Default threshold is 0.0 (no filtering). See skill_semantic_inference.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_semantic_inference_006_q1", "cluster_id": "skill_semantic_inference_006", "question": "How do I filter results by minimum score?", "answer": "Use the `--threshold` parameter to filter results by minimum similarity score:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --query \"quantum computing\" \\\n  --threshold 0.75\n```\n\nOnly results with scores of 0.75 or higher will be returned. The default threshold is 0.0 (no filtering). You can combine this with `--top-k` to also limit the number of results returned.", "question_type": "long", "topics": ["Quickstart", "Semantic Inference"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["threshold", "filtering", "scoring", "quality"], "related_skills": ["skill_semantic_inference.md", "skill_density_explorer.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "education/book-13-semantic-search/07_density_scoring.md"], "original_answer": "Use the `--threshold` parameter to filter results by minimum similarity score:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --query \"quantum computing\" \\\n  --threshold 0.75\n```\n\nOnly results with scores of 0.75 or higher will be returned. Combine with `--top-k` to limit result count. Default threshold is 0.0 (no filtering). See skill_semantic_inference.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_semantic_inference_006_q2", "cluster_id": "skill_semantic_inference_006", "question": "Can I only get high-confidence results?", "answer": "Yes, use the `--threshold` parameter to filter for high-confidence results:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --query \"quantum computing\" \\\n  --threshold 0.75\n```\n\nThis returns only results with similarity scores of 0.75 or higher. Adjust the threshold value based on your confidence requirements (0.0-1.0). You can combine it with `--top-k` to further limit the number of results returned.", "question_type": "long", "topics": ["Quickstart", "Semantic Inference"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["threshold", "filtering", "scoring", "quality"], "related_skills": ["skill_semantic_inference.md", "skill_density_explorer.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "education/book-13-semantic-search/07_density_scoring.md"], "original_answer": "Use the `--threshold` parameter to filter results by minimum similarity score:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --query \"quantum computing\" \\\n  --threshold 0.75\n```\n\nOnly results with scores of 0.75 or higher will be returned. Combine with `--top-k` to limit result count. Default threshold is 0.0 (no filtering). See skill_semantic_inference.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_semantic_inference_006_q3", "cluster_id": "skill_semantic_inference_006", "question": "How do I control result quality?", "answer": "Use the `--threshold` parameter to filter results by minimum similarity score. This ensures only results meeting your quality bar are returned:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --query \"quantum computing\" \\\n  --threshold 0.75\n```\n\nOnly results scoring 0.75 or higher will be included. You can also combine `--threshold` with `--top-k` to both filter by quality and limit result count. The default threshold is 0.0 (no filtering). Lower thresholds return more results but may include lower-quality matches; higher thresholds are more selective.", "question_type": "long", "topics": ["Quickstart", "Semantic Inference"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["threshold", "filtering", "scoring", "quality"], "related_skills": ["skill_semantic_inference.md", "skill_density_explorer.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "education/book-13-semantic-search/07_density_scoring.md"], "original_answer": "Use the `--threshold` parameter to filter results by minimum similarity score:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --query \"quantum computing\" \\\n  --threshold 0.75\n```\n\nOnly results with scores of 0.75 or higher will be returned. Combine with `--top-k` to limit result count. Default threshold is 0.0 (no filtering). See skill_semantic_inference.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_server_tools_001_q0", "cluster_id": "skill_server_tools_001", "question": "How do I create a backend API?", "answer": "To create a backend API in UnifyWeaver, use Flask for simple REST APIs or FastAPI for async APIs with automatic documentation. Call `generate_flask_app([endpoint1, endpoint2], [app_name('YourAPI')], Code)` in Prolog to generate a Flask app, or `generate_fastapi_app([endpoint1, endpoint2], [app_name('YourAPI')], Code)` for FastAPI. For Node.js, use Express with `generate_express_router(api_name, [endpoints([your_endpoints])], Code)`. All three frameworks integrate with UnifyWeaver's code generation system and support inter-process communication patterns for Prolog-Python service connections.", "question_type": "medium", "topics": ["Quickstart", "Server Tools (Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["web-api", "backend", "flask", "fastapi", "express"], "related_skills": ["skill_server_tools.md", "skill_web_frameworks.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl", "src/unifyweaver/glue/fastapi_generator.pl", "src/unifyweaver/glue/express_generator.pl"], "original_answer": "UnifyWeaver can generate backend APIs using Flask, FastAPI, or Express.js. For Python, use Flask for simple routes or FastAPI for async APIs with automatic documentation. For Node.js, use Express with integrated security. Example: In Prolog, call `generate_flask_app([fetch_tasks, create_task], [app_name('TaskAPI')], Code)` to generate a Flask app. See skill_server_tools.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_server_tools_001_q1", "cluster_id": "skill_server_tools_001", "question": "How do I set up a web API for my application?", "answer": "UnifyWeaver generates backend APIs using Flask, FastAPI, or Express.js. For Python, use Flask for simple REST routes or FastAPI for async APIs with automatic Swagger documentation. For Node.js, use Express with built-in security. To set up a Flask API in Prolog, call `generate_flask_app([your_endpoints], [app_name('YourAPI')], Code)` to generate the application code. FastAPI setup uses `generate_fastapi_app([your_endpoints], [app_name('YourAPI')], Code)` with Pydantic models. Express setup uses `generate_express_router(api_name, [endpoints([your_endpoints])], Code)`. Refer to skill_flask_api.md, skill_fastapi.md, or skill_express_api.md for framework-specific details.", "question_type": "medium", "topics": ["Quickstart", "Server Tools (Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["web-api", "backend", "flask", "fastapi", "express"], "related_skills": ["skill_server_tools.md", "skill_web_frameworks.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl", "src/unifyweaver/glue/fastapi_generator.pl", "src/unifyweaver/glue/express_generator.pl"], "original_answer": "UnifyWeaver can generate backend APIs using Flask, FastAPI, or Express.js. For Python, use Flask for simple routes or FastAPI for async APIs with automatic documentation. For Node.js, use Express with integrated security. Example: In Prolog, call `generate_flask_app([fetch_tasks, create_task], [app_name('TaskAPI')], Code)` to generate a Flask app. See skill_server_tools.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_server_tools_001_q2", "cluster_id": "skill_server_tools_001", "question": "What's the best way to build a REST API backend?", "answer": "UnifyWeaver provides three main options for building REST APIs: Flask for simple, synchronous APIs; FastAPI for async APIs with automatic documentation and validation; or Express.js for Node.js backends. Choose based on your language preference and performance needs. In Prolog, use `generate_flask_app([endpoint_list], [app_name('YourAPI')], Code)` to generate a Flask app, or `generate_fastapi_app([endpoint_list], [app_name('YourAPI')], Code)` for FastAPI with Pydantic models. See skill_server_tools.md and its sub-masters (skill_web_frameworks.md, skill_flask_api.md, skill_fastapi.md) for framework-specific details and deployment guidance.", "question_type": "medium", "topics": ["Quickstart", "Server Tools (Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["web-api", "backend", "flask", "fastapi", "express"], "related_skills": ["skill_server_tools.md", "skill_web_frameworks.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl", "src/unifyweaver/glue/fastapi_generator.pl", "src/unifyweaver/glue/express_generator.pl"], "original_answer": "UnifyWeaver can generate backend APIs using Flask, FastAPI, or Express.js. For Python, use Flask for simple routes or FastAPI for async APIs with automatic documentation. For Node.js, use Express with integrated security. Example: In Prolog, call `generate_flask_app([fetch_tasks, create_task], [app_name('TaskAPI')], Code)` to generate a Flask app. See skill_server_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_server_tools_002_q0", "cluster_id": "skill_server_tools_002", "question": "How do I connect Prolog to Python services?", "answer": "UnifyWeaver provides two main approaches to connect Prolog to Python services. First, use Remote Python Call (RPyC) for network-based communication: establish a connection with `rpyc_connect('localhost', [port(18812), security(ssh)], Proxy)`, then execute Python functions with `rpyc_call(Proxy, numpy, mean, [[1,2,3,4,5]], Result)`. Second, use Python Bridges for direct cross-runtime embedding in .NET, JVM, Rust, or Ruby environments via auto-selection with `auto_select_bridge(RuntimeEnv, Preferences, Bridge)`. Choose RPyC for remote services and Python Bridges for embedded Python within your Prolog application.", "question_type": "medium", "topics": ["Quickstart", "Server Tools (Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["prolog", "python", "rpyc", "inter-process-communication", "bridges"], "related_skills": ["skill_server_tools.md", "skill_ipc.md"], "related_docs": ["src/unifyweaver/glue/rpyc_glue.pl", "src/unifyweaver/glue/python_bridges_glue.pl"], "original_answer": "UnifyWeaver provides two main approaches: Remote Python Call (RPyC) for network-based Python RPC, or Python Bridges for cross-runtime embedding. Use RPyC to connect to a Python service over the network with optional SSH security. Example: `rpyc_connect('localhost', [port(18812), security(ssh)], Proxy)` then `rpyc_call(Proxy, numpy, mean, [[1,2,3,4,5]], Result)`. Use Python Bridges for direct embedding in .NET, JVM, Rust, or Ruby environments. See skill_server_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_server_tools_002_q1", "cluster_id": "skill_server_tools_002", "question": "How can I make Prolog call Python code?", "answer": "UnifyWeaver provides two main approaches for Prolog to call Python code: Remote Python Call (RPyC) for network-based RPC, or Python Bridges for cross-runtime embedding. For RPyC, connect to a Python service using `rpyc_connect('localhost', [port(18812), security(ssh)], Proxy)` then execute functions with `rpyc_call(Proxy, module_name, function_name, [args], Result)`. For direct embedding, use Python Bridges which support .NET, JVM, Rust, and Ruby environments. RPyC is best for separate services; Python Bridges for in-process integration.", "question_type": "medium", "topics": ["Quickstart", "Server Tools (Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["prolog", "python", "rpyc", "inter-process-communication", "bridges"], "related_skills": ["skill_server_tools.md", "skill_ipc.md"], "related_docs": ["src/unifyweaver/glue/rpyc_glue.pl", "src/unifyweaver/glue/python_bridges_glue.pl"], "original_answer": "UnifyWeaver provides two main approaches: Remote Python Call (RPyC) for network-based Python RPC, or Python Bridges for cross-runtime embedding. Use RPyC to connect to a Python service over the network with optional SSH security. Example: `rpyc_connect('localhost', [port(18812), security(ssh)], Proxy)` then `rpyc_call(Proxy, numpy, mean, [[1,2,3,4,5]], Result)`. Use Python Bridges for direct embedding in .NET, JVM, Rust, or Ruby environments. See skill_server_tools.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "Base answer mentions skill references rather than concrete implementation paths; unclear which approach is recommended for typical use cases"}
{"pair_id": "skill_server_tools_002_q2", "cluster_id": "skill_server_tools_002", "question": "What are the ways to integrate Prolog with Python backends?", "answer": "UnifyWeaver provides two primary methods for Prolog-Python integration: (1) Remote Python Call (RPyC) for network-based RPC, enabling Prolog to call Python services over the network with optional SSH security using `rpyc_connect('localhost', [port(18812), security(ssh)], Proxy)` followed by `rpyc_call(Proxy, module, function, [args], Result)`, and (2) Python Bridges for direct cross-runtime embedding in .NET, JVM, Rust, or Ruby environments. RPyC is suitable for distributed architectures, while Python Bridges enable tighter integration within a single process. Consult skill_rpyc.md and skill_python_bridges.md for implementation details.", "question_type": "medium", "topics": ["Quickstart", "Server Tools (Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["prolog", "python", "rpyc", "inter-process-communication", "bridges"], "related_skills": ["skill_server_tools.md", "skill_ipc.md"], "related_docs": ["src/unifyweaver/glue/rpyc_glue.pl", "src/unifyweaver/glue/python_bridges_glue.pl"], "original_answer": "UnifyWeaver provides two main approaches: Remote Python Call (RPyC) for network-based Python RPC, or Python Bridges for cross-runtime embedding. Use RPyC to connect to a Python service over the network with optional SSH security. Example: `rpyc_connect('localhost', [port(18812), security(ssh)], Proxy)` then `rpyc_call(Proxy, numpy, mean, [[1,2,3,4,5]], Result)`. Use Python Bridges for direct embedding in .NET, JVM, Rust, or Ruby environments. See skill_server_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_server_tools_003_q0", "cluster_id": "skill_server_tools_003", "question": "How do I set up inter-process communication between applications?", "answer": "UnifyWeaver provides three IPC patterns for inter-process communication: (1) Pipe communication using TSV/JSON for Unix pipeline integration across awk, python, bash, go, and rust - use `generate_pipe_writer()` and `generate_pipe_reader()` to create data handlers; (2) RPyC for Python-to-Python network RPC via `rpyc_connect()` and `rpyc_call()`; (3) Python Bridges for cross-runtime embedding with `auto_select_bridge()`. Choose pipes for simple data flows between processes, RPyC for remote Python service calls, and bridges for embedding runtimes within applications.", "question_type": "medium", "topics": ["Quickstart", "Server Tools (Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["ipc", "pipes", "communication", "unix-pipeline", "data-flow"], "related_skills": ["skill_server_tools.md", "skill_ipc.md"], "related_docs": ["src/unifyweaver/glue/pipe_glue.pl", "src/unifyweaver/glue/rpyc_glue.pl", "src/unifyweaver/glue/python_bridges_glue.pl"], "original_answer": "UnifyWeaver supports three IPC patterns: Pipe communication (TSV/JSON) for Unix pipeline integration across awk, python, bash, go, rust; RPyC for Python-to-Python network RPC; and Python Bridges for cross-runtime embedding. For pipes, use `generate_pipe_writer(python, [name, age, score], [], WriterCode)` to generate data writers. Choose pipes for simple data flows, RPyC for network Python calls, and bridges for embedded runtimes. See skill_server_tools.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_server_tools_003_q1", "cluster_id": "skill_server_tools_003", "question": "What's the best way to have different processes communicate?", "answer": "UnifyWeaver supports three main IPC patterns for inter-process communication: (1) Pipe communication using TSV/JSON format for Unix pipeline integration across awk, python, bash, go, and rust - best for simple data flows; (2) RPyC (Remote Python Call) for Python-to-Python network RPC over TCP/IP; (3) Python Bridges for embedding different runtimes within a single process. Choose pipes for straightforward data pipelines, RPyC when you need network-based Python service calls, and bridges when embedding multiple language runtimes. Generate pipe writers with `generate_pipe_writer(python, [name, age, score], [], WriterCode)` and establish RPyC connections with `rpyc_connect('localhost', [port(18812), security(ssh)], Proxy)`.", "question_type": "medium", "topics": ["Quickstart", "Server Tools (Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["ipc", "pipes", "communication", "unix-pipeline", "data-flow"], "related_skills": ["skill_server_tools.md", "skill_ipc.md"], "related_docs": ["src/unifyweaver/glue/pipe_glue.pl", "src/unifyweaver/glue/rpyc_glue.pl", "src/unifyweaver/glue/python_bridges_glue.pl"], "original_answer": "UnifyWeaver supports three IPC patterns: Pipe communication (TSV/JSON) for Unix pipeline integration across awk, python, bash, go, rust; RPyC for Python-to-Python network RPC; and Python Bridges for cross-runtime embedding. For pipes, use `generate_pipe_writer(python, [name, age, score], [], WriterCode)` to generate data writers. Choose pipes for simple data flows, RPyC for network Python calls, and bridges for embedded runtimes. See skill_server_tools.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_server_tools_003_q2", "cluster_id": "skill_server_tools_003", "question": "How do I implement pipe-based communication?", "answer": "To implement pipe-based communication in UnifyWeaver, use the `generate_pipe_writer` and `generate_pipe_reader` functions from the pipe_glue module. For example, generate a Python pipe writer with `generate_pipe_writer(python, [name, age, score], [], WriterCode)` to output TSV/JSON formatted data. Similarly, use `generate_pipe_reader(awk, [name, age, score], [], ReaderCode)` to read piped data in other languages. Pipes integrate seamlessly across awk, python, bash, go, and rust for Unix pipeline workflows. Use pipes when you need simple, language-agnostic data flows between processes.", "question_type": "medium", "topics": ["Quickstart", "Server Tools (Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["ipc", "pipes", "communication", "unix-pipeline", "data-flow"], "related_skills": ["skill_server_tools.md", "skill_ipc.md"], "related_docs": ["src/unifyweaver/glue/pipe_glue.pl", "src/unifyweaver/glue/rpyc_glue.pl", "src/unifyweaver/glue/python_bridges_glue.pl"], "original_answer": "UnifyWeaver supports three IPC patterns: Pipe communication (TSV/JSON) for Unix pipeline integration across awk, python, bash, go, rust; RPyC for Python-to-Python network RPC; and Python Bridges for cross-runtime embedding. For pipes, use `generate_pipe_writer(python, [name, age, score], [], WriterCode)` to generate data writers. Choose pipes for simple data flows, RPyC for network Python calls, and bridges for embedded runtimes. See skill_server_tools.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer mentions three IPC patterns but the question asks specifically about pipes. The tailored answer focuses on pipes while briefly acknowledging context about RPyC and bridges. Confidence is slightly reduced because the actual API details (parameter meanings, return formats) aren't fully specified in the base answer."}
{"pair_id": "skill_server_tools_004_q0", "cluster_id": "skill_server_tools_004", "question": "How do I deploy and manage backend services?", "answer": "To deploy and manage backend services, UnifyWeaver provides code generation for multiple deployment targets. Declare your service using `declare_service(my_api, [host('server.example.com'), port(8080), target(python)])`, then generate deployment configurations with `generate_docker_compose(my_project, [], ComposeYaml)` for Docker or `generate_k8s_deployment(my_api, [], Manifest)` for Kubernetes. You can also target serverless platforms like AWS Lambda, Google Cloud Functions, and Azure Functions. Manage secrets securely through Vault, AWS Secrets Manager, or Azure Key Vault. Reference skill_server_tools.md for complete deployment options and infrastructure management patterns.", "question_type": "medium", "topics": ["Quickstart", "Server Tools (Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["deployment", "docker", "kubernetes", "cloud-functions", "infrastructure"], "related_skills": ["skill_server_tools.md", "skill_infrastructure.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "UnifyWeaver can generate deployment configurations for Docker, Kubernetes, AWS Lambda, Google Cloud Functions, and Azure Functions. Declare your service with `declare_service(my_api, [host('server.example.com'), port(8080), target(python)])`, then generate Docker Compose with `generate_docker_compose(my_project, [], ComposeYaml)` or Kubernetes manifests with `generate_k8s_deployment(my_api, [], Manifest)`. You can also manage secrets through Vault, AWS Secrets Manager, or Azure Key Vault. See skill_server_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_server_tools_004_q1", "cluster_id": "skill_server_tools_004", "question": "What options do I have for deploying applications?", "answer": "UnifyWeaver provides multiple deployment options through its glue modules. You can generate Docker Compose configurations with `generate_docker_compose(my_project, [], ComposeYaml)` for containerized deployments, or Kubernetes manifests with `generate_k8s_deployment(my_api, [], Manifest)` for orchestrated environments. For serverless deployments, UnifyWeaver supports AWS Lambda, Google Cloud Functions, and Azure Functions. First declare your service using `declare_service(my_api, [host('server.example.com'), port(8080), target(python)])`, then generate the appropriate deployment configuration. Secret management is handled through Vault, AWS Secrets Manager, or Azure Key Vault. Refer to skill_deployment.md for detailed deployment strategies.", "question_type": "medium", "topics": ["Quickstart", "Server Tools (Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["deployment", "docker", "kubernetes", "cloud-functions", "infrastructure"], "related_skills": ["skill_server_tools.md", "skill_infrastructure.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "UnifyWeaver can generate deployment configurations for Docker, Kubernetes, AWS Lambda, Google Cloud Functions, and Azure Functions. Declare your service with `declare_service(my_api, [host('server.example.com'), port(8080), target(python)])`, then generate Docker Compose with `generate_docker_compose(my_project, [], ComposeYaml)` or Kubernetes manifests with `generate_k8s_deployment(my_api, [], Manifest)`. You can also manage secrets through Vault, AWS Secrets Manager, or Azure Key Vault. See skill_server_tools.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer references 'skill_server_tools.md for details' but the actual module documentation appears to be in 'skill_deployment.md'. The base answer is accurate but could be clearer about the workflow (declare service first, then generate config)."}
{"pair_id": "skill_server_tools_004_q2", "cluster_id": "skill_server_tools_004", "question": "How do I containerize and deploy my services?", "answer": "To containerize and deploy your services with UnifyWeaver, use the deployment generation tools. Declare your service with `declare_service(my_api, [host('server.example.com'), port(8080), target(python)])`, then generate deployment configurations: Docker Compose with `generate_docker_compose(my_project, [], ComposeYaml)` for local multi-container setups, or Kubernetes manifests with `generate_k8s_deployment(my_api, [], Manifest)` for orchestrated deployments. UnifyWeaver supports containerization for Docker, Kubernetes, AWS Lambda, Google Cloud Functions, and Azure Functions. Manage sensitive configuration through Vault, AWS Secrets Manager, or Azure Key Vault. Refer to skill_deployment.md for platform-specific configuration details.", "question_type": "medium", "topics": ["Quickstart", "Server Tools (Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["deployment", "docker", "kubernetes", "cloud-functions", "infrastructure"], "related_skills": ["skill_server_tools.md", "skill_infrastructure.md"], "related_docs": ["src/unifyweaver/glue/deployment_glue.pl"], "original_answer": "UnifyWeaver can generate deployment configurations for Docker, Kubernetes, AWS Lambda, Google Cloud Functions, and Azure Functions. Declare your service with `declare_service(my_api, [host('server.example.com'), port(8080), target(python)])`, then generate Docker Compose with `generate_docker_compose(my_project, [], ComposeYaml)` or Kubernetes manifests with `generate_k8s_deployment(my_api, [], Manifest)`. You can also manage secrets through Vault, AWS Secrets Manager, or Azure Key Vault. See skill_server_tools.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_server_tools_005_q0", "cluster_id": "skill_server_tools_005", "question": "How do I add authentication to my API?", "answer": "UnifyWeaver provides multiple authentication backends for APIs: mock, text file, SQLite, PostgreSQL, MongoDB, LDAP, and OAuth2. Configure authentication by specifying a backend, password hashing method (bcrypt), and token type (JWT) in your app specification: `app(my_app, [auth([backend(text_file), password_hash(bcrypt), token_type(jwt)])])`. For simple applications, use text file or SQLite backends. For production systems, use PostgreSQL or MongoDB. For social login integration, use OAuth2. Generate a complete authentication server using `generate_auth_server(AppSpec, node, Files)` which handles token generation, validation, and user management.", "question_type": "medium", "topics": ["Quickstart", "Server Tools (Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["authentication", "auth", "security", "jwt", "oauth2", "bcrypt"], "related_skills": ["skill_server_tools.md", "skill_infrastructure.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "UnifyWeaver supports multiple authentication backends including mock, text file, SQLite, PostgreSQL, MongoDB, LDAP, and OAuth2. Configure authentication with password hashing (bcrypt) and token types (JWT). Example: `app(my_app, [auth([backend(text_file), password_hash(bcrypt), token_type(jwt)])])`. Generate a complete auth server with `generate_auth_server(AppSpec, node, Files)`. Choose text file or SQLite for simple apps, PostgreSQL/MongoDB for production, and OAuth2 for social login. See skill_server_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_server_tools_005_q1", "cluster_id": "skill_server_tools_005", "question": "How do I secure my backend with user authentication?", "answer": "To secure your backend with user authentication, UnifyWeaver provides multiple authentication backends: mock (testing), text file (simple apps), SQLite (small deployments), PostgreSQL/MongoDB (production), LDAP (enterprise), and OAuth2 (social login). Configure authentication in your app specification with password hashing (bcrypt recommended) and token type (JWT). Example: `app(my_app, [auth([backend(text_file), password_hash(bcrypt), token_type(jwt)])])`. Use `generate_auth_server(AppSpec, node, Files)` to generate a complete authentication server. For development, start with text file or SQLite backends; migrate to PostgreSQL/MongoDB for production systems; use OAuth2 for third-party social login integration.", "question_type": "medium", "topics": ["Quickstart", "Server Tools (Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["authentication", "auth", "security", "jwt", "oauth2", "bcrypt"], "related_skills": ["skill_server_tools.md", "skill_infrastructure.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "UnifyWeaver supports multiple authentication backends including mock, text file, SQLite, PostgreSQL, MongoDB, LDAP, and OAuth2. Configure authentication with password hashing (bcrypt) and token types (JWT). Example: `app(my_app, [auth([backend(text_file), password_hash(bcrypt), token_type(jwt)])])`. Generate a complete auth server with `generate_auth_server(AppSpec, node, Files)`. Choose text file or SQLite for simple apps, PostgreSQL/MongoDB for production, and OAuth2 for social login. See skill_server_tools.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_server_tools_005_q2", "cluster_id": "skill_server_tools_005", "question": "What authentication options are available for my services?", "answer": "UnifyWeaver offers several authentication backends: mock (testing), text file (simple apps), SQLite (small deployments), PostgreSQL/MongoDB (production), LDAP (enterprise), and OAuth2 (social login). Configure with `app(my_app, [auth([backend(text_file), password_hash(bcrypt), token_type(jwt)])])`. Use password hashing (bcrypt) and choose JWT tokens. For complete setup, call `generate_auth_server(AppSpec, node, Files)`. Select text file or SQLite for development, PostgreSQL/MongoDB for production, and OAuth2 for third-party integrations.", "question_type": "medium", "topics": ["Quickstart", "Server Tools (Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["authentication", "auth", "security", "jwt", "oauth2", "bcrypt"], "related_skills": ["skill_server_tools.md", "skill_infrastructure.md"], "related_docs": ["src/unifyweaver/glue/auth_backends.pl"], "original_answer": "UnifyWeaver supports multiple authentication backends including mock, text file, SQLite, PostgreSQL, MongoDB, LDAP, and OAuth2. Configure authentication with password hashing (bcrypt) and token types (JWT). Example: `app(my_app, [auth([backend(text_file), password_hash(bcrypt), token_type(jwt)])])`. Generate a complete auth server with `generate_auth_server(AppSpec, node, Files)`. Choose text file or SQLite for simple apps, PostgreSQL/MongoDB for production, and OAuth2 for social login. See skill_server_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_server_tools_006_q0", "cluster_id": "skill_server_tools_006", "question": "How do I create HTTP servers and clients?", "answer": "UnifyWeaver can generate HTTP servers and clients across multiple languages. For servers, use `generate_http_server(Language, Endpoints, [port(Port), cors(true)], ServerCode)` where Language is go, python, node, or rust. For clients, use `generate_http_client(Language, Services, [timeout(Seconds)], ClientCode)` to generate clients with configurable timeouts. Both generators produce complete boilerplate code with error handling and configuration options ready to deploy.", "question_type": "medium", "topics": ["Quickstart", "Server Tools (Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["http", "networking", "server", "client", "web-communication"], "related_skills": ["skill_server_tools.md", "skill_infrastructure.md"], "related_docs": ["src/unifyweaver/glue/network_glue.pl"], "original_answer": "UnifyWeaver can generate HTTP servers and clients in multiple languages. For servers, use `generate_http_server(go, Endpoints, [port(8080), cors(true)], ServerCode)` to create a Go server with CORS enabled. For clients, use `generate_http_client(python, Services, [timeout(30)], ClientCode)` to generate a Python client with timeout configuration. Specify your target language (go, python, node, rust) and UnifyWeaver will generate the appropriate boilerplate with error handling and configuration. See skill_server_tools.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "Base answer provides specific function signatures but lacks information about what Endpoints and Services parameters should contain, and doesn't explain how to configure or extend the generated servers/clients beyond basic options shown."}
{"pair_id": "skill_server_tools_006_q1", "cluster_id": "skill_server_tools_006", "question": "How do I generate network communication code?", "answer": "UnifyWeaver generates network communication code through its glue modules. For HTTP servers, use `generate_http_server(Language, Endpoints, Options, Code)` where Language is go, python, node, or rust - this creates server boilerplate with CORS, port configuration, and error handling. For HTTP clients, use `generate_http_client(Language, Services, Options, Code)` to generate client code with configurable timeouts and retries. For inter-process communication, use pipe-based protocols with `generate_pipe_writer()` and `generate_pipe_reader()` for TSV/JSON data exchange, or RPyC for remote Python calls via `rpyc_connect()` and `rpyc_call()`. Choose based on your communication pattern: HTTP for external APIs, pipes for local process coordination, and RPyC for Python service networking.", "question_type": "medium", "topics": ["Quickstart", "Server Tools (Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["http", "networking", "server", "client", "web-communication"], "related_skills": ["skill_server_tools.md", "skill_infrastructure.md"], "related_docs": ["src/unifyweaver/glue/network_glue.pl"], "original_answer": "UnifyWeaver can generate HTTP servers and clients in multiple languages. For servers, use `generate_http_server(go, Endpoints, [port(8080), cors(true)], ServerCode)` to create a Go server with CORS enabled. For clients, use `generate_http_client(python, Services, [timeout(30)], ClientCode)` to generate a Python client with timeout configuration. Specify your target language (go, python, node, rust) and UnifyWeaver will generate the appropriate boilerplate with error handling and configuration. See skill_server_tools.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer explicitly documents HTTP server/client generation but omits mention of pipe-based and RPyC communication methods that are also relevant to network communication code generation. The tailored answer adds these omitted methods for completeness, though the base answer's focus on HTTP is reasonable for 'network communication.'"}
{"pair_id": "skill_server_tools_006_q2", "cluster_id": "skill_server_tools_006", "question": "What's the easiest way to set up HTTP endpoints?", "answer": "The easiest way to set up HTTP endpoints is to use UnifyWeaver's code generators. For a server, use `generate_http_server(Language, Endpoints, Options, ServerCode)` where Language can be go, python, node, or rust. For example: `generate_http_server(python, [get_users, create_user], [port(8080), cors(true)], ServerCode)` generates a Python server with CORS enabled. For clients, use `generate_http_client(Language, Services, Options, ClientCode)`. These generators create boilerplate with built-in error handling and configuration, eliminating manual setup.", "question_type": "medium", "topics": ["Quickstart", "Server Tools (Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["http", "networking", "server", "client", "web-communication"], "related_skills": ["skill_server_tools.md", "skill_infrastructure.md"], "related_docs": ["src/unifyweaver/glue/network_glue.pl"], "original_answer": "UnifyWeaver can generate HTTP servers and clients in multiple languages. For servers, use `generate_http_server(go, Endpoints, [port(8080), cors(true)], ServerCode)` to create a Go server with CORS enabled. For clients, use `generate_http_client(python, Services, [timeout(30)], ClientCode)` to generate a Python client with timeout configuration. Specify your target language (go, python, node, rust) and UnifyWeaver will generate the appropriate boilerplate with error handling and configuration. See skill_server_tools.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "Base answer mentions specific Prolog predicates but the skill document shows different patterns (e.g., `generate_flask_app`, `generate_fastapi_app`, `generate_express_router`). The generic `generate_http_server` predicate in the base answer may not match actual UnifyWeaver API. Answer hedges by using the base answer's predicates but the confidence is reduced due to this inconsistency with the skill document examples."}
{"pair_id": "skill_sql_target_001_q0", "cluster_id": "skill_sql_target_001", "question": "How do I generate SQL views from Prolog predicates?", "answer": "To generate SQL views from Prolog predicates, use the SQL Target skill. First, load the module and define your table schema with `sql_table/2`. Then define your Prolog predicate and compile it to SQL:\n\n```prolog\n:- use_module('src/unifyweaver/targets/sql_target').\n:- sql_table(employee, [name-text, dept-text, salary-integer]).\n\nhigh_earner(Name, Dept) :- \n    employee(Name, Dept, Salary), \n    Salary > 100000.\n\n?- compile_predicate_to_sql(high_earner/2, [dialect(sqlite)], SQL).\n```\n\nThis generates a CREATE VIEW statement:\n\n```sql\nCREATE VIEW IF NOT EXISTS high_earner AS\nSELECT employee.name, employee.dept\nFROM employee\nWHERE employee.salary > 100000;\n```\n\nYou can specify different database dialects (SQLite, PostgreSQL, MySQL) using the `dialect/1` option, and control output format with `format(view)` for views, `format(cte)` for CTEs, or `format(select)` for standalone SELECT statements.", "question_type": "medium", "topics": ["Quickstart", "SQL Target"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sql", "prolog", "compilation", "views"], "related_skills": ["skill_sql_target.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl", "education/book-10-sql-target/"], "original_answer": "Use the SQL Target skill to compile Prolog predicates to SQL CREATE VIEW statements. Load the module, define your table schema with `sql_table/2`, then compile your predicate:\n\n```prolog\n:- use_module('src/unifyweaver/targets/sql_target').\n:- sql_table(employee, [name-text, dept-text, salary-integer]).\nhigh_earner(Name, Dept) :- employee(Name, Dept, Salary), Salary > 100000.\n?- compile_predicate_to_sql(high_earner/2, [dialect(sqlite)], SQL).\n```\n\nSupports SQLite (default), PostgreSQL, and MySQL dialects. See skill_sql_target.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_sql_target_001_q1", "cluster_id": "skill_sql_target_001", "question": "Can I compile Prolog rules to SQL?", "answer": "Yes, use the SQL Target skill to compile Prolog rules to SQL. Load the module with `use_module('src/unifyweaver/targets/sql_target')`, define your table schema using `sql_table/2`, write your Prolog rule, then call `compile_predicate_to_sql/3` to generate a CREATE VIEW statement. For example: `compile_predicate_to_sql(high_earner/2, [dialect(sqlite)], SQL)` converts a rule like `high_earner(Name, Dept) :- employee(Name, Dept, Salary), Salary > 100000.` into SQL. Supports SQLite, PostgreSQL, and MySQL dialects, plus various output formats (views, CTEs, SELECT statements).", "question_type": "medium", "topics": ["Quickstart", "SQL Target"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sql", "prolog", "compilation", "views"], "related_skills": ["skill_sql_target.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl", "education/book-10-sql-target/"], "original_answer": "Use the SQL Target skill to compile Prolog predicates to SQL CREATE VIEW statements. Load the module, define your table schema with `sql_table/2`, then compile your predicate:\n\n```prolog\n:- use_module('src/unifyweaver/targets/sql_target').\n:- sql_table(employee, [name-text, dept-text, salary-integer]).\nhigh_earner(Name, Dept) :- employee(Name, Dept, Salary), Salary > 100000.\n?- compile_predicate_to_sql(high_earner/2, [dialect(sqlite)], SQL).\n```\n\nSupports SQLite (default), PostgreSQL, and MySQL dialects. See skill_sql_target.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_sql_target_001_q2", "cluster_id": "skill_sql_target_001", "question": "How do I create database views from Prolog?", "answer": "Use the SQL Target skill to compile Prolog predicates to SQL CREATE VIEW statements. Load the module with `use_module('src/unifyweaver/targets/sql_target')`, define your table schema using `sql_table/2`, define your predicate, then call `compile_predicate_to_sql/3` with `format(view)` option (the default). For example:\n\n```prolog\n:- use_module('src/unifyweaver/targets/sql_target').\n:- sql_table(employee, [name-text, dept-text, salary-integer]).\nhigh_earner(Name, Dept) :- employee(Name, Dept, Salary), Salary > 100000.\n?- compile_predicate_to_sql(high_earner/2, [dialect(sqlite), format(view)], SQL).\n```\n\nThis generates a `CREATE VIEW IF NOT EXISTS` statement. The skill supports SQLite (default), PostgreSQL, and MySQL dialects. Choose your dialect with `dialect(Option)` and output format with `format(Option)` \u2014 view, cte, or select.", "question_type": "medium", "topics": ["Quickstart", "SQL Target"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sql", "prolog", "compilation", "views"], "related_skills": ["skill_sql_target.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl", "education/book-10-sql-target/"], "original_answer": "Use the SQL Target skill to compile Prolog predicates to SQL CREATE VIEW statements. Load the module, define your table schema with `sql_table/2`, then compile your predicate:\n\n```prolog\n:- use_module('src/unifyweaver/targets/sql_target').\n:- sql_table(employee, [name-text, dept-text, salary-integer]).\nhigh_earner(Name, Dept) :- employee(Name, Dept, Salary), Salary > 100000.\n?- compile_predicate_to_sql(high_earner/2, [dialect(sqlite)], SQL).\n```\n\nSupports SQLite (default), PostgreSQL, and MySQL dialects. See skill_sql_target.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_sql_target_002_q0", "cluster_id": "skill_sql_target_002", "question": "How do I handle GROUP BY and aggregations when generating SQL?", "answer": "Use the `group_by/4` predicate to generate GROUP BY clauses with aggregation operators: `count`, `sum`, `avg`, `min`, and `max`. For example:\n\n```prolog\ndept_count(Dept, Count) :- group_by(Dept, employee(_, Dept, _), count, Count).\n```\n\nThis generates: `SELECT dept, COUNT(*) FROM employee GROUP BY dept`\n\nFor HAVING clauses, add filter conditions after grouping:\n\n```prolog\nlarge_depts(Dept, Count) :- group_by(Dept, employee(_, Dept, _), count, Count), Count >= 10.\n```\n\nThis generates: `SELECT dept, COUNT(*) FROM employee GROUP BY dept HAVING COUNT(*) >= 10`", "question_type": "long", "topics": ["Quickstart", "SQL Target"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sql", "aggregation", "group-by", "having"], "related_skills": ["skill_sql_target.md", "skill_aggregation_patterns.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl"], "original_answer": "Use the `group_by/4` predicate to generate GROUP BY clauses with aggregation. Supported operators include `count`, `sum`, `avg`, `min`, and `max`:\n\n```prolog\ndept_count(Dept, Count) :- group_by(Dept, employee(_, Dept, _), count, Count).\n```\n\nFor HAVING clauses, add conditions after grouping:\n\n```prolog\nlarge_depts(Dept, Count) :- group_by(Dept, employee(_, Dept, _), count, Count), Count >= 10.\n```\n\nThis compiles to `SELECT dept, COUNT(*) FROM employee GROUP BY dept HAVING COUNT(*) >= 10`. See skill_sql_target.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_sql_target_002_q1", "cluster_id": "skill_sql_target_002", "question": "Can I use COUNT and SUM in compiled SQL?", "answer": "Yes, you can use COUNT and SUM in compiled SQL. Use the `group_by/4` predicate with aggregation operators `count` and `sum`:\n\n```prolog\ndept_count(Dept, Count) :- group_by(Dept, employee(_, Dept, _), count, Count).\n```\n\nThis compiles to `SELECT dept, COUNT(*) FROM employee GROUP BY dept`. You can also use `sum`, `avg`, `min`, and `max` with the same pattern. For filtering aggregated results, add conditions after grouping:\n\n```prolog\nlarge_depts(Dept, Count) :- group_by(Dept, employee(_, Dept, _), count, Count), Count >= 10.\n```\n\nThis generates a HAVING clause in the compiled SQL.", "question_type": "long", "topics": ["Quickstart", "SQL Target"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sql", "aggregation", "group-by", "having"], "related_skills": ["skill_sql_target.md", "skill_aggregation_patterns.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl"], "original_answer": "Use the `group_by/4` predicate to generate GROUP BY clauses with aggregation. Supported operators include `count`, `sum`, `avg`, `min`, and `max`:\n\n```prolog\ndept_count(Dept, Count) :- group_by(Dept, employee(_, Dept, _), count, Count).\n```\n\nFor HAVING clauses, add conditions after grouping:\n\n```prolog\nlarge_depts(Dept, Count) :- group_by(Dept, employee(_, Dept, _), count, Count), Count >= 10.\n```\n\nThis compiles to `SELECT dept, COUNT(*) FROM employee GROUP BY dept HAVING COUNT(*) >= 10`. See skill_sql_target.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_sql_target_002_q2", "cluster_id": "skill_sql_target_002", "question": "How do I group results by columns in SQL output?", "answer": "Use the `group_by/4` predicate to generate GROUP BY clauses. Syntax: `group_by(GroupColumn, FactPattern, AggregationOp, ResultVar)`. Supported aggregation operators are `count`, `sum`, `avg`, `min`, and `max`. Example: `dept_count(Dept, Count) :- group_by(Dept, employee(_, Dept, _), count, Count)` compiles to `SELECT dept, COUNT(*) FROM employee GROUP BY dept`. For HAVING filters, add conditions after grouping: `large_depts(Dept, Count) :- group_by(Dept, employee(_, Dept, _), count, Count), Count >= 10` produces `HAVING COUNT(*) >= 10`. Works across SQLite, PostgreSQL, and MySQL dialects.", "question_type": "long", "topics": ["Quickstart", "SQL Target"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sql", "aggregation", "group-by", "having"], "related_skills": ["skill_sql_target.md", "skill_aggregation_patterns.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl"], "original_answer": "Use the `group_by/4` predicate to generate GROUP BY clauses with aggregation. Supported operators include `count`, `sum`, `avg`, `min`, and `max`:\n\n```prolog\ndept_count(Dept, Count) :- group_by(Dept, employee(_, Dept, _), count, Count).\n```\n\nFor HAVING clauses, add conditions after grouping:\n\n```prolog\nlarge_depts(Dept, Count) :- group_by(Dept, employee(_, Dept, _), count, Count), Count >= 10.\n```\n\nThis compiles to `SELECT dept, COUNT(*) FROM employee GROUP BY dept HAVING COUNT(*) >= 10`. See skill_sql_target.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_sql_target_003_q0", "cluster_id": "skill_sql_target_003", "question": "How do I use window functions like RANK and ROW_NUMBER in SQL output?", "answer": "Use window function predicates with `partition_by` and `order_by` options. Call the window function (e.g., `rank`, `row_number`, `dense_rank`) with a list containing partition and ordering specifications:\n\n```prolog\nranked_employees(Name, Dept, Salary, Rank) :- \n    employee(Name, Dept, Salary),\n    rank(Rank, [partition_by(Dept), order_by(Salary, desc)]).\n```\n\nThis compiles to:\n```sql\nSELECT name, dept, salary,\n       RANK() OVER (PARTITION BY dept ORDER BY salary DESC) AS rank\nFROM employee;\n```\n\nAvailable functions: `row_number`, `rank`, `dense_rank`, `ntile`, `window_sum`, `window_avg`, `lag`, and `lead`. Each generates the corresponding SQL window function. Use `partition_by(Column)` to partition rows and `order_by(Column, asc|desc)` to order within partitions.", "question_type": "long", "topics": ["Quickstart", "SQL Target"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sql", "window-functions", "rank", "partition"], "related_skills": ["skill_sql_target.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl"], "original_answer": "Use window function predicates with `partition_by` and `order_by` options:\n\n```prolog\nranked_employees(Name, Dept, Salary, Rank) :- \n    employee(Name, Dept, Salary),\n    rank(Rank, [partition_by(Dept), order_by(Salary, desc)]).\n```\n\nAvailable functions: `row_number`, `rank`, `dense_rank`, `ntile`, `window_sum`, `window_avg`, `lag`, and `lead`. Each generates the corresponding SQL window function with `PARTITION BY` and `ORDER BY` clauses. See skill_sql_target.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_sql_target_003_q1", "cluster_id": "skill_sql_target_003", "question": "Can I generate window functions from Prolog?", "answer": "Yes, you can generate window functions from Prolog using the SQL Target module. Use window function predicates with `partition_by` and `order_by` options:\n\n```prolog\nranked_employees(Name, Dept, Salary, Rank) :- \n    employee(Name, Dept, Salary),\n    rank(Rank, [partition_by(Dept), order_by(Salary, desc)]).\n```\n\nThis compiles to:\n```sql\nSELECT name, dept, salary,\n       RANK() OVER (PARTITION BY dept ORDER BY salary DESC) AS rank\nFROM employee\n```\n\nSupported functions include: `row_number`, `rank`, `dense_rank`, `ntile`, `window_sum`, `window_avg`, `lag`, and `lead`. Each generates the corresponding SQL window function with `PARTITION BY` and `ORDER BY` clauses.", "question_type": "long", "topics": ["Quickstart", "SQL Target"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sql", "window-functions", "rank", "partition"], "related_skills": ["skill_sql_target.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl"], "original_answer": "Use window function predicates with `partition_by` and `order_by` options:\n\n```prolog\nranked_employees(Name, Dept, Salary, Rank) :- \n    employee(Name, Dept, Salary),\n    rank(Rank, [partition_by(Dept), order_by(Salary, desc)]).\n```\n\nAvailable functions: `row_number`, `rank`, `dense_rank`, `ntile`, `window_sum`, `window_avg`, `lag`, and `lead`. Each generates the corresponding SQL window function with `PARTITION BY` and `ORDER BY` clauses. See skill_sql_target.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_sql_target_003_q2", "cluster_id": "skill_sql_target_003", "question": "How do I rank employees by salary within departments?", "answer": "To rank employees by salary within departments, use the `rank` window function with `partition_by` and `order_by` options:\n\n```prolog\nranked_employees(Name, Dept, Salary, Rank) :-\n    employee(Name, Dept, Salary),\n    rank(Rank, [partition_by(Dept), order_by(Salary, desc)]).\n```\n\nThis compiles to:\n```sql\nSELECT name, dept, salary,\n       RANK() OVER (PARTITION BY dept ORDER BY salary DESC) AS rank\nFROM employee\n```\n\nAlternative window functions: `row_number` (assigns unique sequential numbers), `dense_rank` (like rank but without gaps), `ntile` (distributes rows into N buckets), `lag`/`lead` (access previous/next row values). All support the same `partition_by` and `order_by` options.", "question_type": "long", "topics": ["Quickstart", "SQL Target"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sql", "window-functions", "rank", "partition"], "related_skills": ["skill_sql_target.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl"], "original_answer": "Use window function predicates with `partition_by` and `order_by` options:\n\n```prolog\nranked_employees(Name, Dept, Salary, Rank) :- \n    employee(Name, Dept, Salary),\n    rank(Rank, [partition_by(Dept), order_by(Salary, desc)]).\n```\n\nAvailable functions: `row_number`, `rank`, `dense_rank`, `ntile`, `window_sum`, `window_avg`, `lag`, and `lead`. Each generates the corresponding SQL window function with `PARTITION BY` and `ORDER BY` clauses. See skill_sql_target.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_sql_target_004_q0", "cluster_id": "skill_sql_target_004", "question": "How do I generate recursive CTEs for transitive relationships like ancestors or reachability?", "answer": "To generate recursive CTEs for transitive relationships, use `compile_recursive_cte/5` with your recursive Prolog predicate. Define your base case and recursive case separately:\n\n```prolog\nancestor(X, Y) :- parent(X, Y).\nancestor(X, Z) :- parent(X, Y), ancestor(Y, Z).\n\ncompile_recursive_cte(ancestor, [x, y], ancestor/2, ancestor/2, SQL).\n```\n\nThis generates a WITH RECURSIVE CTE that unions the base case (direct parents) with the recursive case (ancestors of ancestors), enabling queries across multiple levels of relationships. Works with SQLite, PostgreSQL, and MySQL for transitive closure problems like finding all ancestors or reachable nodes.", "question_type": "long", "topics": ["Quickstart", "SQL Target"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sql", "recursive-cte", "transitive-closure", "prolog"], "related_skills": ["skill_sql_target.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl"], "original_answer": "Use `compile_recursive_cte/5` to generate WITH RECURSIVE CTEs from recursive Prolog predicates:\n\n```prolog\nancestor(X, Y) :- parent(X, Y).\nancestor(X, Z) :- parent(X, Y), ancestor(Y, Z).\n\ncompile_recursive_cte(ancestor, [x, y], ancestor/2, ancestor/2, SQL).\n```\n\nThis generates a recursive CTE that unions the base case with the recursive case, enabling multi-level transitive queries like finding all ancestors. See skill_sql_target.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "The base answer lacks clarity on parameter semantics (what [x, y] represents vs the two ancestor/2 arguments), doesn't explain why the base case must be separated from recursion, and provides no example output to validate correctness."}
{"pair_id": "skill_sql_target_004_q1", "cluster_id": "skill_sql_target_004", "question": "Can I compile recursive Prolog rules to recursive SQL CTEs?", "answer": "Yes, you can compile recursive Prolog rules to recursive SQL CTEs using `compile_recursive_cte/5`. For example, with a recursive ancestor predicate:\n\n```prolog\nancestor(X, Y) :- parent(X, Y).\nancestor(X, Z) :- parent(X, Y), ancestor(Y, Z).\n\ncompile_recursive_cte(ancestor, [x, y], ancestor/2, ancestor/2, SQL).\n```\n\nThis generates a WITH RECURSIVE CTE that unions the base case (direct parent-child relationships) with the recursive case (transitive ancestry), enabling multi-level queries to find all ancestors of a person.", "question_type": "long", "topics": ["Quickstart", "SQL Target"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sql", "recursive-cte", "transitive-closure", "prolog"], "related_skills": ["skill_sql_target.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl"], "original_answer": "Use `compile_recursive_cte/5` to generate WITH RECURSIVE CTEs from recursive Prolog predicates:\n\n```prolog\nancestor(X, Y) :- parent(X, Y).\nancestor(X, Z) :- parent(X, Y), ancestor(Y, Z).\n\ncompile_recursive_cte(ancestor, [x, y], ancestor/2, ancestor/2, SQL).\n```\n\nThis generates a recursive CTE that unions the base case with the recursive case, enabling multi-level transitive queries like finding all ancestors. See skill_sql_target.md for details.", "answer_tailored": true, "confidence": 0.75, "confidence_issues": "The base answer references 'skill_sql_target.md' which wasn't fully provided. The exact parameter order and semantics of `compile_recursive_cte/5` are not fully clear from the documentation snippet, so confidence is moderate rather than high."}
{"pair_id": "skill_sql_target_004_q2", "cluster_id": "skill_sql_target_004", "question": "How do I handle transitive closure in SQL?", "answer": "Use `compile_recursive_cte/5` to generate WITH RECURSIVE CTEs from recursive Prolog predicates. Define your recursive predicate with a base case and recursive case, then compile it:\n\n```prolog\nancestor(X, Y) :- parent(X, Y).\nancestor(X, Z) :- parent(X, Y), ancestor(Y, Z).\n\ncompile_recursive_cte(ancestor, [x, y], ancestor/2, ancestor/2, SQL).\n```\n\nThis generates a WITH RECURSIVE CTE that unions the base case with the recursive case, enabling multi-level transitive queries. For example, finding all ancestors of a person, organizational hierarchies, or graph traversals. The recursive CTE will iteratively apply the predicate until no new rows are produced.", "question_type": "long", "topics": ["Quickstart", "SQL Target"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sql", "recursive-cte", "transitive-closure", "prolog"], "related_skills": ["skill_sql_target.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl"], "original_answer": "Use `compile_recursive_cte/5` to generate WITH RECURSIVE CTEs from recursive Prolog predicates:\n\n```prolog\nancestor(X, Y) :- parent(X, Y).\nancestor(X, Z) :- parent(X, Y), ancestor(Y, Z).\n\ncompile_recursive_cte(ancestor, [x, y], ancestor/2, ancestor/2, SQL).\n```\n\nThis generates a recursive CTE that unions the base case with the recursive case, enabling multi-level transitive queries like finding all ancestors. See skill_sql_target.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_sql_target_005_q0", "cluster_id": "skill_sql_target_005", "question": "How do I export Prolog facts to SQL INSERT statements?", "answer": "Use `compile_facts_to_sql/3` to generate CREATE TABLE and INSERT statements from Prolog facts. Example: `compile_facts_to_sql(parent, 2, SQL).` generates a CREATE TABLE statement with TEXT columns and INSERT statements for each fact like `parent(alice, bob).` and `parent(bob, carol).`. Use `write_sql_file/2` to write the output to a file for batch importing into databases. The predicate supports SQLite, PostgreSQL, and MySQL dialects via options.", "question_type": "medium", "topics": ["Quickstart", "SQL Target"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sql", "export", "facts", "insert"], "related_skills": ["skill_sql_target.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl", "src/unifyweaver/sources/sqlite_source.pl"], "original_answer": "Use `compile_facts_to_sql/3` to generate CREATE TABLE and INSERT statements from Prolog facts:\n\n```prolog\nparent(alice, bob).\nparent(bob, carol).\ncompile_facts_to_sql(parent, 2, SQL).\n```\n\nThis generates a CREATE TABLE statement with TEXT columns plus INSERT statements for each fact. Write to a file with `write_sql_file/2` for batch importing into databases. Supports SQLite, PostgreSQL, and MySQL. See skill_sql_target.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer mentions 'compile_facts_to_sql/3' but the skill document doesn't provide the actual predicate signature, syntax details, or usage examples for this specific function. The generated SQL output format (table schema inference, INSERT statement structure) is not documented. The write_sql_file/2 predicate is referenced but not detailed in the skill document. This limits confidence that the answer is complete and accurate."}
{"pair_id": "skill_sql_target_005_q1", "cluster_id": "skill_sql_target_005", "question": "Can I convert Prolog facts to SQL?", "answer": "Yes, use `compile_facts_to_sql/3` to convert Prolog facts into SQL CREATE TABLE and INSERT statements. For example, `compile_facts_to_sql(parent, 2, SQL)` converts facts like `parent(alice, bob)` into a table definition with corresponding insert statements. The generated SQL works with SQLite, PostgreSQL, and MySQL. Use `write_sql_file/2` to write the output directly to a file for batch database imports.", "question_type": "medium", "topics": ["Quickstart", "SQL Target"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sql", "export", "facts", "insert"], "related_skills": ["skill_sql_target.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl", "src/unifyweaver/sources/sqlite_source.pl"], "original_answer": "Use `compile_facts_to_sql/3` to generate CREATE TABLE and INSERT statements from Prolog facts:\n\n```prolog\nparent(alice, bob).\nparent(bob, carol).\ncompile_facts_to_sql(parent, 2, SQL).\n```\n\nThis generates a CREATE TABLE statement with TEXT columns plus INSERT statements for each fact. Write to a file with `write_sql_file/2` for batch importing into databases. Supports SQLite, PostgreSQL, and MySQL. See skill_sql_target.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_sql_target_005_q2", "cluster_id": "skill_sql_target_005", "question": "How do I load Prolog facts into a database?", "answer": "Use `compile_facts_to_sql/3` to generate CREATE TABLE and INSERT statements from Prolog facts. First, define your facts in Prolog (e.g., `parent(alice, bob).`), then call `compile_facts_to_sql(parent, 2, SQL)` to generate SQL. This creates a table with TEXT columns and INSERT statements for each fact. Use `write_sql_file/2` to write the output to a file for batch importing into SQLite, PostgreSQL, or MySQL databases.", "question_type": "medium", "topics": ["Quickstart", "SQL Target"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sql", "export", "facts", "insert"], "related_skills": ["skill_sql_target.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl", "src/unifyweaver/sources/sqlite_source.pl"], "original_answer": "Use `compile_facts_to_sql/3` to generate CREATE TABLE and INSERT statements from Prolog facts:\n\n```prolog\nparent(alice, bob).\nparent(bob, carol).\ncompile_facts_to_sql(parent, 2, SQL).\n```\n\nThis generates a CREATE TABLE statement with TEXT columns plus INSERT statements for each fact. Write to a file with `write_sql_file/2` for batch importing into databases. Supports SQLite, PostgreSQL, and MySQL. See skill_sql_target.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer references 'skill_sql_target.md' which may not be the actual file path. The answer could be more explicit about the order of operations (define facts first, then compile)."}
{"pair_id": "skill_sql_target_006_q0", "cluster_id": "skill_sql_target_006", "question": "Can I combine multiple predicates with UNION, INTERSECT, or EXCEPT in SQL?", "answer": "Yes, you can combine multiple predicates using set operations in SQL. Use `compile_set_operation/4` to combine predicates with UNION, INTERSECT, or EXCEPT:\n\n```prolog\ncompile_set_operation(union, [active_users/1, premium_users/1], [dialect(postgres)], SQL).\n```\n\nSupported operations:\n- `union` - combines results and removes duplicates\n- `union_all` - combines results with duplicates\n- `intersect` - finds rows present in both predicates\n- `except` - finds rows in first predicate but not in second\n\nSpecify your SQL dialect (sqlite, postgres, mysql) as an option to ensure compatibility with your database.", "question_type": "long", "topics": ["Quickstart", "SQL Target"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sql", "set-operations", "union", "intersect"], "related_skills": ["skill_sql_target.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl"], "original_answer": "Use `compile_set_operation/4` to combine multiple predicates with set operations:\n\n```prolog\ncompile_set_operation(union, [active_users/1, premium_users/1], [dialect(postgres)], SQL).\n```\n\nSupported operations: `union` (distinct), `union_all`, `intersect`, and `except`. This is useful for finding intersections, differences, or combined sets of results from multiple predicates. Choose your SQL dialect (sqlite, postgres, mysql) to ensure compatibility. See skill_sql_target.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "Base answer doesn't explicitly name which operation does what (union vs intersect vs except), so I added those descriptions. The answer could benefit from a brief example showing the generated SQL output."}
{"pair_id": "skill_sql_target_006_q1", "cluster_id": "skill_sql_target_006", "question": "How do I use set operations on compiled predicates?", "answer": "Use `compile_set_operation/4` to combine multiple predicates with set operations. Call it with the operation type (union, union_all, intersect, or except), a list of predicates, options including your SQL dialect, and the output variable:\n\n```prolog\ncompile_set_operation(union, [active_users/1, premium_users/1], [dialect(postgres)], SQL).\n```\n\nThis generates SQL that combines results from multiple predicates. For example, `union` returns distinct rows from both predicates, `union_all` includes duplicates, `intersect` returns only rows in both predicates, and `except` returns rows in the first predicate but not the second. Specify your target dialect (sqlite, postgres, or mysql) in the options to ensure compatibility.", "question_type": "long", "topics": ["Quickstart", "SQL Target"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sql", "set-operations", "union", "intersect"], "related_skills": ["skill_sql_target.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl"], "original_answer": "Use `compile_set_operation/4` to combine multiple predicates with set operations:\n\n```prolog\ncompile_set_operation(union, [active_users/1, premium_users/1], [dialect(postgres)], SQL).\n```\n\nSupported operations: `union` (distinct), `union_all`, `intersect`, and `except`. This is useful for finding intersections, differences, or combined sets of results from multiple predicates. Choose your SQL dialect (sqlite, postgres, mysql) to ensure compatibility. See skill_sql_target.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer references a skill document that may not fully detail the return values or error handling. The exact behavior of each set operation and any limitations by dialect are not comprehensively covered in the provided context."}
{"pair_id": "skill_sql_target_006_q2", "cluster_id": "skill_sql_target_006", "question": "How do I combine SQL queries from different Prolog predicates?", "answer": "Use `compile_set_operation/4` to combine results from multiple Prolog predicates using SQL set operations. The syntax is: `compile_set_operation(Operation, [Predicate1/Arity1, Predicate2/Arity2, ...], Options, SQL)`. Supported operations are:\n\n- `union` - combines results and removes duplicates\n- `union_all` - combines results keeping duplicates\n- `intersect` - returns only rows present in all predicates\n- `except` - returns rows from first predicate not in others\n\nExample: `compile_set_operation(union, [active_users/1, premium_users/1], [dialect(postgres)], SQL)` generates a UNION query combining active and premium users. Specify your database dialect (sqlite, postgres, mysql) in the options to ensure correct SQL syntax.", "question_type": "long", "topics": ["Quickstart", "SQL Target"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sql", "set-operations", "union", "intersect"], "related_skills": ["skill_sql_target.md"], "related_docs": ["src/unifyweaver/targets/sql_target.pl"], "original_answer": "Use `compile_set_operation/4` to combine multiple predicates with set operations:\n\n```prolog\ncompile_set_operation(union, [active_users/1, premium_users/1], [dialect(postgres)], SQL).\n```\n\nSupported operations: `union` (distinct), `union_all`, `intersect`, and `except`. This is useful for finding intersections, differences, or combined sets of results from multiple predicates. Choose your SQL dialect (sqlite, postgres, mysql) to ensure compatibility. See skill_sql_target.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer is accurate but could be more complete. It doesn't explicitly explain what each set operation does or provide a more detailed example showing the generated SQL output, which would help users understand the practical difference between operations."}
{"pair_id": "skill_stream_aggregation_001_q0", "cluster_id": "skill_stream_aggregation_001", "question": "How do I count items in generated code?", "answer": "Use aggregate_all/3 with the count operator to count items in generated code. The pattern is `aggregate_all(count, item(_), Count)`, where item(_) is your predicate pattern and Count is unified with the result. This generates efficient counting implementations across Go, C#, Perl, and Ruby, with Go and C# providing the most complete support.", "question_type": "medium", "topics": ["Quickstart", "Stream Aggregation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["aggregation", "runtime", "counting"], "related_skills": ["skill_stream_aggregation.md"], "related_docs": ["docs/BINDING_MATRIX.md", "src/unifyweaver/targets/go_target.pl", "src/unifyweaver/targets/csharp_target.pl"], "original_answer": "Use aggregate_all/3 with the count operator. Example: `aggregate_all(count, item(_), Count)` generates efficient counting code in Go, C#, Perl, or Ruby. Go and C# support the most complete implementation. See skill_stream_aggregation.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_stream_aggregation_001_q1", "cluster_id": "skill_stream_aggregation_001", "question": "How can I get a total count at runtime?", "answer": "Use `aggregate_all(count, item(_), Count)` to get a total count at runtime. This generates efficient counting code across Go, C#, Perl, and Ruby. Go and C# provide the most complete implementation with full support for both ungrouped and grouped counting operations.", "question_type": "medium", "topics": ["Quickstart", "Stream Aggregation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["aggregation", "runtime", "counting"], "related_skills": ["skill_stream_aggregation.md"], "related_docs": ["docs/BINDING_MATRIX.md", "src/unifyweaver/targets/go_target.pl", "src/unifyweaver/targets/csharp_target.pl"], "original_answer": "Use aggregate_all/3 with the count operator. Example: `aggregate_all(count, item(_), Count)` generates efficient counting code in Go, C#, Perl, or Ruby. Go and C# support the most complete implementation. See skill_stream_aggregation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_stream_aggregation_001_q2", "cluster_id": "skill_stream_aggregation_001", "question": "What's the best way to count matching items in generated code?", "answer": "Use aggregate_all/3 with the count operator: `aggregate_all(count, item(_), Count)`. This generates efficient counting code across Go, C#, Perl, and Ruby. Go and C# provide the most complete implementation with full support for both basic counting and grouped aggregation.", "question_type": "medium", "topics": ["Quickstart", "Stream Aggregation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["aggregation", "runtime", "counting"], "related_skills": ["skill_stream_aggregation.md"], "related_docs": ["docs/BINDING_MATRIX.md", "src/unifyweaver/targets/go_target.pl", "src/unifyweaver/targets/csharp_target.pl"], "original_answer": "Use aggregate_all/3 with the count operator. Example: `aggregate_all(count, item(_), Count)` generates efficient counting code in Go, C#, Perl, or Ruby. Go and C# support the most complete implementation. See skill_stream_aggregation.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_stream_aggregation_002_q0", "cluster_id": "skill_stream_aggregation_002", "question": "How do I group data and aggregate by category?", "answer": "Use `aggregate_all/4` to group data and aggregate by category. The syntax is `aggregate_all(AggregationOp, Goal, GroupKey, Result)`. For example, `aggregate_all(count, item(_, Category), Category, Count)` groups items by Category and counts items in each group. This generates a grouped aggregation in Go and C# with full support. In Perl and Ruby, grouping support is partial. You can also add filtering after aggregation (HAVING clause) by adding conditions after the aggregate_all call, particularly in Go where this is fully supported.", "question_type": "medium", "topics": ["Quickstart", "Stream Aggregation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["aggregation", "grouping", "runtime"], "related_skills": ["skill_stream_aggregation.md"], "related_docs": ["docs/BINDING_MATRIX.md", "src/unifyweaver/targets/go_target.pl", "src/unifyweaver/targets/csharp_target.pl"], "original_answer": "Use aggregate_all/4 with grouping. Example: `aggregate_all(count, item(_, Category), Category, Count)` groups by Category and counts per group. This works in Go and C# with full support, and partially in Perl and Ruby. See skill_stream_aggregation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_stream_aggregation_002_q1", "cluster_id": "skill_stream_aggregation_002", "question": "Can I count items per category in generated code?", "answer": "Yes, use aggregate_all/4 with grouping syntax. Example: `aggregate_all(count, item(_, Category), Category, Count)` groups items by Category and returns the count per group. This works with full support in Go and C#, and with partial support in Perl and Ruby.", "question_type": "medium", "topics": ["Quickstart", "Stream Aggregation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["aggregation", "grouping", "runtime"], "related_skills": ["skill_stream_aggregation.md"], "related_docs": ["docs/BINDING_MATRIX.md", "src/unifyweaver/targets/go_target.pl", "src/unifyweaver/targets/csharp_target.pl"], "original_answer": "Use aggregate_all/4 with grouping. Example: `aggregate_all(count, item(_, Category), Category, Count)` groups by Category and counts per group. This works in Go and C# with full support, and partially in Perl and Ruby. See skill_stream_aggregation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_stream_aggregation_002_q2", "cluster_id": "skill_stream_aggregation_002", "question": "How do I aggregate results grouped by a field?", "answer": "Use `aggregate_all/4` to group and aggregate results by a field. The fourth argument specifies the grouping key. Example: `aggregate_all(count, item(_, Category), Category, Count)` groups items by Category and counts items in each group. This returns a mapping of Category to Count. Full support in Go and C#, partial support in Perl and Ruby.", "question_type": "medium", "topics": ["Quickstart", "Stream Aggregation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["aggregation", "grouping", "runtime"], "related_skills": ["skill_stream_aggregation.md"], "related_docs": ["docs/BINDING_MATRIX.md", "src/unifyweaver/targets/go_target.pl", "src/unifyweaver/targets/csharp_target.pl"], "original_answer": "Use aggregate_all/4 with grouping. Example: `aggregate_all(count, item(_, Category), Category, Count)` groups by Category and counts per group. This works in Go and C# with full support, and partially in Perl and Ruby. See skill_stream_aggregation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_stream_aggregation_003_q0", "cluster_id": "skill_stream_aggregation_003", "question": "What aggregation operators are available?", "answer": "The system supports seven aggregation operators: count (returns integer), sum(V) (returns numeric), avg(V) (returns float), min(V) and max(V) (return same type as input), set(V) (returns unique values), and bag(V) (returns all values including duplicates). Go and C# provide full support for all operators across both ungrouped and grouped aggregations. Perl and Ruby support basic operators with limited grouping.", "question_type": "medium", "topics": ["Quickstart", "Stream Aggregation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["aggregation", "operators", "functions"], "related_skills": ["skill_stream_aggregation.md"], "related_docs": ["docs/BINDING_MATRIX.md"], "original_answer": "The system supports: count (integer), sum(V) (numeric), avg(V) (float), min(V) and max(V) (same type as V), set(V) (unique values), and bag(V) (all values with duplicates). Go and C# have full support for all operators. See skill_stream_aggregation.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_stream_aggregation_003_q1", "cluster_id": "skill_stream_aggregation_003", "question": "Can I sum, average, or find min/max values?", "answer": "Yes. The system supports sum(V) for summing numeric values, avg(V) for averages (returns float), and min(V)/max(V) for finding minimum and maximum values (same type as input). Go and C# targets provide full support for all these operators. Perl and Ruby have basic support. Use `aggregate_all(sum(V), goal, Result)` for simple aggregation or `aggregate_all(sum(V), goal, GroupKey, Result)` for grouped aggregation.", "question_type": "medium", "topics": ["Quickstart", "Stream Aggregation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["aggregation", "operators", "functions"], "related_skills": ["skill_stream_aggregation.md"], "related_docs": ["docs/BINDING_MATRIX.md"], "original_answer": "The system supports: count (integer), sum(V) (numeric), avg(V) (float), min(V) and max(V) (same type as V), set(V) (unique values), and bag(V) (all values with duplicates). Go and C# have full support for all operators. See skill_stream_aggregation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_stream_aggregation_003_q2", "cluster_id": "skill_stream_aggregation_003", "question": "Which aggregation functions does the system support?", "answer": "The system supports seven aggregation functions: count (returns integer), sum(V) (returns numeric), avg(V) (returns float), min(V) and max(V) (return same type as input), set(V) (returns unique values), and bag(V) (returns all values with duplicates). Go and C# provide full support for all operators. Perl and Ruby support basic count, sum, avg, min, and max operations.", "question_type": "medium", "topics": ["Quickstart", "Stream Aggregation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["aggregation", "operators", "functions"], "related_skills": ["skill_stream_aggregation.md"], "related_docs": ["docs/BINDING_MATRIX.md"], "original_answer": "The system supports: count (integer), sum(V) (numeric), avg(V) (float), min(V) and max(V) (same type as V), set(V) (unique values), and bag(V) (all values with duplicates). Go and C# have full support for all operators. See skill_stream_aggregation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_stream_aggregation_004_q0", "cluster_id": "skill_stream_aggregation_004", "question": "How do I filter groups after aggregation (HAVING)?", "answer": "To filter groups after aggregation (HAVING), add filtering conditions after the aggregate_all/4 call. Example: `aggregate_all(count, employee(_, Dept, _), Dept, Count), Count > 5.` This returns only departments with more than 5 employees. Go has full HAVING support; C# has partial support; Perl and Ruby have no HAVING support.", "question_type": "long", "topics": ["Quickstart", "Stream Aggregation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["aggregation", "filtering", "having", "grouping"], "related_skills": ["skill_stream_aggregation.md"], "related_docs": ["docs/BINDING_MATRIX.md", "src/unifyweaver/targets/go_target.pl", "src/unifyweaver/targets/csharp_target.pl"], "original_answer": "After aggregating with aggregate_all/4, add filtering conditions. Example: `aggregate_all(count, employee(_, Dept, _), Dept, Count), Count > 5.` Returns only departments with more than 5 employees. Full HAVING support is available in Go; C# has partial support. See skill_stream_aggregation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_stream_aggregation_004_q1", "cluster_id": "skill_stream_aggregation_004", "question": "Can I only return groups that meet certain conditions?", "answer": "Yes, you can filter groups after aggregation using HAVING-style conditions. With `aggregate_all/4`, add filtering conditions after the aggregation call. Example: `aggregate_all(count, employee(_, Dept, _), Dept, Count), Count > 5.` returns only departments with more than 5 employees. Go targets have full HAVING support. C# has partial support. Perl and Ruby do not support HAVING filtering.", "question_type": "long", "topics": ["Quickstart", "Stream Aggregation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["aggregation", "filtering", "having", "grouping"], "related_skills": ["skill_stream_aggregation.md"], "related_docs": ["docs/BINDING_MATRIX.md", "src/unifyweaver/targets/go_target.pl", "src/unifyweaver/targets/csharp_target.pl"], "original_answer": "After aggregating with aggregate_all/4, add filtering conditions. Example: `aggregate_all(count, employee(_, Dept, _), Dept, Count), Count > 5.` Returns only departments with more than 5 employees. Full HAVING support is available in Go; C# has partial support. See skill_stream_aggregation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_stream_aggregation_004_q2", "cluster_id": "skill_stream_aggregation_004", "question": "How do I filter aggregated results?", "answer": "After aggregating with aggregate_all/4, add filtering conditions after the aggregation call. Example: `aggregate_all(count, employee(_, Dept, _), Dept, Count), Count > 5.` This returns only departments with more than 5 employees. This HAVING-style filtering is fully supported in Go, partially supported in C#, and not supported in Perl or Ruby. Add your filter as a separate goal after the aggregate_all predicate.", "question_type": "long", "topics": ["Quickstart", "Stream Aggregation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["aggregation", "filtering", "having", "grouping"], "related_skills": ["skill_stream_aggregation.md"], "related_docs": ["docs/BINDING_MATRIX.md", "src/unifyweaver/targets/go_target.pl", "src/unifyweaver/targets/csharp_target.pl"], "original_answer": "After aggregating with aggregate_all/4, add filtering conditions. Example: `aggregate_all(count, employee(_, Dept, _), Dept, Count), Count > 5.` Returns only departments with more than 5 employees. Full HAVING support is available in Go; C# has partial support. See skill_stream_aggregation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_stream_aggregation_005_q0", "cluster_id": "skill_stream_aggregation_005", "question": "How do I aggregate data from a database in Go?", "answer": "To aggregate data from a database in Go, fetch data from BBolt first using `fetch_from_db/2`, then use `aggregate_all/3` or `aggregate_all/4` for in-memory aggregation. Example: `aggregate_all(sum(Price), member(Item, Items), Total)` after fetching. Go's BBolt integration generates efficient code that loads data then applies aggregation operators like count, sum, avg, min, max, set, or bag. See skill_stream_aggregation.md for complete patterns and HAVING-clause filtering.", "question_type": "long", "topics": ["Quickstart", "Stream Aggregation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["aggregation", "database", "bBolt", "go"], "related_skills": ["skill_stream_aggregation.md"], "related_docs": ["docs/BINDING_MATRIX.md", "src/unifyweaver/targets/go_target.pl"], "original_answer": "Fetch data from BBolt first, then aggregate in-memory. Example: `fetch_from_db(items, Items), aggregate_all(avg(Price), member(item(_, Category, Price), Items), Category, Avg).` Go's BBolt integration performs aggregation after fetching for efficiency. See skill_stream_aggregation.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "Base answer conflates fetch operation with aggregation predicate structure; the member/2 pattern in the example is unclear for BBolt context. Go support is 'Full' per the skill doc, but the answer could better explain the fetch-then-aggregate pattern specific to BBolt databases."}
{"pair_id": "skill_stream_aggregation_005_q1", "cluster_id": "skill_stream_aggregation_005", "question": "Can I use aggregate_all with BBolt data?", "answer": "Yes, you can use aggregate_all with BBolt data. First fetch your data from BBolt using `fetch_from_db/2`, then apply aggregation in-memory. For example: `fetch_from_db(items, Items), aggregate_all(avg(Price), member(item(_, Category, Price), Items), Category, Avg).` This approach is efficient because Go's BBolt integration loads the data once and performs aggregation operations in-memory rather than attempting aggregation at the database level.", "question_type": "long", "topics": ["Quickstart", "Stream Aggregation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["aggregation", "database", "bBolt", "go"], "related_skills": ["skill_stream_aggregation.md"], "related_docs": ["docs/BINDING_MATRIX.md", "src/unifyweaver/targets/go_target.pl"], "original_answer": "Fetch data from BBolt first, then aggregate in-memory. Example: `fetch_from_db(items, Items), aggregate_all(avg(Price), member(item(_, Category, Price), Items), Category, Avg).` Go's BBolt integration performs aggregation after fetching for efficiency. See skill_stream_aggregation.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "The base answer assumes fetch_from_db/2 exists and works with BBolt, but the skill document doesn't explicitly document BBolt integration. The pattern shown may need adjustment depending on actual BBolt API in the codebase. Confidence is moderate because the answer is plausible but not definitively supported by the provided skill documentation."}
{"pair_id": "skill_stream_aggregation_005_q2", "cluster_id": "skill_stream_aggregation_005", "question": "How do I aggregate stored data fetched from the database?", "answer": "Fetch data from BBolt first using `fetch_from_db/2`, then aggregate in-memory with `aggregate_all/4`. Example: `fetch_from_db(items, Items), aggregate_all(avg(Price), member(item(_, Category, Price), Items), Category, Avg).` This pattern works across Go, C#, Perl, and Ruby targets. The fetched data is aggregated using operators like count, sum, avg, min, max, set, or bag. Go provides the most complete support including HAVING-style filtering after aggregation.", "question_type": "long", "topics": ["Quickstart", "Stream Aggregation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["aggregation", "database", "bBolt", "go"], "related_skills": ["skill_stream_aggregation.md"], "related_docs": ["docs/BINDING_MATRIX.md", "src/unifyweaver/targets/go_target.pl"], "original_answer": "Fetch data from BBolt first, then aggregate in-memory. Example: `fetch_from_db(items, Items), aggregate_all(avg(Price), member(item(_, Category, Price), Items), Category, Avg).` Go's BBolt integration performs aggregation after fetching for efficiency. See skill_stream_aggregation.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "Base answer conflates two distinct operations (fetching from BBolt and stream aggregation). The skill document covers runtime aggregation within generated code for Go/C#/Perl/Ruby, but doesn't specifically address BBolt database fetching. The example syntax appears to mix database fetch with stream aggregation patterns, which may not be accurate for actual BBolt integration. Answer assumes the connection between fetch_from_db and aggregate_all is standard practice, but this isn't clearly established in the provided skill document."}
{"pair_id": "skill_stream_aggregation_006_q0", "cluster_id": "skill_stream_aggregation_006", "question": "Which target languages have the best aggregation support?", "answer": "Go has the most complete aggregation support, including aggregate_all/3, aggregate_all/4, and HAVING filters. C# supports both query runtime and generator modes with partial HAVING support. Perl and Ruby have basic aggregation support (count, sum, avg) but lack HAVING clause capabilities.", "question_type": "medium", "topics": ["Quickstart", "Stream Aggregation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["aggregation", "targets", "compatibility", "comparison"], "related_skills": ["skill_stream_aggregation.md"], "related_docs": ["docs/BINDING_MATRIX.md", "src/unifyweaver/targets/go_target.pl", "src/unifyweaver/targets/csharp_target.pl", "src/unifyweaver/targets/perl_target.pl", "src/unifyweaver/targets/ruby_target.pl"], "original_answer": "Go has the most complete support for aggregate_all/3, aggregate_all/4, and HAVING filters. C# supports both modes with partial HAVING. Perl and Ruby support basic aggregation (count, sum, avg) without HAVING. Use Go or C# for advanced aggregation features. See skill_stream_aggregation.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_stream_aggregation_006_q1", "cluster_id": "skill_stream_aggregation_006", "question": "Does Perl support HAVING clauses?", "answer": "No, Perl does not support HAVING clauses. Perl only supports basic aggregation (count, sum, avg) without HAVING filtering. For HAVING clause support, use Go or C# instead.", "question_type": "medium", "topics": ["Quickstart", "Stream Aggregation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["aggregation", "targets", "compatibility", "comparison"], "related_skills": ["skill_stream_aggregation.md"], "related_docs": ["docs/BINDING_MATRIX.md", "src/unifyweaver/targets/go_target.pl", "src/unifyweaver/targets/csharp_target.pl", "src/unifyweaver/targets/perl_target.pl", "src/unifyweaver/targets/ruby_target.pl"], "original_answer": "Go has the most complete support for aggregate_all/3, aggregate_all/4, and HAVING filters. C# supports both modes with partial HAVING. Perl and Ruby support basic aggregation (count, sum, avg) without HAVING. Use Go or C# for advanced aggregation features. See skill_stream_aggregation.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_stream_aggregation_006_q2", "cluster_id": "skill_stream_aggregation_006", "question": "What are the differences in aggregation between Go, C#, Perl, and Ruby?", "answer": "Go has the most complete aggregation support with full `aggregate_all/3` and `aggregate_all/4` along with HAVING clause filtering. C# supports both query runtime and generator modes with full basic aggregation but only partial HAVING support. Perl and Ruby have basic aggregation limited to count, sum, avg, min, max, and set operations without HAVING filtering. Choose Go for advanced grouping with post-aggregation filters, C# for query-based aggregation with limited filtering, and Perl/Ruby only for simple aggregations without group filtering.", "question_type": "medium", "topics": ["Quickstart", "Stream Aggregation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["aggregation", "targets", "compatibility", "comparison"], "related_skills": ["skill_stream_aggregation.md"], "related_docs": ["docs/BINDING_MATRIX.md", "src/unifyweaver/targets/go_target.pl", "src/unifyweaver/targets/csharp_target.pl", "src/unifyweaver/targets/perl_target.pl", "src/unifyweaver/targets/ruby_target.pl"], "original_answer": "Go has the most complete support for aggregate_all/3, aggregate_all/4, and HAVING filters. C# supports both modes with partial HAVING. Perl and Ruby support basic aggregation (count, sum, avg) without HAVING. Use Go or C# for advanced aggregation features. See skill_stream_aggregation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_synthetic_data_001_q0", "cluster_id": "skill_synthetic_data_001", "question": "How do I generate Q&A training data from my documentation?", "answer": "To generate Q&A training data from your documentation, use the `generate_qa_from_skills.py` script. For a single skill file, run: `python training-data/scripts/generate_qa_from_skills.py --skill skill_name.md --model haiku`. To generate from all skills at once, use the `--all` flag instead. The tool outputs JSONL format containing questions, answers, and metadata. For source-mapped generation, you can also use `generate_quickstart_qa.py`. Multiple LLM providers are supported via the `--provider` flag (claude, gemini).", "question_type": "medium", "topics": ["Quickstart", "Training Data"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["training data", "Q&A generation", "synthetic data", "documentation"], "related_skills": ["skill_synthetic_data.md", "skill_qa_generation.md"], "related_docs": ["training-data/scripts/generate_qa_from_skills.py", "training-data/scripts/generate_quickstart_qa.py"], "original_answer": "Use `python training-data/scripts/generate_qa_from_skills.py --skill skill_name.md --model haiku` to generate Q&A pairs from a skill file. For all skills, use `--all` flag. The tool outputs JSONL format with questions, answers, and metadata. You can also use `generate_quickstart_qa.py` for source mapping-based generation. See skill_synthetic_data.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_synthetic_data_001_q1", "cluster_id": "skill_synthetic_data_001", "question": "Can I create Q&A pairs from skill files?", "answer": "Yes, you can create Q&A pairs from skill files using `python training-data/scripts/generate_qa_from_skills.py`. Specify a single skill with `--skill skill_name.md` or generate from all skills using the `--all` flag. The tool outputs JSONL format containing questions, answers, and metadata. You can also use `generate_quickstart_qa.py` for source mapping-based generation.", "question_type": "medium", "topics": ["Quickstart", "Training Data"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["training data", "Q&A generation", "synthetic data", "documentation"], "related_skills": ["skill_synthetic_data.md", "skill_qa_generation.md"], "related_docs": ["training-data/scripts/generate_qa_from_skills.py", "training-data/scripts/generate_quickstart_qa.py"], "original_answer": "Use `python training-data/scripts/generate_qa_from_skills.py --skill skill_name.md --model haiku` to generate Q&A pairs from a skill file. For all skills, use `--all` flag. The tool outputs JSONL format with questions, answers, and metadata. You can also use `generate_quickstart_qa.py` for source mapping-based generation. See skill_synthetic_data.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_synthetic_data_001_q2", "cluster_id": "skill_synthetic_data_001", "question": "How do I turn documentation into training data?", "answer": "To turn documentation into training data, use `python training-data/scripts/generate_qa_from_skills.py --skill skill_name.md --model haiku` to generate Q&A pairs from individual skill files, or add the `--all` flag to process all skills at once. The tool outputs JSONL format containing questions, answers, and metadata. For source mapping-based generation from documentation, use `generate_quickstart_qa.py` instead. You can further enhance answers using `generate_tailored_answers.py` to reword them for diversity. The complete pipeline is documented in skill_synthetic_data.md.", "question_type": "medium", "topics": ["Quickstart", "Training Data"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["training data", "Q&A generation", "synthetic data", "documentation"], "related_skills": ["skill_synthetic_data.md", "skill_qa_generation.md"], "related_docs": ["training-data/scripts/generate_qa_from_skills.py", "training-data/scripts/generate_quickstart_qa.py"], "original_answer": "Use `python training-data/scripts/generate_qa_from_skills.py --skill skill_name.md --model haiku` to generate Q&A pairs from a skill file. For all skills, use `--all` flag. The tool outputs JSONL format with questions, answers, and metadata. You can also use `generate_quickstart_qa.py` for source mapping-based generation. See skill_synthetic_data.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_synthetic_data_002_q0", "cluster_id": "skill_synthetic_data_002", "question": "How do I expand my training dataset with reworded answers?", "answer": "Use `python scripts/generate_tailored_answers.py --input training-data/expanded --model sonnet` to generate reworded and alternative phrasings of answers for your existing Q&A pairs. You can specify `--provider gemini` to use Gemini instead of Claude, or add `--batch-size 5` to control how many pairs are processed at once. This expands your training dataset by creating multiple answer variations for the same question.", "question_type": "medium", "topics": ["Quickstart", "Training Data"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["training data", "answer tailoring", "LLM augmentation", "synthetic data"], "related_skills": ["skill_synthetic_data.md", "skill_answer_tailoring.md"], "related_docs": ["scripts/generate_tailored_answers.py"], "original_answer": "Use `python scripts/generate_tailored_answers.py --input training-data/expanded --model sonnet` to reword and tailor answers for existing Q&A pairs. You can specify `--provider gemini` to use Gemini instead of Claude. Add `--batch-size 5` to control processing batches. The tool generates alternative answer phrasings to expand your dataset. See skill_synthetic_data.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_synthetic_data_002_q1", "cluster_id": "skill_synthetic_data_002", "question": "Can I generate alternative answer variations?", "answer": "Yes, you can generate alternative answer variations using the `python scripts/generate_tailored_answers.py` command. This tool takes existing Q&A pairs from the `training-data/expanded` directory and creates reworded and tailored answer phrasings to expand your dataset. You can specify different LLM models with `--model sonnet` (Claude default) or switch providers with `--provider gemini`. Use `--batch-size 5` to control how many items are processed in each batch. This approach generates multiple phrasings of the same answer to increase training data diversity.", "question_type": "medium", "topics": ["Quickstart", "Training Data"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["training data", "answer tailoring", "LLM augmentation", "synthetic data"], "related_skills": ["skill_synthetic_data.md", "skill_answer_tailoring.md"], "related_docs": ["scripts/generate_tailored_answers.py"], "original_answer": "Use `python scripts/generate_tailored_answers.py --input training-data/expanded --model sonnet` to reword and tailor answers for existing Q&A pairs. You can specify `--provider gemini` to use Gemini instead of Claude. Add `--batch-size 5` to control processing batches. The tool generates alternative answer phrasings to expand your dataset. See skill_synthetic_data.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_synthetic_data_002_q2", "cluster_id": "skill_synthetic_data_002", "question": "How do I augment training data with LLM rewording?", "answer": "Use `python scripts/generate_tailored_answers.py --input training-data/expanded --model sonnet` to reword and augment your existing Q&A pairs with LLM-generated alternative answer phrasings. This expands your training dataset by creating multiple variations of the same answer. You can specify `--provider gemini` to use Gemini instead of Claude, and `--batch-size 5` to control processing batches.", "question_type": "medium", "topics": ["Quickstart", "Training Data"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["training data", "answer tailoring", "LLM augmentation", "synthetic data"], "related_skills": ["skill_synthetic_data.md", "skill_answer_tailoring.md"], "related_docs": ["scripts/generate_tailored_answers.py"], "original_answer": "Use `python scripts/generate_tailored_answers.py --input training-data/expanded --model sonnet` to reword and tailor answers for existing Q&A pairs. You can specify `--provider gemini` to use Gemini instead of Claude. Add `--batch-size 5` to control processing batches. The tool generates alternative answer phrasings to expand your dataset. See skill_synthetic_data.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_synthetic_data_003_q0", "cluster_id": "skill_synthetic_data_003", "question": "What LLM providers can I use for synthetic data generation?", "answer": "You can use Claude or Gemini for synthetic data generation. With Claude, use `--provider claude --model sonnet` (or haiku/opus). With Gemini, use `--provider gemini --model gemini-2.5-flash-preview`. Claude is the default provider. All synthetic data tools support these flags: generate_qa_from_skills.py, generate_tailored_answers.py, and generate_pearl_dataset.py.", "question_type": "medium", "topics": ["Quickstart", "Training Data"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["LLM providers", "Claude", "Gemini", "synthetic data"], "related_skills": ["skill_synthetic_data.md"], "related_docs": [], "original_answer": "Both Claude and Gemini are supported. For Claude use `--provider claude --model sonnet` (or haiku/opus). For Gemini use `--provider gemini --model gemini-2.5-flash-preview`. Claude is the default. All synthetic data tools accept these provider flags: generate_qa_from_skills.py, generate_tailored_answers.py, and generate_pearl_dataset.py. See skill_synthetic_data.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_synthetic_data_003_q1", "cluster_id": "skill_synthetic_data_003", "question": "Does the system support different AI models?", "answer": "Yes, the system supports multiple AI models. Claude is the default provider with options for sonnet, opus, or haiku models using `--provider claude --model <model>`. Gemini is also supported using `--provider gemini --model gemini-2.5-flash-preview`. All synthetic data generation tools (generate_qa_from_skills.py, generate_tailored_answers.py, and generate_pearl_dataset.py) accept these provider and model flags.", "question_type": "medium", "topics": ["Quickstart", "Training Data"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["LLM providers", "Claude", "Gemini", "synthetic data"], "related_skills": ["skill_synthetic_data.md"], "related_docs": [], "original_answer": "Both Claude and Gemini are supported. For Claude use `--provider claude --model sonnet` (or haiku/opus). For Gemini use `--provider gemini --model gemini-2.5-flash-preview`. Claude is the default. All synthetic data tools accept these provider flags: generate_qa_from_skills.py, generate_tailored_answers.py, and generate_pearl_dataset.py. See skill_synthetic_data.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_synthetic_data_003_q2", "cluster_id": "skill_synthetic_data_003", "question": "Can I use Gemini or Claude for training data?", "answer": "Yes, both Claude and Gemini are supported for training data generation. Use `--provider claude --model sonnet` (or haiku/opus) for Claude, or `--provider gemini --model gemini-2.5-flash-preview` for Gemini. Claude is the default. All synthetic data tools (generate_qa_from_skills.py, generate_tailored_answers.py, and generate_pearl_dataset.py) accept these provider flags.", "question_type": "medium", "topics": ["Quickstart", "Training Data"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["LLM providers", "Claude", "Gemini", "synthetic data"], "related_skills": ["skill_synthetic_data.md"], "related_docs": [], "original_answer": "Both Claude and Gemini are supported. For Claude use `--provider claude --model sonnet` (or haiku/opus). For Gemini use `--provider gemini --model gemini-2.5-flash-preview`. Claude is the default. All synthetic data tools accept these provider flags: generate_qa_from_skills.py, generate_tailored_answers.py, and generate_pearl_dataset.py. See skill_synthetic_data.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_synthetic_data_004_q0", "cluster_id": "skill_synthetic_data_004", "question": "How do I generate training data from Pearltrees?", "answer": "Use `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --output reports/pearltrees_targets.jsonl --query-style locate` to generate training targets from Pearltrees RDF exports in JSONL format. For additional dataset processing, use `expand_clusters_to_pairs.py` to expand clusters into Q&A pairs and `generate_tree_refpearls.py` to generate RefPearl datasets. The output is compatible with training pipelines and can be further tailored using `generate_tailored_answers.py` if needed.", "question_type": "medium", "topics": ["Quickstart", "Training Data"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["Pearltrees", "training data", "RDF", "dataset generation"], "related_skills": ["skill_synthetic_data.md", "skill_pearl_dataset.md"], "related_docs": ["scripts/generate_pearl_dataset.py", "scripts/expand_clusters_to_pairs.py", "scripts/generate_tree_refpearls.py"], "original_answer": "Use `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --output reports/pearltrees_targets.jsonl --query-style locate` to generate training targets from Pearltrees RDF exports. The output is JSONL format compatible with training pipelines. You can also use `expand_clusters_to_pairs.py` and `generate_tree_refpearls.py` for additional dataset processing. See skill_synthetic_data.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_synthetic_data_004_q1", "cluster_id": "skill_synthetic_data_004", "question": "Can I create datasets from Pearltrees RDF exports?", "answer": "Yes. Use `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --output reports/pearltrees_targets.jsonl --query-style locate` to generate training targets from Pearltrees RDF exports in JSONL format. For additional dataset processing, you can also use `expand_clusters_to_pairs.py` and `generate_tree_refpearls.py`. See skill_synthetic_data.md for complete details on the synthetic data pipeline.", "question_type": "medium", "topics": ["Quickstart", "Training Data"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["Pearltrees", "training data", "RDF", "dataset generation"], "related_skills": ["skill_synthetic_data.md", "skill_pearl_dataset.md"], "related_docs": ["scripts/generate_pearl_dataset.py", "scripts/expand_clusters_to_pairs.py", "scripts/generate_tree_refpearls.py"], "original_answer": "Use `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --output reports/pearltrees_targets.jsonl --query-style locate` to generate training targets from Pearltrees RDF exports. The output is JSONL format compatible with training pipelines. You can also use `expand_clusters_to_pairs.py` and `generate_tree_refpearls.py` for additional dataset processing. See skill_synthetic_data.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_synthetic_data_004_q2", "cluster_id": "skill_synthetic_data_004", "question": "How do I convert Pearltrees to training data?", "answer": "To convert Pearltrees to training data, use the command: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --output reports/pearltrees_targets.jsonl --query-style locate`. This generates JSONL-formatted training targets from your Pearltrees RDF exports. For additional processing, you can use `expand_clusters_to_pairs.py` to create Q&A pairs from clusters and `generate_tree_refpearls.py` to generate RefPearl datasets. All output follows the standard JSONL training data format compatible with UnifyWeaver's semantic search pipeline.", "question_type": "medium", "topics": ["Quickstart", "Training Data"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["Pearltrees", "training data", "RDF", "dataset generation"], "related_skills": ["skill_synthetic_data.md", "skill_pearl_dataset.md"], "related_docs": ["scripts/generate_pearl_dataset.py", "scripts/expand_clusters_to_pairs.py", "scripts/generate_tree_refpearls.py"], "original_answer": "Use `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --output reports/pearltrees_targets.jsonl --query-style locate` to generate training targets from Pearltrees RDF exports. The output is JSONL format compatible with training pipelines. You can also use `expand_clusters_to_pairs.py` and `generate_tree_refpearls.py` for additional dataset processing. See skill_synthetic_data.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_synthetic_data_005_q0", "cluster_id": "skill_synthetic_data_005", "question": "What's the workflow for creating training data from scratch?", "answer": "To create training data from scratch, follow this workflow: (1) Create a skill_*.md document containing the source material, (2) Run generate_qa_from_skills.py to automatically generate Q&A pairs from the skill document, (3) Review and manually edit the generated pairs for quality, (4) Use expand_clusters_to_pairs.py to expand grouped Q&A into individual question-answer pairs, (5) Apply generate_tailored_answers.py to reword and diversify answers. Output files are saved to training-data/by-topic/ for organized storage and training-data/expanded/ for final datasets. For Pearltrees-specific data, use generate_pearl_dataset.py with RDF exports. See skill_synthetic_data.md for complete documentation and CLI examples.", "question_type": "medium", "topics": ["Quickstart", "Training Data"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["training data pipeline", "bootstrap", "workflow", "synthetic data"], "related_skills": ["skill_synthetic_data.md", "skill_qa_generation.md", "skill_answer_tailoring.md"], "related_docs": ["training-data/scripts/generate_qa_from_skills.py", "scripts/expand_clusters_to_pairs.py", "scripts/generate_tailored_answers.py"], "original_answer": "The pipeline is: (1) Create a skill_*.md document, (2) Generate Q&A using generate_qa_from_skills.py, (3) Review and edit the generated pairs, (4) Expand to individual pairs with expand_clusters_to_pairs.py, (5) Generate tailored answers using generate_tailored_answers.py. Output files go to training-data/by-topic/ and training-data/expanded/. See skill_synthetic_data.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_synthetic_data_005_q1", "cluster_id": "skill_synthetic_data_005", "question": "How do I bootstrap training data for a new feature?", "answer": "To bootstrap training data for a new feature, follow this pipeline: (1) Create a skill_*.md document describing the feature, (2) Run generate_qa_from_skills.py to automatically generate Q&A pairs from your skill document, (3) Review and manually edit the generated pairs for accuracy, (4) Use expand_clusters_to_pairs.py to convert clustered Q&A into individual question-answer pairs, (5) Apply generate_tailored_answers.py to reword answers for diversity. Output files are saved to training-data/by-topic/ for clustered data and training-data/expanded/ for final pairs. Refer to skill_synthetic_data.md for detailed command examples and LLM provider options.", "question_type": "medium", "topics": ["Quickstart", "Training Data"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["training data pipeline", "bootstrap", "workflow", "synthetic data"], "related_skills": ["skill_synthetic_data.md", "skill_qa_generation.md", "skill_answer_tailoring.md"], "related_docs": ["training-data/scripts/generate_qa_from_skills.py", "scripts/expand_clusters_to_pairs.py", "scripts/generate_tailored_answers.py"], "original_answer": "The pipeline is: (1) Create a skill_*.md document, (2) Generate Q&A using generate_qa_from_skills.py, (3) Review and edit the generated pairs, (4) Expand to individual pairs with expand_clusters_to_pairs.py, (5) Generate tailored answers using generate_tailored_answers.py. Output files go to training-data/by-topic/ and training-data/expanded/. See skill_synthetic_data.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_synthetic_data_005_q2", "cluster_id": "skill_synthetic_data_005", "question": "What steps do I follow to build a complete training dataset?", "answer": "To build a complete training dataset, follow these steps: (1) Create a skill_*.md document containing the source material, (2) Generate Q&A pairs using generate_qa_from_skills.py with your chosen LLM provider, (3) Review and manually edit the generated pairs for quality, (4) Expand clustered pairs into individual question-answer pairs using expand_clusters_to_pairs.py, (5) Generate tailored/reworded answers using generate_tailored_answers.py to create variations. Output files are automatically organized in training-data/by-topic/ for initial pairs and training-data/expanded/ for final tailored datasets.", "question_type": "medium", "topics": ["Quickstart", "Training Data"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["training data pipeline", "bootstrap", "workflow", "synthetic data"], "related_skills": ["skill_synthetic_data.md", "skill_qa_generation.md", "skill_answer_tailoring.md"], "related_docs": ["training-data/scripts/generate_qa_from_skills.py", "scripts/expand_clusters_to_pairs.py", "scripts/generate_tailored_answers.py"], "original_answer": "The pipeline is: (1) Create a skill_*.md document, (2) Generate Q&A using generate_qa_from_skills.py, (3) Review and edit the generated pairs, (4) Expand to individual pairs with expand_clusters_to_pairs.py, (5) Generate tailored answers using generate_tailored_answers.py. Output files go to training-data/by-topic/ and training-data/expanded/. See skill_synthetic_data.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_synthetic_data_006_q0", "cluster_id": "skill_synthetic_data_006", "question": "What format should my training data be in?", "answer": "Training data should be in JSONL format, where each line is a complete JSON object containing: id (unique identifier), question (primary question), question_variants (alternative phrasings), level (0-3 specificity), tree_path (hierarchical tags), answer (response text), related_skills (skill file references), related_docs (documentation paths), and tags (searchable keywords).", "question_type": "medium", "topics": ["Quickstart", "Training Data"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["training data format", "JSONL", "output structure", "data schema"], "related_skills": ["skill_synthetic_data.md"], "related_docs": [], "original_answer": "All tools output JSONL format with fields: id (unique identifier), question (primary question), question_variants (alternative phrasings), level (0-3 specificity), tree_path (hierarchical tags), answer (response text), related_skills (skill file references), related_docs (documentation paths), and tags (searchable keywords). Each line is a complete JSON object. See skill_synthetic_data.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_synthetic_data_006_q1", "cluster_id": "skill_synthetic_data_006", "question": "What fields are in the training data output?", "answer": "Training data output uses JSONL format with the following fields: id (unique identifier for each entry), question (the primary question), question_variants (alternative ways to ask the same question), level (specificity level from 0-3), tree_path (hierarchical topic tags), answer (the response text), related_skills (references to relevant skill files), related_docs (paths to documentation files), and tags (searchable keywords). Each line in the JSONL file is a complete JSON object containing all these fields.", "question_type": "medium", "topics": ["Quickstart", "Training Data"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["training data format", "JSONL", "output structure", "data schema"], "related_skills": ["skill_synthetic_data.md"], "related_docs": [], "original_answer": "All tools output JSONL format with fields: id (unique identifier), question (primary question), question_variants (alternative phrasings), level (0-3 specificity), tree_path (hierarchical tags), answer (response text), related_skills (skill file references), related_docs (documentation paths), and tags (searchable keywords). Each line is a complete JSON object. See skill_synthetic_data.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_synthetic_data_006_q2", "cluster_id": "skill_synthetic_data_006", "question": "How is the generated training data structured?", "answer": "Generated training data is structured as JSONL format, where each line contains a complete JSON object with the following fields: id (unique identifier), question (primary question), question_variants (alternative phrasings), level (0-3 specificity scale), tree_path (hierarchical categorization tags), answer (response text), related_skills (references to skill files), related_docs (documentation file paths), and tags (searchable keywords). This consistent structure enables efficient batch processing and semantic indexing of training examples.", "question_type": "medium", "topics": ["Quickstart", "Training Data"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["training data format", "JSONL", "output structure", "data schema"], "related_skills": ["skill_synthetic_data.md"], "related_docs": [], "original_answer": "All tools output JSONL format with fields: id (unique identifier), question (primary question), question_variants (alternative phrasings), level (0-3 specificity), tree_path (hierarchical tags), answer (response text), related_skills (skill file references), related_docs (documentation paths), and tags (searchable keywords). Each line is a complete JSON object. See skill_synthetic_data.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_theming_001_q0", "cluster_id": "skill_theming_001", "question": "How do I define consistent colors and fonts across my app?", "answer": "Use `define_theme/2` to create a theme with colors, typography, spacing, borders, and shadows that will be applied consistently across your app. Define your theme once with `define_theme(my_app, [colors([primary-'#007AFF', background-'#FFFFFF']), typography([family-'Inter', sizeBase-16]), spacing([sm-8, md-16, lg-24])])`, then generate platform-specific code using `generate_theme_code(my_app, vue, CSS)` for Vue, React Native, Flutter, or SwiftUI. This ensures all UI components use the same design tokens regardless of platform.", "question_type": "medium", "topics": ["Quickstart", "Theming"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["design-tokens", "colors", "typography", "theming"], "related_skills": ["skill_component_library.md", "skill_layout_system.md", "skill_responsive_design.md", "skill_gui_design.md", "skill_theming.md"], "related_docs": ["src/unifyweaver/theming/theming.pl", "src/unifyweaver/glue/theme_generator.pl"], "original_answer": "Use `define_theme/2` to create a theme with colors, typography, spacing, borders, and shadows. Example:\n```prolog\ndefine_theme(my_app, [\n    colors([primary-'#007AFF', background-'#FFFFFF']),\n    typography([family-'Inter', sizeBase-16]),\n    spacing([sm-8, md-16, lg-24])\n]).\n```\nThen generate code for your platform with `generate_theme_code(my_app, vue, CSS)`. Supports react_native, vue, flutter, and swiftui targets. See skill_theming.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_theming_001_q1", "cluster_id": "skill_theming_001", "question": "How do I set up a color palette and typography?", "answer": "Use `define_theme/2` to set up a color palette and typography for your app. Provide colors as key-value pairs (e.g., `primary-'#007AFF'`) and typography settings like font family and base size:\n\n```prolog\ndefine_theme(my_app, [\n    colors([primary-'#007AFF', secondary-'#5AC8FA', background-'#FFFFFF']),\n    typography([family-'Inter', sizeBase-16, fontWeight-500])\n]).\n```\n\nThen generate platform-specific code using `generate_theme_code(my_app, Platform, Output)` where Platform can be `vue`, `react_native`, `flutter`, or `swiftui`. This creates a unified theme that applies consistently across your UI components.", "question_type": "medium", "topics": ["Quickstart", "Theming"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["design-tokens", "colors", "typography", "theming"], "related_skills": ["skill_component_library.md", "skill_layout_system.md", "skill_responsive_design.md", "skill_gui_design.md", "skill_theming.md"], "related_docs": ["src/unifyweaver/theming/theming.pl", "src/unifyweaver/glue/theme_generator.pl"], "original_answer": "Use `define_theme/2` to create a theme with colors, typography, spacing, borders, and shadows. Example:\n```prolog\ndefine_theme(my_app, [\n    colors([primary-'#007AFF', background-'#FFFFFF']),\n    typography([family-'Inter', sizeBase-16]),\n    spacing([sm-8, md-16, lg-24])\n]).\n```\nThen generate code for your platform with `generate_theme_code(my_app, vue, CSS)`. Supports react_native, vue, flutter, and swiftui targets. See skill_theming.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_theming_001_q2", "cluster_id": "skill_theming_001", "question": "How do I create a design system with colors and fonts?", "answer": "Use `define_theme/2` to create a design system with colors and fonts. Example:\n```prolog\ndefine_theme(my_design_system, [\n    colors([primary-'#007AFF', secondary-'#5AC8FA', background-'#FFFFFF']),\n    typography([family-'Inter', sizeBase-16, headingFamily-'Helvetica'])\n]).\n```\nThen generate platform-specific code with `generate_theme_code(my_design_system, vue, CSS)`. Supports react_native, flutter, and swiftui as target platforms. This creates a centralized design system for consistent styling across your application.", "question_type": "medium", "topics": ["Quickstart", "Theming"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["design-tokens", "colors", "typography", "theming"], "related_skills": ["skill_component_library.md", "skill_layout_system.md", "skill_responsive_design.md", "skill_gui_design.md", "skill_theming.md"], "related_docs": ["src/unifyweaver/theming/theming.pl", "src/unifyweaver/glue/theme_generator.pl"], "original_answer": "Use `define_theme/2` to create a theme with colors, typography, spacing, borders, and shadows. Example:\n```prolog\ndefine_theme(my_app, [\n    colors([primary-'#007AFF', background-'#FFFFFF']),\n    typography([family-'Inter', sizeBase-16]),\n    spacing([sm-8, md-16, lg-24])\n]).\n```\nThen generate code for your platform with `generate_theme_code(my_app, vue, CSS)`. Supports react_native, vue, flutter, and swiftui targets. See skill_theming.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "Base answer covers theme creation but could be more explicit about typography font configuration. Confidence is good but not highest because the answer doesn't provide a complete typography example showing multiple font sizes or weights."}
{"pair_id": "skill_theming_002_q0", "cluster_id": "skill_theming_002", "question": "How do I add dark mode to my app?", "answer": "To add dark mode to your app, define a dark variant using `define_variant/3` that overrides your theme tokens:\n\n```prolog\ndefine_variant(modern_app, dark, [\n    colors([\n        background-'#1C1C1E',\n        surface-'#2C2C2E',\n        text-'#FFFFFF'\n    ])\n]).\n```\n\nThen apply the dark variant with `apply_variant(BaseTheme, dark, Result)` or retrieve it with `get_variant(modern_app, dark, DarkTheme)`. The variant will override specified tokens while inheriting unmodified tokens from your base theme. Refer to skill_theming.md for complete theming documentation.", "question_type": "medium", "topics": ["Quickstart", "Theming"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["dark-mode", "variants", "theming"], "related_skills": ["skill_component_library.md", "skill_responsive_design.md", "skill_theming.md"], "related_docs": ["src/unifyweaver/theming/theming.pl"], "original_answer": "Define a dark variant using `define_variant/3` to override colors and other tokens:\n```prolog\ndefine_variant(modern_app, dark, [\n    colors([\n        background-'#1C1C1E',\n        surface-'#2C2C2E',\n        text-'#FFFFFF'\n    ])\n]).\n```\nThen merge it with `apply_variant(BaseTheme, dark, Result)` or retrieve with `get_variant(modern_app, dark, DarkTheme)`. The variant overrides inherit unmodified tokens from the base theme. See skill_theming.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer assumes familiarity with define_variant/3 and doesn't explain how to toggle between light and dark modes at runtime or how to detect system preferences. It focuses on the technical implementation but lacks context about when to apply the variant during app lifecycle."}
{"pair_id": "skill_theming_002_q1", "cluster_id": "skill_theming_002", "question": "How do I create light and dark themes?", "answer": "To create light and dark themes, define a dark variant using `define_variant/3` that overrides the base theme's colors and tokens. For example:\n\n```prolog\ndefine_variant(modern_app, dark, [\n    colors([\n        background-'#1C1C1E',\n        surface-'#2C2C2E',\n        text-'#FFFFFF'\n    ])\n]).\n```\n\nThen apply the variant with `apply_variant(BaseTheme, dark, Result)` to merge it with your base theme, or retrieve it directly with `get_variant(modern_app, dark, DarkTheme)`. The variant inherits any unmodified tokens from the base theme, so you only need to override the colors and properties that differ between light and dark modes. For comprehensive theming options, see skill_theming.md.", "question_type": "medium", "topics": ["Quickstart", "Theming"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["dark-mode", "variants", "theming"], "related_skills": ["skill_component_library.md", "skill_responsive_design.md", "skill_theming.md"], "related_docs": ["src/unifyweaver/theming/theming.pl"], "original_answer": "Define a dark variant using `define_variant/3` to override colors and other tokens:\n```prolog\ndefine_variant(modern_app, dark, [\n    colors([\n        background-'#1C1C1E',\n        surface-'#2C2C2E',\n        text-'#FFFFFF'\n    ])\n]).\n```\nThen merge it with `apply_variant(BaseTheme, dark, Result)` or retrieve with `get_variant(modern_app, dark, DarkTheme)`. The variant overrides inherit unmodified tokens from the base theme. See skill_theming.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer assumes familiarity with the theming module and doesn't mention how to actually switch between themes at runtime. It also doesn't clarify whether a light variant needs to be explicitly defined or if it serves as the base."}
{"pair_id": "skill_theming_002_q2", "cluster_id": "skill_theming_002", "question": "How do I support dark mode variants?", "answer": "Support dark mode by defining a dark variant using `define_variant/3` that overrides the base theme's tokens:\n\n```prolog\ndefine_variant(modern_app, dark, [\n    colors([\n        background-'#1C1C1E',\n        surface-'#2C2C2E',\n        text-'#FFFFFF'\n    ])\n]).\n```\n\nThen apply it with `apply_variant(BaseTheme, dark, Result)` or retrieve it with `get_variant(modern_app, dark, DarkTheme)`. The dark variant inherits any unmodified tokens from the base theme, so you only need to override colors and properties that differ in dark mode.", "question_type": "medium", "topics": ["Quickstart", "Theming"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["dark-mode", "variants", "theming"], "related_skills": ["skill_component_library.md", "skill_responsive_design.md", "skill_theming.md"], "related_docs": ["src/unifyweaver/theming/theming.pl"], "original_answer": "Define a dark variant using `define_variant/3` to override colors and other tokens:\n```prolog\ndefine_variant(modern_app, dark, [\n    colors([\n        background-'#1C1C1E',\n        surface-'#2C2C2E',\n        text-'#FFFFFF'\n    ])\n]).\n```\nThen merge it with `apply_variant(BaseTheme, dark, Result)` or retrieve with `get_variant(modern_app, dark, DarkTheme)`. The variant overrides inherit unmodified tokens from the base theme. See skill_theming.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_theming_003_q0", "cluster_id": "skill_theming_003", "question": "How do I generate theme code for different platforms?", "answer": "Use `generate_theme_code(ThemeName, Target, Code)` to generate platform-specific theme code. Supported targets are: `react_native` (outputs JavaScript object), `vue` (outputs CSS custom properties), `flutter` (outputs Dart class), and `swiftui` (outputs Swift struct). Each target uses idiomatic syntax for that platform\u2014CSS variables for Vue, Dart Color classes for Flutter, Swift Color for SwiftUI, etc. Example: `generate_theme_code(my_app, vue, CSS)` generates Vue-compatible CSS theme code.", "question_type": "medium", "topics": ["Quickstart", "Theming"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["code-generation", "react-native", "vue", "flutter", "swiftui"], "related_skills": ["skill_component_library.md", "skill_theming.md"], "related_docs": ["src/unifyweaver/glue/theme_generator.pl"], "original_answer": "Use `generate_theme_code(ThemeName, Target, Code)` with targets: react_native (JavaScript object), vue (CSS custom properties), flutter (Dart class), or swiftui (Swift struct). Example:\n```prolog\ngenerate_theme_code(my_app, vue, CSS).\n```\nThis outputs platform-specific code with all design tokens formatted appropriately. Each platform uses idiomatic syntax (CSS variables for Vue, Swift Color for SwiftUI, etc.). See skill_theming.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_theming_003_q1", "cluster_id": "skill_theming_003", "question": "How do I export my theme to Vue/React/Flutter?", "answer": "Use `generate_theme_code(ThemeName, Target, Code)` to export your theme. Supported targets are: `vue` (CSS custom properties), `react_native` (JavaScript object), `flutter` (Dart class), or `swiftui` (Swift struct). Example: `generate_theme_code(my_app, vue, CSS)` outputs CSS variables; `generate_theme_code(my_app, flutter, DartCode)` outputs a Dart class with design tokens. Each platform uses idiomatic syntax for that framework.", "question_type": "medium", "topics": ["Quickstart", "Theming"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["code-generation", "react-native", "vue", "flutter", "swiftui"], "related_skills": ["skill_component_library.md", "skill_theming.md"], "related_docs": ["src/unifyweaver/glue/theme_generator.pl"], "original_answer": "Use `generate_theme_code(ThemeName, Target, Code)` with targets: react_native (JavaScript object), vue (CSS custom properties), flutter (Dart class), or swiftui (Swift struct). Example:\n```prolog\ngenerate_theme_code(my_app, vue, CSS).\n```\nThis outputs platform-specific code with all design tokens formatted appropriately. Each platform uses idiomatic syntax (CSS variables for Vue, Swift Color for SwiftUI, etc.). See skill_theming.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_theming_003_q2", "cluster_id": "skill_theming_003", "question": "How do I output theme code for multiple platforms?", "answer": "Use `generate_theme_code(ThemeName, Target, Code)` to output theme code for multiple platforms. Call it separately for each target platform: `react_native` (JavaScript object), `vue` (CSS custom properties), `flutter` (Dart class), or `swiftui` (Swift struct). Each invocation generates idiomatic code for that platform\u2014CSS variables for Vue, Dart classes for Flutter, Swift Color structs for SwiftUI, and JavaScript objects for React Native. Example: `generate_theme_code(my_app, vue, CSS)` outputs Vue-formatted theme code. Repeat for other platforms with their respective target atoms.", "question_type": "medium", "topics": ["Quickstart", "Theming"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["code-generation", "react-native", "vue", "flutter", "swiftui"], "related_skills": ["skill_component_library.md", "skill_theming.md"], "related_docs": ["src/unifyweaver/glue/theme_generator.pl"], "original_answer": "Use `generate_theme_code(ThemeName, Target, Code)` with targets: react_native (JavaScript object), vue (CSS custom properties), flutter (Dart class), or swiftui (Swift struct). Example:\n```prolog\ngenerate_theme_code(my_app, vue, CSS).\n```\nThis outputs platform-specific code with all design tokens formatted appropriately. Each platform uses idiomatic syntax (CSS variables for Vue, Swift Color for SwiftUI, etc.). See skill_theming.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_theming_004_q0", "cluster_id": "skill_theming_004", "question": "How do I resolve specific design tokens from my theme?", "answer": "Use `resolve_token(token(Category, Name), Theme, Value)` to get a single design token value:\n\n```prolog\n?- get_theme(modern_app, Theme),\n   resolve_token(token(colors, primary), Theme, Value).\nValue = '#007AFF'\n```\n\nFor resolving multiple token references at once, use `resolve_all_tokens(Spec, Theme, Resolved)` which recursively resolves all token references in a specification. This is particularly useful when you need to resolve tokens embedded in component specifications.", "question_type": "long", "topics": ["Quickstart", "Theming"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["token-resolution", "design-tokens"], "related_skills": ["skill_theming.md"], "related_docs": ["src/unifyweaver/theming/theming.pl"], "original_answer": "Use `resolve_token(token(Category, Name), Theme, Value)` to get a single token:\n```prolog\n?- get_theme(modern_app, Theme),\n   resolve_token(token(colors, primary), Theme, Value).\nValue = '#007AFF'\n```\nOr use `resolve_all_tokens(Spec, Theme, Resolved)` to recursively resolve all token references in a specification. This is useful for resolving tokens in component specs. See skill_theming.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_theming_004_q1", "cluster_id": "skill_theming_004", "question": "How do I get a specific color or font value?", "answer": "Use `resolve_token(token(Category, Name), Theme, Value)` to retrieve a specific color or font value from your theme:\n\n```prolog\n?- get_theme(modern_app, Theme),\n   resolve_token(token(colors, primary), Theme, Value).\nValue = '#007AFF'\n```\n\nFor fonts, use the typography category:\n\n```prolog\n?- get_theme(modern_app, Theme),\n   resolve_token(token(typography, family), Theme, Value).\nValue = 'Inter'\n```\n\nIf you need to resolve multiple token references within a specification, use `resolve_all_tokens(Spec, Theme, Resolved)` instead.", "question_type": "long", "topics": ["Quickstart", "Theming"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["token-resolution", "design-tokens"], "related_skills": ["skill_theming.md"], "related_docs": ["src/unifyweaver/theming/theming.pl"], "original_answer": "Use `resolve_token(token(Category, Name), Theme, Value)` to get a single token:\n```prolog\n?- get_theme(modern_app, Theme),\n   resolve_token(token(colors, primary), Theme, Value).\nValue = '#007AFF'\n```\nOr use `resolve_all_tokens(Spec, Theme, Resolved)` to recursively resolve all token references in a specification. This is useful for resolving tokens in component specs. See skill_theming.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_theming_004_q2", "cluster_id": "skill_theming_004", "question": "How do I look up a token value from my theme?", "answer": "Use `resolve_token(token(Category, Name), Theme, Value)` to look up a single token value from your theme:\n\n```prolog\n?- get_theme(modern_app, Theme),\n   resolve_token(token(colors, primary), Theme, Value).\nValue = '#007AFF'\n```\n\nFor resolving multiple token references within a specification, use `resolve_all_tokens(Spec, Theme, Resolved)` which recursively resolves all token references.", "question_type": "long", "topics": ["Quickstart", "Theming"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["token-resolution", "design-tokens"], "related_skills": ["skill_theming.md"], "related_docs": ["src/unifyweaver/theming/theming.pl"], "original_answer": "Use `resolve_token(token(Category, Name), Theme, Value)` to get a single token:\n```prolog\n?- get_theme(modern_app, Theme),\n   resolve_token(token(colors, primary), Theme, Value).\nValue = '#007AFF'\n```\nOr use `resolve_all_tokens(Spec, Theme, Resolved)` to recursively resolve all token references in a specification. This is useful for resolving tokens in component specs. See skill_theming.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_theming_005_q0", "cluster_id": "skill_theming_005", "question": "How do I organize a semantic color palette with actions and states?", "answer": "Organize a semantic color palette by grouping colors according to their functional purpose. Define a theme that separates colors into categories: actions (primary interactive elements, destructive actions), states (success, warning, error feedback), and surfaces (backgrounds, cards, elevated elements). For example, use `actionPrimary` for main interactive buttons, `actionDestructive` for delete/remove actions, `stateSuccess` for positive feedback, `stateWarning` for alerts, and surface colors for backgrounds and containers. This semantic grouping makes the palette self-documenting and easier to maintain across your design system, since each color name explicitly conveys its purpose rather than generic names like `blue-500`.", "question_type": "long", "topics": ["Quickstart", "Theming"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["semantic-colors", "design-system"], "related_skills": ["skill_gui_design.md", "skill_theming.md"], "related_docs": ["src/unifyweaver/theming/theming.pl"], "original_answer": "Define a semantic theme grouping colors by their purpose:\n```prolog\ndefine_theme(semantic, [\n    colors([\n        actionPrimary-'#007AFF',\n        actionDestructive-'#FF3B30',\n        stateSuccess-'#34C759',\n        stateWarning-'#FF9500',\n        surfaceBackground-'#FFFFFF',\n        surfaceCard-'#F2F2F7'\n    ])\n]).\n```\nThis approach makes it clear which colors are used for interactive elements, feedback states, and background surfaces, improving maintainability across the design system. See skill_theming.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_theming_005_q1", "cluster_id": "skill_theming_005", "question": "How do I define semantic colors for different UI states?", "answer": "Define semantic colors by grouping them by purpose in your theme configuration:\n\n```prolog\ndefine_theme(semantic, [\n    colors([\n        actionPrimary-'#007AFF',\n        actionDestructive-'#FF3B30',\n        stateSuccess-'#34C759',\n        stateWarning-'#FF9500',\n        stateError-'#FF3B30',\n        stateDisabled-'#C7C7CC',\n        surfaceBackground-'#FFFFFF',\n        surfaceCard-'#F2F2F7'\n    ])\n]).\n```\n\nOrganize colors into categories:\n- **action***: Interactive elements (primary, secondary, destructive)\n- **state***: Feedback states (success, warning, error, disabled)\n- **surface***: Background layers (background, card, elevated)\n\nThis semantic approach clarifies intent across your design system and makes maintenance easier when updating colors globally. Reference skill_theming.md for additional theming options like typography and dark mode variants.", "question_type": "long", "topics": ["Quickstart", "Theming"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["semantic-colors", "design-system"], "related_skills": ["skill_gui_design.md", "skill_theming.md"], "related_docs": ["src/unifyweaver/theming/theming.pl"], "original_answer": "Define a semantic theme grouping colors by their purpose:\n```prolog\ndefine_theme(semantic, [\n    colors([\n        actionPrimary-'#007AFF',\n        actionDestructive-'#FF3B30',\n        stateSuccess-'#34C759',\n        stateWarning-'#FF9500',\n        surfaceBackground-'#FFFFFF',\n        surfaceCard-'#F2F2F7'\n    ])\n]).\n```\nThis approach makes it clear which colors are used for interactive elements, feedback states, and background surfaces, improving maintainability across the design system. See skill_theming.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_theming_005_q2", "cluster_id": "skill_theming_005", "question": "How do I structure colors by purpose (actions, states, surfaces)?", "answer": "Structure colors by purpose using a semantic theme that organizes them into functional categories:\n\n```prolog\ndefine_theme(semantic, [\n    colors([\n        % Actions - interactive elements\n        actionPrimary-'#007AFF',\n        actionDestructive-'#FF3B30',\n        % States - feedback and status\n        stateSuccess-'#34C759',\n        stateWarning-'#FF9500',\n        stateError-'#FF3B30',\n        stateInfo-'#007AFF',\n        % Surfaces - backgrounds and containers\n        surfaceBackground-'#FFFFFF',\n        surfaceCard-'#F2F2F7',\n        surfaceOverlay-'#000000'\n    ])\n]).\n```\n\nThis semantic grouping clarifies which colors serve interactive purposes (actions), communicate status (states), or structure layout (surfaces). It improves maintainability by associating colors with their role rather than arbitrary names, making the design system easier to apply consistently across platforms.", "question_type": "long", "topics": ["Quickstart", "Theming"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["semantic-colors", "design-system"], "related_skills": ["skill_gui_design.md", "skill_theming.md"], "related_docs": ["src/unifyweaver/theming/theming.pl"], "original_answer": "Define a semantic theme grouping colors by their purpose:\n```prolog\ndefine_theme(semantic, [\n    colors([\n        actionPrimary-'#007AFF',\n        actionDestructive-'#FF3B30',\n        stateSuccess-'#34C759',\n        stateWarning-'#FF9500',\n        surfaceBackground-'#FFFFFF',\n        surfaceCard-'#F2F2F7'\n    ])\n]).\n```\nThis approach makes it clear which colors are used for interactive elements, feedback states, and background surfaces, improving maintainability across the design system. See skill_theming.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_theming_006_q0", "cluster_id": "skill_theming_006", "question": "How do I create a modular typography scale for my app?", "answer": "Create a modular typography scale by defining a theme with proportional font sizes, weights, and line heights. Use a consistent scaling factor (like 1.25x) between size steps to maintain visual harmony:\n\n```prolog\ndefine_theme(typography_scale, [\n    typography([\n        sizeXs-10, sizeSm-12.8, sizeBase-16, sizeLg-20, sizeXl-25,\n        family-'Inter', familyMono-'SF Mono',\n        weightNormal-400, weightMedium-500, weightBold-700,\n        lineHeightTight-1.25, lineHeightNormal-1.5\n    ])\n]).\n```\n\nApply this scale across your components by referencing the theme. The modular approach ensures consistent typography throughout your app while maintaining proportional relationships between font sizes. Include multiple font families (regular and monospace) and weights to support different content contexts.", "question_type": "long", "topics": ["Quickstart", "Theming"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["typography", "font-sizes", "design-tokens"], "related_skills": ["skill_gui_design.md", "skill_theming.md"], "related_docs": ["src/unifyweaver/theming/theming.pl"], "original_answer": "Define typography with multiple font sizes, weights, and line heights:\n```prolog\ndefine_theme(modular_type, [\n    typography([\n        sizeXs-10, sizeSm-12.8, sizeBase-16, sizeLg-20, sizeXl-25,\n        family-'Inter', familyMono-'SF Mono',\n        weightNormal-400, weightMedium-500, weightBold-700,\n        lineHeightTight-1.25, lineHeightNormal-1.5\n    ])\n]).\n```\nUse a consistent scale factor (e.g., 1.25x) between sizes for visual harmony. Include multiple font families and weights for different contexts. See skill_theming.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_theming_006_q1", "cluster_id": "skill_theming_006", "question": "How do I define font sizes with consistent scaling?", "answer": "Define typography with a consistent scale factor between font sizes. Use `define_theme/2` with `typography/1` to specify sizes, weights, and line heights:\n\n```prolog\ndefine_theme(modular_type, [\n    typography([\n        sizeXs-10, sizeSm-12.8, sizeBase-16, sizeLg-20, sizeXl-25,\n        family-'Inter', familyMono-'SF Mono',\n        weightNormal-400, weightMedium-500, weightBold-700,\n        lineHeightTight-1.25, lineHeightNormal-1.5\n    ])\n]).\n```\n\nThe example uses a 1.25x scale factor between sizes (10 \u2192 12.8 \u2192 16 \u2192 20 \u2192 25). Include multiple font families and weights for different UI contexts. This ensures consistent typography scaling across your entire application.", "question_type": "long", "topics": ["Quickstart", "Theming"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["typography", "font-sizes", "design-tokens"], "related_skills": ["skill_gui_design.md", "skill_theming.md"], "related_docs": ["src/unifyweaver/theming/theming.pl"], "original_answer": "Define typography with multiple font sizes, weights, and line heights:\n```prolog\ndefine_theme(modular_type, [\n    typography([\n        sizeXs-10, sizeSm-12.8, sizeBase-16, sizeLg-20, sizeXl-25,\n        family-'Inter', familyMono-'SF Mono',\n        weightNormal-400, weightMedium-500, weightBold-700,\n        lineHeightTight-1.25, lineHeightNormal-1.5\n    ])\n]).\n```\nUse a consistent scale factor (e.g., 1.25x) between sizes for visual harmony. Include multiple font families and weights for different contexts. See skill_theming.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_theming_006_q2", "cluster_id": "skill_theming_006", "question": "How do I set up a typography scale with multiple sizes?", "answer": "To set up a typography scale with multiple sizes, define a theme with a typography specification that includes multiple font sizes, weights, and line heights:\n\n```prolog\ndefine_theme(modular_type, [\n    typography([\n        sizeXs-10, sizeSm-12.8, sizeBase-16, sizeLg-20, sizeXl-25,\n        family-'Inter', familyMono-'SF Mono',\n        weightNormal-400, weightMedium-500, weightBold-700,\n        lineHeightTight-1.25, lineHeightNormal-1.5\n    ])\n]).\n```\n\nUse a consistent scale factor (e.g., 1.25x) between sizes to maintain visual harmony. Include multiple font families (e.g., 'Inter' for regular text, 'SF Mono' for code) and weights (400 for normal, 500 for medium, 700 for bold) to support different semantic contexts in your UI.", "question_type": "long", "topics": ["Quickstart", "Theming"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["typography", "font-sizes", "design-tokens"], "related_skills": ["skill_gui_design.md", "skill_theming.md"], "related_docs": ["src/unifyweaver/theming/theming.pl"], "original_answer": "Define typography with multiple font sizes, weights, and line heights:\n```prolog\ndefine_theme(modular_type, [\n    typography([\n        sizeXs-10, sizeSm-12.8, sizeBase-16, sizeLg-20, sizeXl-25,\n        family-'Inter', familyMono-'SF Mono',\n        weightNormal-400, weightMedium-500, weightBold-700,\n        lineHeightTight-1.25, lineHeightNormal-1.5\n    ])\n]).\n```\nUse a consistent scale factor (e.g., 1.25x) between sizes for visual harmony. Include multiple font families and weights for different contexts. See skill_theming.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_train_model_001_q0", "cluster_id": "skill_train_model_001", "question": "How do I train a model for folder suggestion and bookmark filing?", "answer": "To train a model for folder suggestion and bookmark filing, use the training script with your JSONL data containing materialized folder paths:\n\n```bash\npython3 scripts/train_pearltrees_federated.py \\\n  reports/pearltrees_targets.jsonl \\\n  models/pearltrees_federated.pkl\n```\n\nYour JSONL file should include `target_text` fields with folder hierarchies like \"Science/Physics/Quantum Mechanics\". The script trains federated projection matrices using Procrustes alignment, creating a `.pkl` model file with cluster assignments. You can customize clustering with `--cluster-method mst` (recommended for hierarchies) or `--model` to change the embedding model. Run `--help` for all options.", "question_type": "medium", "topics": ["Quickstart", "Train Federated Model"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["training", "model", "embeddings", "setup"], "related_skills": ["skill_train_model.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "docs/QUICKSTART_MINDMAP_LINKING.md", "education/book-14-ai-training/05_training_pipeline.md"], "original_answer": "Use the training script with your JSONL data:\n\n```bash\npython3 scripts/train_pearltrees_federated.py reports/pearltrees_targets.jsonl models/pearltrees_federated.pkl\n```\n\nYour JSONL file should have `target_text` fields with materialized paths like \"Science/Physics/Quantum Mechanics\". The script creates a `.pkl` model file with federated projection matrices and clustering assignments. See skill_train_model.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_train_model_001_q1", "cluster_id": "skill_train_model_001", "question": "How do I create a trained model for my data?", "answer": "To create a trained model for your data, use the training script with your JSONL file:\n\n```bash\npython3 scripts/train_pearltrees_federated.py reports/pearltrees_targets.jsonl models/pearltrees_federated.pkl\n```\n\nYour JSONL file must contain `target_text` fields with materialized hierarchy paths (e.g., \"Science/Physics/Quantum Mechanics\"). The script generates a `.pkl` model file containing federated projection matrices and cluster assignments. You can customize the embedding model and clustering method using optional flags like `--model nomic-ai/nomic-embed-text-v1.5` and `--cluster-method mst`. Run with `--help` to see all available options.", "question_type": "medium", "topics": ["Quickstart", "Train Federated Model"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["training", "model", "embeddings", "setup"], "related_skills": ["skill_train_model.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "docs/QUICKSTART_MINDMAP_LINKING.md", "education/book-14-ai-training/05_training_pipeline.md"], "original_answer": "Use the training script with your JSONL data:\n\n```bash\npython3 scripts/train_pearltrees_federated.py reports/pearltrees_targets.jsonl models/pearltrees_federated.pkl\n```\n\nYour JSONL file should have `target_text` fields with materialized paths like \"Science/Physics/Quantum Mechanics\". The script creates a `.pkl` model file with federated projection matrices and clustering assignments. See skill_train_model.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_train_model_001_q2", "cluster_id": "skill_train_model_001", "question": "What's the command to train a semantic search model?", "answer": "To train a semantic search model, run:\n\n```bash\npython3 scripts/train_pearltrees_federated.py INPUT_JSONL OUTPUT_MODEL.pkl\n```\n\nReplace INPUT_JSONL with your data file (JSONL format with `target_text` fields containing materialized paths like \"Science/Physics/Quantum Mechanics\"). The script generates a `.pkl` model file containing federated projection matrices and cluster assignments.\n\nFor advanced options like MST clustering or specific embedding models, use `--help` to see all flags.", "question_type": "medium", "topics": ["Quickstart", "Train Federated Model"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["training", "model", "embeddings", "setup"], "related_skills": ["skill_train_model.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "docs/QUICKSTART_MINDMAP_LINKING.md", "education/book-14-ai-training/05_training_pipeline.md"], "original_answer": "Use the training script with your JSONL data:\n\n```bash\npython3 scripts/train_pearltrees_federated.py reports/pearltrees_targets.jsonl models/pearltrees_federated.pkl\n```\n\nYour JSONL file should have `target_text` fields with materialized paths like \"Science/Physics/Quantum Mechanics\". The script creates a `.pkl` model file with federated projection matrices and clustering assignments. See skill_train_model.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_train_model_002_q0", "cluster_id": "skill_train_model_002", "question": "What embedding models can I use for training?", "answer": "You can use three embedding models for training:\n\n- `nomic-ai/nomic-embed-text-v1.5` (768 dimensions) - default, recommended for best quality\n- `sentence-transformers/all-MiniLM-L6-v2` (384 dimensions) - faster option\n- `BAAI/bge-small-en-v1.5` (384 dimensions) - good quality with balanced performance\n\nSpecify your choice using the `--model` flag when training:\n\n```bash\npython3 scripts/train_pearltrees_federated.py input.jsonl output.pkl --model nomic-ai/nomic-embed-text-v1.5\n```\n\nThe default is nomic-ai/nomic-embed-text-v1.5 if you don't specify a model.", "question_type": "long", "topics": ["Quickstart", "Train Federated Model"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["embeddings", "models", "configuration"], "related_skills": ["skill_train_model.md", "skill_embedding_models.md"], "related_docs": ["education/book-14-ai-training/02_embedding_providers.md"], "original_answer": "Three models are recommended:\n\n- `nomic-ai/nomic-embed-text-v1.5` (768 dims, default) - best quality\n- `sentence-transformers/all-MiniLM-L6-v2` (384 dims) - faster\n- `BAAI/bge-small-en-v1.5` (384 dims) - good quality, balanced\n\nUse the `--model` flag:\n\n```bash\npython3 scripts/train_pearltrees_federated.py input.jsonl output.pkl --model nomic-ai/nomic-embed-text-v1.5\n```\n\nSee skill_train_model.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_train_model_002_q1", "cluster_id": "skill_train_model_002", "question": "Which embedding models are available?", "answer": "UnifyWeaver supports three embedding models for semantic search training:\n\n- **nomic-ai/nomic-embed-text-v1.5** (768 dimensions) - Default and recommended for best quality\n- **sentence-transformers/all-MiniLM-L6-v2** (384 dimensions) - Faster alternative with smaller memory footprint\n- **BAAI/bge-small-en-v1.5** (384 dimensions) - Balanced option with good quality\n\nSpecify your choice using the `--model` flag when training:\n\n```bash\npython3 scripts/train_pearltrees_federated.py input.jsonl output.pkl --model nomic-ai/nomic-embed-text-v1.5\n```\n\nThe default model (nomic-ai/nomic-embed-text-v1.5) provides the highest quality embeddings and is recommended unless you need faster training or reduced memory usage.", "question_type": "long", "topics": ["Quickstart", "Train Federated Model"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["embeddings", "models", "configuration"], "related_skills": ["skill_train_model.md", "skill_embedding_models.md"], "related_docs": ["education/book-14-ai-training/02_embedding_providers.md"], "original_answer": "Three models are recommended:\n\n- `nomic-ai/nomic-embed-text-v1.5` (768 dims, default) - best quality\n- `sentence-transformers/all-MiniLM-L6-v2` (384 dims) - faster\n- `BAAI/bge-small-en-v1.5` (384 dims) - good quality, balanced\n\nUse the `--model` flag:\n\n```bash\npython3 scripts/train_pearltrees_federated.py input.jsonl output.pkl --model nomic-ai/nomic-embed-text-v1.5\n```\n\nSee skill_train_model.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_train_model_002_q2", "cluster_id": "skill_train_model_002", "question": "What's the best embedding model to use?", "answer": "For UnifyWeaver's semantic search training, use `nomic-ai/nomic-embed-text-v1.5` (768 dimensions) as the default choice\u2014it provides the best quality for folder suggestion and bookmark filing tasks. If you need faster training or lower memory usage, `sentence-transformers/all-MiniLM-L6-v2` or `BAAI/bge-small-en-v1.5` (both 384 dimensions) are solid alternatives with good quality. Specify your choice with the `--model` flag when training: `python3 scripts/train_pearltrees_federated.py input.jsonl output.pkl --model nomic-ai/nomic-embed-text-v1.5`", "question_type": "long", "topics": ["Quickstart", "Train Federated Model"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["embeddings", "models", "configuration"], "related_skills": ["skill_train_model.md", "skill_embedding_models.md"], "related_docs": ["education/book-14-ai-training/02_embedding_providers.md"], "original_answer": "Three models are recommended:\n\n- `nomic-ai/nomic-embed-text-v1.5` (768 dims, default) - best quality\n- `sentence-transformers/all-MiniLM-L6-v2` (384 dims) - faster\n- `BAAI/bge-small-en-v1.5` (384 dims) - good quality, balanced\n\nUse the `--model` flag:\n\n```bash\npython3 scripts/train_pearltrees_federated.py input.jsonl output.pkl --model nomic-ai/nomic-embed-text-v1.5\n```\n\nSee skill_train_model.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_train_model_002_q3", "cluster_id": "skill_train_model_002", "question": "How do I choose an embedding model?", "answer": "Choose an embedding model based on your needs:\n\n- **nomic-ai/nomic-embed-text-v1.5** (768 dims) - Best quality, recommended default\n- **sentence-transformers/all-MiniLM-L6-v2** (384 dims) - Faster, smaller footprint\n- **BAAI/bge-small-en-v1.5** (384 dims) - Good quality with balanced performance\n\nUse the `--model` flag when training:\n\n```bash\npython3 scripts/train_pearltrees_federated.py input.jsonl output.pkl --model nomic-ai/nomic-embed-text-v1.5\n```\n\nStart with the default (nomic) unless you need faster processing or lower memory usage.", "question_type": "long", "topics": ["Quickstart", "Train Federated Model"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["embeddings", "models", "configuration"], "related_skills": ["skill_train_model.md", "skill_embedding_models.md"], "related_docs": ["education/book-14-ai-training/02_embedding_providers.md"], "original_answer": "Three models are recommended:\n\n- `nomic-ai/nomic-embed-text-v1.5` (768 dims, default) - best quality\n- `sentence-transformers/all-MiniLM-L6-v2` (384 dims) - faster\n- `BAAI/bge-small-en-v1.5` (384 dims) - good quality, balanced\n\nUse the `--model` flag:\n\n```bash\npython3 scripts/train_pearltrees_federated.py input.jsonl output.pkl --model nomic-ai/nomic-embed-text-v1.5\n```\n\nSee skill_train_model.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_train_model_003_q0", "cluster_id": "skill_train_model_003", "question": "What's the difference between clustering methods like MST and KMeans?", "answer": "MST (Minimum Spanning Tree) and KMeans are two clustering methods used during federated model training:\n\n**MST (Recommended):**\n- Preserves hierarchy structure in your data\n- Best for folder structures and hierarchical organization\n- Works well with Pearltrees/mindmap data\n- Command: `python3 scripts/train_pearltrees_federated.py input.jsonl output.pkl --cluster-method mst --max-clusters 50`\n\n**KMeans:**\n- Faster for large datasets\n- Does not preserve hierarchy\n- Creates clusters based on embedding space distance\n- Better for flat, non-hierarchical data\n\n**None:**\n- Single global projection, no clustering at all\n\nFor hierarchical data like folder suggestions and bookmark filing, MST is recommended because it maintains the structural relationships in your data during projection.", "question_type": "long", "topics": ["Quickstart", "Train Federated Model"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["clustering", "mst", "hierarchy"], "related_skills": ["skill_train_model.md"], "related_docs": ["education/book-13-semantic-search/08_advanced_federation.md"], "original_answer": "Two main clustering methods:\n\n- `mst` (recommended) - preserves hierarchy, works best for folder structures\n- `kmeans` - faster for large datasets, doesn't preserve hierarchy\n- `none` - single global projection, no clustering\n\nFor hierarchical data, use MST:\n\n```bash\npython3 scripts/train_pearltrees_federated.py input.jsonl output.pkl --cluster-method mst --max-clusters 50\n```\n\nSee skill_train_model.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_train_model_003_q1", "cluster_id": "skill_train_model_003", "question": "Should I use MST or KMeans clustering?", "answer": "Choose between MST and KMeans based on your data structure:\n\n**Use MST (recommended)** if your data is hierarchical (like Pearltrees folders or mindmaps with parent-child relationships). MST preserves the hierarchy during clustering, making it ideal for folder suggestion and bookmark filing tasks.\n\n**Use KMeans** if you have a large, flat dataset and speed is critical. KMeans clusters faster but doesn't preserve hierarchical structure.\n\nFor most Pearltrees and mindmap data:\n```bash\npython3 scripts/train_pearltrees_federated.py input.jsonl output.pkl --cluster-method mst --max-clusters 50\n```\n\nIf you have 100k+ items and need faster training, consider KMeans instead.", "question_type": "long", "topics": ["Quickstart", "Train Federated Model"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["clustering", "mst", "hierarchy"], "related_skills": ["skill_train_model.md"], "related_docs": ["education/book-13-semantic-search/08_advanced_federation.md"], "original_answer": "Two main clustering methods:\n\n- `mst` (recommended) - preserves hierarchy, works best for folder structures\n- `kmeans` - faster for large datasets, doesn't preserve hierarchy\n- `none` - single global projection, no clustering\n\nFor hierarchical data, use MST:\n\n```bash\npython3 scripts/train_pearltrees_federated.py input.jsonl output.pkl --cluster-method mst --max-clusters 50\n```\n\nSee skill_train_model.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_train_model_003_q2", "cluster_id": "skill_train_model_003", "question": "How do I choose a clustering method?", "answer": "Choose a clustering method based on your data structure and performance needs:\n\n- **`mst` (recommended)** - Use this for hierarchical data like folder structures. It preserves the hierarchy and works best for Pearltrees/mindmap data.\n- **`kmeans`** - Use this for faster training on large datasets when hierarchy preservation isn't critical.\n- **`none`** - Use this for a single global projection without any clustering.\n\nFor most cases with folder hierarchies, use MST:\n\n```bash\npython3 scripts/train_pearltrees_federated.py input.jsonl output.pkl --cluster-method mst --max-clusters 50\n```\n\nYou can also adjust `--max-clusters` to control how many clusters are created during training.", "question_type": "long", "topics": ["Quickstart", "Train Federated Model"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["clustering", "mst", "hierarchy"], "related_skills": ["skill_train_model.md"], "related_docs": ["education/book-13-semantic-search/08_advanced_federation.md"], "original_answer": "Two main clustering methods:\n\n- `mst` (recommended) - preserves hierarchy, works best for folder structures\n- `kmeans` - faster for large datasets, doesn't preserve hierarchy\n- `none` - single global projection, no clustering\n\nFor hierarchical data, use MST:\n\n```bash\npython3 scripts/train_pearltrees_federated.py input.jsonl output.pkl --cluster-method mst --max-clusters 50\n```\n\nSee skill_train_model.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_train_model_003_q3", "cluster_id": "skill_train_model_003", "question": "What clustering options are available?", "answer": "UnifyWeaver supports three clustering methods for federated model training:\n\n1. **mst** (recommended) - Minimum Spanning Tree clustering that preserves hierarchical structure, ideal for folder-based organization like Pearltrees\n2. **kmeans** - K-means clustering that's faster for large datasets but doesn't preserve hierarchy\n3. **none** - Single global projection with no clustering\n\nFor hierarchical data like folder structures, MST is recommended. Use the `--cluster-method` flag when training:\n\n```bash\npython3 scripts/train_pearltrees_federated.py input.jsonl output.pkl --cluster-method mst --max-clusters 50\n```\n\nYou can control the number of clusters with `--max-clusters` when using MST or kmeans.", "question_type": "long", "topics": ["Quickstart", "Train Federated Model"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["clustering", "mst", "hierarchy"], "related_skills": ["skill_train_model.md"], "related_docs": ["education/book-13-semantic-search/08_advanced_federation.md"], "original_answer": "Two main clustering methods:\n\n- `mst` (recommended) - preserves hierarchy, works best for folder structures\n- `kmeans` - faster for large datasets, doesn't preserve hierarchy\n- `none` - single global projection, no clustering\n\nFor hierarchical data, use MST:\n\n```bash\npython3 scripts/train_pearltrees_federated.py input.jsonl output.pkl --cluster-method mst --max-clusters 50\n```\n\nSee skill_train_model.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_train_model_004_q0", "cluster_id": "skill_train_model_004", "question": "What format should my input data be in?", "answer": "Your input must be JSONL format (one JSON object per line). Each line should contain:\n\n- `id` (required): unique identifier\n- `target_text` (required): materialized folder path using forward slashes (e.g., \"Science/Physics/Quantum Mechanics\")\n- `title` (optional): human-readable name\n- Other fields (optional): included but not used by the training script\n\nExample:\n```\n{\"id\": \"123\", \"target_text\": \"Science/Physics/Quantum Mechanics\", \"title\": \"Quantum Computing\"}\n{\"id\": \"456\", \"target_text\": \"Science/Biology/Genetics\", \"title\": \"CRISPR Guide\"}\n```\n\nMaterialized paths with slashes work best for the federated model training. Pass your JSONL file to the training script as the first argument.", "question_type": "medium", "topics": ["Quickstart", "Train Federated Model"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["input", "format", "data", "jsonl"], "related_skills": ["skill_train_model.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md"], "original_answer": "Your input must be JSONL (one JSON object per line) with a `target_text` field containing materialized folder paths:\n\n```jsonl\n{\"id\": \"123\", \"target_text\": \"Science/Physics/Quantum Mechanics\", \"title\": \"Quantum Computing\"}\n{\"id\": \"456\", \"target_text\": \"Science/Biology/Genetics\", \"title\": \"CRISPR Guide\"}\n```\n\nRequired fields: `id`, `target_text`. Optional: `title` and others. Materialized paths (with slashes) work best for training.\n\nSee skill_train_model.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_train_model_004_q1", "cluster_id": "skill_train_model_004", "question": "How do I format my data for training?", "answer": "Your input must be JSONL format (one JSON object per line). Each line requires an `id` field and a `target_text` field containing the materialized folder path using forward slashes. Optional fields like `title` can be included. Example:\n\n```\n{\"id\": \"123\", \"target_text\": \"Science/Physics/Quantum Mechanics\", \"title\": \"Quantum Computing\"}\n{\"id\": \"456\", \"target_text\": \"Science/Biology/Genetics\", \"title\": \"CRISPR Guide\"}\n```\n\nMaterialized paths (with slashes showing the full hierarchy) work best for training. Pass this file to the training script as the input argument.", "question_type": "medium", "topics": ["Quickstart", "Train Federated Model"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["input", "format", "data", "jsonl"], "related_skills": ["skill_train_model.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md"], "original_answer": "Your input must be JSONL (one JSON object per line) with a `target_text` field containing materialized folder paths:\n\n```jsonl\n{\"id\": \"123\", \"target_text\": \"Science/Physics/Quantum Mechanics\", \"title\": \"Quantum Computing\"}\n{\"id\": \"456\", \"target_text\": \"Science/Biology/Genetics\", \"title\": \"CRISPR Guide\"}\n```\n\nRequired fields: `id`, `target_text`. Optional: `title` and others. Materialized paths (with slashes) work best for training.\n\nSee skill_train_model.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_train_model_004_q2", "cluster_id": "skill_train_model_004", "question": "What fields do I need in my JSONL file?", "answer": "Your JSONL file needs a `target_text` field containing materialized folder paths (using slashes). Required fields are `id` and `target_text`. Optional fields like `title` can be included. Example:\n\n```jsonl\n{\"id\": \"123\", \"target_text\": \"Science/Physics/Quantum Mechanics\", \"title\": \"Quantum Computing\"}\n{\"id\": \"456\", \"target_text\": \"Science/Biology/Genetics\", \"title\": \"CRISPR Guide\"}\n```\n\nMaterialized paths work best for training the federated model.", "question_type": "medium", "topics": ["Quickstart", "Train Federated Model"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["input", "format", "data", "jsonl"], "related_skills": ["skill_train_model.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md"], "original_answer": "Your input must be JSONL (one JSON object per line) with a `target_text` field containing materialized folder paths:\n\n```jsonl\n{\"id\": \"123\", \"target_text\": \"Science/Physics/Quantum Mechanics\", \"title\": \"Quantum Computing\"}\n{\"id\": \"456\", \"target_text\": \"Science/Biology/Genetics\", \"title\": \"CRISPR Guide\"}\n```\n\nRequired fields: `id`, `target_text`. Optional: `title` and others. Materialized paths (with slashes) work best for training.\n\nSee skill_train_model.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_train_model_004_q3", "cluster_id": "skill_train_model_004", "question": "What does a valid input file look like?", "answer": "A valid input file is JSONL format (one JSON object per line) with required fields `id` and `target_text`. The `target_text` field should contain materialized folder paths using forward slashes. Optional fields like `title` can be included. Example:\n\n```jsonl\n{\"id\": \"123\", \"target_text\": \"Science/Physics/Quantum Mechanics\", \"title\": \"Quantum Computing\"}\n{\"id\": \"456\", \"target_text\": \"Science/Biology/Genetics\", \"title\": \"CRISPR Guide\"}\n```\n\nMaterialized paths (with slashes showing the full hierarchy) work best for training the federated model.", "question_type": "medium", "topics": ["Quickstart", "Train Federated Model"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["input", "format", "data", "jsonl"], "related_skills": ["skill_train_model.md"], "related_docs": ["docs/QUICKSTART_MINDMAP_LINKING.md"], "original_answer": "Your input must be JSONL (one JSON object per line) with a `target_text` field containing materialized folder paths:\n\n```jsonl\n{\"id\": \"123\", \"target_text\": \"Science/Physics/Quantum Mechanics\", \"title\": \"Quantum Computing\"}\n{\"id\": \"456\", \"target_text\": \"Science/Biology/Genetics\", \"title\": \"CRISPR Guide\"}\n```\n\nRequired fields: `id`, `target_text`. Optional: `title` and others. Materialized paths (with slashes) work best for training.\n\nSee skill_train_model.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_train_model_005_q0", "cluster_id": "skill_train_model_005", "question": "What does the training script output?", "answer": "The training script outputs a `.pkl` (pickle) file containing the trained federated model. This file includes:\n\n- **Federated W matrices**: One projection matrix per cluster for semantic space alignment\n- **Cluster assignments**: Mapping of which items belong to which cluster\n- **Embedding cache**: Pre-computed embeddings for your training data\n\nYou specify the output path as the second argument when running the training command. This model file is then used by folder suggestion and bookmark filing features for inference.", "question_type": "medium", "topics": ["Quickstart", "Train Federated Model"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["output", "model", "format"], "related_skills": ["skill_train_model.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "The training script creates a `.pkl` (pickle) file containing:\n\n- Federated W matrices (one projection matrix per cluster)\n- Cluster assignments (which items go in which cluster)\n- Embedding cache (cached embeddings for your data)\n\nThis model file is used by folder suggestion and bookmark filing features. You specify the output path as the second argument:\n\n```bash\npython3 scripts/train_pearltrees_federated.py input.jsonl models/my_model.pkl\n```\n\nSee skill_train_model.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_train_model_005_q1", "cluster_id": "skill_train_model_005", "question": "What file does the training create?", "answer": "The training script creates a `.pkl` (pickle) file specified as the second argument in the command. This file contains federated W matrices (one projection matrix per cluster), cluster assignments, and an embedding cache. For example: `python3 scripts/train_pearltrees_federated.py input.jsonl models/my_model.pkl` creates `models/my_model.pkl`.", "question_type": "medium", "topics": ["Quickstart", "Train Federated Model"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["output", "model", "format"], "related_skills": ["skill_train_model.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "The training script creates a `.pkl` (pickle) file containing:\n\n- Federated W matrices (one projection matrix per cluster)\n- Cluster assignments (which items go in which cluster)\n- Embedding cache (cached embeddings for your data)\n\nThis model file is used by folder suggestion and bookmark filing features. You specify the output path as the second argument:\n\n```bash\npython3 scripts/train_pearltrees_federated.py input.jsonl models/my_model.pkl\n```\n\nSee skill_train_model.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_train_model_005_q2", "cluster_id": "skill_train_model_005", "question": "What's in the .pkl model file?", "answer": "The `.pkl` model file contains three main components:\n\n1. **Federated W matrices** - One projection matrix per cluster, used to project embeddings into the target space\n2. **Cluster assignments** - Mapping of which items belong to which cluster\n3. **Embedding cache** - Pre-computed embeddings for your training data\n\nThis file is generated by the training script and used by folder suggestion and bookmark filing features to make predictions on new data.", "question_type": "medium", "topics": ["Quickstart", "Train Federated Model"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["output", "model", "format"], "related_skills": ["skill_train_model.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "The training script creates a `.pkl` (pickle) file containing:\n\n- Federated W matrices (one projection matrix per cluster)\n- Cluster assignments (which items go in which cluster)\n- Embedding cache (cached embeddings for your data)\n\nThis model file is used by folder suggestion and bookmark filing features. You specify the output path as the second argument:\n\n```bash\npython3 scripts/train_pearltrees_federated.py input.jsonl models/my_model.pkl\n```\n\nSee skill_train_model.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_train_model_006_q0", "cluster_id": "skill_train_model_006", "question": "How do I see all training options and settings?", "answer": "Run the help command to see all available training options and settings:\n\n```bash\npython3 scripts/train_pearltrees_federated.py --help\n```\n\nThis displays all available flags and parameters. Common options include:\n- `--cluster-method` (mst, kmeans, none)\n- `--max-clusters` (default: 50)\n- `--model` (embedding model to use)\n\nFor a quick start with defaults:\n\n```bash\npython3 scripts/train_pearltrees_federated.py input.jsonl output.pkl\n```", "question_type": "long", "topics": ["Quickstart", "Train Federated Model"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["options", "help", "parameters"], "related_skills": ["skill_train_model.md"], "related_docs": [], "original_answer": "Run the help command to see all available options:\n\n```bash\npython3 scripts/train_pearltrees_federated.py --help\n```\n\nCommon options include `--cluster-method`, `--max-clusters`, and `--model`. For quick start, the defaults work well:\n\n```bash\npython3 scripts/train_pearltrees_federated.py input.jsonl output.pkl\n```\n\nSee skill_train_model.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_train_model_006_q1", "cluster_id": "skill_train_model_006", "question": "What parameters can I customize?", "answer": "You can customize several parameters when training the federated model:\n\n**Clustering:**\n- `--cluster-method`: Choose `mst` (recommended, preserves hierarchy), `kmeans` (faster for large datasets), or `none` (single global projection)\n- `--max-clusters`: Limit the number of clusters (default varies by method)\n\n**Embedding Model:**\n- `--model`: Select embedding model - `nomic-ai/nomic-embed-text-v1.5` (default, 768 dims), `sentence-transformers/all-MiniLM-L6-v2` (faster, 384 dims), or `BAAI/bge-small-en-v1.5` (384 dims)\n\n**Example with custom parameters:**\n```bash\npython3 scripts/train_pearltrees_federated.py input.jsonl output.pkl \\\n  --cluster-method mst \\\n  --max-clusters 50 \\\n  --model nomic-ai/nomic-embed-text-v1.5\n```\n\nFor all available options, run:\n```bash\npython3 scripts/train_pearltrees_federated.py --help\n```", "question_type": "long", "topics": ["Quickstart", "Train Federated Model"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["options", "help", "parameters"], "related_skills": ["skill_train_model.md"], "related_docs": [], "original_answer": "Run the help command to see all available options:\n\n```bash\npython3 scripts/train_pearltrees_federated.py --help\n```\n\nCommon options include `--cluster-method`, `--max-clusters`, and `--model`. For quick start, the defaults work well:\n\n```bash\npython3 scripts/train_pearltrees_federated.py input.jsonl output.pkl\n```\n\nSee skill_train_model.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_train_model_006_q2", "cluster_id": "skill_train_model_006", "question": "What are the command line options?", "answer": "Run the help command to see all available options:\n\n```bash\npython3 scripts/train_pearltrees_federated.py --help\n```\n\nCommon options include:\n- `--cluster-method` - Choose clustering strategy (mst, kmeans, none)\n- `--max-clusters` - Maximum number of clusters to create\n- `--model` - Embedding model to use (default: nomic-ai/nomic-embed-text-v1.5)\n\nFor a quick start with defaults:\n\n```bash\npython3 scripts/train_pearltrees_federated.py input.jsonl output.pkl\n```", "question_type": "long", "topics": ["Quickstart", "Train Federated Model"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["options", "help", "parameters"], "related_skills": ["skill_train_model.md"], "related_docs": [], "original_answer": "Run the help command to see all available options:\n\n```bash\npython3 scripts/train_pearltrees_federated.py --help\n```\n\nCommon options include `--cluster-method`, `--max-clusters`, and `--model`. For quick start, the defaults work well:\n\n```bash\npython3 scripts/train_pearltrees_federated.py input.jsonl output.pkl\n```\n\nSee skill_train_model.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_train_model_006_q3", "cluster_id": "skill_train_model_006", "question": "How do I get help for the training script?", "answer": "Run the help command to see all available options for the training script:\n\n```bash\npython3 scripts/train_pearltrees_federated.py --help\n```\n\nThis displays all available flags and parameters, including `--cluster-method`, `--max-clusters`, and `--model`. For a quick start, the default settings work well and only require specifying input and output paths:\n\n```bash\npython3 scripts/train_pearltrees_federated.py input.jsonl output.pkl\n```", "question_type": "long", "topics": ["Quickstart", "Train Federated Model"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["options", "help", "parameters"], "related_skills": ["skill_train_model.md"], "related_docs": [], "original_answer": "Run the help command to see all available options:\n\n```bash\npython3 scripts/train_pearltrees_federated.py --help\n```\n\nCommon options include `--cluster-method`, `--max-clusters`, and `--model`. For quick start, the defaults work well:\n\n```bash\npython3 scripts/train_pearltrees_federated.py input.jsonl output.pkl\n```\n\nSee skill_train_model.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_transpiler_extension_001_q0", "cluster_id": "skill_transpiler_extension_001", "question": "How do I add support for reading data from external sources like JSON, CSV, or databases?", "answer": "Use the source mechanism to declare external data formats. UnifyWeaver supports JSON, CSV, XML, YAML, SQLite, HTTP, Python, .NET, bash pipelines, and semantic search sources.\n\nFor JSON data:\n```prolog\n:- source(json, api_response, [\n    json_file('data/response.json'),\n    jq_filter('.items[] | {id, name, status}'),\n    output_format(tsv)\n]).\n\nprocess_items :-\n    api_response(Id, Name, Status),\n    format('~w: ~w (~w)~n', [Id, Name, Status]).\n```\n\nFor other formats (CSV, SQLite, etc.), use the corresponding source type with appropriate options. The transpiler generates target code that processes these sources as predicates in your Prolog code.", "question_type": "medium", "topics": ["Quickstart", "Transpiler Extension"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sources", "data-integration", "external-formats"], "related_skills": ["skill_transpiler_extension.md"], "related_docs": ["docs/guides/cross-target-glue.md"], "original_answer": "Use the source mechanism to declare external data formats. For example, to read from JSON:\n\n```prolog\n:- source(json, api_response, [\n    json_file('data/response.json'),\n    jq_filter('.items[] | {id, name, status}'),\n    output_format(tsv)\n]).\n\nprocess_items :-\n    api_response(Id, Name, Status),\n    format('~w: ~w (~w)~n', [Id, Name, Status]).\n```\n\nUnifyWeaver supports JSON, CSV, XML, YAML, SQLite, HTTP, Python, .NET, bash pipelines, and semantic search sources. See skill_transpiler_extension.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_transpiler_extension_001_q1", "cluster_id": "skill_transpiler_extension_001", "question": "How do I integrate external data formats into my transpilation?", "answer": "Use the source mechanism to declare external data formats in your transpilation. Sources let you define predicates that read from external data and generate target code to process them.\n\nTo integrate an external format, declare a source with the format type and configuration:\n\n```prolog\n:- source(json, api_response, [\n    json_file('data/response.json'),\n    jq_filter('.items[] | {id, name, status}'),\n    output_format(tsv)\n]).\n\nprocess_items :-\n    api_response(Id, Name, Status),\n    format('~w: ~w (~w)~n', [Id, Name, Status]).\n```\n\nSupported formats include: JSON (via jq), CSV/TSV, XML (via xmlstarlet), YAML, SQLite, HTTP, Python functions, .NET assemblies, bash pipelines, and semantic search.\n\nFor custom formats, create a plugin that registers a source type and implements validation and compilation methods. See the skill documentation for the custom source plugin pattern.", "question_type": "medium", "topics": ["Quickstart", "Transpiler Extension"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sources", "data-integration", "external-formats"], "related_skills": ["skill_transpiler_extension.md"], "related_docs": ["docs/guides/cross-target-glue.md"], "original_answer": "Use the source mechanism to declare external data formats. For example, to read from JSON:\n\n```prolog\n:- source(json, api_response, [\n    json_file('data/response.json'),\n    jq_filter('.items[] | {id, name, status}'),\n    output_format(tsv)\n]).\n\nprocess_items :-\n    api_response(Id, Name, Status),\n    format('~w: ~w (~w)~n', [Id, Name, Status]).\n```\n\nUnifyWeaver supports JSON, CSV, XML, YAML, SQLite, HTTP, Python, .NET, bash pipelines, and semantic search sources. See skill_transpiler_extension.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_transpiler_extension_001_q2", "cluster_id": "skill_transpiler_extension_001", "question": "Can I read from SQLite or JSON files in my Prolog code?", "answer": "Yes, you can read from SQLite and JSON files in your Prolog code using the source mechanism. For JSON files, declare a source like this:\n\n```prolog\n:- source(json, api_response, [\n    json_file('data/response.json'),\n    jq_filter('.items[] | {id, name, status}'),\n    output_format(tsv)\n]).\n\nprocess_items :-\n    api_response(Id, Name, Status),\n    format('~w: ~w (~w)~n', [Id, Name, Status]).\n```\n\nFor SQLite, use the sqlite source type:\n\n```prolog\n:- source(sqlite, my_data, [\n    db_file('data/mydb.db'),\n    query('SELECT id, name, status FROM items')\n]).\n```\n\nOnce declared, these sources generate predicates you can call directly in your Prolog code. UnifyWeaver handles transpiling these into the target language.", "question_type": "medium", "topics": ["Quickstart", "Transpiler Extension"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sources", "data-integration", "external-formats"], "related_skills": ["skill_transpiler_extension.md"], "related_docs": ["docs/guides/cross-target-glue.md"], "original_answer": "Use the source mechanism to declare external data formats. For example, to read from JSON:\n\n```prolog\n:- source(json, api_response, [\n    json_file('data/response.json'),\n    jq_filter('.items[] | {id, name, status}'),\n    output_format(tsv)\n]).\n\nprocess_items :-\n    api_response(Id, Name, Status),\n    format('~w: ~w (~w)~n', [Id, Name, Status]).\n```\n\nUnifyWeaver supports JSON, CSV, XML, YAML, SQLite, HTTP, Python, .NET, bash pipelines, and semantic search sources. See skill_transpiler_extension.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_transpiler_extension_001_q3", "cluster_id": "skill_transpiler_extension_001", "question": "How do I define custom data sources?", "answer": "To define custom data sources in UnifyWeaver, use the `source` directive to declare external data formats. For example, to read from JSON:\n\n```prolog\n:- source(json, api_response, [\n    json_file('data/response.json'),\n    jq_filter('.items[] | {id, name, status}'),\n    output_format(tsv)\n]).\n\nprocess_items :-\n    api_response(Id, Name, Status),\n    format('~w: ~w (~w)~n', [Id, Name, Status]).\n```\n\nThe transpiler generates target code that processes these sources. Built-in source types include: JSON (via jq), CSV/TSV, XML (via xmlstarlet), YAML, SQLite, HTTP endpoints, Python functions, .NET assemblies, bash pipelines, and semantic search.\n\nFor custom formats, create a source plugin module that registers with `register_source_type/2`, implements `source_info/1`, `validate_config/1`, and `compile_source/4` predicates.", "question_type": "medium", "topics": ["Quickstart", "Transpiler Extension"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sources", "data-integration", "external-formats"], "related_skills": ["skill_transpiler_extension.md"], "related_docs": ["docs/guides/cross-target-glue.md"], "original_answer": "Use the source mechanism to declare external data formats. For example, to read from JSON:\n\n```prolog\n:- source(json, api_response, [\n    json_file('data/response.json'),\n    jq_filter('.items[] | {id, name, status}'),\n    output_format(tsv)\n]).\n\nprocess_items :-\n    api_response(Id, Name, Status),\n    format('~w: ~w (~w)~n', [Id, Name, Status]).\n```\n\nUnifyWeaver supports JSON, CSV, XML, YAML, SQLite, HTTP, Python, .NET, bash pipelines, and semantic search sources. See skill_transpiler_extension.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_transpiler_extension_002_q0", "cluster_id": "skill_transpiler_extension_002", "question": "How do I call Python functions or Go standard library functions from my Prolog code?", "answer": "Use bindings to map Prolog predicates to target language functions. Initialize the target bindings module, then call the mapped predicates in your Prolog code.\n\nFor Python:\n```prolog\n:- use_module('src/unifyweaver/bindings/python_bindings').\n:- init_python_bindings.\n\nprocess_text(Text, Len) :-\n    string_length(Text, Len),   % Maps to Python's len()\n    Len > 10.\n```\n\nFor Go or other targets, use similar binding initialization. You can also declare custom bindings:\n```prolog\n:- declare_binding(python, my_hash/2, 'hashlib.sha256', [string], [string],\n                   [import('hashlib'), pure]).\n```\n\nBindings are available for 20+ targets including Python, Go, Rust, Bash, C#, and PowerShell. Each binding preserves type information and semantic details for correct code generation.", "question_type": "medium", "topics": ["Quickstart", "Transpiler Extension"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["bindings", "foreign-functions", "stdlib-integration"], "related_skills": ["skill_transpiler_extension.md"], "related_docs": ["docs/proposals/BINDING_PREDICATE_PROPOSAL.md", "docs/BINDING_MATRIX.md"], "original_answer": "Use bindings to map Prolog predicates to target language functions. First, initialize the target bindings, then use the mapped predicates. For example:\n\n```prolog\n:- use_module('src/unifyweaver/bindings/python_bindings').\n:- init_python_bindings.\n\nprocess_text(Text, Len) :-\n    string_length(Text, Len),   % Translates to: len(text)\n    Len > 10.\n```\n\nOr declare custom bindings:\n```prolog\n:- declare_binding(python, my_hash/2, 'hashlib.sha256', [string], [string],\n                   [import('hashlib'), pure]).\n```\n\nBindings available for 20+ targets including Python, Go, Rust, Bash, C#, and PowerShell. See skill_transpiler_extension.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_transpiler_extension_002_q1", "cluster_id": "skill_transpiler_extension_002", "question": "Can I use Python's len() function in Prolog?", "answer": "Yes, you can use Python's len() function in Prolog through bindings. Use the `string_length/2` predicate which maps to Python's `len()` function:\n\n```prolog\n:- use_module('src/unifyweaver/bindings/python_bindings').\n:- init_python_bindings.\n\nprocess_text(Text, Len) :-\n    string_length(Text, Len),   % Translates to: len(text)\n    Len > 10.\n```\n\nAlternatively, declare a custom binding:\n```prolog\n:- declare_binding(python, my_len/2, 'len', [any], [integer],\n                   [pure]).\n\nget_length(Item, Length) :-\n    my_len(Item, Length).\n```\n\nThe transpiler automatically generates Python code that calls the native `len()` function when compiled.", "question_type": "medium", "topics": ["Quickstart", "Transpiler Extension"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["bindings", "foreign-functions", "stdlib-integration"], "related_skills": ["skill_transpiler_extension.md"], "related_docs": ["docs/proposals/BINDING_PREDICATE_PROPOSAL.md", "docs/BINDING_MATRIX.md"], "original_answer": "Use bindings to map Prolog predicates to target language functions. First, initialize the target bindings, then use the mapped predicates. For example:\n\n```prolog\n:- use_module('src/unifyweaver/bindings/python_bindings').\n:- init_python_bindings.\n\nprocess_text(Text, Len) :-\n    string_length(Text, Len),   % Translates to: len(text)\n    Len > 10.\n```\n\nOr declare custom bindings:\n```prolog\n:- declare_binding(python, my_hash/2, 'hashlib.sha256', [string], [string],\n                   [import('hashlib'), pure]).\n```\n\nBindings available for 20+ targets including Python, Go, Rust, Bash, C#, and PowerShell. See skill_transpiler_extension.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer is accurate but somewhat verbose for a direct yes/no question. The example assumes familiarity with bindings initialization. Confidence is high because the mechanism is clearly explained, but slightly reduced because the answer could be more concise for this straightforward use case."}
{"pair_id": "skill_transpiler_extension_002_q2", "cluster_id": "skill_transpiler_extension_002", "question": "How do I map Prolog predicates to target language functions?", "answer": "Use bindings to map Prolog predicates to target language functions. First, initialize the target bindings with the module for your target language, then use the mapped predicates in your code. For example, with Python:\n\n```prolog\n:- use_module('src/unifyweaver/bindings/python_bindings').\n:- init_python_bindings.\n\nprocess_text(Text, Len) :-\n    string_length(Text, Len),   % Translates to: len(text)\n    Len > 10.\n```\n\nFor custom bindings, declare them explicitly:\n```prolog\n:- declare_binding(python, my_hash/2, 'hashlib.sha256', [string], [string],\n                   [import('hashlib'), pure]).\n```\n\nThe binding specifies: target language, predicate signature, target function name, input types, output types, and options like imports or purity. Bindings are available for 20+ targets including Python, Go, Rust, Bash, C#, and PowerShell.", "question_type": "medium", "topics": ["Quickstart", "Transpiler Extension"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["bindings", "foreign-functions", "stdlib-integration"], "related_skills": ["skill_transpiler_extension.md"], "related_docs": ["docs/proposals/BINDING_PREDICATE_PROPOSAL.md", "docs/BINDING_MATRIX.md"], "original_answer": "Use bindings to map Prolog predicates to target language functions. First, initialize the target bindings, then use the mapped predicates. For example:\n\n```prolog\n:- use_module('src/unifyweaver/bindings/python_bindings').\n:- init_python_bindings.\n\nprocess_text(Text, Len) :-\n    string_length(Text, Len),   % Translates to: len(text)\n    Len > 10.\n```\n\nOr declare custom bindings:\n```prolog\n:- declare_binding(python, my_hash/2, 'hashlib.sha256', [string], [string],\n                   [import('hashlib'), pure]).\n```\n\nBindings available for 20+ targets including Python, Go, Rust, Bash, C#, and PowerShell. See skill_transpiler_extension.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_transpiler_extension_002_q3", "cluster_id": "skill_transpiler_extension_002", "question": "How do I bind foreign functions?", "answer": "To bind foreign functions in UnifyWeaver, use the bindings system to map Prolog predicates to target language functions. First, initialize the target bindings module for your language:\n\n```prolog\n:- use_module('src/unifyweaver/bindings/python_bindings').\n:- init_python_bindings.\n```\n\nThen use the mapped predicates directly in your code:\n\n```prolog\nprocess_text(Text, Len) :-\n    string_length(Text, Len),   % Translates to: len(text)\n    Len > 10.\n```\n\nFor custom bindings to foreign functions, declare them explicitly with the target language, predicate signature, function path, argument types, return types, and options:\n\n```prolog\n:- declare_binding(python, my_hash/2, 'hashlib.sha256', [string], [string],\n                   [import('hashlib'), pure]).\n```\n\nUnifyWeaver supports bindings for 20+ targets including Python, Go, Rust, Bash, C#, and PowerShell. Each binding automatically generates the correct transpiled code for your target language while preserving semantic information for proper type and effect handling.", "question_type": "medium", "topics": ["Quickstart", "Transpiler Extension"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["bindings", "foreign-functions", "stdlib-integration"], "related_skills": ["skill_transpiler_extension.md"], "related_docs": ["docs/proposals/BINDING_PREDICATE_PROPOSAL.md", "docs/BINDING_MATRIX.md"], "original_answer": "Use bindings to map Prolog predicates to target language functions. First, initialize the target bindings, then use the mapped predicates. For example:\n\n```prolog\n:- use_module('src/unifyweaver/bindings/python_bindings').\n:- init_python_bindings.\n\nprocess_text(Text, Len) :-\n    string_length(Text, Len),   % Translates to: len(text)\n    Len > 10.\n```\n\nOr declare custom bindings:\n```prolog\n:- declare_binding(python, my_hash/2, 'hashlib.sha256', [string], [string],\n                   [import('hashlib'), pure]).\n```\n\nBindings available for 20+ targets including Python, Go, Rust, Bash, C#, and PowerShell. See skill_transpiler_extension.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_transpiler_extension_003_q0", "cluster_id": "skill_transpiler_extension_003", "question": "How do I create reusable components that can be integrated into the transpilation pipeline?", "answer": "Use the component registry to define reusable units that integrate into the transpilation pipeline. First, define a category for your component type, then register the component type, and finally declare instances:\n\n```prolog\n:- use_module('src/unifyweaver/core/component_registry').\n\n:- define_category(validator, 'Data validation', []).\n:- register_component_type(validator, json_schema, json_validator_module, []).\n:- declare_component(validator, user_validator, json_schema, [schema_file('schemas/user.json')]).\n\n% Use in your transpilation pipeline\nvalidate_user(Input, Result) :-\n    invoke_component(validator, user_validator, Input, Result).\n```\n\nComponent type modules must export five required predicates: type_info/1 (metadata), validate_config/1 (configuration validation), init_component/2 (initialization), invoke_component/4 (runtime execution), and compile_component/4 (code generation for transpilation). This allows your components to participate in the full transpilation pipeline from definition through code generation.", "question_type": "medium", "topics": ["Quickstart", "Transpiler Extension"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["components", "registry", "reusability"], "related_skills": ["skill_transpiler_extension.md"], "related_docs": ["docs/proposals/COMPONENT_REGISTRY.md"], "original_answer": "Use the component registry to define reusable units. First define a category, then register component types, then declare component instances:\n\n```prolog\n:- use_module('src/unifyweaver/core/component_registry').\n\n:- define_category(validator, 'Data validation', []).\n:- register_component_type(validator, json_schema, json_validator_module, []).\n:- declare_component(validator, user_validator, json_schema, [schema_file('schemas/user.json')]).\n\n% Use it\nvalidate_user(Input, Result) :-\n    invoke_component(validator, user_validator, Input, Result).\n```\n\nComponent types must export: type_info/1, validate_config/1, init_component/2, invoke_component/4, and compile_component/4. See skill_transpiler_extension.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer assumes familiarity with the component system's five required exports but doesn't explain their purposes clearly. The confidence is moderate because the answer provides correct structure and usage but lacks detail about how components integrate into the actual transpilation pipeline execution flow."}
{"pair_id": "skill_transpiler_extension_003_q1", "cluster_id": "skill_transpiler_extension_003", "question": "What is the component registry and how do I use it?", "answer": "The component registry is UnifyWeaver's system for defining and managing reusable units that can be invoked during transpilation. To use it: (1) Define a category using `define_category/3` to name the component type and provide metadata, (2) Register component types within that category using `register_component_type/4` to specify the implementation module, (3) Declare component instances using `declare_component/4` with configuration options, (4) Invoke components in your code using `invoke_component/4` to pass data through them. For example, to create a validator component: define the 'validator' category, register 'json_schema' as a type within it, declare a 'user_validator' instance pointing to your JSON schema file, then invoke it with `invoke_component(validator, user_validator, Input, Result)`. Component type modules must export five predicates: `type_info/1` (metadata), `validate_config/1` (configuration validation), `init_component/2` (initialization), `invoke_component/4` (execution logic), and `compile_component/4` (code generation). See skill_transpiler_extension.md for detailed module requirements.", "question_type": "medium", "topics": ["Quickstart", "Transpiler Extension"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["components", "registry", "reusability"], "related_skills": ["skill_transpiler_extension.md"], "related_docs": ["docs/proposals/COMPONENT_REGISTRY.md"], "original_answer": "Use the component registry to define reusable units. First define a category, then register component types, then declare component instances:\n\n```prolog\n:- use_module('src/unifyweaver/core/component_registry').\n\n:- define_category(validator, 'Data validation', []).\n:- register_component_type(validator, json_schema, json_validator_module, []).\n:- declare_component(validator, user_validator, json_schema, [schema_file('schemas/user.json')]).\n\n% Use it\nvalidate_user(Input, Result) :-\n    invoke_component(validator, user_validator, Input, Result).\n```\n\nComponent types must export: type_info/1, validate_config/1, init_component/2, invoke_component/4, and compile_component/4. See skill_transpiler_extension.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_transpiler_extension_003_q2", "cluster_id": "skill_transpiler_extension_003", "question": "How do I register and use custom components?", "answer": "To register and use custom components, use the component registry. First define a category with `define_category/2`, then register a component type with `register_component_type/4` specifying the type name and implementing module, then declare component instances with `declare_component/5` passing configuration options. The implementing module must export: `type_info/1`, `validate_config/1`, `init_component/2`, `invoke_component/4`, and `compile_component/4`. Use `invoke_component/4` to call the component at runtime.\n\nExample:\n```prolog\n:- use_module('src/unifyweaver/core/component_registry').\n:- define_category(validator, 'Data validation', []).\n:- register_component_type(validator, json_schema, json_validator_module, []).\n:- declare_component(validator, my_validator, json_schema, [schema_file('schemas/user.json')]).\nvalidate(Input, Result) :- invoke_component(validator, my_validator, Input, Result).\n```", "question_type": "medium", "topics": ["Quickstart", "Transpiler Extension"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["components", "registry", "reusability"], "related_skills": ["skill_transpiler_extension.md"], "related_docs": ["docs/proposals/COMPONENT_REGISTRY.md"], "original_answer": "Use the component registry to define reusable units. First define a category, then register component types, then declare component instances:\n\n```prolog\n:- use_module('src/unifyweaver/core/component_registry').\n\n:- define_category(validator, 'Data validation', []).\n:- register_component_type(validator, json_schema, json_validator_module, []).\n:- declare_component(validator, user_validator, json_schema, [schema_file('schemas/user.json')]).\n\n% Use it\nvalidate_user(Input, Result) :-\n    invoke_component(validator, user_validator, Input, Result).\n```\n\nComponent types must export: type_info/1, validate_config/1, init_component/2, invoke_component/4, and compile_component/4. See skill_transpiler_extension.md for details.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null}
{"pair_id": "skill_transpiler_extension_003_q3", "cluster_id": "skill_transpiler_extension_003", "question": "Can I create validation or runtime components?", "answer": "Yes, you can create validation and runtime components using the component registry. Define a category (e.g., `validator`), register component types with their implementation modules, then declare component instances with their configuration:\n\n```prolog\n:- use_module('src/unifyweaver/core/component_registry').\n\n:- define_category(validator, 'Data validation', []).\n:- register_component_type(validator, json_schema, json_validator_module, []).\n:- declare_component(validator, user_validator, json_schema, [schema_file('schemas/user.json')]).\n\nvalidate_user(Input, Result) :-\n    invoke_component(validator, user_validator, Input, Result).\n```\n\nYour component type module must export: `type_info/1`, `validate_config/1`, `init_component/2`, `invoke_component/4`, and `compile_component/4`. This makes components reusable across your codebase and integrable into the transpilation pipeline.", "question_type": "medium", "topics": ["Quickstart", "Transpiler Extension"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["components", "registry", "reusability"], "related_skills": ["skill_transpiler_extension.md"], "related_docs": ["docs/proposals/COMPONENT_REGISTRY.md"], "original_answer": "Use the component registry to define reusable units. First define a category, then register component types, then declare component instances:\n\n```prolog\n:- use_module('src/unifyweaver/core/component_registry').\n\n:- define_category(validator, 'Data validation', []).\n:- register_component_type(validator, json_schema, json_validator_module, []).\n:- declare_component(validator, user_validator, json_schema, [schema_file('schemas/user.json')]).\n\n% Use it\nvalidate_user(Input, Result) :-\n    invoke_component(validator, user_validator, Input, Result).\n```\n\nComponent types must export: type_info/1, validate_config/1, init_component/2, invoke_component/4, and compile_component/4. See skill_transpiler_extension.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_transpiler_extension_004_q0", "cluster_id": "skill_transpiler_extension_004", "question": "How do I add support for a new target language?", "answer": "To add support for a new target language in UnifyWeaver, create three files:\n\n1. **Target module** (src/unifyweaver/targets/mylang_target.pl):\n   - Register the target with `register_target(mylang, mylang_target, [options])`\n   - Specify language properties: file extension, comment syntax, supported features (recursion, higher-order functions, etc.)\n   - Implement `compile_to_mylang/3` predicate to generate code from Prolog goals\n\n2. **Bindings module** (src/unifyweaver/bindings/mylang_bindings.pl):\n   - Map Prolog predicates to target language functions using `declare_binding/5`\n   - Specify argument types, return types, and effects (e.g., I/O)\n   - Example: `declare_binding(mylang, print/1, 'print', [string], [], [effect(io)])`\n\n3. **Templates** (optional):\n   - Create code generation patterns for common Prolog constructs\n   - Reduces boilerplate in the compilation logic\n\nThe target registration makes your language available to the transpiler, bindings ensure correct foreign function mapping, and templates streamline code generation.", "question_type": "long", "topics": ["Quickstart", "Transpiler Extension"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["target-language", "extension", "compilation"], "related_skills": ["skill_transpiler_extension.md"], "related_docs": ["docs/guides/cross-target-glue.md"], "original_answer": "Create three files: a target module, bindings module, and optional templates.\n\n1. **Target module** (src/unifyweaver/targets/mylang_target.pl):\n```prolog\n:- initialization(\n    register_target(mylang, mylang_target, [\n        extension('.ml'),\n        comment_style('(* ... *)'),\n        supports([recursion, higher_order])\n    ]),\n    now\n).\n\ncompile_to_mylang(Goal, Options, Code) :- /* logic */ .\n```\n\n2. **Bindings module** (src/unifyweaver/bindings/mylang_bindings.pl):\n```prolog\ninit_mylang_bindings :-\n    declare_binding(mylang, print/1, 'print', [string], [], [effect(io)]).\n```\n\n3. **Templates** (optional) for code generation patterns. See skill_transpiler_extension.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "Base answer lacks implementation details for compile_to_mylang/3 and doesn't explain how bindings connect to code generation. The answer assumes familiarity with the registration system. Could benefit from mentioning testing or validation steps for new targets."}
{"pair_id": "skill_transpiler_extension_004_q1", "cluster_id": "skill_transpiler_extension_004", "question": "Can I generate code for a language UnifyWeaver doesn't support?", "answer": "Yes. To generate code for an unsupported language, create three files: (1) A target module (src/unifyweaver/targets/mylang_target.pl) that registers your language with register_target/3, specifying the file extension, comment style, and supported features; (2) A bindings module (src/unifyweaver/bindings/mylang_bindings.pl) that maps Prolog predicates to target language functions using declare_binding/6; (3) Optional code generation templates that define patterns for translating UnifyWeaver constructs to your language. The target module acts as the entry point, the bindings module defines predicate-to-function mappings for correctness, and templates control the generated syntax. This three-part architecture lets the transpiler generate correct, idiomatic code for any language.", "question_type": "long", "topics": ["Quickstart", "Transpiler Extension"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["target-language", "extension", "compilation"], "related_skills": ["skill_transpiler_extension.md"], "related_docs": ["docs/guides/cross-target-glue.md"], "original_answer": "Create three files: a target module, bindings module, and optional templates.\n\n1. **Target module** (src/unifyweaver/targets/mylang_target.pl):\n```prolog\n:- initialization(\n    register_target(mylang, mylang_target, [\n        extension('.ml'),\n        comment_style('(* ... *)'),\n        supports([recursion, higher_order])\n    ]),\n    now\n).\n\ncompile_to_mylang(Goal, Options, Code) :- /* logic */ .\n```\n\n2. **Bindings module** (src/unifyweaver/bindings/mylang_bindings.pl):\n```prolog\ninit_mylang_bindings :-\n    declare_binding(mylang, print/1, 'print', [string], [], [effect(io)]).\n```\n\n3. **Templates** (optional) for code generation patterns. See skill_transpiler_extension.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The answer could be clearer about how these three components interact during compilation. The base answer references 'skill_transpiler_extension.md' for template details, but doesn't explain what makes templates necessary or optional."}
{"pair_id": "skill_transpiler_extension_004_q2", "cluster_id": "skill_transpiler_extension_004", "question": "How do I extend UnifyWeaver to compile to my custom language?", "answer": "To extend UnifyWeaver to compile to your custom language, create three files:\n\n1. **Target module** (src/unifyweaver/targets/mylang_target.pl): Register your target language with the transpiler, specifying file extension, comment style, and supported features:\n```prolog\n:- initialization(\n    register_target(mylang, mylang_target, [\n        extension('.ml'),\n        comment_style('(* ... *)'),\n        supports([recursion, higher_order])\n    ]),\n    now\n).\n\ncompile_to_mylang(Goal, Options, Code) :- /* your compilation logic */.\n```\n\n2. **Bindings module** (src/unifyweaver/bindings/mylang_bindings.pl): Map Prolog predicates to your target language's standard library functions:\n```prolog\ninit_mylang_bindings :-\n    declare_binding(mylang, print/1, 'print', [string], [], [effect(io)]).\n```\n\n3. **Templates** (optional): Define code generation patterns for common Prolog constructs in your target language.\n\nThe target module is the entry point\u2014it registers your language with the transpiler and implements the core compilation logic. The bindings module handles predicate-to-function mapping, ensuring correct semantic translation.", "question_type": "long", "topics": ["Quickstart", "Transpiler Extension"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["target-language", "extension", "compilation"], "related_skills": ["skill_transpiler_extension.md"], "related_docs": ["docs/guides/cross-target-glue.md"], "original_answer": "Create three files: a target module, bindings module, and optional templates.\n\n1. **Target module** (src/unifyweaver/targets/mylang_target.pl):\n```prolog\n:- initialization(\n    register_target(mylang, mylang_target, [\n        extension('.ml'),\n        comment_style('(* ... *)'),\n        supports([recursion, higher_order])\n    ]),\n    now\n).\n\ncompile_to_mylang(Goal, Options, Code) :- /* logic */ .\n```\n\n2. **Bindings module** (src/unifyweaver/bindings/mylang_bindings.pl):\n```prolog\ninit_mylang_bindings :-\n    declare_binding(mylang, print/1, 'print', [string], [], [effect(io)]).\n```\n\n3. **Templates** (optional) for code generation patterns. See skill_transpiler_extension.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_transpiler_extension_004_q3", "cluster_id": "skill_transpiler_extension_004", "question": "How do I create target language bindings?", "answer": "To create target language bindings, you need to register your target language and declare function mappings:\n\n1. **Register the target** in a target module (e.g., src/unifyweaver/targets/mylang_target.pl):\n```prolog\n:- initialization(\n    register_target(mylang, mylang_target, [\n        extension('.ml'),\n        comment_style('(* ... *)'),\n        supports([recursion, higher_order])\n    ]),\n    now\n).\n```\n\n2. **Create bindings** in a bindings module (e.g., src/unifyweaver/bindings/mylang_bindings.pl):\n```prolog\ninit_mylang_bindings :-\n    declare_binding(mylang, print/1, 'print', [string], [], [effect(io)]).\n```\nThe declare_binding/6 parameters are: target language, Prolog predicate, target function name, input types, output types, and metadata.\n\n3. **Implement compilation** with the compile_to_mylang/3 predicate that generates code for your target language.", "question_type": "long", "topics": ["Quickstart", "Transpiler Extension"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["target-language", "extension", "compilation"], "related_skills": ["skill_transpiler_extension.md"], "related_docs": ["docs/guides/cross-target-glue.md"], "original_answer": "Create three files: a target module, bindings module, and optional templates.\n\n1. **Target module** (src/unifyweaver/targets/mylang_target.pl):\n```prolog\n:- initialization(\n    register_target(mylang, mylang_target, [\n        extension('.ml'),\n        comment_style('(* ... *)'),\n        supports([recursion, higher_order])\n    ]),\n    now\n).\n\ncompile_to_mylang(Goal, Options, Code) :- /* logic */ .\n```\n\n2. **Bindings module** (src/unifyweaver/bindings/mylang_bindings.pl):\n```prolog\ninit_mylang_bindings :-\n    declare_binding(mylang, print/1, 'print', [string], [], [effect(io)]).\n```\n\n3. **Templates** (optional) for code generation patterns. See skill_transpiler_extension.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_transpiler_extension_005_q0", "cluster_id": "skill_transpiler_extension_005", "question": "How do I create a custom data source plugin for a proprietary format?", "answer": "To create a custom data source plugin for a proprietary format, implement a Prolog module with four key predicates:\n\n1. **Registration**: Use `:- initialization(register_source_type(format_name, module_name), now).` to register your plugin on load.\n\n2. **Metadata**: Implement `source_info(info(...))` with name, version, description, and supported arities for your custom format.\n\n3. **Validation**: Implement `validate_config(Config)` to verify that required configuration options (like file paths) are valid before compilation.\n\n4. **Code Generation**: Implement `compile_source(Pred/Arity, Config, Options, BashCode)` to generate the target code that processes your proprietary format.\n\nAfter creating the module, import it with `:- use_module('../core/dynamic_source_compiler').` and then declare sources in your Prolog code using `:- source(format_name, predicate_name, [your_config_options]).`\n\nThe transpiler will call your `compile_source/4` predicate during compilation to generate native code that reads and processes data in your proprietary format.", "question_type": "long", "topics": ["Quickstart", "Transpiler Extension"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sources", "plugins", "custom-formats"], "related_skills": ["skill_transpiler_extension.md"], "related_docs": ["docs/proposals/BINDING_PREDICATE_PROPOSAL.md"], "original_answer": "Create a custom source plugin module that implements required predicates:\n\n```prolog\n:- module(my_source, []).\n:- use_module('../core/dynamic_source_compiler').\n\n:- initialization(\n    register_source_type(my_format, my_source),\n    now\n).\n\nsource_info(info(\n    name('My Format Source'),\n    version('1.0.0'),\n    description('Process my custom format'),\n    supported_arities([1, 2, 3])\n)).\n\nvalidate_config(Config) :-\n    member(my_file(File), Config),\n    exists_file(File).\n\ncompile_source(Pred/Arity, Config, Options, BashCode) :-\n    member(my_file(File), Config),\n    format(atom(BashCode), '# Process ~w from ~w~n...', [Pred, File]).\n```\n\nThen use it with `:- source(my_format, name, [options]).` See skill_transpiler_extension.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_transpiler_extension_005_q1", "cluster_id": "skill_transpiler_extension_005", "question": "Can I create a plugin to read from custom file formats?", "answer": "Yes, you can create a custom source plugin to read from custom file formats. Create a module that implements the required predicates: `source_info/1` (metadata), `validate_config/1` (configuration validation), and `compile_source/4` (code generation). Register your plugin with `register_source_type(my_format, my_source)` during initialization. Once registered, use it in your Prolog code with `:- source(my_format, predicate_name, [options]).` to define predicates that read from your custom format. The transpiler will generate target code that processes these sources.", "question_type": "long", "topics": ["Quickstart", "Transpiler Extension"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sources", "plugins", "custom-formats"], "related_skills": ["skill_transpiler_extension.md"], "related_docs": ["docs/proposals/BINDING_PREDICATE_PROPOSAL.md"], "original_answer": "Create a custom source plugin module that implements required predicates:\n\n```prolog\n:- module(my_source, []).\n:- use_module('../core/dynamic_source_compiler').\n\n:- initialization(\n    register_source_type(my_format, my_source),\n    now\n).\n\nsource_info(info(\n    name('My Format Source'),\n    version('1.0.0'),\n    description('Process my custom format'),\n    supported_arities([1, 2, 3])\n)).\n\nvalidate_config(Config) :-\n    member(my_file(File), Config),\n    exists_file(File).\n\ncompile_source(Pred/Arity, Config, Options, BashCode) :-\n    member(my_file(File), Config),\n    format(atom(BashCode), '# Process ~w from ~w~n...', [Pred, File]).\n```\n\nThen use it with `:- source(my_format, name, [options]).` See skill_transpiler_extension.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_transpiler_extension_005_q2", "cluster_id": "skill_transpiler_extension_005", "question": "How do I implement a custom source type?", "answer": "To implement a custom source type, create a module that registers itself and implements three key predicates:\n\n1. **Register on module load**: Use `register_source_type(my_format, my_source)` in an initialization directive\n\n2. **Implement source_info/1**: Returns metadata about your source type:\n   ```prolog\n   source_info(info(\n       name('My Format Source'),\n       version('1.0.0'),\n       description('Process my custom format'),\n       supported_arities([1, 2, 3])\n   )).\n   ```\n\n3. **Implement validate_config/1**: Validates configuration options before compilation:\n   ```prolog\n   validate_config(Config) :-\n       member(my_file(File), Config),\n       exists_file(File).\n   ```\n\n4. **Implement compile_source/4**: Generates target code:\n   ```prolog\n   compile_source(Pred/Arity, Config, Options, BashCode) :-\n       member(my_file(File), Config),\n       format(atom(BashCode), '# Process ~w from ~w~n...', [Pred, File]).\n   ```\n\nThen declare sources using: `:- source(my_format, name, [my_file('path/to/file')])`.`", "question_type": "long", "topics": ["Quickstart", "Transpiler Extension"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sources", "plugins", "custom-formats"], "related_skills": ["skill_transpiler_extension.md"], "related_docs": ["docs/proposals/BINDING_PREDICATE_PROPOSAL.md"], "original_answer": "Create a custom source plugin module that implements required predicates:\n\n```prolog\n:- module(my_source, []).\n:- use_module('../core/dynamic_source_compiler').\n\n:- initialization(\n    register_source_type(my_format, my_source),\n    now\n).\n\nsource_info(info(\n    name('My Format Source'),\n    version('1.0.0'),\n    description('Process my custom format'),\n    supported_arities([1, 2, 3])\n)).\n\nvalidate_config(Config) :-\n    member(my_file(File), Config),\n    exists_file(File).\n\ncompile_source(Pred/Arity, Config, Options, BashCode) :-\n    member(my_file(File), Config),\n    format(atom(BashCode), '# Process ~w from ~w~n...', [Pred, File]).\n```\n\nThen use it with `:- source(my_format, name, [options]).` See skill_transpiler_extension.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_transpiler_extension_005_q3", "cluster_id": "skill_transpiler_extension_005", "question": "How do I register a new source plugin?", "answer": "To register a new source plugin, create a Prolog module that implements the required predicates:\n\n1. Use `register_source_type/2` in an initialization directive to register your plugin:\n```prolog\n:- initialization(\n    register_source_type(my_format, my_source),\n    now\n).\n```\n\n2. Implement `source_info/1` to declare metadata:\n```prolog\nsource_info(info(\n    name('My Format Source'),\n    version('1.0.0'),\n    description('...'),\n    supported_arities([1, 2, 3])\n)).\n```\n\n3. Implement `validate_config/1` to validate configuration:\n```prolog\nvalidate_config(Config) :-\n    member(my_file(File), Config),\n    exists_file(File).\n```\n\n4. Implement `compile_source/4` to generate target code:\n```prolog\ncompile_source(Pred/Arity, Config, Options, BashCode) :-\n    member(my_file(File), Config),\n    format(atom(BashCode), '# Process ~w from ~w~n...', [Pred, File]).\n```\n\nOnce registered, use the source in your code with: `:- source(my_format, name, [options]).`", "question_type": "long", "topics": ["Quickstart", "Transpiler Extension"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sources", "plugins", "custom-formats"], "related_skills": ["skill_transpiler_extension.md"], "related_docs": ["docs/proposals/BINDING_PREDICATE_PROPOSAL.md"], "original_answer": "Create a custom source plugin module that implements required predicates:\n\n```prolog\n:- module(my_source, []).\n:- use_module('../core/dynamic_source_compiler').\n\n:- initialization(\n    register_source_type(my_format, my_source),\n    now\n).\n\nsource_info(info(\n    name('My Format Source'),\n    version('1.0.0'),\n    description('Process my custom format'),\n    supported_arities([1, 2, 3])\n)).\n\nvalidate_config(Config) :-\n    member(my_file(File), Config),\n    exists_file(File).\n\ncompile_source(Pred/Arity, Config, Options, BashCode) :-\n    member(my_file(File), Config),\n    format(atom(BashCode), '# Process ~w from ~w~n...', [Pred, File]).\n```\n\nThen use it with `:- source(my_format, name, [options]).` See skill_transpiler_extension.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_transpiler_extension_006_q0", "cluster_id": "skill_transpiler_extension_006", "question": "How do I generate pipelines that span multiple target languages?", "answer": "Use the glue system to generate multi-target pipelines by composing steps across different languages. Call `generate_pipeline/3` with a list of steps, where each step specifies a language (awk, python, rust, etc.), a module/script, and configuration options. The glue system automatically handles data serialization and inter-process communication between different language targets, generating a unified shell script that orchestrates the entire pipeline.\n\nExample:\n```prolog\n:- use_module('src/unifyweaver/glue/shell_glue').\n\ngenerate_pipeline :-\n    generate_pipeline(\n        [\n            step(filter, awk, 'filter.awk', []),\n            step(transform, python, 'transform.py', []),\n            step(aggregate, rust, 'aggregate', [])\n        ],\n        [],\n        Script\n    ),\n    write_file('pipeline.sh', Script).\n```\n\nThe generated shell script handles passing data between each stage, so AWK output feeds into Python input, which feeds into Rust, without manual serialization code.", "question_type": "long", "topics": ["Quickstart", "Transpiler Extension"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["cross-target", "glue", "pipelines", "multi-language"], "related_skills": ["skill_transpiler_extension.md"], "related_docs": ["docs/guides/cross-target-glue.md", "education/book-07-cross-target-glue/"], "original_answer": "Use the glue system to generate multi-target pipelines:\n\n```prolog\n:- use_module('src/unifyweaver/glue/shell_glue').\n\ngenerate_pipeline :-\n    generate_pipeline(\n        [\n            step(filter, awk, 'filter.awk', []),\n            step(transform, python, 'transform.py', []),\n            step(aggregate, rust, 'aggregate', [])\n        ],\n        [],\n        Script\n    ),\n    write_file('pipeline.sh', Script).\n```\n\nThis generates a shell script that orchestrates AWK, Python, and Rust components together. The glue system handles data serialization and communication between different language targets. See skill_transpiler_extension.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "Base answer lacks specifics on how glue system handles serialization between stages, what data formats are used for inter-process communication, and concrete examples of how output from one language stage becomes input to the next. The answer assumes readers understand the glue system mechanics without sufficient explanation."}
{"pair_id": "skill_transpiler_extension_006_q1", "cluster_id": "skill_transpiler_extension_006", "question": "Can I combine AWK, Python, and Rust in one pipeline?", "answer": "Yes, you can combine AWK, Python, and Rust in one pipeline using UnifyWeaver's glue system. Use `generate_pipeline/3` with step definitions specifying each tool:\n\n```prolog\n:- use_module('src/unifyweaver/glue/shell_glue').\n\ngenerate_pipeline :-\n    generate_pipeline(\n        [\n            step(filter, awk, 'filter.awk', []),\n            step(transform, python, 'transform.py', []),\n            step(aggregate, rust, 'aggregate', [])\n        ],\n        [],\n        Script\n    ),\n    write_file('pipeline.sh', Script).\n```\n\nThe glue system automatically generates a shell script that orchestrates the three components, handling data serialization and communication between AWK, Python, and Rust stages.", "question_type": "long", "topics": ["Quickstart", "Transpiler Extension"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["cross-target", "glue", "pipelines", "multi-language"], "related_skills": ["skill_transpiler_extension.md"], "related_docs": ["docs/guides/cross-target-glue.md", "education/book-07-cross-target-glue/"], "original_answer": "Use the glue system to generate multi-target pipelines:\n\n```prolog\n:- use_module('src/unifyweaver/glue/shell_glue').\n\ngenerate_pipeline :-\n    generate_pipeline(\n        [\n            step(filter, awk, 'filter.awk', []),\n            step(transform, python, 'transform.py', []),\n            step(aggregate, rust, 'aggregate', [])\n        ],\n        [],\n        Script\n    ),\n    write_file('pipeline.sh', Script).\n```\n\nThis generates a shell script that orchestrates AWK, Python, and Rust components together. The glue system handles data serialization and communication between different language targets. See skill_transpiler_extension.md for details.", "answer_tailored": true, "confidence": 0.75, "confidence_issues": "Base answer references 'skill_transpiler_extension.md' but the provided skill document doesn't detail the glue system mechanics. The answer assumes the API works as shown but lacks implementation details about how data flows between stages and what serialization formats are used."}
{"pair_id": "skill_transpiler_extension_006_q2", "cluster_id": "skill_transpiler_extension_006", "question": "How do I use cross-target glue to connect different languages?", "answer": "Use the glue system to generate multi-target pipelines that connect different languages. Import the shell_glue module and use generate_pipeline/3 to orchestrate components written in different languages (AWK, Python, Rust, etc.). The system automatically handles data serialization and communication between language boundaries, generating a coordinating shell script. Each step specifies the language, script file, and configuration. This allows you to compose heterogeneous language components into unified data processing pipelines without manual inter-language communication code.", "question_type": "long", "topics": ["Quickstart", "Transpiler Extension"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["cross-target", "glue", "pipelines", "multi-language"], "related_skills": ["skill_transpiler_extension.md"], "related_docs": ["docs/guides/cross-target-glue.md", "education/book-07-cross-target-glue/"], "original_answer": "Use the glue system to generate multi-target pipelines:\n\n```prolog\n:- use_module('src/unifyweaver/glue/shell_glue').\n\ngenerate_pipeline :-\n    generate_pipeline(\n        [\n            step(filter, awk, 'filter.awk', []),\n            step(transform, python, 'transform.py', []),\n            step(aggregate, rust, 'aggregate', [])\n        ],\n        [],\n        Script\n    ),\n    write_file('pipeline.sh', Script).\n```\n\nThis generates a shell script that orchestrates AWK, Python, and Rust components together. The glue system handles data serialization and communication between different language targets. See skill_transpiler_extension.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "The base answer references 'skill_transpiler_extension.md' but the actual skill document provided is 'Skill: Transpiler Extension'. The answer assumes the glue system is fully documented and available, but the provided skill document shows only truncated content about sources and bindings with no detailed glue system documentation. The specific API (generate_pipeline/3) and data serialization mechanisms are not elaborated in the available documentation."}
{"pair_id": "skill_transpiler_extension_006_q3", "cluster_id": "skill_transpiler_extension_006", "question": "How do I generate shell scripts that orchestrate multiple languages?", "answer": "Use the glue system to generate multi-target shell scripts that orchestrate multiple languages. Call `generate_pipeline/3` with a list of steps specifying the language, script file, and any options for each component (e.g., AWK for filtering, Python for transformation, Rust for aggregation). The glue system automatically handles data serialization and inter-process communication between different language targets, outputting a single shell script that chains them together.", "question_type": "long", "topics": ["Quickstart", "Transpiler Extension"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["cross-target", "glue", "pipelines", "multi-language"], "related_skills": ["skill_transpiler_extension.md"], "related_docs": ["docs/guides/cross-target-glue.md", "education/book-07-cross-target-glue/"], "original_answer": "Use the glue system to generate multi-target pipelines:\n\n```prolog\n:- use_module('src/unifyweaver/glue/shell_glue').\n\ngenerate_pipeline :-\n    generate_pipeline(\n        [\n            step(filter, awk, 'filter.awk', []),\n            step(transform, python, 'transform.py', []),\n            step(aggregate, rust, 'aggregate', [])\n        ],\n        [],\n        Script\n    ),\n    write_file('pipeline.sh', Script).\n```\n\nThis generates a shell script that orchestrates AWK, Python, and Rust components together. The glue system handles data serialization and communication between different language targets. See skill_transpiler_extension.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "The base answer references specific module paths and API that cannot be verified in the skill document. The truncated skill document makes it impossible to confirm if `generate_pipeline/3` is the correct API or if there are additional required steps for proper data flow between language stages. The answer assumes the user knows how to structure the step tuples correctly."}
{"pair_id": "skill_typescript_target_001_q0", "cluster_id": "skill_typescript_target_001", "question": "How do I compile Prolog code to TypeScript?", "answer": "Use the TypeScript target to compile Prolog predicates to type-safe TypeScript code. First load the module with `?- use_module('src/unifyweaver/targets/typescript_target').` Then call `compile_predicate/3` with your predicate and options, for example `?- compile_predicate(my_pred/2, [type(facts)], Code).` This generates TypeScript code with typed interfaces, query functions, and exports that you can write to `.ts` files using `write_typescript_module/2`. The target supports multiple runtimes (Node.js, Deno, Bun, browser) and features like type annotations, generics, async/await, and ES modules.", "question_type": "medium", "topics": ["Quickstart", "Code Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["compilation", "typescript", "code-generation", "prolog"], "related_skills": ["skill_typescript_target.md"], "related_docs": ["src/unifyweaver/targets/typescript_target.pl", "src/unifyweaver/bindings/typescript_bindings.pl"], "original_answer": "Use the TypeScript target to compile Prolog predicates to type-safe TypeScript code. Load the module and call `compile_predicate/3`: `?- use_module('src/unifyweaver/targets/typescript_target'). ?- compile_predicate(my_pred/2, [type(facts)], Code).` This generates `.ts` files with typed interfaces, query functions, and exports. You can then write the output with `write_typescript_module/2`. See skill_typescript_target.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_typescript_target_001_q1", "cluster_id": "skill_typescript_target_001", "question": "Can I convert Prolog predicates to TypeScript?", "answer": "Yes, you can convert Prolog predicates to TypeScript using the TypeScript target. Load the module with `use_module('src/unifyweaver/targets/typescript_target')` and call `compile_predicate(my_pred/2, [type(facts)], Code)` to compile your predicates. This generates `.ts` files with typed interfaces, query functions, and exports that support Node.js, Deno, Bun, and browser runtimes. You can then write the output using `write_typescript_module/2`. The TypeScript target supports features like type annotations, generics, async/await, ES modules, and various recursion patterns (tail recursion, linear recursion, list folding, transitive closure).", "question_type": "medium", "topics": ["Quickstart", "Code Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["compilation", "typescript", "code-generation", "prolog"], "related_skills": ["skill_typescript_target.md"], "related_docs": ["src/unifyweaver/targets/typescript_target.pl", "src/unifyweaver/bindings/typescript_bindings.pl"], "original_answer": "Use the TypeScript target to compile Prolog predicates to type-safe TypeScript code. Load the module and call `compile_predicate/3`: `?- use_module('src/unifyweaver/targets/typescript_target'). ?- compile_predicate(my_pred/2, [type(facts)], Code).` This generates `.ts` files with typed interfaces, query functions, and exports. You can then write the output with `write_typescript_module/2`. See skill_typescript_target.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_typescript_target_001_q2", "cluster_id": "skill_typescript_target_001", "question": "How do I generate TypeScript from Prolog?", "answer": "To generate TypeScript from Prolog, use the TypeScript target module. First, load it with `?- use_module('src/unifyweaver/targets/typescript_target').` Then compile your predicates with `?- compile_predicate(my_pred/2, [type(facts)], Code).` This generates type-safe TypeScript code with typed interfaces, query functions, and exports. The target supports multiple runtimes (Node.js, Deno, Bun, browser) and compilation types including facts-to-arrays, recursion patterns, and module compilation. Write the output to a file using `write_typescript_module/2`.", "question_type": "medium", "topics": ["Quickstart", "Code Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["compilation", "typescript", "code-generation", "prolog"], "related_skills": ["skill_typescript_target.md"], "related_docs": ["src/unifyweaver/targets/typescript_target.pl", "src/unifyweaver/bindings/typescript_bindings.pl"], "original_answer": "Use the TypeScript target to compile Prolog predicates to type-safe TypeScript code. Load the module and call `compile_predicate/3`: `?- use_module('src/unifyweaver/targets/typescript_target'). ?- compile_predicate(my_pred/2, [type(facts)], Code).` This generates `.ts` files with typed interfaces, query functions, and exports. You can then write the output with `write_typescript_module/2`. See skill_typescript_target.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_typescript_target_002_q0", "cluster_id": "skill_typescript_target_002", "question": "How do I convert Prolog facts to TypeScript typed arrays?", "answer": "Use `compile_facts/3` to convert Prolog facts to TypeScript typed arrays. For example, `?- compile_facts(parent, 2, Code).` generates a `ParentFact` interface with typed properties, exports a `parentFacts` array containing your facts, and creates helper functions: `queryParent()` for filtering by criteria and `isParent()` for membership testing. The generated TypeScript code includes full type safety and works in Node.js, Deno, Bun, or browsers.", "question_type": "long", "topics": ["Quickstart", "Code Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["facts", "typescript", "interfaces", "type-safe"], "related_skills": ["skill_typescript_target.md"], "related_docs": ["src/unifyweaver/targets/typescript_target.pl"], "original_answer": "Use `compile_facts/3` to generate typed interfaces and query functions: `?- compile_facts(parent, 2, Code).` This creates a `ParentFact` interface, exports a `parentFacts` array, and generates helper functions like `queryParent/1` for filtering and `isParent/2` for testing. The generated code includes full type safety and is ready to use in Node.js, Deno, Bun, or browsers. See skill_typescript_target.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_typescript_target_002_q1", "cluster_id": "skill_typescript_target_002", "question": "Can I generate TypeScript interfaces from Prolog facts?", "answer": "Yes. Use `compile_facts/3` to generate TypeScript interfaces from Prolog facts. For example, `?- compile_facts(parent, 2, Code).` generates a `ParentFact` interface with typed fields, exports a `parentFacts` array containing the fact data, and creates helper functions like `queryParent/1` for filtering facts and `isParent/2` for testing membership. The generated code includes full type safety and works in Node.js, Deno, Bun, or browsers.", "question_type": "long", "topics": ["Quickstart", "Code Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["facts", "typescript", "interfaces", "type-safe"], "related_skills": ["skill_typescript_target.md"], "related_docs": ["src/unifyweaver/targets/typescript_target.pl"], "original_answer": "Use `compile_facts/3` to generate typed interfaces and query functions: `?- compile_facts(parent, 2, Code).` This creates a `ParentFact` interface, exports a `parentFacts` array, and generates helper functions like `queryParent/1` for filtering and `isParent/2` for testing. The generated code includes full type safety and is ready to use in Node.js, Deno, Bun, or browsers. See skill_typescript_target.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_typescript_target_002_q2", "cluster_id": "skill_typescript_target_002", "question": "How do I compile Prolog facts with types?", "answer": "Use `compile_facts/3` to generate typed interfaces and query functions from Prolog facts. For example, `?- compile_facts(parent, 2, Code).` generates a `ParentFact` TypeScript interface with type-safe properties, exports a `parentFacts` array containing the compiled facts, and creates helper functions like `queryParent/1` for filtering by criteria and `isParent/2` for membership testing. The generated TypeScript code includes full type annotations and is immediately usable in Node.js, Deno, Bun, or browser environments.", "question_type": "long", "topics": ["Quickstart", "Code Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["facts", "typescript", "interfaces", "type-safe"], "related_skills": ["skill_typescript_target.md"], "related_docs": ["src/unifyweaver/targets/typescript_target.pl"], "original_answer": "Use `compile_facts/3` to generate typed interfaces and query functions: `?- compile_facts(parent, 2, Code).` This creates a `ParentFact` interface, exports a `parentFacts` array, and generates helper functions like `queryParent/1` for filtering and `isParent/2` for testing. The generated code includes full type safety and is ready to use in Node.js, Deno, Bun, or browsers. See skill_typescript_target.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_typescript_target_003_q0", "cluster_id": "skill_typescript_target_003", "question": "How do I generate an Express.js REST API from Prolog?", "answer": "Use `compile_express_service/2` to generate a complete Express.js server with typed endpoints and middleware. Call `?- compile_express_service(service(api, [port(3000), endpoints([endpoint('/users', get, getUsers), ...]), middleware([cors, json])]), Code).` to generate TypeScript code with type-safe route handlers, middleware configuration, and error handling. Write the output to a .ts file and run with `npx ts-node src/server.ts`. The generated code includes request/response types, endpoint resolution, and proper Express.js integration patterns. Refer to skill_typescript_target.md for advanced configuration options.", "question_type": "long", "topics": ["Quickstart", "Code Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["rest-api", "express", "server", "generation"], "related_skills": ["skill_typescript_target.md"], "related_docs": ["src/unifyweaver/targets/typescript_target.pl"], "original_answer": "Use `compile_express_service/2` to generate a complete Express.js server: `?- compile_express_service(service(api, [port(3000), endpoints([endpoint('/users', get, getUsers), ...]), middleware([cors, json])]), Code).` This generates typed endpoints, middleware setup, error handling, and startup code. Write the output with `write_typescript_module/2` and run with `npx ts-node src/server.ts`. See skill_typescript_target.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "Base answer assumes familiarity with Prolog syntax and doesn't explain what the endpoint/middleware parameters do or how to structure the service definition for typical REST patterns (CRUD operations, authentication, etc.). The confidence is slightly lower because the base answer lacks concrete examples of the service configuration structure."}
{"pair_id": "skill_typescript_target_003_q1", "cluster_id": "skill_typescript_target_003", "question": "Can I create a REST service from Prolog specs?", "answer": "Yes, you can create a REST service from Prolog specs using `compile_express_service/2`. This generates a complete Express.js server with typed endpoints, middleware setup, and error handling. Example: `?- compile_express_service(service(api, [port(3000), endpoints([endpoint('/users', get, getUsers), ...]), middleware([cors, json])]), Code).` Write the output with `write_typescript_module/2` and run with `npx ts-node src/server.ts`.", "question_type": "long", "topics": ["Quickstart", "Code Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["rest-api", "express", "server", "generation"], "related_skills": ["skill_typescript_target.md"], "related_docs": ["src/unifyweaver/targets/typescript_target.pl"], "original_answer": "Use `compile_express_service/2` to generate a complete Express.js server: `?- compile_express_service(service(api, [port(3000), endpoints([endpoint('/users', get, getUsers), ...]), middleware([cors, json])]), Code).` This generates typed endpoints, middleware setup, error handling, and startup code. Write the output with `write_typescript_module/2` and run with `npx ts-node src/server.ts`. See skill_typescript_target.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_typescript_target_003_q2", "cluster_id": "skill_typescript_target_003", "question": "How do I compile Prolog to an Express server?", "answer": "Use `compile_express_service/2` to generate a complete Express.js server from Prolog. Call `?- compile_express_service(service(api, [port(3000), endpoints([endpoint('/users', get, getUsers), ...]), middleware([cors, json])]), Code).` This produces a `.ts` file with typed endpoints, middleware configuration, error handling, and server startup code. Write the output with `write_typescript_module/2` and execute with `npx ts-node src/server.ts`. The generated code includes full TypeScript type annotations for request/response handling and middleware integration.", "question_type": "long", "topics": ["Quickstart", "Code Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["rest-api", "express", "server", "generation"], "related_skills": ["skill_typescript_target.md"], "related_docs": ["src/unifyweaver/targets/typescript_target.pl"], "original_answer": "Use `compile_express_service/2` to generate a complete Express.js server: `?- compile_express_service(service(api, [port(3000), endpoints([endpoint('/users', get, getUsers), ...]), middleware([cors, json])]), Code).` This generates typed endpoints, middleware setup, error handling, and startup code. Write the output with `write_typescript_module/2` and run with `npx ts-node src/server.ts`. See skill_typescript_target.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "Base answer references 'skill_typescript_target.md' but the skill document provided doesn't show the Express service compilation section (marked as truncated). The predicates and options shown are reasonable inferences from the overall TypeScript target design, but exact parameter names and behavior cannot be fully verified from the truncated documentation."}
{"pair_id": "skill_typescript_target_004_q0", "cluster_id": "skill_typescript_target_004", "question": "What runtimes can TypeScript code target?", "answer": "The TypeScript target supports four runtimes: Node.js (`node`) for backend services and CLI tools, Deno (`deno`) for secure TypeScript-first development, Bun (`bun`) for fast JavaScript execution, and browsers (`browser`) for web applications. Runtime is auto-detected based on your environment but can be specified explicitly. Each runtime generates code optimized for that environment with appropriate module and import handling.", "question_type": "medium", "topics": ["Quickstart", "Code Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["runtime", "environments", "node", "deno", "bun", "browser"], "related_skills": ["skill_typescript_target.md"], "related_docs": ["src/unifyweaver/targets/typescript_target.pl"], "original_answer": "The TypeScript target supports Node.js, Deno, Bun, and browser environments. Runtime is auto-detected based on your setup but can be specified explicitly. Use `node` for backend services and CLI tools, `deno` for secure TypeScript-first development, `bun` for fast JavaScript execution, or `browser` for web applications. Each runtime generates code optimized for that environment with appropriate module and import handling. See skill_typescript_target.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_typescript_target_004_q1", "cluster_id": "skill_typescript_target_004", "question": "Can I generate code for different JavaScript environments?", "answer": "Yes, the TypeScript target supports multiple JavaScript environments: Node.js (for backend services and CLI tools), Deno (for secure TypeScript-first development), Bun (for fast JavaScript execution), and browser (for web applications). Runtime is auto-detected based on your setup but can be specified explicitly. Each runtime generates code optimized for that environment with appropriate module and import handling.", "question_type": "medium", "topics": ["Quickstart", "Code Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["runtime", "environments", "node", "deno", "bun", "browser"], "related_skills": ["skill_typescript_target.md"], "related_docs": ["src/unifyweaver/targets/typescript_target.pl"], "original_answer": "The TypeScript target supports Node.js, Deno, Bun, and browser environments. Runtime is auto-detected based on your setup but can be specified explicitly. Use `node` for backend services and CLI tools, `deno` for secure TypeScript-first development, `bun` for fast JavaScript execution, or `browser` for web applications. Each runtime generates code optimized for that environment with appropriate module and import handling. See skill_typescript_target.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_typescript_target_004_q2", "cluster_id": "skill_typescript_target_004", "question": "What environments does TypeScript generation support?", "answer": "TypeScript generation supports four environments: Node.js (for backend services and CLI tools), Deno (for secure, TypeScript-first development), Bun (for fast JavaScript execution), and browser (for web applications). The runtime is auto-detected based on your setup but can be specified explicitly. Each runtime generates code optimized for that environment with appropriate module and import handling.", "question_type": "medium", "topics": ["Quickstart", "Code Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["runtime", "environments", "node", "deno", "bun", "browser"], "related_skills": ["skill_typescript_target.md"], "related_docs": ["src/unifyweaver/targets/typescript_target.pl"], "original_answer": "The TypeScript target supports Node.js, Deno, Bun, and browser environments. Runtime is auto-detected based on your setup but can be specified explicitly. Use `node` for backend services and CLI tools, `deno` for secure TypeScript-first development, `bun` for fast JavaScript execution, or `browser` for web applications. Each runtime generates code optimized for that environment with appropriate module and import handling. See skill_typescript_target.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_typescript_target_005_q0", "cluster_id": "skill_typescript_target_005", "question": "How do I compile recursive Prolog predicates to TypeScript?", "answer": "To compile recursive Prolog predicates to TypeScript, use `compile_recursion/3` with pattern specifications. For example: `?- compile_recursion(factorial/2, [pattern(tail_recursion)], Code).` Supported patterns include: `tail_recursion` (converted to while loops for guaranteed tail call optimization), `linear_recursion` (with memoization for Fibonacci-style recursion), `list_fold` (using Array.reduce for list operations), and `transitive_closure` (for graph traversal with iteration). The generated TypeScript includes both recursive and optimized iterative versions when applicable, ensuring type safety with proper TypeScript annotations.", "question_type": "long", "topics": ["Quickstart", "Code Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["recursion", "tail-call-optimization", "patterns", "compilation"], "related_skills": ["skill_typescript_target.md"], "related_docs": ["src/unifyweaver/targets/typescript_target.pl"], "original_answer": "Use `compile_recursion/3` with pattern specifications: `?- compile_recursion(factorial/2, [pattern(tail_recursion)], Code).` Supported patterns include `tail_recursion` (converted to while loops for TCO), `linear_recursion` (with memoization), `list_fold` (using Array.reduce), and `transitive_closure` (for graph traversal). The generated code includes both recursive and optimized versions when appropriate. See skill_typescript_target.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_typescript_target_005_q1", "cluster_id": "skill_typescript_target_005", "question": "Can I generate TypeScript for tail-recursive functions?", "answer": "Yes, you can generate TypeScript for tail-recursive functions using `compile_recursion/3` with the `tail_recursion` pattern. The compiler converts tail-recursive Prolog predicates to TypeScript while loops to guarantee tail call optimization (TCO). For example: `?- compile_recursion(factorial/2, [pattern(tail_recursion)], Code).` generates both a recursive version and an optimized strict version that uses iteration. Other recursion patterns are also supported: `linear_recursion` with memoization, `list_fold` using Array.reduce, and `transitive_closure` for graph traversal.", "question_type": "long", "topics": ["Quickstart", "Code Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["recursion", "tail-call-optimization", "patterns", "compilation"], "related_skills": ["skill_typescript_target.md"], "related_docs": ["src/unifyweaver/targets/typescript_target.pl"], "original_answer": "Use `compile_recursion/3` with pattern specifications: `?- compile_recursion(factorial/2, [pattern(tail_recursion)], Code).` Supported patterns include `tail_recursion` (converted to while loops for TCO), `linear_recursion` (with memoization), `list_fold` (using Array.reduce), and `transitive_closure` (for graph traversal). The generated code includes both recursive and optimized versions when appropriate. See skill_typescript_target.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_typescript_target_005_q2", "cluster_id": "skill_typescript_target_005", "question": "How do I handle Prolog recursion patterns in TypeScript?", "answer": "To handle Prolog recursion patterns in TypeScript, use `compile_recursion/3` with pattern specifications. For example: `?- compile_recursion(factorial/2, [pattern(tail_recursion)], Code).` The TypeScript target supports four main patterns: `tail_recursion` (converted to while loops for guaranteed tail call optimization), `linear_recursion` (with memoization for repeated calls), `list_fold` (using Array.reduce for list operations), and `transitive_closure` (for graph traversal with iteration). The compiler generates both recursive and optimized versions when appropriate\u2014for tail recursion, you get both the recursive form and a strict while-loop version to ensure TCO.", "question_type": "long", "topics": ["Quickstart", "Code Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["recursion", "tail-call-optimization", "patterns", "compilation"], "related_skills": ["skill_typescript_target.md"], "related_docs": ["src/unifyweaver/targets/typescript_target.pl"], "original_answer": "Use `compile_recursion/3` with pattern specifications: `?- compile_recursion(factorial/2, [pattern(tail_recursion)], Code).` Supported patterns include `tail_recursion` (converted to while loops for TCO), `linear_recursion` (with memoization), `list_fold` (using Array.reduce), and `transitive_closure` (for graph traversal). The generated code includes both recursive and optimized versions when appropriate. See skill_typescript_target.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_typescript_target_006_q0", "cluster_id": "skill_typescript_target_006", "question": "How do I use TypeScript bindings for JavaScript standard library functions?", "answer": "TypeScript bindings automatically map Prolog predicates to JavaScript stdlib functions. For strings: `string_length/2` \u2192 `.length`, `string_upper/2` \u2192 `.toUpperCase()`. For arrays: `array_map/3` \u2192 `.map()`, `array_filter/3` \u2192 `.filter()`. For math: `abs/2` \u2192 `Math.abs()`, `sqrt/2` \u2192 `Math.sqrt()`. For Node.js files: `read_file_sync/2` \u2192 `fs.readFileSync()`. The compiler automatically tracks required imports via `collect_binding_import/1` and includes them in generated TypeScript code.", "question_type": "medium", "topics": ["Quickstart", "Code Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["bindings", "stdlib", "javascript", "imports"], "related_skills": ["skill_typescript_target.md"], "related_docs": ["src/unifyweaver/bindings/typescript_bindings.pl", "src/unifyweaver/core/binding_registry.pl"], "original_answer": "TypeScript bindings automatically map Prolog predicates to JavaScript stdlib functions. For strings: `string_length/2` \u2192 `.length`, `string_upper/2` \u2192 `.toUpperCase()`. For arrays: `array_map/3` \u2192 `.map()`, `array_filter/3` \u2192 `.filter()`. For math: `abs/2` \u2192 `Math.abs()`, `sqrt/2` \u2192 `Math.sqrt()`. For files (Node.js): `read_file_sync/2` \u2192 `fs.readFileSync()`. Use `collect_binding_import/1` to track required imports, and they'll be included automatically in generated code. See skill_typescript_target.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_typescript_target_006_q1", "cluster_id": "skill_typescript_target_006", "question": "Can I call JavaScript built-ins from Prolog code?", "answer": "Yes, you can call JavaScript built-ins from Prolog code through automatic TypeScript bindings. String operations like `string_length/2` map to `.length`, `string_upper/2` to `.toUpperCase()`. Array operations like `array_map/3` map to `.map()`, `array_filter/3` to `.filter()`. Math functions like `abs/2` map to `Math.abs()`, `sqrt/2` to `Math.sqrt()`. For Node.js file operations, `read_file_sync/2` maps to `fs.readFileSync()`. The compiler automatically tracks required imports via `collect_binding_import/1` and includes them in the generated TypeScript code.", "question_type": "medium", "topics": ["Quickstart", "Code Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["bindings", "stdlib", "javascript", "imports"], "related_skills": ["skill_typescript_target.md"], "related_docs": ["src/unifyweaver/bindings/typescript_bindings.pl", "src/unifyweaver/core/binding_registry.pl"], "original_answer": "TypeScript bindings automatically map Prolog predicates to JavaScript stdlib functions. For strings: `string_length/2` \u2192 `.length`, `string_upper/2` \u2192 `.toUpperCase()`. For arrays: `array_map/3` \u2192 `.map()`, `array_filter/3` \u2192 `.filter()`. For math: `abs/2` \u2192 `Math.abs()`, `sqrt/2` \u2192 `Math.sqrt()`. For files (Node.js): `read_file_sync/2` \u2192 `fs.readFileSync()`. Use `collect_binding_import/1` to track required imports, and they'll be included automatically in generated code. See skill_typescript_target.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_typescript_target_006_q2", "cluster_id": "skill_typescript_target_006", "question": "How do I map Prolog predicates to String/Array/Math methods?", "answer": "TypeScript bindings automatically map Prolog predicates to JavaScript stdlib functions. For strings: `string_length/2` maps to `.length`, `string_upper/2` to `.toUpperCase()`. For arrays: `array_map/3` maps to `.map()`, `array_filter/3` to `.filter()`. For math: `abs/2` maps to `Math.abs()`, `sqrt/2` to `Math.sqrt()`. For Node.js file operations: `read_file_sync/2` maps to `fs.readFileSync()`. The TypeScript target automatically tracks required imports via `collect_binding_import/1` and includes them in the generated code.", "question_type": "medium", "topics": ["Quickstart", "Code Generation"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["bindings", "stdlib", "javascript", "imports"], "related_skills": ["skill_typescript_target.md"], "related_docs": ["src/unifyweaver/bindings/typescript_bindings.pl", "src/unifyweaver/core/binding_registry.pl"], "original_answer": "TypeScript bindings automatically map Prolog predicates to JavaScript stdlib functions. For strings: `string_length/2` \u2192 `.length`, `string_upper/2` \u2192 `.toUpperCase()`. For arrays: `array_map/3` \u2192 `.map()`, `array_filter/3` \u2192 `.filter()`. For math: `abs/2` \u2192 `Math.abs()`, `sqrt/2` \u2192 `Math.sqrt()`. For files (Node.js): `read_file_sync/2` \u2192 `fs.readFileSync()`. Use `collect_binding_import/1` to track required imports, and they'll be included automatically in generated code. See skill_typescript_target.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "Base answer is accurate but generic. Confidence is slightly lower because the answer doesn't provide concrete compilation examples (e.g., how a specific Prolog predicate call translates to TypeScript) or mention whether mappings are automatic or require explicit configuration."}
{"pair_id": "skill_web_frameworks_001_q0", "cluster_id": "skill_web_frameworks_001", "question": "How do I create a REST API from my Prolog predicates?", "answer": "You can generate REST API servers from your Prolog predicates using Flask, FastAPI, or Express. For simple Python APIs, use `generate_flask_app/3` to convert your Prolog predicates into Flask routes. For async Python APIs with built-in validation, use `generate_fastapi_app/3`. For Node.js, use `generate_express_app/3`. Example: `generate_flask_app([fetch_items, create_item], [app_name('ItemAPI')], Code).` Pass your predicate names as the first argument, options like `app_name/1` as the second, and the generated code is unified with the third argument. Each framework supports common patterns like pagination, CRUD operations, and cursor-based infinite scroll out of the box.", "question_type": "medium", "topics": ["Quickstart", "Web Frameworks (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["api", "rest", "prolog", "web-service"], "related_skills": ["skill_web_frameworks.md", "skill_flask_api.md", "skill_fastapi.md", "skill_express_api.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl", "src/unifyweaver/glue/fastapi_generator.pl", "src/unifyweaver/glue/express_generator.pl"], "original_answer": "You can generate REST API servers from Prolog using Flask, FastAPI, or Express. Use `generate_flask_app/3` for simple Python APIs, `generate_fastapi_app/3` for async Python with validation, or `generate_express_app/3` for Node.js. Example: `generate_flask_app([fetch_items, create_item], [app_name('ItemAPI')], Code).` See skill_web_frameworks.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_web_frameworks_001_q1", "cluster_id": "skill_web_frameworks_001", "question": "How can I expose Prolog logic as HTTP endpoints?", "answer": "You can expose Prolog logic as HTTP endpoints by generating REST API servers using `generate_flask_app/3` for simple Python APIs, `generate_fastapi_app/3` for async Python with validation, or `generate_express_app/3` for Node.js. For example, use `generate_flask_app([fetch_items, create_item], [app_name('ItemAPI')], Code)` to generate a complete Flask app that exposes your Prolog predicates as HTTP endpoints. FastAPI provides automatic validation with Pydantic models, while Express offers native async support for the Node.js ecosystem.", "question_type": "medium", "topics": ["Quickstart", "Web Frameworks (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["api", "rest", "prolog", "web-service"], "related_skills": ["skill_web_frameworks.md", "skill_flask_api.md", "skill_fastapi.md", "skill_express_api.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl", "src/unifyweaver/glue/fastapi_generator.pl", "src/unifyweaver/glue/express_generator.pl"], "original_answer": "You can generate REST API servers from Prolog using Flask, FastAPI, or Express. Use `generate_flask_app/3` for simple Python APIs, `generate_fastapi_app/3` for async Python with validation, or `generate_express_app/3` for Node.js. Example: `generate_flask_app([fetch_items, create_item], [app_name('ItemAPI')], Code).` See skill_web_frameworks.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_web_frameworks_001_q2", "cluster_id": "skill_web_frameworks_001", "question": "Can I turn my Prolog code into a web service?", "answer": "Yes, you can convert Prolog code into a web service by generating REST API servers. Use `generate_flask_app/3` for simple Python APIs, `generate_fastapi_app/3` for async Python with validation, or `generate_express_app/3` for Node.js services. For example: `generate_flask_app([fetch_items, create_item], [app_name('ItemAPI')], Code).` exposes your Prolog predicates as HTTP endpoints. Choose Flask for simplicity, FastAPI for modern async Python with built-in validation, or Express for a JavaScript environment.", "question_type": "medium", "topics": ["Quickstart", "Web Frameworks (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["api", "rest", "prolog", "web-service"], "related_skills": ["skill_web_frameworks.md", "skill_flask_api.md", "skill_fastapi.md", "skill_express_api.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl", "src/unifyweaver/glue/fastapi_generator.pl", "src/unifyweaver/glue/express_generator.pl"], "original_answer": "You can generate REST API servers from Prolog using Flask, FastAPI, or Express. Use `generate_flask_app/3` for simple Python APIs, `generate_fastapi_app/3` for async Python with validation, or `generate_express_app/3` for Node.js. Example: `generate_flask_app([fetch_items, create_item], [app_name('ItemAPI')], Code).` See skill_web_frameworks.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_web_frameworks_002_q0", "cluster_id": "skill_web_frameworks_002", "question": "What's the difference between Flask, FastAPI, and Express for building APIs?", "answer": "Flask is best for simple Python APIs with optional async support, requiring manual validation. FastAPI is ideal for modern Python APIs with native async/await and automatic request validation via Pydantic models. Express is best for Node.js environments with native async capabilities. Key differences: Flask uses decorators and minimal dependencies; FastAPI adds automatic OpenAPI documentation and type-based validation; Express provides middleware-based architecture. All three support pagination, CRUD operations, and CORS, but FastAPI requires less boilerplate for production-grade APIs.", "question_type": "medium", "topics": ["Quickstart", "Web Frameworks (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["comparison", "framework", "api", "python", "nodejs"], "related_skills": ["skill_web_frameworks.md", "skill_flask_api.md", "skill_fastapi.md", "skill_express_api.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl", "src/unifyweaver/glue/fastapi_generator.pl", "src/unifyweaver/glue/express_generator.pl"], "original_answer": "Flask is best for simple Python APIs with optional async. FastAPI is ideal for modern Python APIs with built-in async and automatic Pydantic validation. Express is best if you're using the Node.js ecosystem. All three frameworks support pagination, CRUD operations, and CORS. See skill_web_frameworks.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_web_frameworks_002_q1", "cluster_id": "skill_web_frameworks_002", "question": "Which framework should I use for my REST API?", "answer": "Choose based on your tech stack: Flask for simple Python APIs with minimal overhead, FastAPI for modern Python projects needing async/validation, or Express for Node.js environments. Flask requires manual validation; FastAPI provides automatic Pydantic validation. Express has native async. All support pagination, CRUD, and CORS. Consider team expertise and performance requirements\u2014FastAPI offers the most built-in features, Flask the simplest setup, Express integrates best with JavaScript tooling.", "question_type": "medium", "topics": ["Quickstart", "Web Frameworks (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["comparison", "framework", "api", "python", "nodejs"], "related_skills": ["skill_web_frameworks.md", "skill_flask_api.md", "skill_fastapi.md", "skill_express_api.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl", "src/unifyweaver/glue/fastapi_generator.pl", "src/unifyweaver/glue/express_generator.pl"], "original_answer": "Flask is best for simple Python APIs with optional async. FastAPI is ideal for modern Python APIs with built-in async and automatic Pydantic validation. Express is best if you're using the Node.js ecosystem. All three frameworks support pagination, CRUD operations, and CORS. See skill_web_frameworks.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_web_frameworks_002_q2", "cluster_id": "skill_web_frameworks_002", "question": "Should I use Python or Node.js for my API?", "answer": "Choose Python if you prefer simplicity and have Python expertise in your team. Use Flask for lightweight Python APIs, or FastAPI for modern Python with built-in async and validation. Choose Node.js if you're already in the JavaScript ecosystem or need strong async performance. All three frameworks handle pagination, CRUD, and CORS equally well. Decision factors: team expertise, existing infrastructure, and performance requirements rather than framework capability.", "question_type": "medium", "topics": ["Quickstart", "Web Frameworks (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["comparison", "framework", "api", "python", "nodejs"], "related_skills": ["skill_web_frameworks.md", "skill_flask_api.md", "skill_fastapi.md", "skill_express_api.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl", "src/unifyweaver/glue/fastapi_generator.pl", "src/unifyweaver/glue/express_generator.pl"], "original_answer": "Flask is best for simple Python APIs with optional async. FastAPI is ideal for modern Python APIs with built-in async and automatic Pydantic validation. Express is best if you're using the Node.js ecosystem. All three frameworks support pagination, CRUD operations, and CORS. See skill_web_frameworks.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "Base answer doesn't address the 'Python vs Node.js' choice directly enough\u2014it lists frameworks but doesn't explain why someone would pick one language over another. Added team expertise and infrastructure context which the base answer lacks."}
{"pair_id": "skill_web_frameworks_003_q0", "cluster_id": "skill_web_frameworks_003", "question": "How do I add pagination to my API endpoints?", "answer": "To add pagination to your API endpoints, use page and limit parameters in your query handlers. For example: `@app.get('/api/items') def list_items(page: int = 1, limit: int = 20): offset = (page - 1) * limit; return {\"data\": items, \"pagination\": {...}}`. Calculate the offset as `(page - 1) * limit` to determine which records to return. For infinite scroll use cases, implement cursor-based pagination instead, where you pass a cursor parameter to get the next batch of results. All major frameworks (Flask, FastAPI, Express) support both approaches through the UnifyWeaver generators.", "question_type": "long", "topics": ["Quickstart", "Web Frameworks (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["pagination", "api", "query", "performance"], "related_skills": ["skill_web_frameworks.md", "skill_flask_api.md", "skill_fastapi.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl", "src/unifyweaver/glue/fastapi_generator.pl"], "original_answer": "All frameworks generate handlers with pagination support. Use page and limit parameters: `@app.get('/api/items') def list_items(page: int = 1, limit: int = 20): offset = (page - 1) * limit; return {\"data\": items, \"pagination\": {...}}`. For infinite scroll, use cursor-based pagination instead. See skill_web_frameworks.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_web_frameworks_003_q1", "cluster_id": "skill_web_frameworks_003", "question": "How can I handle large datasets with pagination?", "answer": "For large datasets, use pagination to retrieve data in manageable chunks. All web frameworks (Flask, FastAPI, Express) support pagination through query parameters. Implement offset-based pagination using `page` and `limit` parameters: calculate `offset = (page - 1) * limit` to determine which records to fetch. Return both the data and pagination metadata including current page, total count, and whether more data exists. For better performance with very large datasets, use cursor-based pagination instead, which returns a `nextCursor` token pointing to the next batch of results. This approach is more efficient than offset pagination for large result sets since it doesn't require counting total records. See skill_flask_api.md, skill_fastapi.md, or skill_express_api.md for framework-specific implementation examples.", "question_type": "long", "topics": ["Quickstart", "Web Frameworks (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["pagination", "api", "query", "performance"], "related_skills": ["skill_web_frameworks.md", "skill_flask_api.md", "skill_fastapi.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl", "src/unifyweaver/glue/fastapi_generator.pl"], "original_answer": "All frameworks generate handlers with pagination support. Use page and limit parameters: `@app.get('/api/items') def list_items(page: int = 1, limit: int = 20): offset = (page - 1) * limit; return {\"data\": items, \"pagination\": {...}}`. For infinite scroll, use cursor-based pagination instead. See skill_web_frameworks.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_web_frameworks_003_q2", "cluster_id": "skill_web_frameworks_003", "question": "What's the best way to implement page-based results?", "answer": "For page-based results, use offset-based pagination with page and limit parameters. Calculate the offset as `(page - 1) * limit` and query that range of results. All web frameworks (Flask, FastAPI, Express) support this pattern: `@app.get('/api/items') def list_items(page: int = 1, limit: int = 20): offset = (page - 1) * limit; return {\"data\": items, \"pagination\": {\"page\": page, \"limit\": limit, \"total\": total_count}}`. This approach works well for small to medium datasets where total count is available. For large datasets or better UX, consider cursor-based pagination instead.", "question_type": "long", "topics": ["Quickstart", "Web Frameworks (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["pagination", "api", "query", "performance"], "related_skills": ["skill_web_frameworks.md", "skill_flask_api.md", "skill_fastapi.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl", "src/unifyweaver/glue/fastapi_generator.pl"], "original_answer": "All frameworks generate handlers with pagination support. Use page and limit parameters: `@app.get('/api/items') def list_items(page: int = 1, limit: int = 20): offset = (page - 1) * limit; return {\"data\": items, \"pagination\": {...}}`. For infinite scroll, use cursor-based pagination instead. See skill_web_frameworks.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_web_frameworks_004_q0", "cluster_id": "skill_web_frameworks_004", "question": "How do I create CRUD endpoints for my data models?", "answer": "Create CRUD endpoints by using mutation handlers for each operation. For Flask: use `@app.post('/api/items')` for CREATE, `@app.get('/api/items/<id>')` for READ, `@app.put('/api/items/<id>')` for UPDATE, and `@app.delete('/api/items/<id>')` for DELETE. Define request/response models (ItemInput, ItemOutput) and generate handlers with `generate_flask_query_handler/4`. FastAPI uses Pydantic models for automatic validation. Express uses `app.post()`, `app.get()`, `app.put()`, `app.delete()` methods similarly. Each handler receives data, validates it against your model schema, performs the database operation, and returns success status with the result.", "question_type": "long", "topics": ["Quickstart", "Web Frameworks (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["crud", "mutation", "api", "post", "put", "delete"], "related_skills": ["skill_web_frameworks.md", "skill_flask_api.md", "skill_fastapi.md", "skill_express_api.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl", "src/unifyweaver/glue/fastapi_generator.pl", "src/unifyweaver/glue/express_generator.pl"], "original_answer": "Use mutation handlers for CRUD operations. Example: `@app.post('/api/items') def create_item(data: ItemInput): return {\"success\": True, \"data\": result}`. Generate handlers with `generate_flask_query_handler/4` or equivalent for your framework. Each framework provides decorators for GET, POST, PUT, DELETE methods. See skill_web_frameworks.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "Base answer focuses mainly on POST (create) but the question asks about all CRUD operations. Tailored answer adds complete CRUD pattern coverage, though specific integration with Prolog predicates could be more explicit."}
{"pair_id": "skill_web_frameworks_004_q1", "cluster_id": "skill_web_frameworks_004", "question": "How do I handle POST, PUT, and DELETE requests?", "answer": "To handle POST, PUT, and DELETE requests, use mutation handlers in your web framework. In Flask/FastAPI, use decorators like `@app.post('/api/items')`, `@app.put('/api/items/{id}')`, and `@app.delete('/api/items/{id}')`. Define functions to process the request data and return a response. In Express, use `router.post()`, `router.put()`, and `router.delete()`. Generate these handlers with `generate_flask_query_handler/4` for Flask or the equivalent generator for your framework (FastAPI or Express). All frameworks support these HTTP methods for CRUD operations\u2014POST creates, PUT updates, DELETE removes resources.", "question_type": "long", "topics": ["Quickstart", "Web Frameworks (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["crud", "mutation", "api", "post", "put", "delete"], "related_skills": ["skill_web_frameworks.md", "skill_flask_api.md", "skill_fastapi.md", "skill_express_api.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl", "src/unifyweaver/glue/fastapi_generator.pl", "src/unifyweaver/glue/express_generator.pl"], "original_answer": "Use mutation handlers for CRUD operations. Example: `@app.post('/api/items') def create_item(data: ItemInput): return {\"success\": True, \"data\": result}`. Generate handlers with `generate_flask_query_handler/4` or equivalent for your framework. Each framework provides decorators for GET, POST, PUT, DELETE methods. See skill_web_frameworks.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_web_frameworks_004_q2", "cluster_id": "skill_web_frameworks_004", "question": "How can I implement create, read, update, delete operations in my API?", "answer": "To implement CRUD operations in your API, use mutation handlers with the appropriate HTTP methods. For Create, use POST: `@app.post('/api/items') def create_item(data: ItemInput): return {\"success\": True, \"data\": result}`. For Read, use GET with query parameters. For Update, use PUT: `@app.put('/api/items/{id}')`. For Delete, use DELETE: `@app.delete('/api/items/{id}')`. Generate these handlers using your framework's generator\u2014Flask uses `generate_flask_query_handler/4`, FastAPI uses `generate_fastapi_app/3`, and Express uses `generate_express_router/3`. Each framework provides decorators or methods for all four HTTP verbs needed for full CRUD functionality.", "question_type": "long", "topics": ["Quickstart", "Web Frameworks (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["crud", "mutation", "api", "post", "put", "delete"], "related_skills": ["skill_web_frameworks.md", "skill_flask_api.md", "skill_fastapi.md", "skill_express_api.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl", "src/unifyweaver/glue/fastapi_generator.pl", "src/unifyweaver/glue/express_generator.pl"], "original_answer": "Use mutation handlers for CRUD operations. Example: `@app.post('/api/items') def create_item(data: ItemInput): return {\"success\": True, \"data\": result}`. Generate handlers with `generate_flask_query_handler/4` or equivalent for your framework. Each framework provides decorators for GET, POST, PUT, DELETE methods. See skill_web_frameworks.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_web_frameworks_005_q0", "cluster_id": "skill_web_frameworks_005", "question": "How do I add data validation to my API in FastAPI?", "answer": "FastAPI uses Pydantic models for automatic data validation. Define a model with `generate_pydantic_model(product, [field(name, string), field(price, number), field(quantity, optional(integer))], Model)` and use it in your route handlers. FastAPI automatically validates incoming request data against the model schema, returning validation errors if data doesn't match. Pydantic handles type checking, required fields, and optional fields. This also generates OpenAPI documentation automatically.", "question_type": "long", "topics": ["Quickstart", "Web Frameworks (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["validation", "fastapi", "pydantic", "data-types"], "related_skills": ["skill_web_frameworks.md", "skill_fastapi.md"], "related_docs": ["src/unifyweaver/glue/fastapi_generator.pl"], "original_answer": "FastAPI provides automatic validation through Pydantic models. Generate a model with: `generate_pydantic_model(product, [field(name, string), field(price, number), field(quantity, optional(integer))], Model)`. FastAPI automatically validates incoming requests against the model schema and generates OpenAPI documentation. See skill_web_frameworks.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer references a Prolog generator function that may not be the standard FastAPI approach users expect. The answer could benefit from mentioning that Pydantic models are used directly in FastAPI type hints rather than through a generator function, though the generator approach may be specific to UnifyWeaver's tooling."}
{"pair_id": "skill_web_frameworks_005_q1", "cluster_id": "skill_web_frameworks_005", "question": "How can I validate request data automatically?", "answer": "FastAPI provides automatic request validation through Pydantic models. Define a model using `generate_pydantic_model(product, [field(name, string), field(price, number), field(quantity, optional(integer))], Model)`. FastAPI automatically validates incoming request data against this schema, rejecting invalid requests with detailed error messages, and generates OpenAPI documentation for the validated endpoints.", "question_type": "long", "topics": ["Quickstart", "Web Frameworks (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["validation", "fastapi", "pydantic", "data-types"], "related_skills": ["skill_web_frameworks.md", "skill_fastapi.md"], "related_docs": ["src/unifyweaver/glue/fastapi_generator.pl"], "original_answer": "FastAPI provides automatic validation through Pydantic models. Generate a model with: `generate_pydantic_model(product, [field(name, string), field(price, number), field(quantity, optional(integer))], Model)`. FastAPI automatically validates incoming requests against the model schema and generates OpenAPI documentation. See skill_web_frameworks.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_web_frameworks_005_q2", "cluster_id": "skill_web_frameworks_005", "question": "What's the best way to ensure data types in FastAPI?", "answer": "FastAPI ensures data types through Pydantic models, which provide automatic validation and serialization. Define models using `generate_pydantic_model(product, [field(name, string), field(price, number), field(quantity, optional(integer))], Model)`. FastAPI automatically validates all incoming requests against the model schema, rejecting invalid data with detailed error messages, and generates OpenAPI documentation from the model definitions.", "question_type": "long", "topics": ["Quickstart", "Web Frameworks (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["validation", "fastapi", "pydantic", "data-types"], "related_skills": ["skill_web_frameworks.md", "skill_fastapi.md"], "related_docs": ["src/unifyweaver/glue/fastapi_generator.pl"], "original_answer": "FastAPI provides automatic validation through Pydantic models. Generate a model with: `generate_pydantic_model(product, [field(name, string), field(price, number), field(quantity, optional(integer))], Model)`. FastAPI automatically validates incoming requests against the model schema and generates OpenAPI documentation. See skill_web_frameworks.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_web_frameworks_006_q0", "cluster_id": "skill_web_frameworks_006", "question": "How do I handle infinite scroll or cursor-based pagination?", "answer": "For infinite scroll or cursor-based pagination, use cursor-based pagination instead of offset-based methods. Implement an endpoint like `@app.get('/api/feed') def list_feed(cursor: str = None, limit: int = 20): return {\"data\": items, \"nextCursor\": next_cursor, \"hasMore\": True}`. Cursors encode the position in the dataset, allowing efficient pagination without offset calculations. The cursor is passed back with each response as `nextCursor` so the client can fetch the next batch of items, and `hasMore` indicates whether additional items are available.", "question_type": "long", "topics": ["Quickstart", "Web Frameworks (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["pagination", "cursor", "infinite-scroll", "feed"], "related_skills": ["skill_web_frameworks.md", "skill_flask_api.md", "skill_fastapi.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl", "src/unifyweaver/glue/fastapi_generator.pl"], "original_answer": "Use cursor-based pagination for feeds or large datasets. Example: `@app.get('/api/feed') def list_feed(cursor: str = None, limit: int = 20): return {\"data\": items, \"nextCursor\": next_cursor, \"hasMore\": True}`. Cursors encode the position in the dataset, allowing efficient pagination without offset calculations. See skill_web_frameworks.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_web_frameworks_006_q1", "cluster_id": "skill_web_frameworks_006", "question": "How do I implement feed-style pagination with cursors?", "answer": "Use cursor-based pagination to efficiently paginate through feeds or large datasets. Define an endpoint that accepts a cursor parameter (encoded position in the dataset) and a limit parameter. Return the data items, the next cursor value for the following request, and a hasMore flag to indicate if more data is available. Example: `@app.get('/api/feed') def list_feed(cursor: str = None, limit: int = 20): return {\"data\": items, \"nextCursor\": next_cursor, \"hasMore\": True}`. This approach avoids expensive offset calculations and handles dynamic data efficiently. All web framework generators (Flask, FastAPI, Express) support cursor-based pagination through the Infinite Scroll pattern.", "question_type": "long", "topics": ["Quickstart", "Web Frameworks (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["pagination", "cursor", "infinite-scroll", "feed"], "related_skills": ["skill_web_frameworks.md", "skill_flask_api.md", "skill_fastapi.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl", "src/unifyweaver/glue/fastapi_generator.pl"], "original_answer": "Use cursor-based pagination for feeds or large datasets. Example: `@app.get('/api/feed') def list_feed(cursor: str = None, limit: int = 20): return {\"data\": items, \"nextCursor\": next_cursor, \"hasMore\": True}`. Cursors encode the position in the dataset, allowing efficient pagination without offset calculations. See skill_web_frameworks.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_web_frameworks_006_q2", "cluster_id": "skill_web_frameworks_006", "question": "What's cursor-based pagination and how do I use it?", "answer": "Cursor-based pagination uses an encoded position marker (cursor) to efficiently navigate through datasets without calculating offsets. Instead of using page numbers, you pass a cursor string that represents where you are in the data. The server returns the next cursor with each response, allowing clients to fetch the next batch by passing that cursor back. This approach is ideal for feeds and large datasets because it handles insertions/deletions gracefully and avoids expensive offset calculations. Example: `@app.get('/api/feed') def list_feed(cursor: str = None, limit: int = 20): return {\"data\": items, \"nextCursor\": next_cursor, \"hasMore\": True}`. The cursor typically encodes the last item's ID or timestamp, allowing the server to resume from that exact position on the next request.", "question_type": "long", "topics": ["Quickstart", "Web Frameworks (Sub-Master)"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["pagination", "cursor", "infinite-scroll", "feed"], "related_skills": ["skill_web_frameworks.md", "skill_flask_api.md", "skill_fastapi.md"], "related_docs": ["src/unifyweaver/glue/flask_generator.pl", "src/unifyweaver/glue/fastapi_generator.pl"], "original_answer": "Use cursor-based pagination for feeds or large datasets. Example: `@app.get('/api/feed') def list_feed(cursor: str = None, limit: int = 20): return {\"data\": items, \"nextCursor\": next_cursor, \"hasMore\": True}`. Cursors encode the position in the dataset, allowing efficient pagination without offset calculations. See skill_web_frameworks.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_webapp_security_001_q0", "cluster_id": "skill_webapp_security_001", "question": "How do I add authentication to my generated web app?", "answer": "To add authentication to your generated web app, use the `auth` configuration in `generate_complete_project()`. Choose your backend method: `backend(jwt)` for token-based auth, `backend(session)` for session-based, `backend(oauth2)` for OAuth2, or `backend(basic)` for basic auth. For JWT, include `secret_env('JWT_SECRET')` to reference an environment variable and `expiry(3600)` for token timeout. Then protect routes with navigation guards like `guard(authenticated, '/login')` to redirect unauthenticated users. Refer to skill_webapp_security.md for complete authentication setup details and additional security options.", "question_type": "medium", "topics": ["Quickstart", "Webapp Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["authentication", "jwt", "security", "authorization"], "related_skills": ["skill_app_generation.md", "skill_unifyweaver_compile.md", "skill_webapp_security.md"], "related_docs": ["docs/FIREWALL_GUIDE.md", "docs/CONTROL_PLANE.md", "education/book-08-security-firewall/01_introduction.md", "src/unifyweaver/glue/auth_backends.pl"], "original_answer": "Use the `auth` configuration in `generate_complete_project()` with your preferred backend (jwt, session, oauth2, or basic). For JWT authentication: include `backend(jwt)`, `secret_env('JWT_SECRET')`, and `expiry(3600)` in the auth options. Then add navigation guards like `guard(authenticated, '/login')` to protect routes. See skill_webapp_security.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_webapp_security_001_q1", "cluster_id": "skill_webapp_security_001", "question": "How do I secure my app with login?", "answer": "To secure your app with login, use the `auth` configuration in `generate_complete_project()`. Choose your authentication backend (jwt, session, oauth2, or basic) and configure it with the auth options. For JWT: include `backend(jwt)`, `secret_env('JWT_SECRET')`, and `expiry(3600)`. Protect routes by adding navigation guards like `guard(authenticated, '/login')` to redirect unauthenticated users. Refer to skill_webapp_security.md for detailed implementation steps.", "question_type": "medium", "topics": ["Quickstart", "Webapp Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["authentication", "jwt", "security", "authorization"], "related_skills": ["skill_app_generation.md", "skill_unifyweaver_compile.md", "skill_webapp_security.md"], "related_docs": ["docs/FIREWALL_GUIDE.md", "docs/CONTROL_PLANE.md", "education/book-08-security-firewall/01_introduction.md", "src/unifyweaver/glue/auth_backends.pl"], "original_answer": "Use the `auth` configuration in `generate_complete_project()` with your preferred backend (jwt, session, oauth2, or basic). For JWT authentication: include `backend(jwt)`, `secret_env('JWT_SECRET')`, and `expiry(3600)` in the auth options. Then add navigation guards like `guard(authenticated, '/login')` to protect routes. See skill_webapp_security.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_webapp_security_001_q2", "cluster_id": "skill_webapp_security_001", "question": "What's the easiest way to add user authentication?", "answer": "The easiest way to add user authentication is to use the `auth` configuration in `generate_complete_project()`. Choose your backend method (jwt, session, oauth2, or basic) and include it in the auth options. For JWT: add `backend(jwt)`, `secret_env('JWT_SECRET')`, and `expiry(3600)`. Then protect your routes with navigation guards like `guard(authenticated, '/login')`. See skill_webapp_security.md for complete setup details.", "question_type": "medium", "topics": ["Quickstart", "Webapp Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["authentication", "jwt", "security", "authorization"], "related_skills": ["skill_app_generation.md", "skill_unifyweaver_compile.md", "skill_webapp_security.md"], "related_docs": ["docs/FIREWALL_GUIDE.md", "docs/CONTROL_PLANE.md", "education/book-08-security-firewall/01_introduction.md", "src/unifyweaver/glue/auth_backends.pl"], "original_answer": "Use the `auth` configuration in `generate_complete_project()` with your preferred backend (jwt, session, oauth2, or basic). For JWT authentication: include `backend(jwt)`, `secret_env('JWT_SECRET')`, and `expiry(3600)` in the auth options. Then add navigation guards like `guard(authenticated, '/login')` to protect routes. See skill_webapp_security.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer assumes users know how to structure the auth options within generate_complete_project(). A more direct answer could specify the exact syntax or provide a minimal code example, but the information provided is accurate and addresses the core question."}
{"pair_id": "skill_webapp_security_001_q3", "cluster_id": "skill_webapp_security_001", "question": "How do I set up authentication for my application?", "answer": "To set up authentication for your application, use the `auth` configuration in `generate_complete_project()`. Choose your backend type: `jwt` for token-based auth, `session` for server-side sessions, `oauth2` for third-party providers, or `basic` for simple authentication. For JWT, include `backend(jwt)`, `secret_env('JWT_SECRET')`, and `expiry(3600)` in your auth options. Protect your routes by adding navigation guards like `guard(authenticated, '/login')` to redirect unauthenticated users. Refer to skill_webapp_security.md for detailed configuration options and security best practices.", "question_type": "medium", "topics": ["Quickstart", "Webapp Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["authentication", "jwt", "security", "authorization"], "related_skills": ["skill_app_generation.md", "skill_unifyweaver_compile.md", "skill_webapp_security.md"], "related_docs": ["docs/FIREWALL_GUIDE.md", "docs/CONTROL_PLANE.md", "education/book-08-security-firewall/01_introduction.md", "src/unifyweaver/glue/auth_backends.pl"], "original_answer": "Use the `auth` configuration in `generate_complete_project()` with your preferred backend (jwt, session, oauth2, or basic). For JWT authentication: include `backend(jwt)`, `secret_env('JWT_SECRET')`, and `expiry(3600)` in the auth options. Then add navigation guards like `guard(authenticated, '/login')` to protect routes. See skill_webapp_security.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_webapp_security_002_q0", "cluster_id": "skill_webapp_security_002", "question": "How do I protect specific pages with login requirements?", "answer": "To protect specific pages with login requirements, use navigation guards in your app configuration. Define a guard like `guard(authenticated, '/login')` that redirects unauthenticated users to the login page. Add this guard directly to the screens you want to protect: `screen(admin, 'AdminView', [guard(authenticated)])`. For role-based protection (like admin-only pages), use `guard(admin, '/unauthorized')` instead. Configure these guards in your app specification and they'll enforce access control automatically during navigation. Refer to skill_webapp_security.md for complete authentication configuration options.", "question_type": "medium", "topics": ["Quickstart", "Webapp Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["authorization", "guards", "routes", "access-control"], "related_skills": ["skill_app_generation.md", "skill_webapp_security.md"], "related_docs": ["docs/CONTROL_PLANE.md", "education/book-08-security-firewall/02_firewall_policies.md"], "original_answer": "Use navigation guards in your app configuration. Define guards like `guard(authenticated, '/login')` for login requirements or `guard(admin, '/unauthorized')` for role-based access. Add these guards to specific screens in your navigation: `screen(admin, 'AdminView', [guard(admin)])`. See skill_webapp_security.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer assumes the guard syntax is correct without confirming the exact Prolog guard predicate format. The answer is tailored but would benefit from verification of the actual guard implementation in the codebase."}
{"pair_id": "skill_webapp_security_002_q1", "cluster_id": "skill_webapp_security_002", "question": "How do I add navigation guards to routes?", "answer": "Add navigation guards to routes by defining them in your app configuration. Use `guard(guardName, fallbackPath)` syntax\u2014for example, `guard(authenticated, '/login')` requires authentication or redirects to login, while `guard(admin, '/unauthorized')` enforces role-based access. Apply guards to specific screens by adding them to the screen definition: `screen(admin, 'AdminView', [guard(admin)])`. For comprehensive authentication and guard setup, see skill_webapp_security.md.", "question_type": "medium", "topics": ["Quickstart", "Webapp Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["authorization", "guards", "routes", "access-control"], "related_skills": ["skill_app_generation.md", "skill_webapp_security.md"], "related_docs": ["docs/CONTROL_PLANE.md", "education/book-08-security-firewall/02_firewall_policies.md"], "original_answer": "Use navigation guards in your app configuration. Define guards like `guard(authenticated, '/login')` for login requirements or `guard(admin, '/unauthorized')` for role-based access. Add these guards to specific screens in your navigation: `screen(admin, 'AdminView', [guard(admin)])`. See skill_webapp_security.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "Base answer could be more explicit about how guards integrate with the overall Prolog app specification and the order of guard evaluation. The answer assumes familiarity with the app configuration structure."}
{"pair_id": "skill_webapp_security_002_q2", "cluster_id": "skill_webapp_security_002", "question": "How do I make certain screens admin-only?", "answer": "To make screens admin-only, add a guard to the screen definition in your navigation: `screen(admin_panel, 'AdminPanelView', [guard(admin)])`. The guard redirects unauthorized users to a specified route like `guard(admin, '/unauthorized')`. Define all guards in your app configuration and ensure your authentication system assigns admin roles. See skill_webapp_security.md for complete guard configuration and role-based access control setup.", "question_type": "medium", "topics": ["Quickstart", "Webapp Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["authorization", "guards", "routes", "access-control"], "related_skills": ["skill_app_generation.md", "skill_webapp_security.md"], "related_docs": ["docs/CONTROL_PLANE.md", "education/book-08-security-firewall/02_firewall_policies.md"], "original_answer": "Use navigation guards in your app configuration. Define guards like `guard(authenticated, '/login')` for login requirements or `guard(admin, '/unauthorized')` for role-based access. Add these guards to specific screens in your navigation: `screen(admin, 'AdminView', [guard(admin)])`. See skill_webapp_security.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_webapp_security_002_q3", "cluster_id": "skill_webapp_security_002", "question": "How do I restrict access to specific pages?", "answer": "Use navigation guards in your app configuration to restrict page access. Define guards like `guard(authenticated, '/login')` for pages requiring authentication or `guard(admin, '/unauthorized')` for role-based access control. Add guards directly to specific screens: `screen(admin_panel, 'AdminView', [guard(admin)])`. For detailed implementation including role-based restrictions, auth flows, and custom guard logic, see skill_webapp_security.md.", "question_type": "medium", "topics": ["Quickstart", "Webapp Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["authorization", "guards", "routes", "access-control"], "related_skills": ["skill_app_generation.md", "skill_webapp_security.md"], "related_docs": ["docs/CONTROL_PLANE.md", "education/book-08-security-firewall/02_firewall_policies.md"], "original_answer": "Use navigation guards in your app configuration. Define guards like `guard(authenticated, '/login')` for login requirements or `guard(admin, '/unauthorized')` for role-based access. Add these guards to specific screens in your navigation: `screen(admin, 'AdminView', [guard(admin)])`. See skill_webapp_security.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer assumes familiarity with navigation guard syntax; a user might need clarification on how to define custom guard types beyond the examples shown. The relationship between guard names (e.g., 'admin') and actual permission checking logic in the codebase is not fully specified in the original answer."}
{"pair_id": "skill_webapp_security_003_q0", "cluster_id": "skill_webapp_security_003", "question": "How do I enable HTTPS/TLS for my web application?", "answer": "Enable HTTPS/TLS using the tls_config module: `use_module('src/unifyweaver/glue/tls_config')` then `generate_tls_config(tls_options([cert_file('/path/to/cert.pem'), key_file('/path/to/key.pem'), min_version('TLSv1.2')]), ConfigOutput)`. This generates TLS configuration for your web application backend.", "question_type": "medium", "topics": ["Quickstart", "Webapp Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["tls", "https", "encryption", "certificates"], "related_skills": ["skill_unifyweaver_compile.md", "skill_webapp_security.md"], "related_docs": ["docs/FIREWALL_GUIDE.md", "education/book-08-security-firewall/03_lifecycle_hooks.md", "src/unifyweaver/glue/tls_config.pl"], "original_answer": "Import the TLS configuration module with `?- use_module('src/unifyweaver/glue/tls_config').` Then use `generate_tls_config()` with your certificate paths: `tls_options([cert_file('/path/to/cert.pem'), key_file('/path/to/key.pem'), min_version('TLSv1.2')])`. See skill_webapp_security.md for details.", "answer_tailored": true, "confidence": 0.85, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_webapp_security_003_q1", "cluster_id": "skill_webapp_security_003", "question": "How do I configure SSL certificates?", "answer": "Configure SSL certificates using UnifyWeaver's tls_config module: `generate_tls_config(tls_options([cert_file('/path/to/cert.pem'), key_file('/path/to/key.pem'), min_version('TLSv1.2')]), Config)`. Specify paths to your certificate and key files. See `src/unifyweaver/glue/tls_config.pl` for implementation.", "question_type": "medium", "topics": ["Quickstart", "Webapp Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["tls", "https", "encryption", "certificates"], "related_skills": ["skill_unifyweaver_compile.md", "skill_webapp_security.md"], "related_docs": ["docs/FIREWALL_GUIDE.md", "education/book-08-security-firewall/03_lifecycle_hooks.md", "src/unifyweaver/glue/tls_config.pl"], "original_answer": "Import the TLS configuration module with `?- use_module('src/unifyweaver/glue/tls_config').` Then use `generate_tls_config()` with your certificate paths: `tls_options([cert_file('/path/to/cert.pem'), key_file('/path/to/key.pem'), min_version('TLSv1.2')])`. See skill_webapp_security.md for details.", "answer_tailored": true, "confidence": 0.85, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_webapp_security_003_q2", "cluster_id": "skill_webapp_security_003", "question": "How do I set up TLS encryption?", "answer": "Import the TLS configuration module with `?- use_module('src/unifyweaver/glue/tls_config').` Then configure TLS options by calling `tls_options([cert_file('/path/to/cert.pem'), key_file('/path/to/key.pem'), min_version('TLSv1.2')])` with your certificate and key file paths. This sets up TLS encryption with a minimum version of TLSv1.2. See skill_webapp_security.md for additional security configuration details.", "question_type": "medium", "topics": ["Quickstart", "Webapp Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["tls", "https", "encryption", "certificates"], "related_skills": ["skill_unifyweaver_compile.md", "skill_webapp_security.md"], "related_docs": ["docs/FIREWALL_GUIDE.md", "education/book-08-security-firewall/03_lifecycle_hooks.md", "src/unifyweaver/glue/tls_config.pl"], "original_answer": "Import the TLS configuration module with `?- use_module('src/unifyweaver/glue/tls_config').` Then use `generate_tls_config()` with your certificate paths: `tls_options([cert_file('/path/to/cert.pem'), key_file('/path/to/key.pem'), min_version('TLSv1.2')])`. See skill_webapp_security.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "The base answer references `generate_tls_config()` which may not be the actual function name; the corrected version uses `tls_options()` directly. The answer assumes the user has certificate files readily available and knows where to place them. No information about certificate generation or obtaining valid certificates is provided."}
{"pair_id": "skill_webapp_security_003_q3", "cluster_id": "skill_webapp_security_003", "question": "How do I make my app use HTTPS?", "answer": "To make your UnifyWeaver-generated app use HTTPS, use the tls_config module: `use_module('src/unifyweaver/glue/tls_config')`, then call `generate_tls_config/2` with your cert_file and key_file paths. For production, set `min_version('TLSv1.2')` to disable older protocols.", "question_type": "medium", "topics": ["Quickstart", "Webapp Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["tls", "https", "encryption", "certificates"], "related_skills": ["skill_unifyweaver_compile.md", "skill_webapp_security.md"], "related_docs": ["docs/FIREWALL_GUIDE.md", "education/book-08-security-firewall/03_lifecycle_hooks.md", "src/unifyweaver/glue/tls_config.pl"], "original_answer": "Import the TLS configuration module with `?- use_module('src/unifyweaver/glue/tls_config').` Then use `generate_tls_config()` with your certificate paths: `tls_options([cert_file('/path/to/cert.pem'), key_file('/path/to/key.pem'), min_version('TLSv1.2')])`. See skill_webapp_security.md for details.", "answer_tailored": true, "confidence": 0.85, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_webapp_security_004_q0", "cluster_id": "skill_webapp_security_004", "question": "How do I restrict shell commands in my backend to prevent dangerous operations?", "answer": "To restrict shell commands in your backend and prevent dangerous operations, use the shell sandbox module by calling `?- use_module('src/unifyweaver/glue/shell_sandbox').` Then execute sandboxed commands with `sandbox_command('ls -la /tmp', [allowed_paths(['/tmp', '/var/data']), denied_commands(['rm', 'sudo']), timeout(30)], Result)`. You can configure security levels (sandbox, trusted, superadmin) with different isolation backends (app_filter for command whitelisting, proot for filesystem isolation). For generated apps, declare shell access policies in your app specification using the `shell_access([...])` option with role-based access control.", "question_type": "long", "topics": ["Quickstart", "Webapp Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sandbox", "shell", "command-execution", "permissions"], "related_skills": ["skill_app_generation.md", "skill_webapp_security.md"], "related_docs": ["education/book-08-security-firewall/04_target_security.md", "education/book-08-security-firewall/05_validation_fallback.md", "src/unifyweaver/glue/shell_sandbox.pl"], "original_answer": "Use the shell sandbox module: `?- use_module('src/unifyweaver/glue/shell_sandbox').` Then call `sandbox_command()` with allowed paths, denied commands, and timeout: `sandbox_command('ls -la /tmp', [allowed_paths(['/tmp', '/var/data']), denied_commands(['rm', 'sudo']), timeout(30)], Result)`. See skill_webapp_security.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_webapp_security_004_q1", "cluster_id": "skill_webapp_security_004", "question": "How do I sandbox shell commands?", "answer": "To sandbox shell commands, use the shell sandbox module: `?- use_module('src/unifyweaver/glue/shell_sandbox').` Then call `sandbox_command()` with configuration for allowed paths, denied commands, and timeout: `sandbox_command('ls -la /tmp', [allowed_paths(['/tmp', '/var/data']), denied_commands(['rm', 'sudo']), timeout(30)], Result)`. This restricts command execution to safe paths and blocks dangerous operations. See skill_webapp_security.md for detailed security guidance.", "question_type": "long", "topics": ["Quickstart", "Webapp Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sandbox", "shell", "command-execution", "permissions"], "related_skills": ["skill_app_generation.md", "skill_webapp_security.md"], "related_docs": ["education/book-08-security-firewall/04_target_security.md", "education/book-08-security-firewall/05_validation_fallback.md", "src/unifyweaver/glue/shell_sandbox.pl"], "original_answer": "Use the shell sandbox module: `?- use_module('src/unifyweaver/glue/shell_sandbox').` Then call `sandbox_command()` with allowed paths, denied commands, and timeout: `sandbox_command('ls -la /tmp', [allowed_paths(['/tmp', '/var/data']), denied_commands(['rm', 'sudo']), timeout(30)], Result)`. See skill_webapp_security.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_webapp_security_004_q2", "cluster_id": "skill_webapp_security_004", "question": "How do I prevent malicious shell execution?", "answer": "Use the shell sandbox module to prevent malicious shell execution. Load it with `?- use_module('src/unifyweaver/glue/shell_sandbox').` Then use `sandbox_command()` to execute commands with security constraints: `sandbox_command('command', [allowed_paths(['/tmp', '/var/data']), denied_commands(['rm', 'sudo']), timeout(30)], Result)`. This restricts command execution to allowed paths, blocks dangerous commands like `rm` and `sudo`, and enforces timeouts to prevent runaway processes. See skill_webapp_security.md for additional security patterns.", "question_type": "long", "topics": ["Quickstart", "Webapp Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sandbox", "shell", "command-execution", "permissions"], "related_skills": ["skill_app_generation.md", "skill_webapp_security.md"], "related_docs": ["education/book-08-security-firewall/04_target_security.md", "education/book-08-security-firewall/05_validation_fallback.md", "src/unifyweaver/glue/shell_sandbox.pl"], "original_answer": "Use the shell sandbox module: `?- use_module('src/unifyweaver/glue/shell_sandbox').` Then call `sandbox_command()` with allowed paths, denied commands, and timeout: `sandbox_command('ls -la /tmp', [allowed_paths(['/tmp', '/var/data']), denied_commands(['rm', 'sudo']), timeout(30)], Result)`. See skill_webapp_security.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer references 'skill_webapp_security.md' but the skill document provided is for 'App Generation'. The answer assumes the shell sandbox module exists and is properly documented in security materials, but the current context only shows app generation documentation. The confidence is moderate because the technical details appear sound but the referenced documentation may not be accessible in the actual skill set."}
{"pair_id": "skill_webapp_security_004_q3", "cluster_id": "skill_webapp_security_004", "question": "How do I limit what commands can run?", "answer": "To limit what commands can run, use the shell sandbox module with `use_module('src/unifyweaver/glue/shell_sandbox')`. Then call `sandbox_command()` to execute commands with restrictions: `sandbox_command('ls -la /tmp', [allowed_paths(['/tmp', '/var/data']), denied_commands(['rm', 'sudo']), timeout(30)], Result)`. This enforces allowed directories, blocks dangerous commands, and sets execution timeouts. Refer to skill_webapp_security.md for comprehensive security configuration.", "question_type": "long", "topics": ["Quickstart", "Webapp Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["sandbox", "shell", "command-execution", "permissions"], "related_skills": ["skill_app_generation.md", "skill_webapp_security.md"], "related_docs": ["education/book-08-security-firewall/04_target_security.md", "education/book-08-security-firewall/05_validation_fallback.md", "src/unifyweaver/glue/shell_sandbox.pl"], "original_answer": "Use the shell sandbox module: `?- use_module('src/unifyweaver/glue/shell_sandbox').` Then call `sandbox_command()` with allowed paths, denied commands, and timeout: `sandbox_command('ls -la /tmp', [allowed_paths(['/tmp', '/var/data']), denied_commands(['rm', 'sudo']), timeout(30)], Result)`. See skill_webapp_security.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_webapp_security_005_q0", "cluster_id": "skill_webapp_security_005", "question": "What are the different authentication backends available?", "answer": "UnifyWeaver supports four authentication backends: (1) `jwt` - stateless API authentication with secret_env and expiry options, (2) `session` - server-side sessions with configurable store and cookie_name, (3) `oauth2` - third-party provider integration with client_id configuration, (4) `basic` - simple HTTP Basic authentication with realm. JWT is optimal for APIs, session-based auth for traditional web applications, OAuth2 for social login integration, and Basic auth for simple use cases. Refer to skill_webapp_security.md for implementation details and configuration options.", "question_type": "medium", "topics": ["Quickstart", "Webapp Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["authentication", "jwt", "oauth2", "sessions"], "related_skills": ["skill_app_generation.md", "skill_webapp_security.md"], "related_docs": ["education/book-08-security-firewall/01_introduction.md", "src/unifyweaver/glue/auth_backends.pl"], "original_answer": "UnifyWeaver supports four authentication backends: (1) `jwt` - stateless API auth with secret_env and expiry options, (2) `session` - server-side sessions with store and cookie_name, (3) `oauth2` - third-party login with provider and client_id, (4) `basic` - simple authentication with realm. Choose based on your app's needs: JWT for APIs, session for traditional apps, OAuth2 for social login. See skill_webapp_security.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_webapp_security_005_q1", "cluster_id": "skill_webapp_security_005", "question": "Should I use JWT or session-based auth?", "answer": "JWT is best for stateless API authentication with secret_env and expiry options, while session-based auth works better for traditional server-side applications with persistent user state and cookie storage. Choose JWT if you're building an API or microservices architecture; choose sessions if you need server-side control and easier logout/revocation. UnifyWeaver supports both\u2014see skill_webapp_security.md for implementation details.", "question_type": "medium", "topics": ["Quickstart", "Webapp Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["authentication", "jwt", "oauth2", "sessions"], "related_skills": ["skill_app_generation.md", "skill_webapp_security.md"], "related_docs": ["education/book-08-security-firewall/01_introduction.md", "src/unifyweaver/glue/auth_backends.pl"], "original_answer": "UnifyWeaver supports four authentication backends: (1) `jwt` - stateless API auth with secret_env and expiry options, (2) `session` - server-side sessions with store and cookie_name, (3) `oauth2` - third-party login with provider and client_id, (4) `basic` - simple authentication with realm. Choose based on your app's needs: JWT for APIs, session for traditional apps, OAuth2 for social login. See skill_webapp_security.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_webapp_security_005_q2", "cluster_id": "skill_webapp_security_005", "question": "What's the difference between OAuth2 and basic auth?", "answer": "OAuth2 and basic auth are two different authentication methods supported by UnifyWeaver. Basic auth is simple authentication that sends credentials directly (username/password) with a realm parameter. OAuth2 is third-party login that delegates authentication to an external provider (like Google or GitHub) using a provider and client_id. Choose basic auth for simple internal apps, OAuth2 when you want social login or federated identity. Both are configured in skill_webapp_security.md.", "question_type": "medium", "topics": ["Quickstart", "Webapp Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["authentication", "jwt", "oauth2", "sessions"], "related_skills": ["skill_app_generation.md", "skill_webapp_security.md"], "related_docs": ["education/book-08-security-firewall/01_introduction.md", "src/unifyweaver/glue/auth_backends.pl"], "original_answer": "UnifyWeaver supports four authentication backends: (1) `jwt` - stateless API auth with secret_env and expiry options, (2) `session` - server-side sessions with store and cookie_name, (3) `oauth2` - third-party login with provider and client_id, (4) `basic` - simple authentication with realm. Choose based on your app's needs: JWT for APIs, session for traditional apps, OAuth2 for social login. See skill_webapp_security.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "Base answer mentions both methods but lacks key technical differences (stateless vs stateful, direct credentials vs tokens/redirects, security implications). Answer reconstructed from limited context in base material."}
{"pair_id": "skill_webapp_security_005_q3", "cluster_id": "skill_webapp_security_005", "question": "Which authentication method should I choose?", "answer": "UnifyWeaver supports four authentication methods: (1) `jwt` - stateless API authentication with secret_env and expiry configuration, best for APIs and microservices; (2) `session` - server-side sessions with configurable store and cookie settings, suitable for traditional web applications; (3) `oauth2` - third-party authentication via providers like Google or GitHub using client_id, ideal for social login; (4) `basic` - simple username/password authentication with realm configuration. Choose JWT for stateless APIs, session for server-rendered apps requiring state, OAuth2 when you need social login integration, or basic auth for simple internal applications. Refer to skill_webapp_security.md for implementation details specific to your framework.", "question_type": "medium", "topics": ["Quickstart", "Webapp Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["authentication", "jwt", "oauth2", "sessions"], "related_skills": ["skill_app_generation.md", "skill_webapp_security.md"], "related_docs": ["education/book-08-security-firewall/01_introduction.md", "src/unifyweaver/glue/auth_backends.pl"], "original_answer": "UnifyWeaver supports four authentication backends: (1) `jwt` - stateless API auth with secret_env and expiry options, (2) `session` - server-side sessions with store and cookie_name, (3) `oauth2` - third-party login with provider and client_id, (4) `basic` - simple authentication with realm. Choose based on your app's needs: JWT for APIs, session for traditional apps, OAuth2 for social login. See skill_webapp_security.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_webapp_security_006_q0", "cluster_id": "skill_webapp_security_006", "question": "How do I set up role-based access control in my app?", "answer": "To set up role-based access control in your app, define role-based guards in your authentication configuration using `guard(role('admin'))` or `guard(permission('delete_users'))` for specific permissions. Apply these guards directly to screens in your app specification: `screen(admin, 'AdminView', [guard(role('admin'))])`. The authentication backend will automatically enforce these guards based on each user's roles and permissions. For detailed implementation including auth setup, see skill_webapp_security.md.", "question_type": "long", "topics": ["Quickstart", "Webapp Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["authorization", "roles", "permissions", "access-control"], "related_skills": ["skill_app_generation.md", "skill_webapp_security.md"], "related_docs": ["docs/CONTROL_PLANE.md", "education/book-08-security-firewall/02_firewall_policies.md", "education/book-08-security-firewall/04_target_security.md", "src/unifyweaver/glue/auth_backends.pl"], "original_answer": "Use role-based guards in your authentication configuration. Define guards like `guard(role('admin'))` or `guard(permission('delete_users'))` for specific permissions. Apply them to screens: `screen(admin, 'AdminView', [guard(role('admin'))])`. The authentication backend will enforce these guards based on user roles and permissions. See skill_webapp_security.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer assumes user knows where/how to define guards in the app specification. Answer clarifies this is done in screen definitions but could be more explicit about where guards are configured in the overall app structure (e.g., in the auth section vs screen-level)."}
{"pair_id": "skill_webapp_security_006_q1", "cluster_id": "skill_webapp_security_006", "question": "How do I add admin and user roles?", "answer": "Add admin and user roles by defining role-based guards in your authentication configuration. Use `guard(role('admin'))` for admin-only screens and `guard(role('user'))` for user screens. Apply guards directly to screens: `screen(admin, 'AdminView', [guard(role('admin'))])` and `screen(dashboard, 'DashboardView', [guard(role('user'))])`. The authentication backend will enforce these role checks automatically. For fine-grained control, use permission-based guards like `guard(permission('delete_users'))` instead. Refer to skill_webapp_security.md for complete authentication setup.", "question_type": "long", "topics": ["Quickstart", "Webapp Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["authorization", "roles", "permissions", "access-control"], "related_skills": ["skill_app_generation.md", "skill_webapp_security.md"], "related_docs": ["docs/CONTROL_PLANE.md", "education/book-08-security-firewall/02_firewall_policies.md", "education/book-08-security-firewall/04_target_security.md", "src/unifyweaver/glue/auth_backends.pl"], "original_answer": "Use role-based guards in your authentication configuration. Define guards like `guard(role('admin'))` or `guard(permission('delete_users'))` for specific permissions. Apply them to screens: `screen(admin, 'AdminView', [guard(role('admin'))])`. The authentication backend will enforce these guards based on user roles and permissions. See skill_webapp_security.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer assumes familiarity with guard syntax and doesn't explain where to define roles initially. The tailored version adds examples for both roles but could benefit from mentioning role assignment during user creation/login flow, which isn't covered in the base answer."}
{"pair_id": "skill_webapp_security_006_q2", "cluster_id": "skill_webapp_security_006", "question": "How do I check user permissions?", "answer": "Use role-based guards in your authentication configuration. Define guards like `guard(role('admin'))` or `guard(permission('delete_users'))` for the specific permissions you need to check. Apply them directly to screens: `screen(admin, 'AdminView', [guard(role('admin'))])`. The authentication backend will automatically enforce these guards based on the user's assigned roles and permissions at runtime. For detailed implementation, see skill_webapp_security.md.", "question_type": "long", "topics": ["Quickstart", "Webapp Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["authorization", "roles", "permissions", "access-control"], "related_skills": ["skill_app_generation.md", "skill_webapp_security.md"], "related_docs": ["docs/CONTROL_PLANE.md", "education/book-08-security-firewall/02_firewall_policies.md", "education/book-08-security-firewall/04_target_security.md", "src/unifyweaver/glue/auth_backends.pl"], "original_answer": "Use role-based guards in your authentication configuration. Define guards like `guard(role('admin'))` or `guard(permission('delete_users'))` for specific permissions. Apply them to screens: `screen(admin, 'AdminView', [guard(role('admin'))])`. The authentication backend will enforce these guards based on user roles and permissions. See skill_webapp_security.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer assumes guard-based permission checking, which may not cover all permission-checking scenarios (e.g., checking permissions at runtime within a component, checking multiple permissions with AND/OR logic, or dynamic permission evaluation)."}
{"pair_id": "skill_webapp_security_006_q3", "cluster_id": "skill_webapp_security_006", "question": "How do I implement different access levels?", "answer": "Implement different access levels using role-based guards in your authentication configuration. Define guards for specific roles or permissions: `guard(role('admin'))` for admin access, `guard(permission('delete_users'))` for specific permissions, or `guard(role('user'))` for standard users. Apply these guards directly to screens in your app specification: `screen(admin_panel, 'AdminView', [guard(role('admin'))])`. The authentication backend automatically enforces these guards based on user roles and permissions assigned during login. For detailed implementation patterns and security considerations, refer to skill_webapp_security.md.", "question_type": "long", "topics": ["Quickstart", "Webapp Security"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["authorization", "roles", "permissions", "access-control"], "related_skills": ["skill_app_generation.md", "skill_webapp_security.md"], "related_docs": ["docs/CONTROL_PLANE.md", "education/book-08-security-firewall/02_firewall_policies.md", "education/book-08-security-firewall/04_target_security.md", "src/unifyweaver/glue/auth_backends.pl"], "original_answer": "Use role-based guards in your authentication configuration. Define guards like `guard(role('admin'))` or `guard(permission('delete_users'))` for specific permissions. Apply them to screens: `screen(admin, 'AdminView', [guard(role('admin'))])`. The authentication backend will enforce these guards based on user roles and permissions. See skill_webapp_security.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer assumes the user is working within UnifyWeaver's Prolog app generation system. If they're asking about a different framework or context, this answer may not apply. The answer could be more explicit about what 'different access levels' means (admin, user, guest, etc.) but the role/permission pattern covers the general case."}
{"pair_id": "skill_webassembly_001_q0", "cluster_id": "skill_webassembly_001", "question": "How do I compile a Prolog algorithm to run fast in the browser?", "answer": "To compile a Prolog algorithm for fast browser execution, use the LLVM target to compile to WebAssembly. Start by compiling your predicate to LLVM IR with `compile_tail_recursion_llvm(factorial/2, [export(true)], LLVMCode)` for tail-recursive functions (or `compile_linear_recursion_llvm` for Fibonacci-style recursion). Then generate a WebAssembly module using `compile_wasm_module([factorial], [], WASMCode)`. Finally, create TypeScript bindings with `generate_ts_bindings([factorial], TSCode)` for seamless browser integration. This approach leverages LLVM's optimization and guarantees O(1) stack space via tail-call optimization.", "question_type": "medium", "topics": ["Quickstart", "WebAssembly"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["webassembly", "performance", "browser", "compilation"], "related_skills": ["skill_webassembly.md"], "related_docs": ["src/unifyweaver/targets/llvm_target.pl"], "original_answer": "Use the LLVM target to compile Prolog to WebAssembly. First compile your predicate to LLVM IR using `compile_tail_recursion_llvm(factorial/2, [export(true)], LLVMCode)`, then generate WebAssembly with `compile_wasm_module([factorial], [], WASMCode)`. Generate TypeScript bindings with `generate_ts_bindings([factorial], TSCode)` for easy browser integration. See skill_webassembly.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_webassembly_001_q1", "cluster_id": "skill_webassembly_001", "question": "Can I run Prolog code at native speed in a web browser?", "answer": "Yes. Use the LLVM target to compile Prolog to WebAssembly for native-speed browser execution. Compile your predicate to LLVM IR with `compile_tail_recursion_llvm(factorial/2, [export(true)], LLVMCode)`, then generate WebAssembly with `compile_wasm_module([factorial], [], WASMCode)`. The `musttail` annotation in the generated LLVM guarantees tail-call optimization for O(1) stack usage. Generate TypeScript bindings with `generate_ts_bindings([factorial], TSCode)` for seamless browser integration.", "question_type": "medium", "topics": ["Quickstart", "WebAssembly"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["webassembly", "performance", "browser", "compilation"], "related_skills": ["skill_webassembly.md"], "related_docs": ["src/unifyweaver/targets/llvm_target.pl"], "original_answer": "Use the LLVM target to compile Prolog to WebAssembly. First compile your predicate to LLVM IR using `compile_tail_recursion_llvm(factorial/2, [export(true)], LLVMCode)`, then generate WebAssembly with `compile_wasm_module([factorial], [], WASMCode)`. Generate TypeScript bindings with `generate_ts_bindings([factorial], TSCode)` for easy browser integration. See skill_webassembly.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_webassembly_001_q2", "cluster_id": "skill_webassembly_001", "question": "How do I generate WebAssembly from Prolog?", "answer": "To generate WebAssembly from Prolog, use the LLVM target compilation pipeline. First, compile your Prolog predicate to LLVM IR using `compile_tail_recursion_llvm(factorial/2, [export(true)], LLVMCode)` for tail-recursive functions or `compile_linear_recursion_llvm(Pred/Arity, Options, Code)` for other patterns. Then generate the WebAssembly module with `compile_wasm_module([factorial], [], WASMCode)`. Finally, create TypeScript bindings using `generate_ts_bindings([factorial], TSCode)` for browser integration. The compilation uses clang with the wasm32 target to produce optimized .wasm files.", "question_type": "medium", "topics": ["Quickstart", "WebAssembly"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["webassembly", "performance", "browser", "compilation"], "related_skills": ["skill_webassembly.md"], "related_docs": ["src/unifyweaver/targets/llvm_target.pl"], "original_answer": "Use the LLVM target to compile Prolog to WebAssembly. First compile your predicate to LLVM IR using `compile_tail_recursion_llvm(factorial/2, [export(true)], LLVMCode)`, then generate WebAssembly with `compile_wasm_module([factorial], [], WASMCode)`. Generate TypeScript bindings with `generate_ts_bindings([factorial], TSCode)` for easy browser integration. See skill_webassembly.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_webassembly_002_q0", "cluster_id": "skill_webassembly_002", "question": "How do I generate code bindings for Go, Rust, or C from my Prolog functions?", "answer": "To generate code bindings for Go, Rust, or C from your Prolog functions, use the FFI generation functions: `generate_c_header(Functions, HeaderCode)` for C headers, `generate_cgo_bindings(Functions, GoCode)` for Go, and `generate_rust_ffi(Functions, RustCode)` for Rust. First compile your functions to LLVM IR using `compile_shared_library_llvm(Functions, [], LLVMCode)`, then build a shared library with `build_shared_library(LLFile, OutputName, Commands)`. The generated bindings will handle the calling conventions and type mappings for each language.", "question_type": "long", "topics": ["Quickstart", "WebAssembly"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["ffi", "cgo", "rust", "c", "interop"], "related_skills": ["skill_webassembly.md"], "related_docs": ["src/unifyweaver/targets/llvm_target.pl"], "original_answer": "Generate foreign function interface code using `generate_c_header(Functions, HeaderCode)` for C, `generate_cgo_bindings(Functions, GoCode)` for Go, or `generate_rust_ffi(Functions, RustCode)` for Rust. First compile to LLVM IR with `compile_shared_library_llvm(Functions, [], LLVMCode)`, then build a shared library with `build_shared_library(LLFile, OutputName, Commands)`. See skill_webassembly.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "The base answer references functions that appear in the skill document's capability list but their detailed signatures and actual behavior are not fully documented in the provided skill reference. The answer assumes these functions exist and work as described, but the truncation of the skill document suggests information may be incomplete."}
{"pair_id": "skill_webassembly_002_q1", "cluster_id": "skill_webassembly_002", "question": "Can I use Prolog functions in Go or Rust?", "answer": "Yes, you can use Prolog functions in Go or Rust by generating foreign function interface code. Use `generate_rust_ffi(Functions, RustCode)` for Rust or `generate_cgo_bindings(Functions, GoCode)` for Go. First compile your Prolog functions to LLVM IR with `compile_shared_library_llvm(Functions, [], LLVMCode)`, then build a shared library using `build_shared_library(LLFile, OutputName, Commands)`. This allows your Go or Rust code to call the compiled Prolog functions via FFI.", "question_type": "long", "topics": ["Quickstart", "WebAssembly"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["ffi", "cgo", "rust", "c", "interop"], "related_skills": ["skill_webassembly.md"], "related_docs": ["src/unifyweaver/targets/llvm_target.pl"], "original_answer": "Generate foreign function interface code using `generate_c_header(Functions, HeaderCode)` for C, `generate_cgo_bindings(Functions, GoCode)` for Go, or `generate_rust_ffi(Functions, RustCode)` for Rust. First compile to LLVM IR with `compile_shared_library_llvm(Functions, [], LLVMCode)`, then build a shared library with `build_shared_library(LLFile, OutputName, Commands)`. See skill_webassembly.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer references a skill document but the specific Go/Rust FFI functions mentioned are not shown in the provided skill documentation excerpt. The answer assumes these functions exist and are available, which cannot be fully verified from the given material."}
{"pair_id": "skill_webassembly_002_q2", "cluster_id": "skill_webassembly_002", "question": "How do I create FFI bindings for other languages?", "answer": "To create FFI bindings for other languages, use the appropriate generation function for your target language: `generate_c_header(Functions, HeaderCode)` for C, `generate_cgo_bindings(Functions, GoCode)` for Go, or `generate_rust_ffi(Functions, RustCode)` for Rust. First compile your Prolog code to LLVM IR using `compile_shared_library_llvm(Functions, [], LLVMCode)`, then build the shared library with `build_shared_library(LLFile, OutputName, Commands)`. This creates a native library that can be called from your target language.", "question_type": "long", "topics": ["Quickstart", "WebAssembly"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["ffi", "cgo", "rust", "c", "interop"], "related_skills": ["skill_webassembly.md"], "related_docs": ["src/unifyweaver/targets/llvm_target.pl"], "original_answer": "Generate foreign function interface code using `generate_c_header(Functions, HeaderCode)` for C, `generate_cgo_bindings(Functions, GoCode)` for Go, or `generate_rust_ffi(Functions, RustCode)` for Rust. First compile to LLVM IR with `compile_shared_library_llvm(Functions, [], LLVMCode)`, then build a shared library with `build_shared_library(LLFile, OutputName, Commands)`. See skill_webassembly.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "The base answer mentions FFI functions but the skill document doesn't include detailed implementation details for these functions. The answer assumes these predicates exist and are documented elsewhere. Confidence is moderate because the functions are correctly named and the workflow is sound, but specific parameter requirements and output formats aren't fully documented in the provided skill document."}
{"pair_id": "skill_webassembly_003_q0", "cluster_id": "skill_webassembly_003", "question": "How do I handle recursive functions without stack overflow?", "answer": "Use `compile_tail_recursion_llvm(Pred/Arity, [export(true)], Code)` to generate LLVM IR with `musttail` annotations that guarantee tail-call optimization. This ensures O(1) stack space regardless of recursion depth, preventing stack overflow. The compiler enforces this optimization at compile time rather than relying on runtime behavior. For other recursion patterns like Fibonacci, use `compile_linear_recursion_llvm/3` with memoization to avoid exponential calls.", "question_type": "long", "topics": ["Quickstart", "WebAssembly"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["tail-call", "optimization", "recursion", "stack"], "related_skills": ["skill_webassembly.md"], "related_docs": ["src/unifyweaver/targets/llvm_target.pl"], "original_answer": "Use `compile_tail_recursion_llvm(Pred/Arity, [export(true)], Code)` which generates LLVM IR with `musttail` annotations. This guarantees tail-call optimization with O(1) stack space, preventing stack overflow even with deep recursion. The compiler enforces the optimization at compile time, not runtime. See skill_webassembly.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_webassembly_003_q1", "cluster_id": "skill_webassembly_003", "question": "How do I optimize tail-recursive functions?", "answer": "To optimize tail-recursive functions, use `compile_tail_recursion_llvm(Pred/Arity, [export(true)], Code)` to generate LLVM IR with `musttail` annotations. This guarantees tail-call optimization at compile time, achieving O(1) stack space and preventing stack overflow during deep recursion. The `musttail` keyword enforces the optimization directly in the generated LLVM IR rather than relying on runtime behavior.", "question_type": "long", "topics": ["Quickstart", "WebAssembly"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["tail-call", "optimization", "recursion", "stack"], "related_skills": ["skill_webassembly.md"], "related_docs": ["src/unifyweaver/targets/llvm_target.pl"], "original_answer": "Use `compile_tail_recursion_llvm(Pred/Arity, [export(true)], Code)` which generates LLVM IR with `musttail` annotations. This guarantees tail-call optimization with O(1) stack space, preventing stack overflow even with deep recursion. The compiler enforces the optimization at compile time, not runtime. See skill_webassembly.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_webassembly_003_q2", "cluster_id": "skill_webassembly_003", "question": "What guarantees O(1) stack space for recursion?", "answer": "The `musttail` annotation in LLVM IR guarantees O(1) stack space for recursion. When you use `compile_tail_recursion_llvm(Pred/Arity, [export(true)], Code)`, it generates LLVM IR with `musttail` instructions that enforce tail-call optimization at compile time. This eliminates stack growth by reusing the current stack frame for recursive calls, preventing stack overflow regardless of recursion depth.", "question_type": "long", "topics": ["Quickstart", "WebAssembly"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["tail-call", "optimization", "recursion", "stack"], "related_skills": ["skill_webassembly.md"], "related_docs": ["src/unifyweaver/targets/llvm_target.pl"], "original_answer": "Use `compile_tail_recursion_llvm(Pred/Arity, [export(true)], Code)` which generates LLVM IR with `musttail` annotations. This guarantees tail-call optimization with O(1) stack space, preventing stack overflow even with deep recursion. The compiler enforces the optimization at compile time, not runtime. See skill_webassembly.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_webassembly_004_q0", "cluster_id": "skill_webassembly_004", "question": "How do I compile a graph algorithm like reachability to WebAssembly?", "answer": "Compile a reachability graph algorithm to WebAssembly by first generating LLVM IR with `compile_transitive_closure_llvm(reachable/2, [export(true)], LLVMCode)` to handle the graph traversal. Export your edge facts with `generate_graph_data_export(edge/2, DataCode)`. Then build the WASM module using `build_wasm_module('graph.ll', 'graph', BuildCmds)`, which generates clang commands targeting wasm32. Finally, create TypeScript bindings with `generate_ts_bindings([reachable, get_edges], TSCode)` to call the algorithm from the browser. This approach uses tail-call optimization via LLVM's musttail annotation to ensure efficient memory usage during graph traversal.", "question_type": "long", "topics": ["Quickstart", "WebAssembly"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["graph", "transitive-closure", "algorithms", "wasm"], "related_skills": ["skill_webassembly.md"], "related_docs": ["src/unifyweaver/targets/llvm_target.pl"], "original_answer": "Compile with `compile_transitive_closure_llvm(reachable/2, [], LLVMCode)`, export graph data with `generate_graph_data_export(edge/2, DataCode)`, then build the WASM module with `build_wasm_module('graph.ll', 'graph', BuildCmds)`. Generate TypeScript bindings with `generate_ts_bindings([reachable, get_edges], TSCode)` for browser access. See skill_webassembly.md for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "The base answer references `generate_graph_data_export` which is not documented in the skill document. While the core workflow (LLVM IR \u2192 WASM \u2192 TypeScript bindings) is sound, the specific function for exporting graph data is inferred rather than verified from the documentation."}
{"pair_id": "skill_webassembly_004_q1", "cluster_id": "skill_webassembly_004", "question": "How do I convert Prolog graph traversal to WASM?", "answer": "Compile your Prolog graph traversal predicate with `compile_transitive_closure_llvm(reachable/2, [export(true)], LLVMCode)` to generate LLVM IR with guaranteed tail-call optimization. Export your graph data using `generate_graph_data_export(edge/2, DataCode)`. Build the WASM module with `build_wasm_module('graph.ll', 'graph', BuildCmds)` which outputs the clang compilation command. Finally, generate TypeScript bindings with `generate_ts_bindings([reachable], TSCode)` to call the compiled function from the browser. The transitive closure compilation handles graph reachability efficiently in native-speed WebAssembly.", "question_type": "long", "topics": ["Quickstart", "WebAssembly"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["graph", "transitive-closure", "algorithms", "wasm"], "related_skills": ["skill_webassembly.md"], "related_docs": ["src/unifyweaver/targets/llvm_target.pl"], "original_answer": "Compile with `compile_transitive_closure_llvm(reachable/2, [], LLVMCode)`, export graph data with `generate_graph_data_export(edge/2, DataCode)`, then build the WASM module with `build_wasm_module('graph.ll', 'graph', BuildCmds)`. Generate TypeScript bindings with `generate_ts_bindings([reachable, get_edges], TSCode)` for browser access. See skill_webassembly.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer references `generate_graph_data_export` which is not documented in the skill document - this function may not exist or may have a different name. The confidence is reduced because the exact API for graph data export is unclear."}
{"pair_id": "skill_webassembly_004_q2", "cluster_id": "skill_webassembly_004", "question": "Can I use transitive closure with WebAssembly?", "answer": "Yes. Use `compile_transitive_closure_llvm(Pred/Arity, Options, Code)` to generate LLVM IR for graph traversal, then `build_wasm_module(LLFile, OutputName, Commands)` to compile to WebAssembly. Generate TypeScript bindings with `generate_ts_bindings([predicate], TSCode)` for browser access.", "question_type": "long", "topics": ["Quickstart", "WebAssembly"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["graph", "transitive-closure", "algorithms", "wasm"], "related_skills": ["skill_webassembly.md"], "related_docs": ["src/unifyweaver/targets/llvm_target.pl"], "original_answer": "Compile with `compile_transitive_closure_llvm(reachable/2, [], LLVMCode)`, export graph data with `generate_graph_data_export(edge/2, DataCode)`, then build the WASM module with `build_wasm_module('graph.ll', 'graph', BuildCmds)`. Generate TypeScript bindings with `generate_ts_bindings([reachable, get_edges], TSCode)` for browser access. See skill_webassembly.md for details.", "answer_tailored": true, "confidence": 0.75, "confidence_issues": "Base answer references `generate_graph_data_export` which is not documented in the skill document. Answer simplified to documented APIs. Confidence lowered due to potential missing context about graph data handling in WASM."}
{"pair_id": "skill_webassembly_005_q0", "cluster_id": "skill_webassembly_005", "question": "What commands do I run to convert LLVM IR to a WebAssembly file?", "answer": "Use the `build_wasm_module(LLFile, OutputName, Commands)` predicate which returns the shell commands needed to convert LLVM IR to WebAssembly. Execute the returned commands, typically: `clang --target=wasm32 -O3 -nostdlib -Wl,--no-entry -Wl,--export-all -o factorial.wasm factorial.ll`. This generates the final WASM binary for browser execution.", "question_type": "long", "topics": ["Quickstart", "WebAssembly"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["wasm", "compilation", "clang", "build"], "related_skills": ["skill_webassembly.md"], "related_docs": ["src/unifyweaver/targets/llvm_target.pl"], "original_answer": "Use `build_wasm_module(LLFile, OutputName, Commands)` which returns the shell commands needed. For example: `clang --target=wasm32 -O3 -nostdlib -Wl,--no-entry -Wl,--export-all -o factorial.wasm factorial.ll`. Execute these commands to generate the final WASM binary for browser use. See skill_webassembly.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_webassembly_005_q1", "cluster_id": "skill_webassembly_005", "question": "How do I build a WASM binary from LLVM code?", "answer": "Use `build_wasm_module(LLFile, OutputName, Commands)` to get the shell commands for compilation. For example, execute: `clang --target=wasm32 -O3 -nostdlib -Wl,--no-entry -Wl,--export-all -o factorial.wasm factorial.ll`. This generates the WASM binary from your LLVM IR file for browser execution.", "question_type": "long", "topics": ["Quickstart", "WebAssembly"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["wasm", "compilation", "clang", "build"], "related_skills": ["skill_webassembly.md"], "related_docs": ["src/unifyweaver/targets/llvm_target.pl"], "original_answer": "Use `build_wasm_module(LLFile, OutputName, Commands)` which returns the shell commands needed. For example: `clang --target=wasm32 -O3 -nostdlib -Wl,--no-entry -Wl,--export-all -o factorial.wasm factorial.ll`. Execute these commands to generate the final WASM binary for browser use. See skill_webassembly.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_webassembly_005_q2", "cluster_id": "skill_webassembly_005", "question": "What's the compilation command for WebAssembly?", "answer": "The compilation command for WebAssembly is generated by `build_wasm_module(LLFile, OutputName, Commands)`, which returns shell commands to compile LLVM IR to WASM. The typical command is: `clang --target=wasm32 -O3 -nostdlib -Wl,--no-entry -Wl,--export-all -o factorial.wasm factorial.ll`. Execute this command to generate the final WASM binary for browser use.", "question_type": "long", "topics": ["Quickstart", "WebAssembly"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["wasm", "compilation", "clang", "build"], "related_skills": ["skill_webassembly.md"], "related_docs": ["src/unifyweaver/targets/llvm_target.pl"], "original_answer": "Use `build_wasm_module(LLFile, OutputName, Commands)` which returns the shell commands needed. For example: `clang --target=wasm32 -O3 -nostdlib -Wl,--no-entry -Wl,--export-all -o factorial.wasm factorial.ll`. Execute these commands to generate the final WASM binary for browser use. See skill_webassembly.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_webassembly_006_q0", "cluster_id": "skill_webassembly_006", "question": "How do I handle strings in WebAssembly modules from my Prolog code?", "answer": "Use `compile_wasm_string_module(Functions, Options, Code)` to generate a WebAssembly module with built-in string support. Call `generate_wasm_string_runtime(RuntimeCode)` to get memory allocation functions that handle string data in WASM. Then use `generate_ts_string_bindings(Functions, TSCode)` to create TypeScript bindings that automatically encode/decode strings between your browser code and the WebAssembly module.", "question_type": "long", "topics": ["Quickstart", "WebAssembly"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["strings", "wasm", "memory", "typescript"], "related_skills": ["skill_webassembly.md"], "related_docs": ["src/unifyweaver/targets/llvm_target.pl"], "original_answer": "Use `compile_wasm_string_module(Functions, Options, Code)` and `generate_wasm_string_runtime(RuntimeCode)` which include memory allocation functions for string handling in WASM. Generate TypeScript bindings with `generate_ts_string_bindings(Functions, TSCode)` to automatically handle string encoding/decoding in your browser code. See skill_webassembly.md for details.", "answer_tailored": true, "confidence": 0.75, "confidence_issues": "The base answer references 'skill_webassembly.md' but the skill document shown doesn't include complete documentation for `generate_ts_string_bindings`. The truncated skill document leaves uncertainty about whether this function exists or has different parameters. The confidence is reduced because the tailored answer depends on incomplete source material."}
{"pair_id": "skill_webassembly_006_q1", "cluster_id": "skill_webassembly_006", "question": "Can I pass strings to WASM functions?", "answer": "Yes. Use `compile_wasm_string_module(Functions, Options, Code)` to compile functions that handle strings, paired with `generate_wasm_string_runtime(RuntimeCode)` which includes memory allocation for string handling. Generate TypeScript bindings with `generate_ts_string_bindings(Functions, TSCode)` to automatically manage string encoding/decoding between JavaScript and WASM. This handles the FFI layer so you can pass strings to WASM functions transparently.", "question_type": "long", "topics": ["Quickstart", "WebAssembly"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["strings", "wasm", "memory", "typescript"], "related_skills": ["skill_webassembly.md"], "related_docs": ["src/unifyweaver/targets/llvm_target.pl"], "original_answer": "Use `compile_wasm_string_module(Functions, Options, Code)` and `generate_wasm_string_runtime(RuntimeCode)` which include memory allocation functions for string handling in WASM. Generate TypeScript bindings with `generate_ts_string_bindings(Functions, TSCode)` to automatically handle string encoding/decoding in your browser code. See skill_webassembly.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The skill document is truncated and doesn't show the complete implementation details of `generate_ts_string_bindings`, which is referenced but not fully documented in the provided context."}
{"pair_id": "skill_webassembly_006_q2", "cluster_id": "skill_webassembly_006", "question": "How do I generate WASM with string support?", "answer": "Use `compile_wasm_string_module(Functions, Options, Code)` to generate WASM with string support and `generate_wasm_string_runtime(RuntimeCode)` to include memory allocation functions for string handling. Then use `generate_ts_string_bindings(Functions, TSCode)` to create TypeScript bindings that automatically handle string encoding/decoding in the browser.", "question_type": "long", "topics": ["Quickstart", "WebAssembly"], "source_file": "by-topic/quickstart/skills-generated.jsonl", "tags": ["strings", "wasm", "memory", "typescript"], "related_skills": ["skill_webassembly.md"], "related_docs": ["src/unifyweaver/targets/llvm_target.pl"], "original_answer": "Use `compile_wasm_string_module(Functions, Options, Code)` and `generate_wasm_string_runtime(RuntimeCode)` which include memory allocation functions for string handling in WASM. Generate TypeScript bindings with `generate_ts_string_bindings(Functions, TSCode)` to automatically handle string encoding/decoding in your browser code. See skill_webassembly.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_filing_001_q0", "cluster_id": "skill_bookmark_filing_001", "question": "How do I automatically file bookmarks into my Pearltrees folder hierarchy?", "answer": "Use the bookmark filing skill to automatically file bookmarks into your Pearltrees hierarchy. Run `python3 scripts/infer_pearltrees_federated.py --model models/pearltrees_federated_single.pkl --query \"BOOKMARK_TITLE\" --top-k 10 --tree` to find semantically similar folders using a federated projection model (93% Recall@1). For automated filing with LLM-based refinement, use `python3 scripts/bookmark_filing_assistant.py --bookmark \"BOOKMARK_TITLE\" --provider claude --top-k 10`. The system will return ranked folder candidates based on semantic similarity, allowing you to select the most appropriate destination folder.", "question_type": "medium", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["bookmarks", "pearltrees", "semantic-search", "filing", "automation"], "related_skills": ["skill_bookmark_filing.md", "skill_train_model.md", "skill_semantic_inference.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "docs/QUICKSTART_MINDMAP_LINKING.md", "education/book-13-semantic-search/16_bookmark_filing.md", "education/book-13-semantic-search/05_semantic_playbook.md"], "original_answer": "Use the bookmark filing skill to automatically find semantically similar folders using a federated projection model (93% Recall@1). Run `python3 scripts/infer_pearltrees_federated.py --model models/pearltrees_federated_single.pkl --query \"BOOKMARK_TITLE\" --top-k 10 --tree` to get candidates, or use the full filing assistant with LLM refinement: `python3 scripts/bookmark_filing_assistant.py --bookmark \"BOOKMARK_TITLE\" --provider claude --top-k 10`.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_filing_001_q1", "cluster_id": "skill_bookmark_filing_001", "question": "Can I organize bookmarks using semantic search?", "answer": "Yes, you can organize bookmarks using semantic search through the bookmark filing skill. Use the federated projection model to find semantically similar folders by running `python3 scripts/infer_pearltrees_federated.py --model models/pearltrees_federated_single.pkl --query \"BOOKMARK_TITLE\" --top-k 10 --tree`. This model achieves 93% Recall@1 accuracy. For automated filing with LLM-based refinement, use `python3 scripts/bookmark_filing_assistant.py --bookmark \"BOOKMARK_TITLE\" --provider claude --top-k 10`. You can also filter by account or use account-specific models for more targeted organization.", "question_type": "medium", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["bookmarks", "pearltrees", "semantic-search", "filing", "automation"], "related_skills": ["skill_bookmark_filing.md", "skill_train_model.md", "skill_semantic_inference.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "docs/QUICKSTART_MINDMAP_LINKING.md", "education/book-13-semantic-search/16_bookmark_filing.md", "education/book-13-semantic-search/05_semantic_playbook.md"], "original_answer": "Use the bookmark filing skill to automatically find semantically similar folders using a federated projection model (93% Recall@1). Run `python3 scripts/infer_pearltrees_federated.py --model models/pearltrees_federated_single.pkl --query \"BOOKMARK_TITLE\" --top-k 10 --tree` to get candidates, or use the full filing assistant with LLM refinement: `python3 scripts/bookmark_filing_assistant.py --bookmark \"BOOKMARK_TITLE\" --provider claude --top-k 10`.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_bookmark_filing_001_q2", "cluster_id": "skill_bookmark_filing_001", "question": "What's the best way to sort bookmarks into folders?", "answer": "The best way to sort bookmarks into folders is to use the bookmark filing skill, which automatically matches bookmarks to semantically similar folders. Start with the semantic candidate tool: `python3 scripts/infer_pearltrees_federated.py --model models/pearltrees_federated_single.pkl --query \"BOOKMARK_TITLE\" --top-k 10 --tree`. This uses a federated projection model with 93% Recall@1 accuracy to find the most relevant folders. For more refined selections, use the full filing assistant with LLM refinement: `python3 scripts/bookmark_filing_assistant.py --bookmark \"BOOKMARK_TITLE\" --provider claude --top-k 10`. This approach combines semantic matching with hierarchical context awareness to place bookmarks in the most specific matching folder.", "question_type": "medium", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["bookmarks", "pearltrees", "semantic-search", "filing", "automation"], "related_skills": ["skill_bookmark_filing.md", "skill_train_model.md", "skill_semantic_inference.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "docs/QUICKSTART_MINDMAP_LINKING.md", "education/book-13-semantic-search/16_bookmark_filing.md", "education/book-13-semantic-search/05_semantic_playbook.md"], "original_answer": "Use the bookmark filing skill to automatically find semantically similar folders using a federated projection model (93% Recall@1). Run `python3 scripts/infer_pearltrees_federated.py --model models/pearltrees_federated_single.pkl --query \"BOOKMARK_TITLE\" --top-k 10 --tree` to get candidates, or use the full filing assistant with LLM refinement: `python3 scripts/bookmark_filing_assistant.py --bookmark \"BOOKMARK_TITLE\" --provider claude --top-k 10`.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_filing_001_q3", "cluster_id": "skill_bookmark_filing_001", "question": "How do I find the right folder for a bookmark?", "answer": "To find the right folder for a bookmark, use the bookmark filing skill which leverages semantic search. Run `python3 scripts/infer_pearltrees_federated.py --model models/pearltrees_federated_single.pkl --query \"BOOKMARK_TITLE\" --top-k 10 --tree` to see semantically similar folders ranked by relevance score. For automatic selection with LLM refinement, use `python3 scripts/bookmark_filing_assistant.py --bookmark \"BOOKMARK_TITLE\" --provider claude --top-k 10`. The system achieves 93% accuracy on the first result and 99% within the top 5 candidates. For account-specific models or filtering, add the `--account` parameter or use an account-specific model file.", "question_type": "medium", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["bookmarks", "pearltrees", "semantic-search", "filing", "automation"], "related_skills": ["skill_bookmark_filing.md", "skill_train_model.md", "skill_semantic_inference.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "docs/QUICKSTART_MINDMAP_LINKING.md", "education/book-13-semantic-search/16_bookmark_filing.md", "education/book-13-semantic-search/05_semantic_playbook.md"], "original_answer": "Use the bookmark filing skill to automatically find semantically similar folders using a federated projection model (93% Recall@1). Run `python3 scripts/infer_pearltrees_federated.py --model models/pearltrees_federated_single.pkl --query \"BOOKMARK_TITLE\" --top-k 10 --tree` to get candidates, or use the full filing assistant with LLM refinement: `python3 scripts/bookmark_filing_assistant.py --bookmark \"BOOKMARK_TITLE\" --provider claude --top-k 10`.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_filing_002_q0", "cluster_id": "skill_bookmark_filing_002", "question": "Can I use different semantic models for different Pearltrees accounts?", "answer": "Yes, you can use different semantic models for different Pearltrees accounts. You have two options: (1) Use account-specific models by pointing to the model file with `--model models/pearltrees_federated_s243a.pkl` (for s243a account with 275 clusters) or `--model models/pearltrees_federated_s243a_groups.pkl` (for cross-account migration with 48 clusters). (2) Use the general model `pearltrees_federated_single.pkl` for all accounts and filter results by account using the `--account s243a_groups` flag. Account-specific models are optimized for their respective account's folder structure and may provide better semantic matching.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["accounts", "models", "federation", "multi-account"], "related_skills": ["skill_bookmark_filing.md", "skill_train_model.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "scripts/infer_pearltrees_federated.py", "scripts/generate_account_training_data.py"], "original_answer": "Yes. Use the general model `pearltrees_federated_single.pkl` for all accounts, or use account-specific models: `pearltrees_federated_s243a.pkl` for s243a account (275 clusters) or `pearltrees_federated_s243a_groups.pkl` for cross-account migration (48 clusters). Filter by account with `--account s243a_groups` flag or point to the specific model file with `--model models/pearltrees_federated_s243a_groups.pkl`.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_bookmark_filing_002_q1", "cluster_id": "skill_bookmark_filing_002", "question": "How do I file bookmarks for a specific account?", "answer": "To file bookmarks for a specific account, use either account-specific models or the filter flag. Use `--model models/pearltrees_federated_s243a.pkl` for the s243a account (275 clusters) or `--model models/pearltrees_federated_s243a_groups.pkl` for cross-account migration (48 clusters). Alternatively, use the general model with the `--account` flag: `--model models/pearltrees_federated_single.pkl --account s243a_groups`. For LLM-assisted filing, use `python3 scripts/bookmark_filing_assistant.py --bookmark \"TITLE\" --account s243a_groups --provider claude --top-k 10`.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["accounts", "models", "federation", "multi-account"], "related_skills": ["skill_bookmark_filing.md", "skill_train_model.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "scripts/infer_pearltrees_federated.py", "scripts/generate_account_training_data.py"], "original_answer": "Yes. Use the general model `pearltrees_federated_single.pkl` for all accounts, or use account-specific models: `pearltrees_federated_s243a.pkl` for s243a account (275 clusters) or `pearltrees_federated_s243a_groups.pkl` for cross-account migration (48 clusters). Filter by account with `--account s243a_groups` flag or point to the specific model file with `--model models/pearltrees_federated_s243a_groups.pkl`.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_filing_002_q2", "cluster_id": "skill_bookmark_filing_002", "question": "Do I need separate models for different Pearltrees groups?", "answer": "Yes, you have options depending on your use case. Use the general model `pearltrees_federated_single.pkl` to search across all accounts with a single model. For account-specific searches, use dedicated models: `pearltrees_federated_s243a.pkl` for the s243a account (275 clusters) or `pearltrees_federated_s243a_groups.pkl` for cross-account migration (48 clusters). You can either filter results with the `--account` flag or point directly to the account-specific model file using `--model`.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["accounts", "models", "federation", "multi-account"], "related_skills": ["skill_bookmark_filing.md", "skill_train_model.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "scripts/infer_pearltrees_federated.py", "scripts/generate_account_training_data.py"], "original_answer": "Yes. Use the general model `pearltrees_federated_single.pkl` for all accounts, or use account-specific models: `pearltrees_federated_s243a.pkl` for s243a account (275 clusters) or `pearltrees_federated_s243a_groups.pkl` for cross-account migration (48 clusters). Filter by account with `--account s243a_groups` flag or point to the specific model file with `--model models/pearltrees_federated_s243a_groups.pkl`.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_filing_002_q3", "cluster_id": "skill_bookmark_filing_002", "question": "Can I switch between account-specific and general models?", "answer": "Yes, you can switch between account-specific and general models. Use `pearltrees_federated_single.pkl` for searching across all accounts, or switch to account-specific models like `pearltrees_federated_s243a.pkl` for s243a account or `pearltrees_federated_s243a_groups.pkl` for cross-account migration. Specify which model to use with the `--model` flag: `--model models/pearltrees_federated_s243a_groups.pkl`. You can also filter results by account without changing models using the `--account` flag.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["accounts", "models", "federation", "multi-account"], "related_skills": ["skill_bookmark_filing.md", "skill_train_model.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "scripts/infer_pearltrees_federated.py", "scripts/generate_account_training_data.py"], "original_answer": "Yes. Use the general model `pearltrees_federated_single.pkl` for all accounts, or use account-specific models: `pearltrees_federated_s243a.pkl` for s243a account (275 clusters) or `pearltrees_federated_s243a_groups.pkl` for cross-account migration (48 clusters). Filter by account with `--account s243a_groups` flag or point to the specific model file with `--model models/pearltrees_federated_s243a_groups.pkl`.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_filing_003_q0", "cluster_id": "skill_bookmark_filing_003", "question": "How do I get filing recommendations that consider my existing bookmarks in each folder?", "answer": "To get filing recommendations that consider your existing bookmarks, import your Pearltrees RDF exports to SQLite using `python3 scripts/import_pearltrees_to_db.py --account s243a data/s243a.rdf --account s243a_groups data/s243a_groups.rdf --output pearltrees.db`. Then pass the database to the filing assistant: `python3 scripts/bookmark_filing_assistant.py --bookmark \"BOOKMARK_TITLE\" --db pearltrees.db`. The LLM will analyze existing bookmarks in each candidate folder to make contextually better filing decisions.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["database", "existing-bookmarks", "folder-contents", "context"], "related_skills": ["skill_bookmark_filing.md"], "related_docs": ["scripts/import_pearltrees_to_db.py", "scripts/bookmark_filing_assistant.py", "education/book-13-semantic-search/16_bookmark_filing.md"], "original_answer": "Import your Pearltrees RDF exports to a SQLite database using `python3 scripts/import_pearltrees_to_db.py --account s243a data/s243a.rdf --account s243a_groups data/s243a_groups.rdf --output pearltrees.db`. Then use the filing assistant with the database: `python3 scripts/bookmark_filing_assistant.py --bookmark \"BOOKMARK_TITLE\" --db pearltrees.db`. The LLM will see existing bookmarks in each candidate folder to make better decisions.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer references scripts and features not explicitly documented in the skill document. The --db flag for bookmark_filing_assistant.py is not mentioned in the Commands section. The import script command syntax appears correct but lacks confirmation in provided documentation."}
{"pair_id": "skill_bookmark_filing_003_q1", "cluster_id": "skill_bookmark_filing_003", "question": "Can the filing assistant see what bookmarks are already in folders?", "answer": "Yes, the filing assistant can see existing bookmarks in folders when you import your Pearltrees RDF exports to a SQLite database. Run `python3 scripts/import_pearltrees_to_db.py --account s243a data/s243a.rdf --account s243a_groups data/s243a_groups.rdf --output pearltrees.db`, then use `python3 scripts/bookmark_filing_assistant.py --bookmark \"BOOKMARK_TITLE\" --db pearltrees.db`. The LLM will examine existing bookmarks in each candidate folder to make better filing decisions.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["database", "existing-bookmarks", "folder-contents", "context"], "related_skills": ["skill_bookmark_filing.md"], "related_docs": ["scripts/import_pearltrees_to_db.py", "scripts/bookmark_filing_assistant.py", "education/book-13-semantic-search/16_bookmark_filing.md"], "original_answer": "Import your Pearltrees RDF exports to a SQLite database using `python3 scripts/import_pearltrees_to_db.py --account s243a data/s243a.rdf --account s243a_groups data/s243a_groups.rdf --output pearltrees.db`. Then use the filing assistant with the database: `python3 scripts/bookmark_filing_assistant.py --bookmark \"BOOKMARK_TITLE\" --db pearltrees.db`. The LLM will see existing bookmarks in each candidate folder to make better decisions.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer assumes database integration exists and works as described, but the skill document provided doesn't mention database parameters or this feature. The answer may be incomplete or describe functionality not yet fully documented."}
{"pair_id": "skill_bookmark_filing_003_q2", "cluster_id": "skill_bookmark_filing_003", "question": "How do I make filing decisions based on folder contents?", "answer": "To see what's in a Pearltrees folder, first import your data with `python scripts/import_pearltrees_to_db.py --account <name> <rdf_file> --output pearltrees.db`. Then query the database to see folder contents. The import creates trees and pearls tables with parent relationships.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["database", "existing-bookmarks", "folder-contents", "context"], "related_skills": ["skill_bookmark_filing.md"], "related_docs": ["scripts/import_pearltrees_to_db.py", "scripts/bookmark_filing_assistant.py", "education/book-13-semantic-search/16_bookmark_filing.md"], "original_answer": "Import your Pearltrees RDF exports to a SQLite database using `python3 scripts/import_pearltrees_to_db.py --account s243a data/s243a.rdf --account s243a_groups data/s243a_groups.rdf --output pearltrees.db`. Then use the filing assistant with the database: `python3 scripts/bookmark_filing_assistant.py --bookmark \"BOOKMARK_TITLE\" --db pearltrees.db`. The LLM will see existing bookmarks in each candidate folder to make better decisions.", "answer_tailored": true, "confidence": 0.8, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_bookmark_filing_003_q3", "cluster_id": "skill_bookmark_filing_003", "question": "Does the system show me existing bookmarks when suggesting folders?", "answer": "Yes, the system can show existing bookmarks when suggesting folders. Import your Pearltrees RDF exports to SQLite using `python3 scripts/import_pearltrees_to_db.py --account s243a data/s243a.rdf --account s243a_groups data/s243a_groups.rdf --output pearltrees.db`. Then run the filing assistant with `python3 scripts/bookmark_filing_assistant.py --bookmark \"BOOKMARK_TITLE\" --db pearltrees.db`. The LLM will review existing bookmarks in each candidate folder to make better filing decisions.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["database", "existing-bookmarks", "folder-contents", "context"], "related_skills": ["skill_bookmark_filing.md"], "related_docs": ["scripts/import_pearltrees_to_db.py", "scripts/bookmark_filing_assistant.py", "education/book-13-semantic-search/16_bookmark_filing.md"], "original_answer": "Import your Pearltrees RDF exports to a SQLite database using `python3 scripts/import_pearltrees_to_db.py --account s243a data/s243a.rdf --account s243a_groups data/s243a_groups.rdf --output pearltrees.db`. Then use the filing assistant with the database: `python3 scripts/bookmark_filing_assistant.py --bookmark \"BOOKMARK_TITLE\" --db pearltrees.db`. The LLM will see existing bookmarks in each candidate folder to make better decisions.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "Base answer assumes user has RDF files available and wants to set up a database. The answer doesn't clarify if this is mandatory or optional for the feature, or if there's a simpler way to see existing bookmarks without database setup."}
{"pair_id": "skill_bookmark_filing_004_q0", "cluster_id": "skill_bookmark_filing_004", "question": "Which LLM provider should I use for the bookmark filing assistant?", "answer": "Make the filing assistant aware of existing bookmarks by importing Pearltrees data: `python scripts/import_pearltrees_to_db.py --account <name> <rdf_file> --output pearltrees.db`. This creates a database with your trees and pearls that can be queried for context during filing.", "question_type": "medium", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["llm", "providers", "api", "cost", "setup"], "related_skills": ["skill_bookmark_filing.md"], "related_docs": ["scripts/bookmark_filing_assistant.py", "education/book-13-semantic-search/01_introduction.md"], "original_answer": "Choose based on your setup: Claude CLI (`--provider claude`) is cheapest with subscription, Gemini CLI (`--provider gemini`) works headless, OpenAI API (`--provider openai`) requires OPENAI_API_KEY, Anthropic API (`--provider anthropic`) requires ANTHROPIC_API_KEY, or Local Ollama (`--provider ollama`) if you have ollama installed. Use `python3 scripts/bookmark_filing_assistant.py --bookmark \"TITLE\" --provider claude --top-k 10`.", "answer_tailored": true, "confidence": 0.8, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_bookmark_filing_004_q1", "cluster_id": "skill_bookmark_filing_004", "question": "What are the LLM options for filing bookmarks?", "answer": "The bookmark filing assistant supports five LLM providers: Claude CLI (--provider claude, cheapest with subscription), Gemini CLI (--provider gemini, headless), OpenAI API (--provider openai, requires OPENAI_API_KEY), Anthropic API (--provider anthropic, requires ANTHROPIC_API_KEY), and Local Ollama (--provider ollama, requires ollama installed). Use them with: python3 scripts/bookmark_filing_assistant.py --bookmark \"TITLE\" --provider [choice] --top-k 10", "question_type": "medium", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["llm", "providers", "api", "cost", "setup"], "related_skills": ["skill_bookmark_filing.md"], "related_docs": ["scripts/bookmark_filing_assistant.py", "education/book-13-semantic-search/01_introduction.md"], "original_answer": "Choose based on your setup: Claude CLI (`--provider claude`) is cheapest with subscription, Gemini CLI (`--provider gemini`) works headless, OpenAI API (`--provider openai`) requires OPENAI_API_KEY, Anthropic API (`--provider anthropic`) requires ANTHROPIC_API_KEY, or Local Ollama (`--provider ollama`) if you have ollama installed. Use `python3 scripts/bookmark_filing_assistant.py --bookmark \"TITLE\" --provider claude --top-k 10`.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_bookmark_filing_004_q2", "cluster_id": "skill_bookmark_filing_004", "question": "Is there a free way to get LLM-based filing recommendations?", "answer": "Improve filing accuracy by providing context from existing data. Import your Pearltrees with `python scripts/import_pearltrees_to_db.py --account <name> <rdf_file> --output db.db`. The database can then be queried to show the LLM what's already in each folder.", "question_type": "medium", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["llm", "providers", "api", "cost", "setup"], "related_skills": ["skill_bookmark_filing.md"], "related_docs": ["scripts/bookmark_filing_assistant.py", "education/book-13-semantic-search/01_introduction.md"], "original_answer": "Choose based on your setup: Claude CLI (`--provider claude`) is cheapest with subscription, Gemini CLI (`--provider gemini`) works headless, OpenAI API (`--provider openai`) requires OPENAI_API_KEY, Anthropic API (`--provider anthropic`) requires ANTHROPIC_API_KEY, or Local Ollama (`--provider ollama`) if you have ollama installed. Use `python3 scripts/bookmark_filing_assistant.py --bookmark \"TITLE\" --provider claude --top-k 10`.", "answer_tailored": true, "confidence": 0.8, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_bookmark_filing_004_q3", "cluster_id": "skill_bookmark_filing_004", "question": "Which LLM provider is most cost-effective for bookmark filing?", "answer": "To check for duplicates before filing, first import existing bookmarks with `python scripts/import_pearltrees_to_db.py`. Query the database for matching URLs or titles before adding new bookmarks. The pearls table contains see_also_uri for existing bookmark URLs.", "question_type": "medium", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["llm", "providers", "api", "cost", "setup"], "related_skills": ["skill_bookmark_filing.md"], "related_docs": ["scripts/bookmark_filing_assistant.py", "education/book-13-semantic-search/01_introduction.md"], "original_answer": "Choose based on your setup: Claude CLI (`--provider claude`) is cheapest with subscription, Gemini CLI (`--provider gemini`) works headless, OpenAI API (`--provider openai`) requires OPENAI_API_KEY, Anthropic API (`--provider anthropic`) requires ANTHROPIC_API_KEY, or Local Ollama (`--provider ollama`) if you have ollama installed. Use `python3 scripts/bookmark_filing_assistant.py --bookmark \"TITLE\" --provider claude --top-k 10`.", "answer_tailored": true, "confidence": 0.75, "confidence_issues": "Duplicate checking requires custom query logic not built into the filing tool", "manually_reviewed": true}
{"pair_id": "skill_bookmark_filing_001_q0", "cluster_id": "skill_bookmark_filing_001", "question": "How do I find the best folder to file a bookmark in my Pearltrees?", "answer": "To find the best folder to file a bookmark in Pearltrees, use the semantic search model with:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated_single.pkl \\\n  --query \"BOOKMARK_TITLE\" \\\n  --top-k 10 --tree\n```\n\nThis displays candidate folders in a tree view with semantic relevance scores. The model achieves 93% accuracy at finding the correct folder on the first try.\n\nFor automatic folder selection based on hierarchical context, use the filing assistant:\n\n```bash\npython3 scripts/bookmark_filing_assistant.py \\\n  --bookmark \"BOOKMARK_TITLE\" \\\n  --url \"OPTIONAL_URL\" \\\n  --provider claude \\\n  --top-k 10\n```\n\nWhen choosing between candidates, prefer the most specific matching folder rather than general parent folders, and check for duplicate folder names at different hierarchy levels.", "question_type": "medium", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["semantic-search", "bookmark-filing", "pearltrees", "federated-model"], "related_skills": ["skill_bookmark_filing.md", "skill_semantic_inference.md", "skill_mindmap_linking.md"], "related_docs": ["scripts/infer_pearltrees_federated.py", "scripts/bookmark_filing_assistant.py", "docs/design/FEDERATED_MODEL_FORMAT.md", "education/book-13-semantic-search/16_bookmark_filing.md", "education/book-13-semantic-search/05_semantic_playbook.md"], "original_answer": "Use the federated projection model for semantic search:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated_single.pkl \\\n  --query \"BOOKMARK_TITLE\" \\\n  --top-k 10 --tree\n```\n\nFor AI-assisted selection with folder context:\n\n```bash\npython3 scripts/bookmark_filing_assistant.py \\\n  --bookmark \"BOOKMARK_TITLE\" \\\n  --url \"OPTIONAL_URL\" \\\n  --provider claude \\\n  --top-k 10\n```\n\nThe model achieves 93% Recall@1 accuracy. See `skill_bookmark_filing.md` for model options and filing guidelines.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_filing_001_q1", "cluster_id": "skill_bookmark_filing_001", "question": "Where should I put this bookmark in Pearltrees?", "answer": "To file a bookmark in Pearltrees, use semantic search to find the best folder match. First, run the federated projection model with your bookmark title:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated_single.pkl \\\n  --query \"BOOKMARK_TITLE\" \\\n  --top-k 10 --tree\n```\n\nThis shows the 10 most semantically similar folders (93% accuracy). Review the tree output and select the most specific matching folder.\n\nFor AI-assisted selection that considers hierarchical context:\n\n```bash\npython3 scripts/bookmark_filing_assistant.py \\\n  --bookmark \"BOOKMARK_TITLE\" \\\n  --url \"OPTIONAL_URL\" \\\n  --provider claude \\\n  --top-k 10\n```\n\nThe model supports filtering by account (--account flag) or using account-specific models if you have bookmarks in a particular Pearltrees account. See skill_bookmark_filing.md for available models and filing guidelines.", "question_type": "medium", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["semantic-search", "bookmark-filing", "pearltrees", "federated-model"], "related_skills": ["skill_bookmark_filing.md", "skill_semantic_inference.md", "skill_mindmap_linking.md"], "related_docs": ["scripts/infer_pearltrees_federated.py", "scripts/bookmark_filing_assistant.py", "docs/design/FEDERATED_MODEL_FORMAT.md", "education/book-13-semantic-search/16_bookmark_filing.md", "education/book-13-semantic-search/05_semantic_playbook.md"], "original_answer": "Use the federated projection model for semantic search:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated_single.pkl \\\n  --query \"BOOKMARK_TITLE\" \\\n  --top-k 10 --tree\n```\n\nFor AI-assisted selection with folder context:\n\n```bash\npython3 scripts/bookmark_filing_assistant.py \\\n  --bookmark \"BOOKMARK_TITLE\" \\\n  --url \"OPTIONAL_URL\" \\\n  --provider claude \\\n  --top-k 10\n```\n\nThe model achieves 93% Recall@1 accuracy. See `skill_bookmark_filing.md` for model options and filing guidelines.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null}
{"pair_id": "skill_bookmark_filing_001_q2", "cluster_id": "skill_bookmark_filing_001", "question": "How do I organize bookmarks into Pearltrees folders?", "answer": "To organize bookmarks into Pearltrees folders, use the federated projection model for semantic search. For basic semantic candidate retrieval, run:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated_single.pkl \\\n  --query \"BOOKMARK_TITLE\" \\\n  --top-k 10 --tree\n```\n\nFor AI-assisted folder selection that considers hierarchical context, use the filing assistant:\n\n```bash\npython3 scripts/bookmark_filing_assistant.py \\\n  --bookmark \"BOOKMARK_TITLE\" \\\n  --url \"OPTIONAL_URL\" \\\n  --provider claude \\\n  --top-k 10\n```\n\nThe semantic model achieves 93% Recall@1 accuracy. You can filter by account with `--account` flag, use account-specific models for better accuracy, or adjust `--top-k` to see more candidates. Filing decisions should prioritize the most specific matching folder while considering the hierarchy.", "question_type": "medium", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["semantic-search", "bookmark-filing", "pearltrees", "federated-model"], "related_skills": ["skill_bookmark_filing.md", "skill_semantic_inference.md", "skill_mindmap_linking.md"], "related_docs": ["scripts/infer_pearltrees_federated.py", "scripts/bookmark_filing_assistant.py", "docs/design/FEDERATED_MODEL_FORMAT.md", "education/book-13-semantic-search/16_bookmark_filing.md", "education/book-13-semantic-search/05_semantic_playbook.md"], "original_answer": "Use the federated projection model for semantic search:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated_single.pkl \\\n  --query \"BOOKMARK_TITLE\" \\\n  --top-k 10 --tree\n```\n\nFor AI-assisted selection with folder context:\n\n```bash\npython3 scripts/bookmark_filing_assistant.py \\\n  --bookmark \"BOOKMARK_TITLE\" \\\n  --url \"OPTIONAL_URL\" \\\n  --provider claude \\\n  --top-k 10\n```\n\nThe model achieves 93% Recall@1 accuracy. See `skill_bookmark_filing.md` for model options and filing guidelines.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_filing_001_q3", "cluster_id": "skill_bookmark_filing_001", "question": "What's the best Pearltrees folder for my bookmark?", "answer": "Use the federated projection model to find semantically similar folders. Run:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated_single.pkl \\\n  --query \"YOUR_BOOKMARK_TITLE\" \\\n  --top-k 10 --tree\n```\n\nThis displays candidate folders in a hierarchy view with relevance scores. For AI-assisted selection that considers folder context, use:\n\n```bash\npython3 scripts/bookmark_filing_assistant.py \\\n  --bookmark \"YOUR_BOOKMARK_TITLE\" \\\n  --url \"OPTIONAL_URL\" \\\n  --provider claude \\\n  --top-k 10\n```\n\nThe model achieves 93% Recall@1 accuracy. Choose the highest-ranked folder that matches your bookmark's specificity, or use the LLM tool for context-aware recommendations. For account-specific results, add `--account ACCOUNT_NAME` or use account-specific models.", "question_type": "medium", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["semantic-search", "bookmark-filing", "pearltrees", "federated-model"], "related_skills": ["skill_bookmark_filing.md", "skill_semantic_inference.md", "skill_mindmap_linking.md"], "related_docs": ["scripts/infer_pearltrees_federated.py", "scripts/bookmark_filing_assistant.py", "docs/design/FEDERATED_MODEL_FORMAT.md", "education/book-13-semantic-search/16_bookmark_filing.md", "education/book-13-semantic-search/05_semantic_playbook.md"], "original_answer": "Use the federated projection model for semantic search:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated_single.pkl \\\n  --query \"BOOKMARK_TITLE\" \\\n  --top-k 10 --tree\n```\n\nFor AI-assisted selection with folder context:\n\n```bash\npython3 scripts/bookmark_filing_assistant.py \\\n  --bookmark \"BOOKMARK_TITLE\" \\\n  --url \"OPTIONAL_URL\" \\\n  --provider claude \\\n  --top-k 10\n```\n\nThe model achieves 93% Recall@1 accuracy. See `skill_bookmark_filing.md` for model options and filing guidelines.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_filing_002_q0", "cluster_id": "skill_bookmark_filing_002", "question": "Can I filter bookmark filing suggestions to only show folders from a specific Pearltrees account?", "answer": "Yes, you can filter bookmark filing suggestions to a specific Pearltrees account in two ways:\n\n1. **Using the `--account` flag** with the general model:\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated_single.pkl \\\n  --query \"BOOKMARK_TITLE\" \\\n  --account s243a_groups \\\n  --top-k 10 --tree\n```\n\n2. **Using an account-specific model** for better accuracy:\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated_s243a_groups.pkl \\\n  --query \"BOOKMARK_TITLE\" \\\n  --top-k 10 --tree\n```\n\nAvailable account-specific models: `pearltrees_federated_s243a.pkl` (s243a account) and `pearltrees_federated_s243a_groups.pkl` (s243a_groups account). The general model `pearltrees_federated_single.pkl` searches across all accounts.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing", "Account Filtering"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["semantic-search", "bookmark-filing", "account-filtering", "multi-account"], "related_skills": ["skill_bookmark_filing.md", "skill_train_model.md"], "related_docs": ["scripts/infer_pearltrees_federated.py", "scripts/generate_account_training_data.py", "docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "Yes, use the `--account` flag to filter by account:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated_single.pkl \\\n  --query \"BOOKMARK_TITLE\" \\\n  --account s243a_groups \\\n  --top-k 10 --tree\n```\n\nOr use an account-specific model:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated_s243a_groups.pkl \\\n  --query \"BOOKMARK_TITLE\" \\\n  --top-k 10 --tree\n```\n\nAvailable models: `pearltrees_federated_single.pkl` (all accounts), `pearltrees_federated_s243a.pkl` (s243a only), `pearltrees_federated_s243a_groups.pkl` (s243a_groups). See `skill_bookmark_filing.md` for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_bookmark_filing_002_q1", "cluster_id": "skill_bookmark_filing_002", "question": "How do I file bookmarks in only my personal Pearltrees folders?", "answer": "To file bookmarks in only your personal Pearltrees folders (s243a), use the `--account` flag with the account name:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated_single.pkl \\\n  --query \"BOOKMARK_TITLE\" \\\n  --account s243a \\\n  --top-k 10 --tree\n```\n\nAlternatively, use the account-specific model for better accuracy:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated_s243a.pkl \\\n  --query \"BOOKMARK_TITLE\" \\\n  --top-k 10 --tree\n```\n\nThe `--account s243a` flag restricts results to your personal folders only. The dedicated `pearltrees_federated_s243a.pkl` model (275 clusters) provides more granular folder recommendations for your account.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing", "Account Filtering"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["semantic-search", "bookmark-filing", "account-filtering", "multi-account"], "related_skills": ["skill_bookmark_filing.md", "skill_train_model.md"], "related_docs": ["scripts/infer_pearltrees_federated.py", "scripts/generate_account_training_data.py", "docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "Yes, use the `--account` flag to filter by account:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated_single.pkl \\\n  --query \"BOOKMARK_TITLE\" \\\n  --account s243a_groups \\\n  --top-k 10 --tree\n```\n\nOr use an account-specific model:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated_s243a_groups.pkl \\\n  --query \"BOOKMARK_TITLE\" \\\n  --top-k 10 --tree\n```\n\nAvailable models: `pearltrees_federated_single.pkl` (all accounts), `pearltrees_federated_s243a.pkl` (s243a only), `pearltrees_federated_s243a_groups.pkl` (s243a_groups). See `skill_bookmark_filing.md` for details.", "answer_tailored": true, "confidence": 0.75, "confidence_issues": "Base answer referenced s243a_groups (group account) when question asks for personal folders (s243a only). Corrected account name in tailored answer, but uncertainty remains about whether 's243a' vs 's243a_groups' distinction is clear to the user without more context about their account setup."}
{"pair_id": "skill_bookmark_filing_002_q2", "cluster_id": "skill_bookmark_filing_002", "question": "Can I search only certain Pearltrees accounts when organizing bookmarks?", "answer": "Yes, you can search only certain Pearltrees accounts when organizing bookmarks. Use the `--account` flag to filter by account:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated_single.pkl \\\n  --query \"BOOKMARK_TITLE\" \\\n  --account s243a_groups \\\n  --top-k 10 --tree\n```\n\nAlternatively, use an account-specific model for more targeted results:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated_s243a_groups.pkl \\\n  --query \"BOOKMARK_TITLE\" \\\n  --top-k 10 --tree\n```\n\nAvailable account-specific models:\n- `pearltrees_federated_single.pkl` - Search across all accounts\n- `pearltrees_federated_s243a.pkl` - Search s243a account only\n- `pearltrees_federated_s243a_groups.pkl` - Search s243a_groups account only", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing", "Account Filtering"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["semantic-search", "bookmark-filing", "account-filtering", "multi-account"], "related_skills": ["skill_bookmark_filing.md", "skill_train_model.md"], "related_docs": ["scripts/infer_pearltrees_federated.py", "scripts/generate_account_training_data.py", "docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "Yes, use the `--account` flag to filter by account:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated_single.pkl \\\n  --query \"BOOKMARK_TITLE\" \\\n  --account s243a_groups \\\n  --top-k 10 --tree\n```\n\nOr use an account-specific model:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated_s243a_groups.pkl \\\n  --query \"BOOKMARK_TITLE\" \\\n  --top-k 10 --tree\n```\n\nAvailable models: `pearltrees_federated_single.pkl` (all accounts), `pearltrees_federated_s243a.pkl` (s243a only), `pearltrees_federated_s243a_groups.pkl` (s243a_groups). See `skill_bookmark_filing.md` for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_bookmark_filing_002_q3", "cluster_id": "skill_bookmark_filing_002", "question": "How do I limit folder suggestions to one account?", "answer": "Use the `--account` flag to filter by account:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated_single.pkl \\\n  --query \"BOOKMARK_TITLE\" \\\n  --account s243a_groups \\\n  --top-k 10 --tree\n```\n\nAlternatively, use an account-specific model to automatically limit results to that account:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated_s243a_groups.pkl \\\n  --query \"BOOKMARK_TITLE\" \\\n  --top-k 10 --tree\n```\n\nAvailable account-specific models: `pearltrees_federated_s243a.pkl` (s243a only) and `pearltrees_federated_s243a_groups.pkl` (s243a_groups only).", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing", "Account Filtering"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["semantic-search", "bookmark-filing", "account-filtering", "multi-account"], "related_skills": ["skill_bookmark_filing.md", "skill_train_model.md"], "related_docs": ["scripts/infer_pearltrees_federated.py", "scripts/generate_account_training_data.py", "docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "Yes, use the `--account` flag to filter by account:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated_single.pkl \\\n  --query \"BOOKMARK_TITLE\" \\\n  --account s243a_groups \\\n  --top-k 10 --tree\n```\n\nOr use an account-specific model:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated_s243a_groups.pkl \\\n  --query \"BOOKMARK_TITLE\" \\\n  --top-k 10 --tree\n```\n\nAvailable models: `pearltrees_federated_single.pkl` (all accounts), `pearltrees_federated_s243a.pkl` (s243a only), `pearltrees_federated_s243a_groups.pkl` (s243a_groups). See `skill_bookmark_filing.md` for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_filing_003_q0", "cluster_id": "skill_bookmark_filing_003", "question": "How can I see what bookmarks are already in candidate folders before filing?", "answer": "To see what bookmarks are already in candidate folders before filing, import your Pearltrees RDF exports to SQLite and use the database with the filing assistant:\n\n```bash\npython3 scripts/import_pearltrees_to_db.py \\\n  --account s243a data/s243a.rdf \\\n  --account s243a_groups data/s243a_groups.rdf \\\n  --output pearltrees.db\n\npython3 scripts/bookmark_filing_assistant.py \\\n  --bookmark \"your bookmark title\" \\\n  --db pearltrees.db\n```\n\nWhen you run the filing assistant with the `--db` flag, it will display existing bookmarks in each candidate folder, helping you avoid duplicates and make better filing decisions.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing", "Folder Contents"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["bookmark-filing", "database", "rdf-import", "folder-contents"], "related_skills": ["skill_bookmark_filing.md"], "related_docs": ["scripts/import_pearltrees_to_db.py", "scripts/bookmark_filing_assistant.py", "education/book-13-semantic-search/16_bookmark_filing.md"], "original_answer": "Import your Pearltrees RDF exports to SQLite, then use the database with the filing assistant:\n\n```bash\n# Import RDF data\npython3 scripts/import_pearltrees_to_db.py \\\n  --account s243a data/s243a.rdf \\\n  --account s243a_groups data/s243a_groups.rdf \\\n  --output pearltrees.db\n\n# Use with filing assistant\npython3 scripts/bookmark_filing_assistant.py \\\n  --bookmark \"Machine learning tutorial\" \\\n  --db pearltrees.db\n```\n\nThe LLM will show existing bookmarks in candidate folders to help you avoid duplicates and make better filing decisions. See `skill_bookmark_filing.md` for details.", "answer_tailored": true, "confidence": 0.75, "confidence_issues": "The base answer references a script `import_pearltrees_to_db.py` and a `--db` parameter for the filing assistant that are not documented in the provided skill document. The answer is technically sound but lacks verification that these tools exist and work as described in the actual codebase."}
{"pair_id": "skill_bookmark_filing_003_q1", "cluster_id": "skill_bookmark_filing_003", "question": "Can the filing assistant show me existing folder contents?", "answer": "The filing assistant cannot directly show existing folder contents from the Pearltrees interface. However, you can import your Pearltrees RDF exports to SQLite and use the database with the filing assistant to view existing bookmarks:\n\n```bash\n# Import RDF data\npython3 scripts/import_pearltrees_to_db.py \\\n  --account s243a data/s243a.rdf \\\n  --account s243a_groups data/s243a_groups.rdf \\\n  --output pearltrees.db\n\n# Use with filing assistant\npython3 scripts/bookmark_filing_assistant.py \\\n  --bookmark \"Machine learning tutorial\" \\\n  --db pearltrees.db\n```\n\nOnce imported, the LLM will display existing bookmarks in candidate folders, helping you avoid duplicates and make better filing decisions.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing", "Folder Contents"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["bookmark-filing", "database", "rdf-import", "folder-contents"], "related_skills": ["skill_bookmark_filing.md"], "related_docs": ["scripts/import_pearltrees_to_db.py", "scripts/bookmark_filing_assistant.py", "education/book-13-semantic-search/16_bookmark_filing.md"], "original_answer": "Import your Pearltrees RDF exports to SQLite, then use the database with the filing assistant:\n\n```bash\n# Import RDF data\npython3 scripts/import_pearltrees_to_db.py \\\n  --account s243a data/s243a.rdf \\\n  --account s243a_groups data/s243a_groups.rdf \\\n  --output pearltrees.db\n\n# Use with filing assistant\npython3 scripts/bookmark_filing_assistant.py \\\n  --bookmark \"Machine learning tutorial\" \\\n  --db pearltrees.db\n```\n\nThe LLM will show existing bookmarks in candidate folders to help you avoid duplicates and make better filing decisions. See `skill_bookmark_filing.md` for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "The base answer assumes the filing assistant has a --db parameter and LLM integration for showing existing bookmarks, but this is not explicitly confirmed in the skill document provided. The skill document doesn't mention database integration or existing bookmark display capabilities in the filing assistant commands shown."}
{"pair_id": "skill_bookmark_filing_003_q2", "cluster_id": "skill_bookmark_filing_003", "question": "How do I know what's already in a Pearltrees folder before adding a bookmark?", "answer": "To see what's in a Pearltrees folder, first import your data with `python scripts/import_pearltrees_to_db.py --account <name> <rdf_file> --output pearltrees.db`. Then query the database to see folder contents. The import creates trees and pearls tables with parent relationships.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing", "Folder Contents"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["bookmark-filing", "database", "rdf-import", "folder-contents"], "related_skills": ["skill_bookmark_filing.md"], "related_docs": ["scripts/import_pearltrees_to_db.py", "scripts/bookmark_filing_assistant.py", "education/book-13-semantic-search/16_bookmark_filing.md"], "original_answer": "Import your Pearltrees RDF exports to SQLite, then use the database with the filing assistant:\n\n```bash\n# Import RDF data\npython3 scripts/import_pearltrees_to_db.py \\\n  --account s243a data/s243a.rdf \\\n  --account s243a_groups data/s243a_groups.rdf \\\n  --output pearltrees.db\n\n# Use with filing assistant\npython3 scripts/bookmark_filing_assistant.py \\\n  --bookmark \"Machine learning tutorial\" \\\n  --db pearltrees.db\n```\n\nThe LLM will show existing bookmarks in candidate folders to help you avoid duplicates and make better filing decisions. See `skill_bookmark_filing.md` for details.", "answer_tailored": true, "confidence": 0.8, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_bookmark_filing_003_q3", "cluster_id": "skill_bookmark_filing_003", "question": "Can I view bookmarks in folders during filing?", "answer": "Yes, you can view bookmarks in folders during filing. Import your Pearltrees RDF exports to SQLite, then use the database with the filing assistant. The LLM will display existing bookmarks in candidate folders to help you avoid duplicates and make better filing decisions:\n\n```bash\n# Import RDF data\npython3 scripts/import_pearltrees_to_db.py \\\n  --account s243a data/s243a.rdf \\\n  --account s243a_groups data/s243a_groups.rdf \\\n  --output pearltrees.db\n\n# Use with filing assistant to see bookmarks in candidate folders\npython3 scripts/bookmark_filing_assistant.py \\\n  --bookmark \"Machine learning tutorial\" \\\n  --db pearltrees.db\n```\n\nThis shows you what's already in each candidate folder before you file new bookmarks.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing", "Folder Contents"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["bookmark-filing", "database", "rdf-import", "folder-contents"], "related_skills": ["skill_bookmark_filing.md"], "related_docs": ["scripts/import_pearltrees_to_db.py", "scripts/bookmark_filing_assistant.py", "education/book-13-semantic-search/16_bookmark_filing.md"], "original_answer": "Import your Pearltrees RDF exports to SQLite, then use the database with the filing assistant:\n\n```bash\n# Import RDF data\npython3 scripts/import_pearltrees_to_db.py \\\n  --account s243a data/s243a.rdf \\\n  --account s243a_groups data/s243a_groups.rdf \\\n  --output pearltrees.db\n\n# Use with filing assistant\npython3 scripts/bookmark_filing_assistant.py \\\n  --bookmark \"Machine learning tutorial\" \\\n  --db pearltrees.db\n```\n\nThe LLM will show existing bookmarks in candidate folders to help you avoid duplicates and make better filing decisions. See `skill_bookmark_filing.md` for details.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "Base answer assumes RDF import is the primary way to view bookmarks, but doesn't clarify if this is the only method or if other ways exist. The skill document focuses on semantic search and filing, not explicitly on viewing existing bookmarks during the process. Confidence lowered due to this gap between the question intent and answer scope."}
{"pair_id": "skill_bookmark_filing_004_q0", "cluster_id": "skill_bookmark_filing_004", "question": "What LLM providers can I use for bookmark filing assistance?", "answer": "Make the filing assistant aware of existing bookmarks by importing Pearltrees data: `python scripts/import_pearltrees_to_db.py --account <name> <rdf_file> --output pearltrees.db`. This creates a database with your trees and pearls that can be queried for context during filing.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing", "LLM Providers"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["bookmark-filing", "llm", "providers", "ai-assistance"], "related_skills": ["skill_bookmark_filing.md"], "related_docs": ["scripts/bookmark_filing_assistant.py", "education/book-13-semantic-search/16_bookmark_filing.md"], "original_answer": "The bookmark filing assistant supports multiple LLM providers:\n\n- **Claude CLI**: `--provider claude` (cheapest with subscription)\n- **Gemini CLI**: `--provider gemini` (Gemini headless)\n- **OpenAI API**: `--provider openai` (requires OPENAI_API_KEY)\n- **Anthropic API**: `--provider anthropic` (requires ANTHROPIC_API_KEY)\n- **Local Ollama**: `--provider ollama` (requires ollama installed)\n\nExample:\n```bash\npython3 scripts/bookmark_filing_assistant.py \\\n  --bookmark \"BOOKMARK_TITLE\" \\\n  --provider claude \\\n  --top-k 10\n```\n\nThe LLM receives semantic search candidates with hierarchical context and makes the final folder selection. See `skill_bookmark_filing.md` for details.", "answer_tailored": true, "confidence": 0.8, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_bookmark_filing_004_q1", "cluster_id": "skill_bookmark_filing_004", "question": "Which AI models work with the bookmark filing assistant?", "answer": "The bookmark filing assistant supports the following AI models via different LLM providers:\n\n- **Claude** via Claude CLI: `--provider claude` (cheapest with subscription)\n- **Gemini** via Gemini CLI: `--provider gemini` (Gemini headless)\n- **OpenAI's models** via OpenAI API: `--provider openai` (requires OPENAI_API_KEY)\n- **Anthropic's Claude models** via Anthropic API: `--provider anthropic` (requires ANTHROPIC_API_KEY)\n- **Local models** via Ollama: `--provider ollama` (requires ollama installed)\n\nUsage example:\n```bash\npython3 scripts/bookmark_filing_assistant.py \\\n  --bookmark \"BOOKMARK_TITLE\" \\\n  --provider claude \\\n  --top-k 10\n```\n\nThe selected LLM receives semantic search candidates with hierarchical context to make the final folder selection.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing", "LLM Providers"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["bookmark-filing", "llm", "providers", "ai-assistance"], "related_skills": ["skill_bookmark_filing.md"], "related_docs": ["scripts/bookmark_filing_assistant.py", "education/book-13-semantic-search/16_bookmark_filing.md"], "original_answer": "The bookmark filing assistant supports multiple LLM providers:\n\n- **Claude CLI**: `--provider claude` (cheapest with subscription)\n- **Gemini CLI**: `--provider gemini` (Gemini headless)\n- **OpenAI API**: `--provider openai` (requires OPENAI_API_KEY)\n- **Anthropic API**: `--provider anthropic` (requires ANTHROPIC_API_KEY)\n- **Local Ollama**: `--provider ollama` (requires ollama installed)\n\nExample:\n```bash\npython3 scripts/bookmark_filing_assistant.py \\\n  --bookmark \"BOOKMARK_TITLE\" \\\n  --provider claude \\\n  --top-k 10\n```\n\nThe LLM receives semantic search candidates with hierarchical context and makes the final folder selection. See `skill_bookmark_filing.md` for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_bookmark_filing_004_q2", "cluster_id": "skill_bookmark_filing_004", "question": "Can I use different LLMs for filing bookmarks?", "answer": "Improve filing accuracy by providing context from existing data. Import your Pearltrees with `python scripts/import_pearltrees_to_db.py --account <name> <rdf_file> --output db.db`. The database can then be queried to show the LLM what's already in each folder.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing", "LLM Providers"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["bookmark-filing", "llm", "providers", "ai-assistance"], "related_skills": ["skill_bookmark_filing.md"], "related_docs": ["scripts/bookmark_filing_assistant.py", "education/book-13-semantic-search/16_bookmark_filing.md"], "original_answer": "The bookmark filing assistant supports multiple LLM providers:\n\n- **Claude CLI**: `--provider claude` (cheapest with subscription)\n- **Gemini CLI**: `--provider gemini` (Gemini headless)\n- **OpenAI API**: `--provider openai` (requires OPENAI_API_KEY)\n- **Anthropic API**: `--provider anthropic` (requires ANTHROPIC_API_KEY)\n- **Local Ollama**: `--provider ollama` (requires ollama installed)\n\nExample:\n```bash\npython3 scripts/bookmark_filing_assistant.py \\\n  --bookmark \"BOOKMARK_TITLE\" \\\n  --provider claude \\\n  --top-k 10\n```\n\nThe LLM receives semantic search candidates with hierarchical context and makes the final folder selection. See `skill_bookmark_filing.md` for details.", "answer_tailored": true, "confidence": 0.8, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_bookmark_filing_004_q3", "cluster_id": "skill_bookmark_filing_004", "question": "What are the options for AI-assisted bookmark organization?", "answer": "To check for duplicates before filing, first import existing bookmarks with `python scripts/import_pearltrees_to_db.py`. Query the database for matching URLs or titles before adding new bookmarks. The pearls table contains see_also_uri for existing bookmark URLs.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing", "LLM Providers"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["bookmark-filing", "llm", "providers", "ai-assistance"], "related_skills": ["skill_bookmark_filing.md"], "related_docs": ["scripts/bookmark_filing_assistant.py", "education/book-13-semantic-search/16_bookmark_filing.md"], "original_answer": "The bookmark filing assistant supports multiple LLM providers:\n\n- **Claude CLI**: `--provider claude` (cheapest with subscription)\n- **Gemini CLI**: `--provider gemini` (Gemini headless)\n- **OpenAI API**: `--provider openai` (requires OPENAI_API_KEY)\n- **Anthropic API**: `--provider anthropic` (requires ANTHROPIC_API_KEY)\n- **Local Ollama**: `--provider ollama` (requires ollama installed)\n\nExample:\n```bash\npython3 scripts/bookmark_filing_assistant.py \\\n  --bookmark \"BOOKMARK_TITLE\" \\\n  --provider claude \\\n  --top-k 10\n```\n\nThe LLM receives semantic search candidates with hierarchical context and makes the final folder selection. See `skill_bookmark_filing.md` for details.", "answer_tailored": true, "confidence": 0.75, "confidence_issues": "Duplicate checking requires custom query logic not built into the filing tool", "manually_reviewed": true}
{"pair_id": "skill_bookmark_filing_001_q0", "cluster_id": "skill_bookmark_filing_001", "question": "How do I find the best folder to save a bookmark in?", "answer": "To find the best folder for a bookmark, use the semantic search tool `scripts/infer_pearltrees_federated.py` with your bookmark title. This identifies semantically similar folders ranked by relevance score. For more sophisticated folder selection that considers the folder hierarchy and context, use `scripts/bookmark_filing_assistant.py` which can optionally call an LLM to make the final filing decision based on the semantic candidates and hierarchical structure.", "question_type": "medium", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["bookmarks", "organization", "semantic-search"], "related_skills": ["skill_bookmark_filing.md"], "related_docs": ["scripts/infer_pearltrees_federated.py", "scripts/bookmark_filing_assistant.py"], "original_answer": "You can find semantic matches for a bookmark title using `scripts/infer_pearltrees_federated.py`. For a full recommendation including hierarchy analysis, use the `scripts/bookmark_filing_assistant.py` tool.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_filing_001_q1", "cluster_id": "skill_bookmark_filing_001", "question": "Where should I file this URL?", "answer": "To file a URL, use `scripts/bookmark_filing_assistant.py` with the `--url` flag: `python3 scripts/bookmark_filing_assistant.py --bookmark \"TITLE\" --url \"URL\" --provider claude --top-k 10`. This tool performs semantic search on your bookmark title and optionally uses an LLM to recommend the best folder in your hierarchy. Alternatively, use `scripts/infer_pearltrees_federated.py` with just the bookmark title for semantic candidates without LLM selection.", "question_type": "medium", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["bookmarks", "organization", "semantic-search"], "related_skills": ["skill_bookmark_filing.md"], "related_docs": ["scripts/infer_pearltrees_federated.py", "scripts/bookmark_filing_assistant.py"], "original_answer": "You can find semantic matches for a bookmark title using `scripts/infer_pearltrees_federated.py`. For a full recommendation including hierarchy analysis, use the `scripts/bookmark_filing_assistant.py` tool.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_bookmark_filing_001_q2", "cluster_id": "skill_bookmark_filing_001", "question": "Find matching folders for a bookmark", "answer": "Use `scripts/infer_pearltrees_federated.py` to find semantic matches for a bookmark. Run with `--query \"BOOKMARK_TITLE\"` and `--top-k 10` to get the top 10 matching folders. Add `--tree` to see hierarchy or `--json` for JSON output. For account-specific results, add `--account ACCOUNT_NAME`. For full filing assistance with LLM-based selection, use `scripts/bookmark_filing_assistant.py` with `--bookmark \"TITLE\"` and `--provider claude`.", "question_type": "medium", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["bookmarks", "organization", "semantic-search"], "related_skills": ["skill_bookmark_filing.md"], "related_docs": ["scripts/infer_pearltrees_federated.py", "scripts/bookmark_filing_assistant.py"], "original_answer": "You can find semantic matches for a bookmark title using `scripts/infer_pearltrees_federated.py`. For a full recommendation including hierarchy analysis, use the `scripts/bookmark_filing_assistant.py` tool.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_filing_001_q3", "cluster_id": "skill_bookmark_filing_001", "question": "Organize links into folders", "answer": "Use `scripts/infer_pearltrees_federated.py` to find semantically similar folders for your bookmark, or use `scripts/bookmark_filing_assistant.py` for full filing assistance with LLM-based hierarchy analysis. The federated model achieves 93% accuracy at finding the right folder. Example: `python3 scripts/infer_pearltrees_federated.py --model models/pearltrees_federated_single.pkl --query \"BOOKMARK_TITLE\" --top-k 10 --tree` to see folder suggestions in tree view.", "question_type": "medium", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["bookmarks", "organization", "semantic-search"], "related_skills": ["skill_bookmark_filing.md"], "related_docs": ["scripts/infer_pearltrees_federated.py", "scripts/bookmark_filing_assistant.py"], "original_answer": "You can find semantic matches for a bookmark title using `scripts/infer_pearltrees_federated.py`. For a full recommendation including hierarchy analysis, use the `scripts/bookmark_filing_assistant.py` tool.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_filing_002_q0", "cluster_id": "skill_bookmark_filing_002", "question": "Can I use an LLM to help organize my bookmarks?", "answer": "Yes, you can use an LLM to help organize your bookmarks. The `scripts/bookmark_filing_assistant.py` tool finds semantically similar folders using a federated projection model, then asks an LLM (Claude, Gemini, OpenAI, or Ollama) to select the best folder based on the hierarchy and context. Run it with: `python3 scripts/bookmark_filing_assistant.py --bookmark \"BOOKMARK_TITLE\" --provider claude --top-k 10`. This combines semantic search (93% Recall@1) with LLM reasoning for accurate folder selection.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["llm", "automation", "bookmarks"], "related_skills": ["skill_bookmark_filing.md"], "related_docs": ["scripts/bookmark_filing_assistant.py"], "original_answer": "Yes. The `scripts/bookmark_filing_assistant.py` tool retrieves semantic candidates and then asks an LLM (Claude, Gemini, OpenAI, or Ollama) to select the best fit based on the folder structure.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_filing_002_q1", "cluster_id": "skill_bookmark_filing_002", "question": "Auto-file bookmarks with AI", "answer": "Yes. Use `scripts/bookmark_filing_assistant.py` to auto-file bookmarks with AI. The tool retrieves semantic folder candidates using a federated projection model (93% Recall@1), then an LLM (Claude, Gemini, OpenAI, or Ollama) selects the best folder based on the hierarchy. Example: `python3 scripts/bookmark_filing_assistant.py --bookmark \"BOOKMARK_TITLE\" --url \"OPTIONAL_URL\" --provider claude --top-k 10`", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["llm", "automation", "bookmarks"], "related_skills": ["skill_bookmark_filing.md"], "related_docs": ["scripts/bookmark_filing_assistant.py"], "original_answer": "Yes. The `scripts/bookmark_filing_assistant.py` tool retrieves semantic candidates and then asks an LLM (Claude, Gemini, OpenAI, or Ollama) to select the best fit based on the folder structure.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_filing_002_q2", "cluster_id": "skill_bookmark_filing_002", "question": "Ask Claude where to put a link", "answer": "Yes. Use `scripts/bookmark_filing_assistant.py` with the `--provider claude` flag to ask Claude where to file a link. Run: `python3 scripts/bookmark_filing_assistant.py --bookmark \"YOUR_LINK_TITLE\" --url \"OPTIONAL_URL\" --provider claude --top-k 10`. Claude will analyze the semantic candidates and recommend the best folder based on the Pearltrees hierarchy.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["llm", "automation", "bookmarks"], "related_skills": ["skill_bookmark_filing.md"], "related_docs": ["scripts/bookmark_filing_assistant.py"], "original_answer": "Yes. The `scripts/bookmark_filing_assistant.py` tool retrieves semantic candidates and then asks an LLM (Claude, Gemini, OpenAI, or Ollama) to select the best fit based on the folder structure.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_filing_002_q3", "cluster_id": "skill_bookmark_filing_002", "question": "Use Gemini to sort bookmarks", "answer": "Yes. Use the `scripts/bookmark_filing_assistant.py` script with the `--provider gemini` flag to leverage Gemini for bookmark sorting. The script retrieves semantic candidates and then asks Gemini to select the best folder based on the hierarchy. Example: `python3 scripts/bookmark_filing_assistant.py --bookmark \"BOOKMARK_TITLE\" --url \"OPTIONAL_URL\" --provider gemini --top-k 10`. Gemini is available as a CLI headless option.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["llm", "automation", "bookmarks"], "related_skills": ["skill_bookmark_filing.md"], "related_docs": ["scripts/bookmark_filing_assistant.py"], "original_answer": "Yes. The `scripts/bookmark_filing_assistant.py` tool retrieves semantic candidates and then asks an LLM (Claude, Gemini, OpenAI, or Ollama) to select the best fit based on the folder structure.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_filing_003_q0", "cluster_id": "skill_bookmark_filing_003", "question": "How do I search for folders in a specific account?", "answer": "To search for folders in a specific account, use the `--account` flag with the inference script: `python3 scripts/infer_pearltrees_federated.py --model models/pearltrees_federated_single.pkl --query \"BOOKMARK_TITLE\" --account ACCOUNT_NAME --top-k 10 --tree`. Alternatively, use an account-specific model file directly: `python3 scripts/infer_pearltrees_federated.py --model models/pearltrees_federated_ACCOUNT_NAME.pkl --query \"BOOKMARK_TITLE\" --top-k 10 --tree`. Account-specific models (e.g., `pearltrees_federated_s243a.pkl`) are trained only on that account's data and may provide better results for account-focused searches.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["filtering", "accounts", "search"], "related_skills": ["skill_bookmark_filing.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "scripts/infer_pearltrees_federated.py"], "original_answer": "Use the `--account` flag with `scripts/infer_pearltrees_federated.py` to filter results, or use a specific model file (e.g., `models/pearltrees_federated_s243a.pkl`) that is trained only on that account's data.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_bookmark_filing_003_q1", "cluster_id": "skill_bookmark_filing_003", "question": "Limit bookmark filing to one group", "answer": "To limit bookmark filing to one group, use the `--account` flag with `scripts/infer_pearltrees_federated.py` to filter semantic candidates to that specific group, or use an account-specific model file (e.g., `models/pearltrees_federated_s243a_groups.pkl`) trained only on that group's folder hierarchy. For example: `python3 scripts/infer_pearltrees_federated.py --model models/pearltrees_federated_single.pkl --query \"BOOKMARK_TITLE\" --account s243a_groups --top-k 10 --tree`", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["filtering", "accounts", "search"], "related_skills": ["skill_bookmark_filing.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "scripts/infer_pearltrees_federated.py"], "original_answer": "Use the `--account` flag with `scripts/infer_pearltrees_federated.py` to filter results, or use a specific model file (e.g., `models/pearltrees_federated_s243a.pkl`) that is trained only on that account's data.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_filing_003_q2", "cluster_id": "skill_bookmark_filing_003", "question": "Search s243a folders only", "answer": "To see what's in a Pearltrees folder, first import your data with `python scripts/import_pearltrees_to_db.py --account <name> <rdf_file> --output pearltrees.db`. Then query the database to see folder contents. The import creates trees and pearls tables with parent relationships.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["filtering", "accounts", "search"], "related_skills": ["skill_bookmark_filing.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "scripts/infer_pearltrees_federated.py"], "original_answer": "Use the `--account` flag with `scripts/infer_pearltrees_federated.py` to filter results, or use a specific model file (e.g., `models/pearltrees_federated_s243a.pkl`) that is trained only on that account's data.", "answer_tailored": true, "confidence": 0.8, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_bookmark_filing_003_q3", "cluster_id": "skill_bookmark_filing_003", "question": "Filter folder candidates by account", "answer": "Filter folder candidates by account using the `--account` flag with `scripts/infer_pearltrees_federated.py`. For example: `python3 scripts/infer_pearltrees_federated.py --model models/pearltrees_federated_single.pkl --query \"BOOKMARK_TITLE\" --account s243a_groups --top-k 10 --tree`. Alternatively, use an account-specific model file directly, such as `models/pearltrees_federated_s243a_groups.pkl`, which is pre-trained only on that account's data.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["filtering", "accounts", "search"], "related_skills": ["skill_bookmark_filing.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "scripts/infer_pearltrees_federated.py"], "original_answer": "Use the `--account` flag with `scripts/infer_pearltrees_federated.py` to filter results, or use a specific model file (e.g., `models/pearltrees_federated_s243a.pkl`) that is trained only on that account's data.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_bookmark_filing_004_q0", "cluster_id": "skill_bookmark_filing_004", "question": "How can I make the filing assistant aware of existing bookmarks?", "answer": "Make the filing assistant aware of existing bookmarks by importing Pearltrees data: `python scripts/import_pearltrees_to_db.py --account <name> <rdf_file> --output pearltrees.db`. This creates a database with your trees and pearls that can be queried for context during filing.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["context", "database", "accuracy"], "related_skills": ["skill_bookmark_filing.md"], "related_docs": ["scripts/import_pearltrees_to_db.py", "scripts/bookmark_filing_assistant.py"], "original_answer": "First, import your existing data into a local database using `scripts/import_pearltrees_to_db.py`. Then pass the `--db` flag to the filing assistant. This allows the LLM to see examples of what is already inside the candidate folders.", "answer_tailored": true, "confidence": 0.8, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_bookmark_filing_004_q1", "cluster_id": "skill_bookmark_filing_004", "question": "Can the filer see what's already in the folder?", "answer": "Yes. First, import your existing Pearltrees data into a local database using `scripts/import_pearltrees_to_db.py`. Then pass the `--db` flag to the filing assistant (`scripts/bookmark_filing_assistant.py`). This allows the LLM to see examples of what is already inside the candidate folders when making filing recommendations.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["context", "database", "accuracy"], "related_skills": ["skill_bookmark_filing.md"], "related_docs": ["scripts/import_pearltrees_to_db.py", "scripts/bookmark_filing_assistant.py"], "original_answer": "First, import your existing data into a local database using `scripts/import_pearltrees_to_db.py`. Then pass the `--db` flag to the filing assistant. This allows the LLM to see examples of what is already inside the candidate folders.", "answer_tailored": true, "confidence": 0.72, "confidence_issues": "The base answer assumes a database import workflow exists, but the skill document doesn't mention this script in the commands section. The mechanism for how the filer visualizes folder contents isn't explicitly detailed in the provided documentation."}
{"pair_id": "skill_bookmark_filing_004_q2", "cluster_id": "skill_bookmark_filing_004", "question": "Improve filing accuracy with context", "answer": "Improve filing accuracy by providing context from existing data. Import your Pearltrees with `python scripts/import_pearltrees_to_db.py --account <name> <rdf_file> --output db.db`. The database can then be queried to show the LLM what's already in each folder.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["context", "database", "accuracy"], "related_skills": ["skill_bookmark_filing.md"], "related_docs": ["scripts/import_pearltrees_to_db.py", "scripts/bookmark_filing_assistant.py"], "original_answer": "First, import your existing data into a local database using `scripts/import_pearltrees_to_db.py`. Then pass the `--db` flag to the filing assistant. This allows the LLM to see examples of what is already inside the candidate folders.", "answer_tailored": true, "confidence": 0.8, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_bookmark_filing_004_q3", "cluster_id": "skill_bookmark_filing_004", "question": "Check for duplicates before filing", "answer": "To check for duplicates before filing, first import existing bookmarks with `python scripts/import_pearltrees_to_db.py`. Query the database for matching URLs or titles before adding new bookmarks. The pearls table contains see_also_uri for existing bookmark URLs.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["context", "database", "accuracy"], "related_skills": ["skill_bookmark_filing.md"], "related_docs": ["scripts/import_pearltrees_to_db.py", "scripts/bookmark_filing_assistant.py"], "original_answer": "First, import your existing data into a local database using `scripts/import_pearltrees_to_db.py`. Then pass the `--db` flag to the filing assistant. This allows the LLM to see examples of what is already inside the candidate folders.", "answer_tailored": true, "confidence": 0.75, "confidence_issues": "Duplicate checking requires custom query logic not built into the filing tool", "manually_reviewed": true}
{"pair_id": "skill_bookmark_filing_001_q0", "cluster_id": "skill_bookmark_filing_001", "question": "How do I automatically organize bookmarks into my Pearltrees folders?", "answer": "To automatically organize bookmarks into your Pearltrees folders, use the bookmark filing assistant with semantic search. Run: python3 scripts/bookmark_filing_assistant.py --bookmark \"Your Bookmark Title\" --url \"optional_url\" --provider claude --top-k 10. This uses a federated projection model (93% Recall@1) to find semantically similar folders and can use an LLM to make the final selection. For faster results without LLM assistance, use: python3 scripts/infer_pearltrees_federated.py --model models/pearltrees_federated.pkl --query \"Bookmark Title\" --top-k 10 --tree. The system supports multi-account organization and includes MCP server integration for workflow automation.", "question_type": "medium", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["bookmarks", "semantic-search", "organization", "pearltrees"], "related_skills": ["skill_bookmark_tools.md", "skill_folder_suggestion.md", "skill_semantic_inference.md", "skill_bookmark_filing.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "docs/QUICKSTART_MINDMAP_LINKING.md", "education/book-13-semantic-search/16_bookmark_filing.md"], "original_answer": "Use the bookmark filing assistant with semantic search and optional LLM selection. Run: python3 scripts/bookmark_filing_assistant.py --bookmark \"Your Bookmark Title\" --url \"optional_url\" --provider claude --top-k 10. The system uses a federated projection model (93% Recall@1) to find semantically similar folders, then can use an LLM to make the final selection. For faster results without LLM, use: python3 scripts/infer_pearltrees_federated.py --model models/pearltrees_federated_single.pkl --query \"Bookmark Title\" --top-k 10 --tree. See skill_bookmark_filing.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_filing_001_q1", "cluster_id": "skill_bookmark_filing_001", "question": "What's the best way to file bookmarks into folder hierarchies?", "answer": "The best way to file bookmarks into folder hierarchies is to use the bookmark filing assistant with semantic search. Run: python3 scripts/bookmark_filing_assistant.py --bookmark \"Your Bookmark Title\" --url \"optional_url\" --provider claude --top-k 10. This uses a federated projection model (93% Recall@1) to find semantically similar folders and lets an LLM make the final selection. For faster results without LLM selection, use: python3 scripts/infer_pearltrees_federated.py --model models/pearltrees_federated.pkl --query \"Bookmark Title\" --top-k 10 --tree to see candidates in a tree view. The system supports multi-account filing and integrates with MCP servers for automation.", "question_type": "medium", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["bookmarks", "semantic-search", "organization", "pearltrees"], "related_skills": ["skill_bookmark_tools.md", "skill_folder_suggestion.md", "skill_semantic_inference.md", "skill_bookmark_filing.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "docs/QUICKSTART_MINDMAP_LINKING.md", "education/book-13-semantic-search/16_bookmark_filing.md"], "original_answer": "Use the bookmark filing assistant with semantic search and optional LLM selection. Run: python3 scripts/bookmark_filing_assistant.py --bookmark \"Your Bookmark Title\" --url \"optional_url\" --provider claude --top-k 10. The system uses a federated projection model (93% Recall@1) to find semantically similar folders, then can use an LLM to make the final selection. For faster results without LLM, use: python3 scripts/infer_pearltrees_federated.py --model models/pearltrees_federated_single.pkl --query \"Bookmark Title\" --top-k 10 --tree. See skill_bookmark_filing.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_filing_001_q2", "cluster_id": "skill_bookmark_filing_001", "question": "Can I use semantic search to organize my bookmarks?", "answer": "Yes, you can use semantic search to organize your bookmarks. Use the bookmark filing assistant which employs a federated projection model (93% Recall@1) to find semantically similar folders for your bookmarks. Run: python3 scripts/bookmark_filing_assistant.py --bookmark \"Your Bookmark Title\" --url \"optional_url\" --provider claude --top-k 10. The system identifies semantically related folders and can use an LLM (Claude, Gemini, OpenAI) to make the final selection. For faster results without LLM selection, use: python3 scripts/infer_pearltrees_federated.py --model models/pearltrees_federated.pkl --query \"Bookmark Title\" --top-k 10 --tree to see candidate folders in a tree view. This works across multiple Pearltrees accounts.", "question_type": "medium", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["bookmarks", "semantic-search", "organization", "pearltrees"], "related_skills": ["skill_bookmark_tools.md", "skill_folder_suggestion.md", "skill_semantic_inference.md", "skill_bookmark_filing.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md", "docs/QUICKSTART_MINDMAP_LINKING.md", "education/book-13-semantic-search/16_bookmark_filing.md"], "original_answer": "Use the bookmark filing assistant with semantic search and optional LLM selection. Run: python3 scripts/bookmark_filing_assistant.py --bookmark \"Your Bookmark Title\" --url \"optional_url\" --provider claude --top-k 10. The system uses a federated projection model (93% Recall@1) to find semantically similar folders, then can use an LLM to make the final selection. For faster results without LLM, use: python3 scripts/infer_pearltrees_federated.py --model models/pearltrees_federated_single.pkl --query \"Bookmark Title\" --top-k 10 --tree. See skill_bookmark_filing.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_filing_002_q0", "cluster_id": "skill_bookmark_filing_002", "question": "What LLM providers can I use for bookmark filing recommendations?", "answer": "Five LLM providers are supported for bookmark filing: Claude CLI (--provider claude, cheapest with subscription), Gemini CLI (--provider gemini, headless), OpenAI API (--provider openai, requires OPENAI_API_KEY), Anthropic API (--provider anthropic, requires ANTHROPIC_API_KEY), and Local Ollama (--provider ollama, requires ollama installed). Use the --provider flag with the bookmark_filing_assistant.py script.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["llm-providers", "bookmark-filing", "configuration"], "related_skills": ["skill_bookmark_filing.md"], "related_docs": [], "original_answer": "Five LLM providers are supported: Claude CLI (cheapest with subscription), Gemini CLI (headless), OpenAI API (requires OPENAI_API_KEY), Anthropic API (requires ANTHROPIC_API_KEY), and Local Ollama (requires ollama installed). Use the --provider flag: --provider claude, --provider gemini, --provider openai, --provider anthropic, or --provider ollama. See skill_bookmark_filing.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_bookmark_filing_002_q1", "cluster_id": "skill_bookmark_filing_002", "question": "Which AI services work with bookmark filing?", "answer": "The bookmark filing skill supports five LLM providers for AI-assisted folder selection: Claude CLI (--provider claude), Gemini CLI (--provider gemini), OpenAI API (--provider openai), Anthropic API (--provider anthropic), and Local Ollama (--provider ollama). Use these with the bookmark_filing_assistant.py script: `python3 scripts/bookmark_filing_assistant.py --bookmark \"TITLE\" --provider claude`. Each provider has different requirements (CLI subscriptions vs API keys vs local installation).", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["llm-providers", "bookmark-filing", "configuration"], "related_skills": ["skill_bookmark_filing.md"], "related_docs": [], "original_answer": "Five LLM providers are supported: Claude CLI (cheapest with subscription), Gemini CLI (headless), OpenAI API (requires OPENAI_API_KEY), Anthropic API (requires ANTHROPIC_API_KEY), and Local Ollama (requires ollama installed). Use the --provider flag: --provider claude, --provider gemini, --provider openai, --provider anthropic, or --provider ollama. See skill_bookmark_filing.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_bookmark_filing_002_q2", "cluster_id": "skill_bookmark_filing_002", "question": "Can I use OpenAI or Gemini for filing bookmarks?", "answer": "Yes, both OpenAI and Gemini are supported for filing bookmarks. Use `--provider openai` (requires OPENAI_API_KEY environment variable) or `--provider gemini` (headless mode). Run the bookmark filing assistant with: `python3 scripts/bookmark_filing_assistant.py --bookmark \"TITLE\" --provider openai --top-k 10` or substitute `gemini` for `openai`. Five total providers are available: Claude CLI, Gemini CLI, OpenAI API, Anthropic API, and Local Ollama.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["llm-providers", "bookmark-filing", "configuration"], "related_skills": ["skill_bookmark_filing.md"], "related_docs": [], "original_answer": "Five LLM providers are supported: Claude CLI (cheapest with subscription), Gemini CLI (headless), OpenAI API (requires OPENAI_API_KEY), Anthropic API (requires ANTHROPIC_API_KEY), and Local Ollama (requires ollama installed). Use the --provider flag: --provider claude, --provider gemini, --provider openai, --provider anthropic, or --provider ollama. See skill_bookmark_filing.md for details.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_bookmark_filing_002_q3", "cluster_id": "skill_bookmark_filing_002", "question": "What's the cheapest way to get LLM recommendations?", "answer": "The cheapest way to get LLM recommendations is to use Claude CLI with the --provider claude flag in the bookmark_filing_assistant.py script, which is cheapest with a Claude subscription. If you don't have a subscription, Local Ollama (--provider ollama) is free but requires ollama to be installed locally. Other providers (Gemini CLI, OpenAI API, Anthropic API) require API keys and paid plans.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["llm-providers", "bookmark-filing", "configuration"], "related_skills": ["skill_bookmark_filing.md"], "related_docs": [], "original_answer": "Five LLM providers are supported: Claude CLI (cheapest with subscription), Gemini CLI (headless), OpenAI API (requires OPENAI_API_KEY), Anthropic API (requires ANTHROPIC_API_KEY), and Local Ollama (requires ollama installed). Use the --provider flag: --provider claude, --provider gemini, --provider openai, --provider anthropic, or --provider ollama. See skill_bookmark_filing.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_filing_003_q0", "cluster_id": "skill_bookmark_filing_003", "question": "How do I search for folder candidates when filing a bookmark?", "answer": "To search for folder candidates when filing a bookmark, run: `python3 scripts/infer_pearltrees_federated.py --model models/pearltrees_federated_single.pkl --query \"Your Bookmark Title\" --top-k 10`. Add `--tree` for tree-formatted output or `--json` for JSON format. Starred folders (\u2605) indicate candidate matches with rank and confidence scores. Use the general model for searches across all accounts, or use account-specific models like `pearltrees_federated_s243a.pkl` with the `--account` flag to filter results to a single account.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["semantic-search", "candidates", "inference"], "related_skills": ["skill_semantic_inference.md", "skill_bookmark_filing.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "Run: python3 scripts/infer_pearltrees_federated.py --model models/pearltrees_federated_single.pkl --query \"Your Bookmark Title\" --top-k 10 --tree for tree-formatted output, or add --json for JSON format. Starred folders (\u2605) indicate candidate matches with rank and confidence score. The general model works across all accounts; for single-account searches, use account-specific models like pearltrees_federated_s243a.pkl with the --account flag to filter results. See skill_bookmark_filing.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_filing_003_q1", "cluster_id": "skill_bookmark_filing_003", "question": "Can I see what folders might match my bookmark?", "answer": "Yes, you can see matching folders for your bookmark. Run: python3 scripts/infer_pearltrees_federated.py --model models/pearltrees_federated.pkl --query \"Your Bookmark Title\" --top-k 5. This shows the top matching folders with confidence scores. Use --tree for tree-formatted output or --json for JSON. For account-specific results, use the account model (e.g., pearltrees_federated_s243a.pkl) with the --account flag.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["semantic-search", "candidates", "inference"], "related_skills": ["skill_semantic_inference.md", "skill_bookmark_filing.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "Run: python3 scripts/infer_pearltrees_federated.py --model models/pearltrees_federated_single.pkl --query \"Your Bookmark Title\" --top-k 10 --tree for tree-formatted output, or add --json for JSON format. Starred folders (\u2605) indicate candidate matches with rank and confidence score. The general model works across all accounts; for single-account searches, use account-specific models like pearltrees_federated_s243a.pkl with the --account flag to filter results. See skill_bookmark_filing.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_filing_003_q2", "cluster_id": "skill_bookmark_filing_003", "question": "How do I get semantic search results in tree format?", "answer": "To see what's in a Pearltrees folder, first import your data with `python scripts/import_pearltrees_to_db.py --account <name> <rdf_file> --output pearltrees.db`. Then query the database to see folder contents. The import creates trees and pearls tables with parent relationships.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["semantic-search", "candidates", "inference"], "related_skills": ["skill_semantic_inference.md", "skill_bookmark_filing.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "Run: python3 scripts/infer_pearltrees_federated.py --model models/pearltrees_federated_single.pkl --query \"Your Bookmark Title\" --top-k 10 --tree for tree-formatted output, or add --json for JSON format. Starred folders (\u2605) indicate candidate matches with rank and confidence score. The general model works across all accounts; for single-account searches, use account-specific models like pearltrees_federated_s243a.pkl with the --account flag to filter results. See skill_bookmark_filing.md for details.", "answer_tailored": true, "confidence": 0.8, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_bookmark_filing_004_q0", "cluster_id": "skill_bookmark_filing_004", "question": "Should I use the general model or an account-specific model for filing bookmarks?", "answer": "Make the filing assistant aware of existing bookmarks by importing Pearltrees data: `python scripts/import_pearltrees_to_db.py --account <name> <rdf_file> --output pearltrees.db`. This creates a database with your trees and pearls that can be queried for context during filing.", "question_type": "medium", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["models", "federated-projection", "accounts"], "related_skills": ["skill_semantic_inference.md", "skill_bookmark_filing.md"], "related_docs": ["education/book-13-semantic-search/08_advanced_federation.md"], "original_answer": "Three models are available: pearltrees_federated_single.pkl (51 clusters, all accounts, general search), pearltrees_federated_s243a.pkl (275 clusters, s243a-focused), and pearltrees_federated_s243a_groups.pkl (48 clusters, cross-account migration). Use the general model for broad searches. Use s243a for searches within that account only. Use s243a_groups for migrating/organizing items across multiple accounts. All models achieve 93% Recall@1 and 99% Recall@5 accuracy. See skill_bookmark_filing.md for details.", "answer_tailored": true, "confidence": 0.8, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_bookmark_filing_004_q1", "cluster_id": "skill_bookmark_filing_004", "question": "What's the difference between federated_single and account-specific models?", "answer": "The federated_single model (pearltrees_federated_single.pkl) contains 51 clusters trained across all accounts for general semantic search. Account-specific models like pearltrees_federated_s243a.pkl contain more clusters (275 for s243a) and are optimized for searches within a single account. Use federated_single for broad cross-account searches, and account-specific models when you need higher precision within a particular account. Both achieve 93% Recall@1 and 99% Recall@5 accuracy.", "question_type": "medium", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["models", "federated-projection", "accounts"], "related_skills": ["skill_semantic_inference.md", "skill_bookmark_filing.md"], "related_docs": ["education/book-13-semantic-search/08_advanced_federation.md"], "original_answer": "Three models are available: pearltrees_federated_single.pkl (51 clusters, all accounts, general search), pearltrees_federated_s243a.pkl (275 clusters, s243a-focused), and pearltrees_federated_s243a_groups.pkl (48 clusters, cross-account migration). Use the general model for broad searches. Use s243a for searches within that account only. Use s243a_groups for migrating/organizing items across multiple accounts. All models achieve 93% Recall@1 and 99% Recall@5 accuracy. See skill_bookmark_filing.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_filing_004_q2", "cluster_id": "skill_bookmark_filing_004", "question": "Which model gives better results for my use case?", "answer": "Improve filing accuracy by providing context from existing data. Import your Pearltrees with `python scripts/import_pearltrees_to_db.py --account <name> <rdf_file> --output db.db`. The database can then be queried to show the LLM what's already in each folder.", "question_type": "medium", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["models", "federated-projection", "accounts"], "related_skills": ["skill_semantic_inference.md", "skill_bookmark_filing.md"], "related_docs": ["education/book-13-semantic-search/08_advanced_federation.md"], "original_answer": "Three models are available: pearltrees_federated_single.pkl (51 clusters, all accounts, general search), pearltrees_federated_s243a.pkl (275 clusters, s243a-focused), and pearltrees_federated_s243a_groups.pkl (48 clusters, cross-account migration). Use the general model for broad searches. Use s243a for searches within that account only. Use s243a_groups for migrating/organizing items across multiple accounts. All models achieve 93% Recall@1 and 99% Recall@5 accuracy. See skill_bookmark_filing.md for details.", "answer_tailored": true, "confidence": 0.8, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_bookmark_filing_005_q0", "cluster_id": "skill_bookmark_filing_005", "question": "How can I see what bookmarks already exist in candidate folders?", "answer": "Import your Pearltrees RDF exports using `python3 scripts/import_pearltrees_to_db.py --account s243a data/s243a.rdf --account s243a_groups data/s243a_groups.rdf --output pearltrees.db`. Then run the filing assistant with the database flag: `python3 scripts/bookmark_filing_assistant.py --bookmark \"Your Bookmark\" --db pearltrees.db`. The LLM will display existing bookmarks in each candidate folder (e.g., \"Deep Learning: PyTorch tutorial, Keras getting started\") so you can see what's already filed there before making a selection.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["database", "import", "rdf", "folder-contents"], "related_skills": ["skill_bookmark_filing.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "First import your Pearltrees RDF exports: python3 scripts/import_pearltrees_to_db.py --account s243a data/s243a.rdf --account s243a_groups data/s243a_groups.rdf --output pearltrees.db. Then use the filing assistant with the database: python3 scripts/bookmark_filing_assistant.py --bookmark \"Your Bookmark\" --db pearltrees.db. The LLM will now see existing bookmarks in candidate folders (e.g., \"Deep Learning: PyTorch tutorial, Keras getting started\") and make better recommendations based on folder context. See skill_bookmark_filing.md for details.", "answer_tailored": true, "confidence": 0.75, "confidence_issues": "Base answer assumes database import workflow is the primary way to see bookmarks, but doesn't mention if there are direct query commands or web UI methods to browse existing bookmarks. The answer is correct but may not be complete for users who prefer alternatives to the database-LLM workflow."}
{"pair_id": "skill_bookmark_filing_005_q1", "cluster_id": "skill_bookmark_filing_005", "question": "Can the filing assistant show me existing bookmarks in folders?", "answer": "The filing assistant can show existing bookmarks in folders by first importing your Pearltrees RDF exports using `python3 scripts/import_pearltrees_to_db.py` with your account data and output database file. Then run the filing assistant with the `--db` flag: `python3 scripts/bookmark_filing_assistant.py --bookmark \"Your Bookmark\" --db pearltrees.db`. The LLM will display existing bookmarks found in each candidate folder (e.g., \"Deep Learning: PyTorch tutorial, Keras getting started\") to inform better recommendations based on folder context.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["database", "import", "rdf", "folder-contents"], "related_skills": ["skill_bookmark_filing.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "First import your Pearltrees RDF exports: python3 scripts/import_pearltrees_to_db.py --account s243a data/s243a.rdf --account s243a_groups data/s243a_groups.rdf --output pearltrees.db. Then use the filing assistant with the database: python3 scripts/bookmark_filing_assistant.py --bookmark \"Your Bookmark\" --db pearltrees.db. The LLM will now see existing bookmarks in candidate folders (e.g., \"Deep Learning: PyTorch tutorial, Keras getting started\") and make better recommendations based on folder context. See skill_bookmark_filing.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer references 'skill_bookmark_filing.md' which is not shown in the provided skill document. The exact format and behavior of how existing bookmarks are displayed is inferred from context but not explicitly documented in the skill reference provided."}
{"pair_id": "skill_bookmark_filing_005_q2", "cluster_id": "skill_bookmark_filing_005", "question": "How do I import my Pearltrees data to see folder contents?", "answer": "To import your Pearltrees data and see folder contents, run: python3 scripts/import_pearltrees_to_db.py --account s243a data/s243a.rdf --account s243a_groups data/s243a_groups.rdf --output pearltrees.db. This imports your RDF exports into a database. You can then use the bookmark filing assistant to view folder context: python3 scripts/bookmark_filing_assistant.py --bookmark \"Your Bookmark\" --db pearltrees.db. The system will display existing bookmarks in candidate folders, helping you understand what's already filed in each location.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["database", "import", "rdf", "folder-contents"], "related_skills": ["skill_bookmark_filing.md"], "related_docs": ["docs/design/FEDERATED_MODEL_FORMAT.md"], "original_answer": "First import your Pearltrees RDF exports: python3 scripts/import_pearltrees_to_db.py --account s243a data/s243a.rdf --account s243a_groups data/s243a_groups.rdf --output pearltrees.db. Then use the filing assistant with the database: python3 scripts/bookmark_filing_assistant.py --bookmark \"Your Bookmark\" --db pearltrees.db. The LLM will now see existing bookmarks in candidate folders (e.g., \"Deep Learning: PyTorch tutorial, Keras getting started\") and make better recommendations based on folder context. See skill_bookmark_filing.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer assumes the user has RDF files and knows what account names to use. It doesn't explain how to obtain the RDF exports from Pearltrees or what format they should be in. The answer also doesn't clarify whether running the filing assistant is the only way to view folder contents, or if there are other methods to browse the imported data directly."}
{"pair_id": "skill_bookmark_filing_006_q0", "cluster_id": "skill_bookmark_filing_006", "question": "What filing guidelines should I follow when choosing between similar folders?", "answer": "When choosing between similar folders, follow these four guidelines: (1) Match specificity\u2014file in the most specific matching folder when possible rather than a parent folder, (2) Consider hierarchy\u2014use a parent folder only if the content is truly general or broad, (3) Check for duplicates\u2014similar-named folders often exist at different hierarchy depths, so verify you're choosing the correct level before filing, (4) Account for sharing\u2014remember that group folders (s243a_groups) are shared across accounts and may have different organizational conventions. Use the semantic model's confidence scores to compare folder matches objectively. For detailed filing standards, see skill_bookmark_filing.md.", "question_type": "medium", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["filing-decisions", "hierarchy", "best-practices"], "related_skills": ["skill_folder_suggestion.md", "skill_bookmark_filing.md"], "related_docs": ["education/book-13-semantic-search/05_semantic_playbook.md"], "original_answer": "Follow four guidelines: (1) Match specificity\u2014file in the most specific matching folder when possible, (2) Consider hierarchy\u2014a parent folder may be better for general or broad topics, (3) Check duplicates\u2014similar-named folders often exist at different hierarchy depths so verify you're choosing the right level, (4) Account matters\u2014remember that group folders (s243a_groups) are shared across accounts. The semantic model provides confidence scores to help compare folder matches. See skill_bookmark_filing.md for details.", "answer_tailored": true, "confidence": 0.78, "confidence_issues": "The base answer addresses filing guidelines well, but the skill document itself focuses on folder suggestion via semantic similarity rather than manual filing guidelines. The answer repurposes content from skill_bookmark_filing.md (referenced but not provided), so confidence is moderate rather than high."}
{"pair_id": "skill_bookmark_filing_006_q1", "cluster_id": "skill_bookmark_filing_006", "question": "How do I decide between parent and child folders?", "answer": "When deciding between parent and child folders, use four guidelines: (1) Match specificity\u2014file in the most specific matching folder when possible, (2) Consider hierarchy\u2014a parent folder may be better for general or broad topics, (3) Check duplicates\u2014similar-named folders often exist at different hierarchy depths so verify you're choosing the right level, (4) Account matters\u2014remember that group folders (s243a_groups) are shared across accounts. Use the semantic model's confidence scores to compare matches between parent and child options. When a child folder scores >50% confidence, it's usually the better choice; below 25% suggests the parent may be more appropriate. See skill_bookmark_filing.md for additional filing strategies.", "question_type": "medium", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["filing-decisions", "hierarchy", "best-practices"], "related_skills": ["skill_folder_suggestion.md", "skill_bookmark_filing.md"], "related_docs": ["education/book-13-semantic-search/05_semantic_playbook.md"], "original_answer": "Follow four guidelines: (1) Match specificity\u2014file in the most specific matching folder when possible, (2) Consider hierarchy\u2014a parent folder may be better for general or broad topics, (3) Check duplicates\u2014similar-named folders often exist at different hierarchy depths so verify you're choosing the right level, (4) Account matters\u2014remember that group folders (s243a_groups) are shared across accounts. The semantic model provides confidence scores to help compare folder matches. See skill_bookmark_filing.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_bookmark_filing_006_q2", "cluster_id": "skill_bookmark_filing_006", "question": "Should I file in the most specific folder or a more general one?", "answer": "File in the most specific matching folder when possible. Use the semantic model's confidence scores to guide your decision: >50% confidence indicates a strong match for a specific folder. However, consider the folder hierarchy\u2014a parent folder may be more appropriate for broad or general topics that don't fit well in any specific subfolder. Always check for similarly-named folders at different hierarchy depths to ensure you're choosing the correct specificity level. For shared folders (s243a_groups), verify the folder is account-appropriate before filing.", "question_type": "medium", "topics": ["Semantic-Search", "Bookmark Filing"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["filing-decisions", "hierarchy", "best-practices"], "related_skills": ["skill_folder_suggestion.md", "skill_bookmark_filing.md"], "related_docs": ["education/book-13-semantic-search/05_semantic_playbook.md"], "original_answer": "Follow four guidelines: (1) Match specificity\u2014file in the most specific matching folder when possible, (2) Consider hierarchy\u2014a parent folder may be better for general or broad topics, (3) Check duplicates\u2014similar-named folders often exist at different hierarchy depths so verify you're choosing the right level, (4) Account matters\u2014remember that group folders (s243a_groups) are shared across accounts. The semantic model provides confidence scores to help compare folder matches. See skill_bookmark_filing.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_bookmark_tools_001_q0", "cluster_id": "skill_bookmark_tools_001", "question": "Where should I file this bookmark in my Pearltrees collection?", "answer": "To file a bookmark in your Pearltrees collection, use the semantic bookmark filing system. First, get folder suggestions by running:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --query \"YOUR_BOOKMARK_TITLE\" \\\n  --top-k 10 --tree\n```\n\nThis shows the top 10 semantic matches as a tree view. For LLM-assisted selection that recommends the best folder:\n\n```bash\npython3 scripts/bookmark_filing_assistant.py \\\n  --bookmark \"YOUR_BOOKMARK_TITLE\" \\\n  --url \"https://example.com\" \\\n  --provider claude\n```\n\nThe system uses federated projection models trained on Pearltrees hierarchy data, achieving 93% Recall@1. If you have multiple accounts, filter with `--account s243a_groups` or similar. The tool returns semantic candidates ranked by relevance to help you choose the best folder.", "question_type": "medium", "topics": ["Semantic-Search", "Bookmark Tools (Sub-Master)"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["bookmark-filing", "semantic-search", "organization"], "related_skills": ["skill_bookmark_tools.md", "skill_bookmark_filing.md"], "related_docs": ["scripts/infer_pearltrees_federated.py", "scripts/bookmark_filing_assistant.py"], "original_answer": "Use semantic bookmark filing to get folder suggestions. Run:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --query \"BOOKMARK_TITLE\" \\\n  --top-k 10 --tree\n```\n\nOr use LLM-assisted filing:\n\n```bash\npython3 scripts/bookmark_filing_assistant.py \\\n  --bookmark \"Title\" \\\n  --url \"https://example.com\" \\\n  --provider claude\n```\n\nThe system achieves 93% Recall@1 with federated projection models. See skill_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_tools_001_q1", "cluster_id": "skill_bookmark_tools_001", "question": "How do I organize bookmarks into folders?", "answer": "To organize bookmarks into folders, use semantic bookmark filing with the federated projection model. Run `python3 scripts/infer_pearltrees_federated.py --model models/pearltrees_federated.pkl --query \"BOOKMARK_TITLE\" --top-k 10 --tree` to get folder suggestions as a tree view. For LLM-assisted filing that selects the best folder automatically, use `python3 scripts/bookmark_filing_assistant.py --bookmark \"Title\" --url \"https://example.com\" --provider claude`. The system achieves 93% accuracy in suggesting the correct folder. For organizing entire collections, use MST-based folder grouping with `python3 scripts/mindmap/mst_folder_grouping.py --trees-only --target-size 10 --max-depth 5 -o folder_structure.json`.", "question_type": "medium", "topics": ["Semantic-Search", "Bookmark Tools (Sub-Master)"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["bookmark-filing", "semantic-search", "organization"], "related_skills": ["skill_bookmark_tools.md", "skill_bookmark_filing.md"], "related_docs": ["scripts/infer_pearltrees_federated.py", "scripts/bookmark_filing_assistant.py"], "original_answer": "Use semantic bookmark filing to get folder suggestions. Run:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --query \"BOOKMARK_TITLE\" \\\n  --top-k 10 --tree\n```\n\nOr use LLM-assisted filing:\n\n```bash\npython3 scripts/bookmark_filing_assistant.py \\\n  --bookmark \"Title\" \\\n  --url \"https://example.com\" \\\n  --provider claude\n```\n\nThe system achieves 93% Recall@1 with federated projection models. See skill_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_tools_001_q2", "cluster_id": "skill_bookmark_tools_001", "question": "What folder should this URL go into?", "answer": "To find the right folder for a URL, use semantic bookmark filing with the federated projection model. Run:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --query \"BOOKMARK_TITLE\" \\\n  --top-k 10 --tree\n```\n\nThis shows folder candidates ranked by semantic relevance. For LLM-assisted selection:\n\n```bash\npython3 scripts/bookmark_filing_assistant.py \\\n  --bookmark \"Title\" \\\n  --url \"https://example.com\" \\\n  --provider claude\n```\n\nThe system achieves 93% Recall@1 accuracy. Use the tree view to see the folder hierarchy and choose the best match.", "question_type": "medium", "topics": ["Semantic-Search", "Bookmark Tools (Sub-Master)"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["bookmark-filing", "semantic-search", "organization"], "related_skills": ["skill_bookmark_tools.md", "skill_bookmark_filing.md"], "related_docs": ["scripts/infer_pearltrees_federated.py", "scripts/bookmark_filing_assistant.py"], "original_answer": "Use semantic bookmark filing to get folder suggestions. Run:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --query \"BOOKMARK_TITLE\" \\\n  --top-k 10 --tree\n```\n\nOr use LLM-assisted filing:\n\n```bash\npython3 scripts/bookmark_filing_assistant.py \\\n  --bookmark \"Title\" \\\n  --url \"https://example.com\" \\\n  --provider claude\n```\n\nThe system achieves 93% Recall@1 with federated projection models. See skill_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_tools_001_q3", "cluster_id": "skill_bookmark_tools_001", "question": "Can I get suggestions for where to save a bookmark?", "answer": "Yes, you can get folder suggestions for bookmarks using semantic filing. Run `python3 scripts/infer_pearltrees_federated.py --model models/pearltrees_federated.pkl --query \"YOUR_BOOKMARK_TITLE\" --top-k 10 --tree` to see semantic folder candidates in tree view. Alternatively, use `python3 scripts/bookmark_filing_assistant.py --bookmark \"Title\" --url \"https://example.com\" --provider claude` for LLM-assisted suggestions. The system achieves 93% accuracy with federated projection models trained on Pearltrees hierarchy data.", "question_type": "medium", "topics": ["Semantic-Search", "Bookmark Tools (Sub-Master)"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["bookmark-filing", "semantic-search", "organization"], "related_skills": ["skill_bookmark_tools.md", "skill_bookmark_filing.md"], "related_docs": ["scripts/infer_pearltrees_federated.py", "scripts/bookmark_filing_assistant.py"], "original_answer": "Use semantic bookmark filing to get folder suggestions. Run:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --query \"BOOKMARK_TITLE\" \\\n  --top-k 10 --tree\n```\n\nOr use LLM-assisted filing:\n\n```bash\npython3 scripts/bookmark_filing_assistant.py \\\n  --bookmark \"Title\" \\\n  --url \"https://example.com\" \\\n  --provider claude\n```\n\nThe system achieves 93% Recall@1 with federated projection models. See skill_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_tools_002_q0", "cluster_id": "skill_bookmark_tools_002", "question": "How do I organize a flat collection of items into a folder hierarchy?", "answer": "Use MST-based folder grouping to organize flat collections into a semantic folder hierarchy:\n\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --trees-only \\\n  --target-size 10 \\\n  --max-depth 5 \\\n  -o folder_structure.json\n```\n\nThis command creates a folder hierarchy from your flat collection with folders containing approximately 10 items each and a maximum depth of 5 levels.\n\nFor collections mixing existing Pearltrees folders with new items, use hybrid mode:\n\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --tree-source hybrid \\\n  --embed-blend 0.3 \\\n  --target-size 10 \\\n  -o folder_structure.json\n```\n\nThe output is a JSON file containing the organized folder structure that you can then apply to your Pearltrees account.", "question_type": "medium", "topics": ["Semantic-Search", "Bookmark Tools (Sub-Master)"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["folder-grouping", "hierarchy", "mst-clustering"], "related_skills": ["skill_bookmark_tools.md", "skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/mst_folder_grouping.py", "scripts/mindmap/hierarchy_objective.py"], "original_answer": "Use MST-based folder grouping to organize collections hierarchically:\n\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --trees-only \\\n  --target-size 10 \\\n  --max-depth 5 \\\n  -o folder_structure.json\n```\n\nFor hybrid organization combining curated and new items:\n\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --tree-source hybrid \\\n  --embed-blend 0.3 \\\n  --target-size 10 \\\n  -o folder_structure.json\n```\n\nSee skill_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_tools_002_q1", "cluster_id": "skill_bookmark_tools_002", "question": "Can I automatically group related items into folders?", "answer": "Yes, you can automatically group related items into folders using MST-based folder grouping. Run:\n\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --trees-only \\\n  --target-size 10 \\\n  --max-depth 5 \\\n  -o folder_structure.json\n```\n\nThis organizes items hierarchically based on semantic similarity. For a hybrid approach combining curated folders with new items:\n\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --tree-source hybrid \\\n  --embed-blend 0.3 \\\n  --target-size 10 \\\n  -o folder_structure.json\n```\n\nThe output JSON contains the folder hierarchy structure ready for use.", "question_type": "medium", "topics": ["Semantic-Search", "Bookmark Tools (Sub-Master)"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["folder-grouping", "hierarchy", "mst-clustering"], "related_skills": ["skill_bookmark_tools.md", "skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/mst_folder_grouping.py", "scripts/mindmap/hierarchy_objective.py"], "original_answer": "Use MST-based folder grouping to organize collections hierarchically:\n\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --trees-only \\\n  --target-size 10 \\\n  --max-depth 5 \\\n  -o folder_structure.json\n```\n\nFor hybrid organization combining curated and new items:\n\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --tree-source hybrid \\\n  --embed-blend 0.3 \\\n  --target-size 10 \\\n  -o folder_structure.json\n```\n\nSee skill_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_tools_002_q2", "cluster_id": "skill_bookmark_tools_002", "question": "How do I create a folder structure from a list of bookmarks?", "answer": "Use the MST-based folder grouping tool to organize a list of bookmarks into a folder structure:\n\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --trees-only \\\n  --target-size 10 \\\n  --max-depth 5 \\\n  -o folder_structure.json\n```\n\nThis creates a hierarchical folder structure from your flat bookmark collection. For organizing a mix of existing curated items and new bookmarks, use the hybrid mode:\n\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --tree-source hybrid \\\n  --embed-blend 0.3 \\\n  --target-size 10 \\\n  -o folder_structure.json\n```\n\nThe `--target-size 10` parameter controls folder size, and `--max-depth 5` limits hierarchy depth. Output is saved to the specified JSON file for use in your Pearltrees organization.", "question_type": "medium", "topics": ["Semantic-Search", "Bookmark Tools (Sub-Master)"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["folder-grouping", "hierarchy", "mst-clustering"], "related_skills": ["skill_bookmark_tools.md", "skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/mst_folder_grouping.py", "scripts/mindmap/hierarchy_objective.py"], "original_answer": "Use MST-based folder grouping to organize collections hierarchically:\n\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --trees-only \\\n  --target-size 10 \\\n  --max-depth 5 \\\n  -o folder_structure.json\n```\n\nFor hybrid organization combining curated and new items:\n\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --tree-source hybrid \\\n  --embed-blend 0.3 \\\n  --target-size 10 \\\n  -o folder_structure.json\n```\n\nSee skill_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_tools_002_q3", "cluster_id": "skill_bookmark_tools_002", "question": "What's the best way to build semantic folder groupings?", "answer": "The best way to build semantic folder groupings is to use MST-based folder grouping, which organizes collections hierarchically using minimum spanning tree algorithms. Run: `python3 scripts/mindmap/mst_folder_grouping.py --trees-only --target-size 10 --max-depth 5 -o folder_structure.json`. For hybrid organization that combines curated items with new content, use: `python3 scripts/mindmap/mst_folder_grouping.py --tree-source hybrid --embed-blend 0.3 --target-size 10 -o folder_structure.json`. This approach leverages federated projection models trained on Pearltrees hierarchy data to create semantically coherent folder structures.", "question_type": "medium", "topics": ["Semantic-Search", "Bookmark Tools (Sub-Master)"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["folder-grouping", "hierarchy", "mst-clustering"], "related_skills": ["skill_bookmark_tools.md", "skill_mst_folder_grouping.md"], "related_docs": ["scripts/mindmap/mst_folder_grouping.py", "scripts/mindmap/hierarchy_objective.py"], "original_answer": "Use MST-based folder grouping to organize collections hierarchically:\n\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --trees-only \\\n  --target-size 10 \\\n  --max-depth 5 \\\n  -o folder_structure.json\n```\n\nFor hybrid organization combining curated and new items:\n\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --tree-source hybrid \\\n  --embed-blend 0.3 \\\n  --target-size 10 \\\n  -o folder_structure.json\n```\n\nSee skill_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_tools_003_q0", "cluster_id": "skill_bookmark_tools_003", "question": "How do I suggest the best folder for a single item?", "answer": "Use the folder suggestion tool to find the best placement for a single item:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"\n```\n\nOr suggest by item title:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --title \"ITEM_TITLE\"\n```\n\nThe system uses semantic similarity and Procrustes projection to rank folders by probability of fit. If you need to check a folder for misplacements, use the `--check-folder` flag with a similarity threshold.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Tools (Sub-Master)"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["folder-suggestion", "semantic-similarity", "item-placement"], "related_skills": ["skill_bookmark_tools.md", "skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/suggest_folder.py"], "original_answer": "Use folder suggestion to find the best placement:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"\n```\n\nOr suggest by item title:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --title \"ITEM_TITLE\"\n```\n\nTo check a folder for misplacements:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py \\\n  --check-folder \"FOLDER_PATH\" \\\n  --threshold 0.5\n```\n\nThe system uses semantic similarity and Procrustes projection for probability-based ranking. See skill_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_tools_003_q1", "cluster_id": "skill_bookmark_tools_003", "question": "Can I find where an item best fits in my hierarchy?", "answer": "Yes, use folder suggestion to find where an item best fits in your hierarchy. Run `python3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"` to get semantic placement recommendations, or use `--title \"ITEM_TITLE\"` if you know the item name. The system uses semantic similarity and Procrustes projection to rank folders by probability. To check a specific folder for misplacements, use `--check-folder \"FOLDER_PATH\" --threshold 0.5`. This works across your Pearltrees hierarchy and supports multi-account organization.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Tools (Sub-Master)"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["folder-suggestion", "semantic-similarity", "item-placement"], "related_skills": ["skill_bookmark_tools.md", "skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/suggest_folder.py"], "original_answer": "Use folder suggestion to find the best placement:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"\n```\n\nOr suggest by item title:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --title \"ITEM_TITLE\"\n```\n\nTo check a folder for misplacements:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py \\\n  --check-folder \"FOLDER_PATH\" \\\n  --threshold 0.5\n```\n\nThe system uses semantic similarity and Procrustes projection for probability-based ranking. See skill_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_tools_003_q2", "cluster_id": "skill_bookmark_tools_003", "question": "How do I check if an item is in the right folder?", "answer": "To check if an item is in the right folder, use the folder suggestion tool with the `--check-folder` option:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py \\\n  --check-folder \"FOLDER_PATH\" \\\n  --threshold 0.5\n```\n\nThis scans the folder for items that might be misplaced based on semantic similarity and Procrustes projection. You can also suggest the best folder for a specific item:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"\n```\n\nor by item title:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --title \"ITEM_TITLE\"\n```\n\nThe system ranks suggestions using probability-based semantic matching to identify if items are optimally placed.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Tools (Sub-Master)"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["folder-suggestion", "semantic-similarity", "item-placement"], "related_skills": ["skill_bookmark_tools.md", "skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/suggest_folder.py"], "original_answer": "Use folder suggestion to find the best placement:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"\n```\n\nOr suggest by item title:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --title \"ITEM_TITLE\"\n```\n\nTo check a folder for misplacements:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py \\\n  --check-folder \"FOLDER_PATH\" \\\n  --threshold 0.5\n```\n\nThe system uses semantic similarity and Procrustes projection for probability-based ranking. See skill_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_bookmark_tools_003_q3", "cluster_id": "skill_bookmark_tools_003", "question": "What's the most semantically similar folder for this item?", "answer": "To find the most semantically similar folder for an item, use the folder suggestion tool:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"\n```\n\nOr suggest by item title:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --title \"ITEM_TITLE\"\n```\n\nThe system uses semantic similarity and Procrustes projection to rank folders by probability, returning the best match based on the item's semantic relationship to folder contents.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Tools (Sub-Master)"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["folder-suggestion", "semantic-similarity", "item-placement"], "related_skills": ["skill_bookmark_tools.md", "skill_folder_suggestion.md"], "related_docs": ["scripts/mindmap/suggest_folder.py"], "original_answer": "Use folder suggestion to find the best placement:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --tree-id \"TREE_ID\"\n```\n\nOr suggest by item title:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py --title \"ITEM_TITLE\"\n```\n\nTo check a folder for misplacements:\n\n```bash\npython3 scripts/mindmap/suggest_folder.py \\\n  --check-folder \"FOLDER_PATH\" \\\n  --threshold 0.5\n```\n\nThe system uses semantic similarity and Procrustes projection for probability-based ranking. See skill_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_tools_004_q0", "cluster_id": "skill_bookmark_tools_004", "question": "How do I file multiple bookmarks in batch?", "answer": "To file multiple bookmarks in batch, use the semantic search tool with batch input:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --input bookmarks.txt \\\n  --output suggestions.jsonl\n```\n\nEach line in `bookmarks.txt` should contain one bookmark title. The tool outputs semantic folder candidates for each bookmark in `suggestions.jsonl`.\n\nTo filter by account (s243a or s243a_groups):\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --input bookmarks.txt \\\n  --account s243a_groups \\\n  --output suggestions.jsonl\n```\n\nFor LLM-assisted selection across multiple bookmarks, see the bookmark_filing_assistant script with batch processing options.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Tools (Sub-Master)"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["batch-processing", "semantic-search", "automation"], "related_skills": ["skill_bookmark_tools.md", "skill_bookmark_filing.md"], "related_docs": ["scripts/infer_pearltrees_federated.py"], "original_answer": "Use batch filing with the semantic search tool:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --input bookmarks.txt \\\n  --output suggestions.jsonl\n```\n\nYou can also filter by account (s243a or s243a_groups):\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --input bookmarks.txt \\\n  --account s243a_groups \\\n  --output suggestions.jsonl\n```\n\nThis returns semantic candidates for each bookmark with tree view formatting. See skill_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "Base answer assumes --input flag supports batch file reading, but this wasn't explicitly confirmed in the skill document excerpt. Batch format (one bookmark per line vs. JSON) is inferred but not specified. LLM batch processing method is mentioned but not detailed."}
{"pair_id": "skill_bookmark_tools_004_q1", "cluster_id": "skill_bookmark_tools_004", "question": "Can I process multiple bookmarks at once?", "answer": "Yes, you can process multiple bookmarks at once using batch filing with the semantic search tool. Use the `--input` flag to specify a file containing your bookmarks:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --input bookmarks.txt \\\n  --output suggestions.jsonl\n```\n\nThis generates semantic folder candidates for each bookmark in JSONL format. You can also filter results by account (s243a or s243a_groups) using the `--account` flag:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --input bookmarks.txt \\\n  --account s243a_groups \\\n  --output suggestions.jsonl\n```", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Tools (Sub-Master)"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["batch-processing", "semantic-search", "automation"], "related_skills": ["skill_bookmark_tools.md", "skill_bookmark_filing.md"], "related_docs": ["scripts/infer_pearltrees_federated.py"], "original_answer": "Use batch filing with the semantic search tool:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --input bookmarks.txt \\\n  --output suggestions.jsonl\n```\n\nYou can also filter by account (s243a or s243a_groups):\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --input bookmarks.txt \\\n  --account s243a_groups \\\n  --output suggestions.jsonl\n```\n\nThis returns semantic candidates for each bookmark with tree view formatting. See skill_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_bookmark_tools_004_q2", "cluster_id": "skill_bookmark_tools_004", "question": "How do I get filing suggestions for a list of URLs?", "answer": "Use the semantic search tool with batch input to get filing suggestions for multiple URLs:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --input bookmarks.txt \\\n  --output suggestions.jsonl\n```\n\nYour input file should contain one bookmark title or URL per line. The tool outputs semantic candidates for each item in JSONL format.\n\nTo filter suggestions by account (s243a or s243a_groups):\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --input bookmarks.txt \\\n  --account s243a_groups \\\n  --output suggestions.jsonl\n```\n\nFor tree-view formatting of results, add the `--tree` flag. See skill_bookmark_filing.md for additional options.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Tools (Sub-Master)"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["batch-processing", "semantic-search", "automation"], "related_skills": ["skill_bookmark_tools.md", "skill_bookmark_filing.md"], "related_docs": ["scripts/infer_pearltrees_federated.py"], "original_answer": "Use batch filing with the semantic search tool:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --input bookmarks.txt \\\n  --output suggestions.jsonl\n```\n\nYou can also filter by account (s243a or s243a_groups):\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --input bookmarks.txt \\\n  --account s243a_groups \\\n  --output suggestions.jsonl\n```\n\nThis returns semantic candidates for each bookmark with tree view formatting. See skill_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_tools_004_q3", "cluster_id": "skill_bookmark_tools_004", "question": "What's the fastest way to organize several bookmarks?", "answer": "Use batch filing with the semantic search tool for the fastest organization of multiple bookmarks:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --input bookmarks.txt \\\n  --output suggestions.jsonl\n```\n\nThis processes all bookmarks at once and returns semantic folder candidates. You can filter by account if needed:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --input bookmarks.txt \\\n  --account s243a_groups \\\n  --output suggestions.jsonl\n```\n\nFor even faster organization of larger collections, consider using MST-based folder grouping to automatically build hierarchies from flat bookmark lists.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Tools (Sub-Master)"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["batch-processing", "semantic-search", "automation"], "related_skills": ["skill_bookmark_tools.md", "skill_bookmark_filing.md"], "related_docs": ["scripts/infer_pearltrees_federated.py"], "original_answer": "Use batch filing with the semantic search tool:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --input bookmarks.txt \\\n  --output suggestions.jsonl\n```\n\nYou can also filter by account (s243a or s243a_groups):\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --input bookmarks.txt \\\n  --account s243a_groups \\\n  --output suggestions.jsonl\n```\n\nThis returns semantic candidates for each bookmark with tree view formatting. See skill_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer assumes the --input flag supports file input for batch processing, but this wasn't explicitly verified in the skill documentation provided. The confidence is slightly reduced due to this assumption."}
{"pair_id": "skill_bookmark_tools_005_q0", "cluster_id": "skill_bookmark_tools_005", "question": "What accounts and models are available for bookmark organization?", "answer": "Three federated projection models are available for bookmark organization:\n\n1. `pearltrees_federated_single.pkl` - Supports all accounts with 51 clusters for general semantic search\n2. `pearltrees_federated_s243a.pkl` - Single-account model for s243a with 275 clusters for focused organization\n3. `pearltrees_federated_s243a_groups.pkl` - Single-account model for s243a_groups with 48 clusters for cross-account organization\n\nAll models achieve 93% Recall@1 using federated projection trained on Pearltrees hierarchy data. Specify the model and account when running bookmark filing commands:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --account s243a_groups\n```\n\nChoose the model based on your account (s243a, s243a_groups, or all) and organizational needs.", "question_type": "medium", "topics": ["Semantic-Search", "Bookmark Tools (Sub-Master)"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["models", "accounts", "semantic-projection"], "related_skills": ["skill_bookmark_tools.md", "skill_ml_tools.md", "skill_train_model.md"], "related_docs": [], "original_answer": "Three models are available:\n\n- `pearltrees_federated_single.pkl` - All accounts, 51 clusters, general search\n- `pearltrees_federated_s243a.pkl` - s243a account, 275 clusters, focused organization\n- `pearltrees_federated_s243a_groups.pkl` - s243a_groups account, 48 clusters, cross-account\n\nModels achieve 93% Recall@1 using federated projection trained on Pearltrees hierarchy data. Specify model and account in commands:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --account s243a_groups\n```\n\nModels are trained via skill_train_model.md. See skill_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_tools_005_q1", "cluster_id": "skill_bookmark_tools_005", "question": "Which semantic models should I use?", "answer": "Use `pearltrees_federated_single.pkl` for general bookmark filing across all accounts with 51 clusters. Use `pearltrees_federated_s243a.pkl` for the s243a account specifically with 275 clusters for more granular organization. Use `pearltrees_federated_s243a_groups.pkl` for cross-account s243a_groups work with 48 clusters. All models achieve 93% Recall@1 using federated projection. Specify your choice via the `--model` and `--account` flags when running inference scripts.", "question_type": "medium", "topics": ["Semantic-Search", "Bookmark Tools (Sub-Master)"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["models", "accounts", "semantic-projection"], "related_skills": ["skill_bookmark_tools.md", "skill_ml_tools.md", "skill_train_model.md"], "related_docs": [], "original_answer": "Three models are available:\n\n- `pearltrees_federated_single.pkl` - All accounts, 51 clusters, general search\n- `pearltrees_federated_s243a.pkl` - s243a account, 275 clusters, focused organization\n- `pearltrees_federated_s243a_groups.pkl` - s243a_groups account, 48 clusters, cross-account\n\nModels achieve 93% Recall@1 using federated projection trained on Pearltrees hierarchy data. Specify model and account in commands:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --account s243a_groups\n```\n\nModels are trained via skill_train_model.md. See skill_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_tools_005_q2", "cluster_id": "skill_bookmark_tools_005", "question": "How many clusters do different models support?", "answer": "Three federated projection models support different cluster counts: pearltrees_federated_single.pkl supports 51 clusters across all accounts, pearltrees_federated_s243a.pkl supports 275 clusters for the s243a account, and pearltrees_federated_s243a_groups.pkl supports 48 clusters for the s243a_groups account. All models achieve 93% Recall@1 using federated projection trained on Pearltrees hierarchy data.", "question_type": "medium", "topics": ["Semantic-Search", "Bookmark Tools (Sub-Master)"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["models", "accounts", "semantic-projection"], "related_skills": ["skill_bookmark_tools.md", "skill_ml_tools.md", "skill_train_model.md"], "related_docs": [], "original_answer": "Three models are available:\n\n- `pearltrees_federated_single.pkl` - All accounts, 51 clusters, general search\n- `pearltrees_federated_s243a.pkl` - s243a account, 275 clusters, focused organization\n- `pearltrees_federated_s243a_groups.pkl` - s243a_groups account, 48 clusters, cross-account\n\nModels achieve 93% Recall@1 using federated projection trained on Pearltrees hierarchy data. Specify model and account in commands:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --account s243a_groups\n```\n\nModels are trained via skill_train_model.md. See skill_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_tools_005_q3", "cluster_id": "skill_bookmark_tools_005", "question": "What's the difference between account-specific and general models?", "answer": "Three federated projection models serve different organizational scopes:\n\n1. **pearltrees_federated_single.pkl** - General model across all accounts with 51 clusters, best for broad cross-account searches\n2. **pearltrees_federated_s243a.pkl** - Account-specific model for s243a with 275 clusters, provides finer-grained organization for a single account\n3. **pearltrees_federated_s243a_groups.pkl** - Account-specific model for s243a_groups with 48 clusters, optimized for cross-account sharing scenarios\n\nAccount-specific models use more clusters and are trained exclusively on that account's hierarchy, enabling more precise semantic matching within that account's organizational patterns. General models sacrifice granularity for broader applicability. All achieve 93% Recall@1. Specify the model and account when running inference commands.", "question_type": "medium", "topics": ["Semantic-Search", "Bookmark Tools (Sub-Master)"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["models", "accounts", "semantic-projection"], "related_skills": ["skill_bookmark_tools.md", "skill_ml_tools.md", "skill_train_model.md"], "related_docs": [], "original_answer": "Three models are available:\n\n- `pearltrees_federated_single.pkl` - All accounts, 51 clusters, general search\n- `pearltrees_federated_s243a.pkl` - s243a account, 275 clusters, focused organization\n- `pearltrees_federated_s243a_groups.pkl` - s243a_groups account, 48 clusters, cross-account\n\nModels achieve 93% Recall@1 using federated projection trained on Pearltrees hierarchy data. Specify model and account in commands:\n\n```bash\npython3 scripts/infer_pearltrees_federated.py \\\n  --model models/pearltrees_federated.pkl \\\n  --account s243a_groups\n```\n\nModels are trained via skill_train_model.md. See skill_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_tools_006_q0", "cluster_id": "skill_bookmark_tools_006", "question": "How do I organize a new collection from start to finish?", "answer": "To organize a new collection from start to finish, follow this three-step workflow:\n\n1. Generate embeddings for your items:\n```bash\npython3 scripts/generate_embeddings.py \\\n  --input items.jsonl \\\n  --output embeddings.npz\n```\n\n2. Build an optimal folder structure using MST-based grouping:\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --embeddings embeddings.npz \\\n  --target-size 10 \\\n  -o folder_structure.json\n```\nThe `target-size` parameter controls the average items per folder. Adjust it based on your collection size and organization preferences.\n\n3. Evaluate the quality of your folder hierarchy:\n```bash\npython3 scripts/mindmap/hierarchy_objective.py \\\n  --tree folder_structure.json \\\n  --embeddings embeddings.npz\n```\n\nUse the evaluation results to fine-tune `target-size` and `max-depth` parameters until your organization meets your needs. Iterate steps 2-3 as needed.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Tools (Sub-Master)"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["workflow", "embeddings", "hierarchy-evaluation"], "related_skills": ["skill_bookmark_tools.md", "skill_mst_folder_grouping.md", "skill_hierarchy_objective.md"], "related_docs": ["scripts/mindmap/mst_folder_grouping.py", "scripts/mindmap/hierarchy_objective.py"], "original_answer": "Use this three-step workflow:\n\n1. Generate embeddings:\n```bash\npython3 scripts/generate_embeddings.py \\\n  --input items.jsonl \\\n  --output embeddings.npz\n```\n\n2. Build folder structure:\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --embeddings embeddings.npz \\\n  --target-size 10 \\\n  -o folder_structure.json\n```\n\n3. Evaluate quality:\n```bash\npython3 scripts/mindmap/hierarchy_objective.py \\\n  --tree folder_structure.json \\\n  --embeddings embeddings.npz\n```\n\nAdjust `target-size` and `max-depth` parameters to optimize organization. See skill_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_tools_006_q1", "cluster_id": "skill_bookmark_tools_006", "question": "What's the workflow for processing a new collection?", "answer": "To process a new collection, follow this three-step workflow:\n\n1. Generate embeddings from your items:\n```bash\npython3 scripts/generate_embeddings.py \\\n  --input items.jsonl \\\n  --output embeddings.npz\n```\n\n2. Build a folder structure using Minimum Spanning Tree organization:\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --embeddings embeddings.npz \\\n  --target-size 10 \\\n  -o folder_structure.json\n```\n\n3. Evaluate the organization quality:\n```bash\npython3 scripts/mindmap/hierarchy_objective.py \\\n  --tree folder_structure.json \\\n  --embeddings embeddings.npz\n```\n\nTune the `target-size` (folder size target) and `max-depth` (hierarchy depth limit) parameters to optimize how your collection is organized. Start with target-size=10 and adjust based on evaluation results.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Tools (Sub-Master)"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["workflow", "embeddings", "hierarchy-evaluation"], "related_skills": ["skill_bookmark_tools.md", "skill_mst_folder_grouping.md", "skill_hierarchy_objective.md"], "related_docs": ["scripts/mindmap/mst_folder_grouping.py", "scripts/mindmap/hierarchy_objective.py"], "original_answer": "Use this three-step workflow:\n\n1. Generate embeddings:\n```bash\npython3 scripts/generate_embeddings.py \\\n  --input items.jsonl \\\n  --output embeddings.npz\n```\n\n2. Build folder structure:\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --embeddings embeddings.npz \\\n  --target-size 10 \\\n  -o folder_structure.json\n```\n\n3. Evaluate quality:\n```bash\npython3 scripts/mindmap/hierarchy_objective.py \\\n  --tree folder_structure.json \\\n  --embeddings embeddings.npz\n```\n\nAdjust `target-size` and `max-depth` parameters to optimize organization. See skill_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_tools_006_q2", "cluster_id": "skill_bookmark_tools_006", "question": "How do I evaluate if my folder structure is good?", "answer": "To evaluate if your folder structure is good, use this three-step workflow:\n\n1. Generate embeddings for your items:\n```bash\npython3 scripts/generate_embeddings.py \\\n  --input items.jsonl \\\n  --output embeddings.npz\n```\n\n2. Build a folder structure using semantic clustering:\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --embeddings embeddings.npz \\\n  --target-size 10 \\\n  -o folder_structure.json\n```\n\n3. Evaluate the quality of your structure:\n```bash\npython3 scripts/mindmap/hierarchy_objective.py \\\n  --tree folder_structure.json \\\n  --embeddings embeddings.npz\n```\n\nThe evaluation script will measure how well your folders semantically group related items. Adjust the `target-size` parameter (controls average folder size) and `max-depth` parameter (controls hierarchy depth) to optimize for better organization quality.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Tools (Sub-Master)"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["workflow", "embeddings", "hierarchy-evaluation"], "related_skills": ["skill_bookmark_tools.md", "skill_mst_folder_grouping.md", "skill_hierarchy_objective.md"], "related_docs": ["scripts/mindmap/mst_folder_grouping.py", "scripts/mindmap/hierarchy_objective.py"], "original_answer": "Use this three-step workflow:\n\n1. Generate embeddings:\n```bash\npython3 scripts/generate_embeddings.py \\\n  --input items.jsonl \\\n  --output embeddings.npz\n```\n\n2. Build folder structure:\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --embeddings embeddings.npz \\\n  --target-size 10 \\\n  -o folder_structure.json\n```\n\n3. Evaluate quality:\n```bash\npython3 scripts/mindmap/hierarchy_objective.py \\\n  --tree folder_structure.json \\\n  --embeddings embeddings.npz\n```\n\nAdjust `target-size` and `max-depth` parameters to optimize organization. See skill_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_bookmark_tools_006_q3", "cluster_id": "skill_bookmark_tools_006", "question": "Can I generate embeddings and build hierarchies automatically?", "answer": "Yes, you can generate embeddings and build hierarchies automatically using a three-step workflow:\n\n1. Generate embeddings from your items:\n```bash\npython3 scripts/generate_embeddings.py \\\n  --input items.jsonl \\\n  --output embeddings.npz\n```\n\n2. Build the folder structure using MST-based organization:\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --embeddings embeddings.npz \\\n  --target-size 10 \\\n  -o folder_structure.json\n```\n\n3. Evaluate the quality of your hierarchy:\n```bash\npython3 scripts/mindmap/hierarchy_objective.py \\\n  --tree folder_structure.json \\\n  --embeddings embeddings.npz\n```\n\nYou can tune the organization by adjusting the `target-size` parameter (controls folder sizes) and `max-depth` parameter (controls hierarchy depth) to match your needs.", "question_type": "long", "topics": ["Semantic-Search", "Bookmark Tools (Sub-Master)"], "source_file": "by-topic/semantic-search/skills-generated.jsonl", "tags": ["workflow", "embeddings", "hierarchy-evaluation"], "related_skills": ["skill_bookmark_tools.md", "skill_mst_folder_grouping.md", "skill_hierarchy_objective.md"], "related_docs": ["scripts/mindmap/mst_folder_grouping.py", "scripts/mindmap/hierarchy_objective.py"], "original_answer": "Use this three-step workflow:\n\n1. Generate embeddings:\n```bash\npython3 scripts/generate_embeddings.py \\\n  --input items.jsonl \\\n  --output embeddings.npz\n```\n\n2. Build folder structure:\n```bash\npython3 scripts/mindmap/mst_folder_grouping.py \\\n  --embeddings embeddings.npz \\\n  --target-size 10 \\\n  -o folder_structure.json\n```\n\n3. Evaluate quality:\n```bash\npython3 scripts/mindmap/hierarchy_objective.py \\\n  --tree folder_structure.json \\\n  --embeddings embeddings.npz\n```\n\nAdjust `target-size` and `max-depth` parameters to optimize organization. See skill_bookmark_tools.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_synthetic_data_001_q0", "cluster_id": "skill_synthetic_data_001", "question": "How do I generate Q&A training pairs from my documentation?", "answer": "Use the Q&A generation tool to automatically create training pairs from your skill documents:\n\n```bash\npython training-data/scripts/generate_qa_from_skills.py --skill skill_mindmap_linking.md --model haiku\n```\n\nOr generate from all skills at once:\n\n```bash\npython training-data/scripts/generate_qa_from_skills.py --all --provider gemini\n```\n\nThe tool outputs JSONL format with questions, answers, related skills, and tags. You can then review and edit the generated pairs. Supports Claude and Gemini providers with various model options.", "question_type": "medium", "topics": ["Quickstart", "Synthetic Data"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["training data", "Q&A generation", "documentation", "LLM"], "related_skills": ["skill_synthetic_data.md", "skill_qa_generation.md"], "related_docs": ["training-data/scripts/generate_qa_from_skills.py", "training-data/scripts/generate_quickstart_qa.py"], "original_answer": "Use the Q&A generation tool to automatically create training pairs from your skill documents:\n\n```bash\npython training-data/scripts/generate_qa_from_skills.py --skill skill_mindmap_linking.md --model haiku\n```\n\nOr generate from all skills at once:\n\n```bash\npython training-data/scripts/generate_qa_from_skills.py --all --provider gemini\n```\n\nThe tool outputs JSONL format with questions, answers, related skills, and tags. You can then review and edit the generated pairs. See skill_synthetic_data.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_synthetic_data_001_q1", "cluster_id": "skill_synthetic_data_001", "question": "How can I create Q&A pairs from skills or docs?", "answer": "Use the Q&A generation tool to automatically create training pairs from your skill documents. Run `python training-data/scripts/generate_qa_from_skills.py --skill skill_mindmap_linking.md --model haiku` to generate Q&A from a single skill, or `python training-data/scripts/generate_qa_from_skills.py --all --provider gemini` to generate from all skills at once. The tool outputs JSONL format containing questions, answers, related skills, and tags that you can review and edit. For more details, see skill_synthetic_data.md.", "question_type": "medium", "topics": ["Quickstart", "Synthetic Data"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["training data", "Q&A generation", "documentation", "LLM"], "related_skills": ["skill_synthetic_data.md", "skill_qa_generation.md"], "related_docs": ["training-data/scripts/generate_qa_from_skills.py", "training-data/scripts/generate_quickstart_qa.py"], "original_answer": "Use the Q&A generation tool to automatically create training pairs from your skill documents:\n\n```bash\npython training-data/scripts/generate_qa_from_skills.py --skill skill_mindmap_linking.md --model haiku\n```\n\nOr generate from all skills at once:\n\n```bash\npython training-data/scripts/generate_qa_from_skills.py --all --provider gemini\n```\n\nThe tool outputs JSONL format with questions, answers, related skills, and tags. You can then review and edit the generated pairs. See skill_synthetic_data.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_synthetic_data_001_q2", "cluster_id": "skill_synthetic_data_001", "question": "How do I turn documentation into training data?", "answer": "To turn documentation into training data, use the Q&A generation tool to automatically create question-answer pairs from your skill documents. Run `python training-data/scripts/generate_qa_from_skills.py --skill skill_mindmap_linking.md --model haiku` to generate from a single skill, or `python training-data/scripts/generate_qa_from_skills.py --all --provider gemini` to generate from all skills at once. The tool outputs JSONL format containing questions, answers, related skills, and tags that you can review and edit. For answer rewriting and expansion, use `python scripts/generate_tailored_answers.py --input training-data/expanded --model sonnet`. For Pearltrees RDF data, use `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --output reports/pearltrees_targets.jsonl`. See skill_synthetic_data.md for the full pipeline details and additional options.", "question_type": "medium", "topics": ["Quickstart", "Synthetic Data"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["training data", "Q&A generation", "documentation", "LLM"], "related_skills": ["skill_synthetic_data.md", "skill_qa_generation.md"], "related_docs": ["training-data/scripts/generate_qa_from_skills.py", "training-data/scripts/generate_quickstart_qa.py"], "original_answer": "Use the Q&A generation tool to automatically create training pairs from your skill documents:\n\n```bash\npython training-data/scripts/generate_qa_from_skills.py --skill skill_mindmap_linking.md --model haiku\n```\n\nOr generate from all skills at once:\n\n```bash\npython training-data/scripts/generate_qa_from_skills.py --all --provider gemini\n```\n\nThe tool outputs JSONL format with questions, answers, related skills, and tags. You can then review and edit the generated pairs. See skill_synthetic_data.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_synthetic_data_002_q0", "cluster_id": "skill_synthetic_data_002", "question": "How do I expand and reword training answers with an LLM?", "answer": "Use the answer tailoring tool to generate reworded versions of existing answers with an LLM. Run `python scripts/generate_tailored_answers.py --input training-data/expanded --model sonnet` to reword answers from all files in that directory, or `python scripts/generate_tailored_answers.py --file training-data/expanded/mindmap/pairs.jsonl --batch-size 5` to tailor answers from a specific file. You can choose from Claude models (sonnet, opus, haiku) or Gemini models. This expands your training dataset by creating natural answer variations without changing the core information.", "question_type": "medium", "topics": ["Quickstart", "Synthetic Data"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["training data", "answer expansion", "LLM", "augmentation"], "related_skills": ["skill_synthetic_data.md", "skill_answer_tailoring.md"], "related_docs": ["scripts/generate_tailored_answers.py"], "original_answer": "Use the answer tailoring tool to generate reworded versions of existing answers:\n\n```bash\npython scripts/generate_tailored_answers.py --input training-data/expanded --model sonnet\n```\n\nOr tailor answers from a specific file:\n\n```bash\npython scripts/generate_tailored_answers.py --file training-data/expanded/mindmap/pairs.jsonl --batch-size 5\n```\n\nYou can use Claude (sonnet, opus, haiku) or Gemini models. This expands your training dataset with natural answer variations. See skill_synthetic_data.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_synthetic_data_002_q1", "cluster_id": "skill_synthetic_data_002", "question": "How can I create variations of my answers?", "answer": "Use the answer tailoring tool to generate reworded versions of existing answers. Run `python scripts/generate_tailored_answers.py --input training-data/expanded --model sonnet` to tailor answers from all files, or specify a single file with `--file training-data/expanded/mindmap/pairs.jsonl --batch-size 5`. You can choose between Claude models (sonnet, opus, haiku) or Gemini models to create natural variations that expand your training dataset.", "question_type": "medium", "topics": ["Quickstart", "Synthetic Data"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["training data", "answer expansion", "LLM", "augmentation"], "related_skills": ["skill_synthetic_data.md", "skill_answer_tailoring.md"], "related_docs": ["scripts/generate_tailored_answers.py"], "original_answer": "Use the answer tailoring tool to generate reworded versions of existing answers:\n\n```bash\npython scripts/generate_tailored_answers.py --input training-data/expanded --model sonnet\n```\n\nOr tailor answers from a specific file:\n\n```bash\npython scripts/generate_tailored_answers.py --file training-data/expanded/mindmap/pairs.jsonl --batch-size 5\n```\n\nYou can use Claude (sonnet, opus, haiku) or Gemini models. This expands your training dataset with natural answer variations. See skill_synthetic_data.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_synthetic_data_002_q2", "cluster_id": "skill_synthetic_data_002", "question": "How do I tailor answers for training data?", "answer": "To tailor answers for training data, use the answer tailoring tool to generate reworded versions of existing answers. Run `python scripts/generate_tailored_answers.py --input training-data/expanded --model sonnet` to process all answers in a directory, or use `--file training-data/expanded/mindmap/pairs.jsonl` to tailor answers from a specific file. You can also set `--batch-size` to control processing. The tool supports Claude models (sonnet, opus, haiku) and Gemini models. This creates natural answer variations that expand your training dataset without manually rewriting each response.", "question_type": "medium", "topics": ["Quickstart", "Synthetic Data"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["training data", "answer expansion", "LLM", "augmentation"], "related_skills": ["skill_synthetic_data.md", "skill_answer_tailoring.md"], "related_docs": ["scripts/generate_tailored_answers.py"], "original_answer": "Use the answer tailoring tool to generate reworded versions of existing answers:\n\n```bash\npython scripts/generate_tailored_answers.py --input training-data/expanded --model sonnet\n```\n\nOr tailor answers from a specific file:\n\n```bash\npython scripts/generate_tailored_answers.py --file training-data/expanded/mindmap/pairs.jsonl --batch-size 5\n```\n\nYou can use Claude (sonnet, opus, haiku) or Gemini models. This expands your training dataset with natural answer variations. See skill_synthetic_data.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_synthetic_data_003_q0", "cluster_id": "skill_synthetic_data_003", "question": "What's the workflow for bootstrapping training data from a new feature?", "answer": "To bootstrap training data from a new feature, follow this pipeline: (1) Create a skill document describing the feature in skills/skill_new_feature.md, (2) Generate Q&A pairs from the skill document using `python training-data/scripts/generate_qa_from_skills.py --skill skills/skill_new_feature.md --model haiku`, (3) Review and manually edit the generated pairs in training-data/by-topic/, (4) Expand question clusters into individual Q&A pairs using `expand_clusters_to_pairs.py`, (5) Generate reworded answers using `python scripts/generate_tailored_answers.py --input training-data/by-topic/ --model sonnet`. Both Claude and Gemini models are supported. The final output is JSONL format ready for training your semantic search system.", "question_type": "medium", "topics": ["Quickstart", "Synthetic Data"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["training data", "workflow", "bootstrap", "feature"], "related_skills": ["skill_synthetic_data.md", "skill_qa_generation.md"], "related_docs": ["scripts/expand_clusters_to_pairs.py"], "original_answer": "Follow this pipeline: (1) Create a skill document (skills/skill_new_feature.md), (2) Generate Q&A pairs using `generate_qa_from_skills.py`, (3) Review and edit the generated pairs in training-data/by-topic/, (4) Expand clusters to individual pairs with `expand_clusters_to_pairs.py`, (5) Generate tailored answers using `generate_tailored_answers.py`. All tools support Claude and Gemini models. The output is JSONL format ready for training. See skill_synthetic_data.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_synthetic_data_003_q1", "cluster_id": "skill_synthetic_data_003", "question": "How do I create training data for a new capability?", "answer": "To create training data for a new capability: (1) Write a skill document (skills/skill_your_feature.md) that explains the capability, (2) Run `generate_qa_from_skills.py --skill skills/skill_your_feature.md --model haiku` to auto-generate Q&A pairs, (3) Review and refine the generated pairs in training-data/by-topic/, (4) Use `expand_clusters_to_pairs.py` to convert grouped Q&A into individual training examples, (5) Run `generate_tailored_answers.py --input training-data/expanded --model haiku` to generate variant answer wordings. All scripts support Claude (haiku/sonnet/opus) and Gemini models. Output is JSONL format ready for use in semantic search training.", "question_type": "medium", "topics": ["Quickstart", "Synthetic Data"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["training data", "workflow", "bootstrap", "feature"], "related_skills": ["skill_synthetic_data.md", "skill_qa_generation.md"], "related_docs": ["scripts/expand_clusters_to_pairs.py"], "original_answer": "Follow this pipeline: (1) Create a skill document (skills/skill_new_feature.md), (2) Generate Q&A pairs using `generate_qa_from_skills.py`, (3) Review and edit the generated pairs in training-data/by-topic/, (4) Expand clusters to individual pairs with `expand_clusters_to_pairs.py`, (5) Generate tailored answers using `generate_tailored_answers.py`. All tools support Claude and Gemini models. The output is JSONL format ready for training. See skill_synthetic_data.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_synthetic_data_003_q2", "cluster_id": "skill_synthetic_data_003", "question": "How do I set up training data from scratch?", "answer": "To set up training data from scratch: (1) Create a skill document in skills/skill_new_feature.md describing your feature, (2) Run `python training-data/scripts/generate_qa_from_skills.py --skill skills/skill_new_feature.md --model haiku` to generate Q&A pairs, (3) Review and edit generated pairs in training-data/by-topic/, (4) Use `python scripts/expand_clusters_to_pairs.py` to convert clusters into individual Q&A pairs, (5) Run `python scripts/generate_tailored_answers.py --input training-data/expanded --model haiku` to generate variant answers. All tools support Claude (haiku, sonnet, opus) and Gemini models via `--provider` flag. Output is JSONL format ready for training.", "question_type": "medium", "topics": ["Quickstart", "Synthetic Data"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["training data", "workflow", "bootstrap", "feature"], "related_skills": ["skill_synthetic_data.md", "skill_qa_generation.md"], "related_docs": ["scripts/expand_clusters_to_pairs.py"], "original_answer": "Follow this pipeline: (1) Create a skill document (skills/skill_new_feature.md), (2) Generate Q&A pairs using `generate_qa_from_skills.py`, (3) Review and edit the generated pairs in training-data/by-topic/, (4) Expand clusters to individual pairs with `expand_clusters_to_pairs.py`, (5) Generate tailored answers using `generate_tailored_answers.py`. All tools support Claude and Gemini models. The output is JSONL format ready for training. See skill_synthetic_data.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_synthetic_data_004_q0", "cluster_id": "skill_synthetic_data_004", "question": "How do I generate training data from Pearltrees exports?", "answer": "Use the Pearltrees dataset generation tool to convert RDF exports into training targets:\n\n```bash\npython scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --output reports/pearltrees_targets.jsonl --query-style locate\n```\n\nThis generates structured JSONL training data from your Pearltrees collections. The tool reads your RDF export and produces training examples with queries and targets. You can adjust the --query-style parameter (e.g., 'locate', 'describe') to customize how locations and relationships are extracted. The output integrates directly with your training pipeline.", "question_type": "medium", "topics": ["Quickstart", "Synthetic Data"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["training data", "Pearltrees", "RDF", "dataset generation"], "related_skills": ["skill_synthetic_data.md", "skill_pearl_dataset.md"], "related_docs": ["scripts/generate_pearl_dataset.py"], "original_answer": "Use the Pearltrees dataset generation tool to convert RDF exports into training targets:\n\n```bash\npython scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --output reports/pearltrees_targets.jsonl --query-style locate\n```\n\nThis generates structured JSONL training data from your Pearltrees collections. You can adjust the query-style parameter to customize how locations and relationships are extracted. The output integrates with your training pipeline. See skill_synthetic_data.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_synthetic_data_004_q1", "cluster_id": "skill_synthetic_data_004", "question": "How can I create training datasets from Pearltrees RDF?", "answer": "To create training datasets from Pearltrees RDF, use the generate_pearl_dataset.py script to convert RDF exports into JSONL training targets. Run: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --output reports/pearltrees_targets.jsonl --query-style locate`. This generates structured training data from your Pearltrees collections. You can adjust the --query-style parameter (e.g., 'locate') to customize how relationships are extracted from the RDF. The output integrates directly into your training pipeline.", "question_type": "medium", "topics": ["Quickstart", "Synthetic Data"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["training data", "Pearltrees", "RDF", "dataset generation"], "related_skills": ["skill_synthetic_data.md", "skill_pearl_dataset.md"], "related_docs": ["scripts/generate_pearl_dataset.py"], "original_answer": "Use the Pearltrees dataset generation tool to convert RDF exports into training targets:\n\n```bash\npython scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --output reports/pearltrees_targets.jsonl --query-style locate\n```\n\nThis generates structured JSONL training data from your Pearltrees collections. You can adjust the query-style parameter to customize how locations and relationships are extracted. The output integrates with your training pipeline. See skill_synthetic_data.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_synthetic_data_004_q2", "cluster_id": "skill_synthetic_data_004", "question": "How do I extract training targets from my Pearltrees data?", "answer": "Use the Pearltrees dataset generation tool to convert RDF exports into training targets. Run `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --output reports/pearltrees_targets.jsonl --query-style locate` to generate structured JSONL training data from your Pearltrees collections. The `query-style` parameter controls how locations and relationships are extracted. This output integrates directly with the training pipeline. Refer to skill_synthetic_data.md for additional customization options.", "question_type": "medium", "topics": ["Quickstart", "Synthetic Data"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["training data", "Pearltrees", "RDF", "dataset generation"], "related_skills": ["skill_synthetic_data.md", "skill_pearl_dataset.md"], "related_docs": ["scripts/generate_pearl_dataset.py"], "original_answer": "Use the Pearltrees dataset generation tool to convert RDF exports into training targets:\n\n```bash\npython scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --output reports/pearltrees_targets.jsonl --query-style locate\n```\n\nThis generates structured JSONL training data from your Pearltrees collections. You can adjust the query-style parameter to customize how locations and relationships are extracted. The output integrates with your training pipeline. See skill_synthetic_data.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_qa_generation_001_q0", "cluster_id": "skill_qa_generation_001", "question": "How do I create Q&A training data from my skill documentation?", "answer": "Use `generate_qa_from_skills.py` to create Q&A pairs from your skill markdown files. Run `python training-data/scripts/generate_qa_from_skills.py --skill skill_mindmap_linking.md` for a single skill, or add `--all` to generate from all skills at once. The tool extracts questions from the 'When to Use' section and generates answers from skill content using an LLM, outputting JSONL to `by-topic/<topic>/skills-generated.jsonl`. You can specify the LLM provider (claude or gemini), model, and number of pairs with options like `--provider gemini --model gemini-2.5-flash-preview --pairs 4`. For more details, see skill_qa_generation.md.", "question_type": "medium", "topics": ["Quickstart", "Q&A Generation"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["training-data", "qa-generation", "documentation", "llm"], "related_skills": ["skill_synthetic_data.md", "skill_answer_tailoring.md", "skill_qa_generation.md"], "related_docs": ["training-data/by-topic/SOURCE_MAPPING.md", "training-data/scripts/generate_qa_from_skills.py"], "original_answer": "Use `generate_qa_from_skills.py` to generate Q&A pairs from skill markdown files. Run `python training-data/scripts/generate_qa_from_skills.py --skill skill_mindmap_linking.md` for a single skill, or use `--all` to process all skill files. The tool extracts the 'When to Use' section for question ideas and examples for answers, then uses an LLM to generate structured JSONL output to `by-topic/<topic>/skills-generated.jsonl`. You can customize the LLM provider, model, and number of pairs with options like `--provider gemini --pairs 4`. See skill_qa_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_qa_generation_001_q1", "cluster_id": "skill_qa_generation_001", "question": "How do I generate question-answer pairs from skill files?", "answer": "To generate question-answer pairs from skill files, use the `generate_qa_from_skills.py` script located in `training-data/scripts/`. For a single skill file, run: `python training-data/scripts/generate_qa_from_skills.py --skill skill_mindmap_linking.md --model haiku`. To generate Q&A from all skill files, use the `--all` flag instead. The script extracts content from the 'When to Use' section to generate question ideas and uses examples as answer references, then outputs structured JSONL data to `training-data/by-topic/<topic>/skills-generated.jsonl`. You can specify the LLM provider (claude or gemini) and model type, as well as control the number of Q&A pairs generated with `--pairs`.", "question_type": "medium", "topics": ["Quickstart", "Q&A Generation"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["training-data", "qa-generation", "documentation", "llm"], "related_skills": ["skill_synthetic_data.md", "skill_answer_tailoring.md", "skill_qa_generation.md"], "related_docs": ["training-data/by-topic/SOURCE_MAPPING.md", "training-data/scripts/generate_qa_from_skills.py"], "original_answer": "Use `generate_qa_from_skills.py` to generate Q&A pairs from skill markdown files. Run `python training-data/scripts/generate_qa_from_skills.py --skill skill_mindmap_linking.md` for a single skill, or use `--all` to process all skill files. The tool extracts the 'When to Use' section for question ideas and examples for answers, then uses an LLM to generate structured JSONL output to `by-topic/<topic>/skills-generated.jsonl`. You can customize the LLM provider, model, and number of pairs with options like `--provider gemini --pairs 4`. See skill_qa_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_qa_generation_001_q2", "cluster_id": "skill_qa_generation_001", "question": "What's the process for creating training data from documentation?", "answer": "To create training data from documentation, use `generate_qa_from_skills.py` to generate Q&A pairs from skill markdown files. Run `python training-data/scripts/generate_qa_from_skills.py --skill skill_mindmap_linking.md` for a single skill, or use `--all` to process all skills. The tool extracts the 'When to Use' section for questions and examples for answers, then generates structured JSONL output. You can customize the LLM provider and model with options like `--provider gemini --model gemini-2.5-flash-preview`. For answer expansion, use `generate_tailored_answers.py` to reword answers with an LLM. Output goes to `training-data/by-topic/<topic>/skills-generated.jsonl`.", "question_type": "medium", "topics": ["Quickstart", "Q&A Generation"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["training-data", "qa-generation", "documentation", "llm"], "related_skills": ["skill_synthetic_data.md", "skill_answer_tailoring.md", "skill_qa_generation.md"], "related_docs": ["training-data/by-topic/SOURCE_MAPPING.md", "training-data/scripts/generate_qa_from_skills.py"], "original_answer": "Use `generate_qa_from_skills.py` to generate Q&A pairs from skill markdown files. Run `python training-data/scripts/generate_qa_from_skills.py --skill skill_mindmap_linking.md` for a single skill, or use `--all` to process all skill files. The tool extracts the 'When to Use' section for question ideas and examples for answers, then uses an LLM to generate structured JSONL output to `by-topic/<topic>/skills-generated.jsonl`. You can customize the LLM provider, model, and number of pairs with options like `--provider gemini --pairs 4`. See skill_qa_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_qa_generation_002_q0", "cluster_id": "skill_qa_generation_002", "question": "What's the difference between the two Q&A generation tools?", "answer": "`generate_qa_from_skills.py` creates task-oriented Q&A pairs directly from individual skill markdown files, making it ideal for how-to training data from specific skills. `generate_quickstart_qa.py` generates capability-based Q&A from SOURCE_MAPPING.md by reading referenced source files and organizing data by topics. Use the first tool when building training data from new or existing skills, and the second when mapping source files to broader capabilities. Both output JSONL with support for multiple LLM providers.", "question_type": "medium", "topics": ["Quickstart", "Q&A Generation"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["training-data", "qa-generation", "tools", "workflow"], "related_skills": ["skill_synthetic_data.md", "skill_answer_tailoring.md", "skill_qa_generation.md"], "related_docs": ["training-data/scripts/generate_quickstart_qa.py", "training-data/by-topic/SOURCE_MAPPING.md"], "original_answer": "Use `generate_qa_from_skills.py` for task-oriented Q&A from individual skill markdown files\u2014it's best for how-to training data. Use `generate_quickstart_qa.py` for capability-based Q&A from SOURCE_MAPPING.md\u2014it reads referenced source files and generates training data organized by topics. Choose `generate_qa_from_skills.py` if you're creating data from new skills, or `generate_quickstart_qa.py` if you're mapping existing source files to capabilities. Both output JSONL format with configurable LLM providers and models. See skill_qa_generation.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "Base answer mentions 'new skills' vs 'existing source files' distinction which may not be entirely clear without seeing the actual tool implementations. The description of when to use each tool is inferred from the base answer context."}
{"pair_id": "skill_qa_generation_002_q1", "cluster_id": "skill_qa_generation_002", "question": "When should I use generate_qa_from_skills vs generate_quickstart_qa?", "answer": "Use `generate_qa_from_skills.py` when you have individual skill markdown files and want to generate task-oriented Q&A training data from them. Use `generate_quickstart_qa.py` when you have a SOURCE_MAPPING.md file that references source documents and you want to generate capability-based Q&A organized by topics. In summary: choose `generate_qa_from_skills.py` for skill-based data generation, and `generate_quickstart_qa.py` for source-file-based capability mapping.", "question_type": "medium", "topics": ["Quickstart", "Q&A Generation"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["training-data", "qa-generation", "tools", "workflow"], "related_skills": ["skill_synthetic_data.md", "skill_answer_tailoring.md", "skill_qa_generation.md"], "related_docs": ["training-data/scripts/generate_quickstart_qa.py", "training-data/by-topic/SOURCE_MAPPING.md"], "original_answer": "Use `generate_qa_from_skills.py` for task-oriented Q&A from individual skill markdown files\u2014it's best for how-to training data. Use `generate_quickstart_qa.py` for capability-based Q&A from SOURCE_MAPPING.md\u2014it reads referenced source files and generates training data organized by topics. Choose `generate_qa_from_skills.py` if you're creating data from new skills, or `generate_quickstart_qa.py` if you're mapping existing source files to capabilities. Both output JSONL format with configurable LLM providers and models. See skill_qa_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_qa_generation_002_q2", "cluster_id": "skill_qa_generation_002", "question": "Which tool should I use for my training data?", "answer": "For training data generation, choose between two tools: Use `generate_qa_from_skills.py` if you're creating task-oriented Q&A from individual skill markdown files\u2014it's ideal for how-to training data from new skills. Use `generate_quickstart_qa.py` if you're generating capability-based Q&A from SOURCE_MAPPING.md\u2014it reads referenced source files and organizes training data by topics. Both output JSONL format and support configurable LLM providers (Claude, Gemini) and models. For Pearltrees datasets specifically, use `generate_pearl_dataset.py`.", "question_type": "medium", "topics": ["Quickstart", "Q&A Generation"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["training-data", "qa-generation", "tools", "workflow"], "related_skills": ["skill_synthetic_data.md", "skill_answer_tailoring.md", "skill_qa_generation.md"], "related_docs": ["training-data/scripts/generate_quickstart_qa.py", "training-data/by-topic/SOURCE_MAPPING.md"], "original_answer": "Use `generate_qa_from_skills.py` for task-oriented Q&A from individual skill markdown files\u2014it's best for how-to training data. Use `generate_quickstart_qa.py` for capability-based Q&A from SOURCE_MAPPING.md\u2014it reads referenced source files and generates training data organized by topics. Choose `generate_qa_from_skills.py` if you're creating data from new skills, or `generate_quickstart_qa.py` if you're mapping existing source files to capabilities. Both output JSONL format with configurable LLM providers and models. See skill_qa_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_qa_generation_003_q0", "cluster_id": "skill_qa_generation_003", "question": "How do I check what skill coverage gaps exist in my training data?", "answer": "Run `python training-data/scripts/generate_qa_from_skills.py --coverage` to analyze skill coverage gaps. This command scans your capability tree and identifies which skills have corresponding documentation (marked with checkmarks) and which are missing. The output provides a prioritized list of suggested new skills to create, helping you focus your documentation efforts on the highest-impact gaps for your training data.", "question_type": "long", "topics": ["Quickstart", "Q&A Generation"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["training-data", "qa-generation", "coverage-analysis", "planning"], "related_skills": ["skill_synthetic_data.md", "skill_qa_generation.md"], "related_docs": ["training-data/scripts/generate_qa_from_skills.py"], "original_answer": "Run `python training-data/scripts/generate_qa_from_skills.py --coverage` to analyze skill coverage gaps. This command identifies which capabilities in your capability tree have corresponding skills (marked with checkmarks) and which are missing. The output shows suggested new skills to create, helping you prioritize what documentation to write next. This is useful for identifying gaps in your quickstart agent's training data. See skill_qa_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_qa_generation_003_q1", "cluster_id": "skill_qa_generation_003", "question": "How do I find out which capabilities don't have corresponding skills?", "answer": "Run `python training-data/scripts/generate_qa_from_skills.py --coverage` to analyze which capabilities lack corresponding skills. This command generates a coverage report showing capabilities with checkmarks (have skills) and those without (missing skills), along with suggested new skills to prioritize creating. See skill_qa_generation.md for details.", "question_type": "long", "topics": ["Quickstart", "Q&A Generation"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["training-data", "qa-generation", "coverage-analysis", "planning"], "related_skills": ["skill_synthetic_data.md", "skill_qa_generation.md"], "related_docs": ["training-data/scripts/generate_qa_from_skills.py"], "original_answer": "Run `python training-data/scripts/generate_qa_from_skills.py --coverage` to analyze skill coverage gaps. This command identifies which capabilities in your capability tree have corresponding skills (marked with checkmarks) and which are missing. The output shows suggested new skills to create, helping you prioritize what documentation to write next. This is useful for identifying gaps in your quickstart agent's training data. See skill_qa_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_qa_generation_003_q2", "cluster_id": "skill_qa_generation_003", "question": "Can I analyze which skills are missing?", "answer": "Run `python training-data/scripts/generate_qa_from_skills.py --coverage` to analyze which skills are missing. This command identifies which capabilities in your capability tree have corresponding skills and which lack documentation. The output shows gaps in your training data and suggests new skills to create, helping you prioritize what documentation to write next.", "question_type": "long", "topics": ["Quickstart", "Q&A Generation"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["training-data", "qa-generation", "coverage-analysis", "planning"], "related_skills": ["skill_synthetic_data.md", "skill_qa_generation.md"], "related_docs": ["training-data/scripts/generate_qa_from_skills.py"], "original_answer": "Run `python training-data/scripts/generate_qa_from_skills.py --coverage` to analyze skill coverage gaps. This command identifies which capabilities in your capability tree have corresponding skills (marked with checkmarks) and which are missing. The output shows suggested new skills to create, helping you prioritize what documentation to write next. This is useful for identifying gaps in your quickstart agent's training data. See skill_qa_generation.md for details.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null}
{"pair_id": "skill_qa_generation_004_q0", "cluster_id": "skill_qa_generation_004", "question": "What should good Q&A pairs look like for training data?", "answer": "Good Q&A pairs for training data should ask questions as users would naturally ask them, without mentioning skill names since users don't know them. Include 2-3 question variants to improve training diversity. Answers must be concise yet complete, with relevant code examples and command snippets. Reference documentation paths for users wanting to learn more. Structure output as JSONL with: id, question, question_variants, level (0=identity, 1=capabilities, 2=general task, 3=specific task, 4=details), tree_path for organization, answer, related_skills, related_docs, and tags. Focus on practical, actionable content that helps new users accomplish real tasks.", "question_type": "medium", "topics": ["Quickstart", "Q&A Generation"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["training-data", "qa-generation", "best-practices", "quality"], "related_skills": ["skill_synthetic_data.md", "skill_answer_tailoring.md", "skill_qa_generation.md"], "related_docs": ["training-data/scripts/generate_qa_from_skills.py"], "original_answer": "Good questions should be user-centric (what a new user would ask), avoid mentioning skill names since users don't know them, and include 2-3 variants for training diversity. Answers should be concise but complete, include relevant code examples and commands, and reference documentation paths for 'learn more'. The output JSONL format includes levels (0=identity, 1=capabilities, 2=general task, 3=specific task, 4=details), tree paths for organization, related skills/docs, and tags for discoverability. Focus on practical, actionable Q&A that helps new users accomplish real tasks. See skill_qa_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_qa_generation_004_q1", "cluster_id": "skill_qa_generation_004", "question": "How do I write quality questions and answers for training?", "answer": "Write user-centric questions that reflect what new users would actually ask, without referencing skill names since users don't know them internally. Include 2-3 question variants to improve training diversity. Answers should be concise yet complete, with relevant code examples and commands, plus documentation paths for further learning. Organize answers using the JSONL structure with levels (0=identity, 1=capabilities, 2=general task, 3=specific task, 4=details), tree paths for context, related skills/docs references, and tags for discoverability. Prioritize practical, actionable content that helps new users accomplish real tasks rather than abstract explanations.", "question_type": "medium", "topics": ["Quickstart", "Q&A Generation"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["training-data", "qa-generation", "best-practices", "quality"], "related_skills": ["skill_synthetic_data.md", "skill_answer_tailoring.md", "skill_qa_generation.md"], "related_docs": ["training-data/scripts/generate_qa_from_skills.py"], "original_answer": "Good questions should be user-centric (what a new user would ask), avoid mentioning skill names since users don't know them, and include 2-3 variants for training diversity. Answers should be concise but complete, include relevant code examples and commands, and reference documentation paths for 'learn more'. The output JSONL format includes levels (0=identity, 1=capabilities, 2=general task, 3=specific task, 4=details), tree paths for organization, related skills/docs, and tags for discoverability. Focus on practical, actionable Q&A that helps new users accomplish real tasks. See skill_qa_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_qa_generation_004_q2", "cluster_id": "skill_qa_generation_004", "question": "What makes a good training question?", "answer": "Good training questions should reflect what actual users would ask, not internal terminology. Avoid referencing skill names\u2014users don't know those exist. Create 2-3 question variants to improve training diversity. Answers must be concise yet complete, with practical code examples and commands where applicable. Include references to documentation paths for users who want to learn more. Use the JSONL format with levels (0=identity, 1=capabilities, 2=general task, 3=specific task, 4=details) to categorize questions by complexity, organize with tree paths, tag for discoverability, and link related skills and docs. The goal is actionable Q&A that helps new users accomplish real tasks, not theoretical knowledge.", "question_type": "medium", "topics": ["Quickstart", "Q&A Generation"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["training-data", "qa-generation", "best-practices", "quality"], "related_skills": ["skill_synthetic_data.md", "skill_answer_tailoring.md", "skill_qa_generation.md"], "related_docs": ["training-data/scripts/generate_qa_from_skills.py"], "original_answer": "Good questions should be user-centric (what a new user would ask), avoid mentioning skill names since users don't know them, and include 2-3 variants for training diversity. Answers should be concise but complete, include relevant code examples and commands, and reference documentation paths for 'learn more'. The output JSONL format includes levels (0=identity, 1=capabilities, 2=general task, 3=specific task, 4=details), tree paths for organization, related skills/docs, and tags for discoverability. Focus on practical, actionable Q&A that helps new users accomplish real tasks. See skill_qa_generation.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_answer_tailoring_001_q0", "cluster_id": "skill_answer_tailoring_001", "question": "How do I create variations of my training data answers?", "answer": "To create variations of Q&A answers for training data, use `python scripts/generate_tailored_answers.py --input <jsonl_dir>`. This reads (question, base_answer) pairs and generates reworded answers that directly address each question while maintaining semantic equivalence. Output includes `answer_tailored: true` and preserves original in `original_answer`.", "question_type": "medium", "topics": ["Quickstart", "Answer Tailoring"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["training-data", "data-augmentation", "llm", "answers"], "related_skills": ["skill_answer_tailoring.md", "skill_synthetic_data.md", "skill_qa_generation.md"], "related_docs": ["scripts/generate_tailored_answers.py", "scripts/expand_clusters_to_pairs.py"], "original_answer": "Use the generate_tailored_answers.py script to automatically reword your Q&A pairs. Run `python scripts/generate_tailored_answers.py --input training-data/expanded` to process all JSONL files in a directory. The script rewrites answers to directly address the question while maintaining semantic equivalence. Each pair gets a `answer_tailored: true` flag and the original answer is preserved as `original_answer`. See skill_answer_tailoring.md for details.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_answer_tailoring_001_q1", "cluster_id": "skill_answer_tailoring_001", "question": "How can I generate different versions of my Q&A answers?", "answer": "tailored answer that directly addresses the question", "question_type": "medium", "topics": ["Quickstart", "Answer Tailoring"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["training-data", "data-augmentation", "llm", "answers"], "related_skills": ["skill_answer_tailoring.md", "skill_synthetic_data.md", "skill_qa_generation.md"], "related_docs": ["scripts/generate_tailored_answers.py", "scripts/expand_clusters_to_pairs.py"], "original_answer": "Use the generate_tailored_answers.py script to automatically reword your Q&A pairs. Run `python scripts/generate_tailored_answers.py --input training-data/expanded` to process all JSONL files in a directory. The script rewrites answers to directly address the question while maintaining semantic equivalence. Each pair gets a `answer_tailored: true` flag and the original answer is preserved as `original_answer`. See skill_answer_tailoring.md for details.", "answer_tailored": true, "confidence": 0.85, "confidence_issues": null}
{"pair_id": "skill_answer_tailoring_001_q2", "cluster_id": "skill_answer_tailoring_001", "question": "What's the best way to reword answers for training data diversity?", "answer": "For training data diversity, use the answer tailoring script: `python scripts/generate_tailored_answers.py --input training-data/expanded`. Each base answer gets reworded to directly address its specific question with natural variation. Use `--provider gemini` or `--model haiku` for bulk processing, `--model sonnet` for quality-sensitive data.", "question_type": "medium", "topics": ["Quickstart", "Answer Tailoring"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["training-data", "data-augmentation", "llm", "answers"], "related_skills": ["skill_answer_tailoring.md", "skill_synthetic_data.md", "skill_qa_generation.md"], "related_docs": ["scripts/generate_tailored_answers.py", "scripts/expand_clusters_to_pairs.py"], "original_answer": "Use the generate_tailored_answers.py script to automatically reword your Q&A pairs. Run `python scripts/generate_tailored_answers.py --input training-data/expanded` to process all JSONL files in a directory. The script rewrites answers to directly address the question while maintaining semantic equivalence. Each pair gets a `answer_tailored: true` flag and the original answer is preserved as `original_answer`. See skill_answer_tailoring.md for details.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_answer_tailoring_001_q3", "cluster_id": "skill_answer_tailoring_001", "question": "How do I augment my training data with answer variations?", "answer": "Augment training data with answer variations using `python scripts/generate_tailored_answers.py --input <dir>`. The script generates reworded answers that maintain semantic equivalence while directly addressing each question. Supports resumable processing and saves progress after each batch.", "question_type": "medium", "topics": ["Quickstart", "Answer Tailoring"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["training-data", "data-augmentation", "llm", "answers"], "related_skills": ["skill_answer_tailoring.md", "skill_synthetic_data.md", "skill_qa_generation.md"], "related_docs": ["scripts/generate_tailored_answers.py", "scripts/expand_clusters_to_pairs.py"], "original_answer": "Use the generate_tailored_answers.py script to automatically reword your Q&A pairs. Run `python scripts/generate_tailored_answers.py --input training-data/expanded` to process all JSONL files in a directory. The script rewrites answers to directly address the question while maintaining semantic equivalence. Each pair gets a `answer_tailored: true` flag and the original answer is preserved as `original_answer`. See skill_answer_tailoring.md for details.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_answer_tailoring_002_q0", "cluster_id": "skill_answer_tailoring_002", "question": "How do I choose between different LLM providers for tailoring answers?", "answer": "Choose LLM provider with `--provider claude` or `--provider gemini`. Claude haiku is fast and low-cost for bulk processing. Sonnet offers better quality at medium cost. Gemini flash is similar to haiku. For quality-sensitive data, use `--model sonnet` or `--model opus`.", "question_type": "long", "topics": ["Quickstart", "Answer Tailoring"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["llm-selection", "performance", "cost-optimization"], "related_skills": ["skill_answer_tailoring.md"], "related_docs": ["scripts/generate_tailored_answers.py"], "original_answer": "Use `--provider` and `--model` flags to select your LLM. For bulk processing, use haiku or gemini-2.5-flash-preview (fast, low cost). For quality-sensitive data, use sonnet. Run `python scripts/generate_tailored_answers.py --input training-data/expanded --provider gemini --model gemini-2.5-flash-preview`. Claude providers (haiku, sonnet, opus) offer increasing quality at higher cost. See skill_answer_tailoring.md for details.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_answer_tailoring_002_q1", "cluster_id": "skill_answer_tailoring_002", "question": "Which model should I use for answer rewriting?", "answer": "For answer rewriting, use `--model haiku` (Claude) or `--model gemini-2.5-flash-preview` (Gemini) for bulk processing. Use `--model sonnet` for quality-sensitive data, `--model opus` for best quality. Set with `python scripts/generate_tailored_answers.py --model <name>`.", "question_type": "long", "topics": ["Quickstart", "Answer Tailoring"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["llm-selection", "performance", "cost-optimization"], "related_skills": ["skill_answer_tailoring.md"], "related_docs": ["scripts/generate_tailored_answers.py"], "original_answer": "Use `--provider` and `--model` flags to select your LLM. For bulk processing, use haiku or gemini-2.5-flash-preview (fast, low cost). For quality-sensitive data, use sonnet. Run `python scripts/generate_tailored_answers.py --input training-data/expanded --provider gemini --model gemini-2.5-flash-preview`. Claude providers (haiku, sonnet, opus) offer increasing quality at higher cost. See skill_answer_tailoring.md for details.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_answer_tailoring_002_q2", "cluster_id": "skill_answer_tailoring_002", "question": "What's faster - Claude or Gemini for answer tailoring?", "answer": "Claude haiku and Gemini flash are similarly fast for answer tailoring. Gemini may have longer timeouts. For speed: use `--provider gemini --model gemini-2.5-flash-preview` or `--provider claude --model haiku`. Both support `--delay` to control rate limiting.", "question_type": "long", "topics": ["Quickstart", "Answer Tailoring"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["llm-selection", "performance", "cost-optimization"], "related_skills": ["skill_answer_tailoring.md"], "related_docs": ["scripts/generate_tailored_answers.py"], "original_answer": "Use `--provider` and `--model` flags to select your LLM. For bulk processing, use haiku or gemini-2.5-flash-preview (fast, low cost). For quality-sensitive data, use sonnet. Run `python scripts/generate_tailored_answers.py --input training-data/expanded --provider gemini --model gemini-2.5-flash-preview`. Claude providers (haiku, sonnet, opus) offer increasing quality at higher cost. See skill_answer_tailoring.md for details.", "answer_tailored": true, "confidence": 0.85, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_answer_tailoring_002_q3", "cluster_id": "skill_answer_tailoring_002", "question": "Should I use haiku, sonnet, or opus for generating answer variations?", "answer": "tailored answer directly addressing the question", "question_type": "long", "topics": ["Quickstart", "Answer Tailoring"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["llm-selection", "performance", "cost-optimization"], "related_skills": ["skill_answer_tailoring.md"], "related_docs": ["scripts/generate_tailored_answers.py"], "original_answer": "Use `--provider` and `--model` flags to select your LLM. For bulk processing, use haiku or gemini-2.5-flash-preview (fast, low cost). For quality-sensitive data, use sonnet. Run `python scripts/generate_tailored_answers.py --input training-data/expanded --provider gemini --model gemini-2.5-flash-preview`. Claude providers (haiku, sonnet, opus) offer increasing quality at higher cost. See skill_answer_tailoring.md for details.", "answer_tailored": true, "confidence": 0.85, "confidence_issues": null}
{"pair_id": "skill_answer_tailoring_003_q0", "cluster_id": "skill_answer_tailoring_003", "question": "How do I handle rate limiting when processing large datasets?", "answer": "To handle rate limiting when processing large datasets, adjust the `--batch-size` and `--delay` parameters in the answer tailoring script. For rate limit safety with large datasets, use smaller batches with longer delays: `python scripts/generate_tailored_answers.py --input training-data/expanded --batch-size 5 --delay 1.0`. If you need faster processing, you can increase the batch size to 20 and decrease the delay to 0.2 seconds: `--batch-size 20 --delay 0.2`. If you encounter timeouts during processing, reduce the batch size further and increase the delay to 2.0 seconds to give the API more recovery time between requests.", "question_type": "long", "topics": ["Quickstart", "Answer Tailoring"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["rate-limiting", "api-optimization", "batch-processing"], "related_skills": ["skill_answer_tailoring.md"], "related_docs": ["scripts/generate_tailored_answers.py"], "original_answer": "Adjust `--batch-size` and `--delay` parameters to control API rate. For rate limit safety, use smaller batches with longer delays: `python scripts/generate_tailored_answers.py --input training-data/expanded --batch-size 5 --delay 1.0`. For faster processing, increase batch size and decrease delay: `--batch-size 20 --delay 0.2`. If timeouts occur, reduce batch size further and increase delay to 2.0 seconds. See skill_answer_tailoring.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_answer_tailoring_003_q1", "cluster_id": "skill_answer_tailoring_003", "question": "My answer tailoring keeps timing out - how do I fix it?", "answer": "For bulk processing, Claude haiku or Gemini flash offer the best speed/cost balance: `--provider claude --model haiku` or `--provider gemini --model gemini-2.5-flash-preview`. Use `--batch-size 10 --delay 0.5` to avoid rate limits while maintaining throughput.", "question_type": "long", "topics": ["Quickstart", "Answer Tailoring"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["rate-limiting", "api-optimization", "batch-processing"], "related_skills": ["skill_answer_tailoring.md"], "related_docs": ["scripts/generate_tailored_answers.py"], "original_answer": "Adjust `--batch-size` and `--delay` parameters to control API rate. For rate limit safety, use smaller batches with longer delays: `python scripts/generate_tailored_answers.py --input training-data/expanded --batch-size 5 --delay 1.0`. For faster processing, increase batch size and decrease delay: `--batch-size 20 --delay 0.2`. If timeouts occur, reduce batch size further and increase delay to 2.0 seconds. See skill_answer_tailoring.md for details.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_answer_tailoring_003_q2", "cluster_id": "skill_answer_tailoring_003", "question": "How can I safely process thousands of Q&A pairs without hitting API limits?", "answer": "Process thousands of Q&A pairs safely with: `python scripts/generate_tailored_answers.py --input <dir> --batch-size 5 --delay 1.0`. The script saves progress after each batch and skips already-processed pairs automatically. Reduce batch size and increase delay if hitting limits.", "question_type": "long", "topics": ["Quickstart", "Answer Tailoring"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["rate-limiting", "api-optimization", "batch-processing"], "related_skills": ["skill_answer_tailoring.md"], "related_docs": ["scripts/generate_tailored_answers.py"], "original_answer": "Adjust `--batch-size` and `--delay` parameters to control API rate. For rate limit safety, use smaller batches with longer delays: `python scripts/generate_tailored_answers.py --input training-data/expanded --batch-size 5 --delay 1.0`. For faster processing, increase batch size and decrease delay: `--batch-size 20 --delay 0.2`. If timeouts occur, reduce batch size further and increase delay to 2.0 seconds. See skill_answer_tailoring.md for details.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_answer_tailoring_003_q3", "cluster_id": "skill_answer_tailoring_003", "question": "What batch size and delay should I use?", "answer": "Default batch size is 10 with 0.5s delay between calls. For rate-limit-safe processing: `--batch-size 5 --delay 1.0`. For faster processing (if limits allow): `--batch-size 20 --delay 0.2`. Progress saves after each batch.", "question_type": "long", "topics": ["Quickstart", "Answer Tailoring"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["rate-limiting", "api-optimization", "batch-processing"], "related_skills": ["skill_answer_tailoring.md"], "related_docs": ["scripts/generate_tailored_answers.py"], "original_answer": "Adjust `--batch-size` and `--delay` parameters to control API rate. For rate limit safety, use smaller batches with longer delays: `python scripts/generate_tailored_answers.py --input training-data/expanded --batch-size 5 --delay 1.0`. For faster processing, increase batch size and decrease delay: `--batch-size 20 --delay 0.2`. If timeouts occur, reduce batch size further and increase delay to 2.0 seconds. See skill_answer_tailoring.md for details.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_answer_tailoring_004_q0", "cluster_id": "skill_answer_tailoring_004", "question": "How do I resume an interrupted answer tailoring job?", "answer": "Handle rate limiting by adjusting batch size and delay: `python scripts/generate_tailored_answers.py --batch-size 5 --delay 2.0`. Smaller batches with longer delays reduce API pressure. The script saves progress after each batch, so you can safely restart if needed.", "question_type": "long", "topics": ["Quickstart", "Answer Tailoring"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["resumable-processing", "workflow", "error-recovery"], "related_skills": ["skill_answer_tailoring.md"], "related_docs": ["scripts/generate_tailored_answers.py"], "original_answer": "The script automatically resumes from where it stopped. Just run the same command again: `python scripts/generate_tailored_answers.py --input training-data/expanded`. It checks the output file for already-processed `pair_id` values and skips pairs with `answer_tailored: true`. To reprocess everything from scratch, use the `--no-skip` flag: `python scripts/generate_tailored_answers.py --input training-data/expanded --no-skip`. See skill_answer_tailoring.md for details.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_answer_tailoring_004_q1", "cluster_id": "skill_answer_tailoring_004", "question": "Can I restart my tailoring script without reprocessing everything?", "answer": "If hitting rate limits, increase delay and reduce batch size: `--batch-size 5 --delay 2.0`. The script automatically skips already-processed pairs, so you can restart safely. Progress is saved after each batch completion.", "question_type": "long", "topics": ["Quickstart", "Answer Tailoring"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["resumable-processing", "workflow", "error-recovery"], "related_skills": ["skill_answer_tailoring.md"], "related_docs": ["scripts/generate_tailored_answers.py"], "original_answer": "The script automatically resumes from where it stopped. Just run the same command again: `python scripts/generate_tailored_answers.py --input training-data/expanded`. It checks the output file for already-processed `pair_id` values and skips pairs with `answer_tailored: true`. To reprocess everything from scratch, use the `--no-skip` flag: `python scripts/generate_tailored_answers.py --input training-data/expanded --no-skip`. See skill_answer_tailoring.md for details.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_answer_tailoring_004_q2", "cluster_id": "skill_answer_tailoring_004", "question": "How do I continue where I left off?", "answer": "Slow down API calls with the `--delay` option: `python scripts/generate_tailored_answers.py --delay 2.0` for 2-second delays between calls. Combine with smaller batches: `--batch-size 5 --delay 1.5` for safe bulk processing.", "question_type": "long", "topics": ["Quickstart", "Answer Tailoring"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["resumable-processing", "workflow", "error-recovery"], "related_skills": ["skill_answer_tailoring.md"], "related_docs": ["scripts/generate_tailored_answers.py"], "original_answer": "The script automatically resumes from where it stopped. Just run the same command again: `python scripts/generate_tailored_answers.py --input training-data/expanded`. It checks the output file for already-processed `pair_id` values and skips pairs with `answer_tailored: true`. To reprocess everything from scratch, use the `--no-skip` flag: `python scripts/generate_tailored_answers.py --input training-data/expanded --no-skip`. See skill_answer_tailoring.md for details.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_answer_tailoring_004_q3", "cluster_id": "skill_answer_tailoring_004", "question": "Does the script skip already-processed pairs?", "answer": "Yes, the script automatically skips already-processed pairs. When you re-run with the same output directory, it checks for existing `pair_id` values with `answer_tailored: true` and skips them. Use `--no-skip` to force reprocessing all pairs.", "question_type": "long", "topics": ["Quickstart", "Answer Tailoring"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["resumable-processing", "workflow", "error-recovery"], "related_skills": ["skill_answer_tailoring.md"], "related_docs": ["scripts/generate_tailored_answers.py"], "original_answer": "The script automatically resumes from where it stopped. Just run the same command again: `python scripts/generate_tailored_answers.py --input training-data/expanded`. It checks the output file for already-processed `pair_id` values and skips pairs with `answer_tailored: true`. To reprocess everything from scratch, use the `--no-skip` flag: `python scripts/generate_tailored_answers.py --input training-data/expanded --no-skip`. See skill_answer_tailoring.md for details.", "answer_tailored": true, "confidence": 0.9, "confidence_issues": null, "manually_reviewed": true}
{"pair_id": "skill_pearl_dataset_001_q0", "cluster_id": "skill_pearl_dataset_001", "question": "How do I create training data from Pearltrees?", "answer": "Export your Pearltrees as RDF from Settings > Export, then run:\n\n```bash\npython scripts/generate_pearl_dataset.py \\\n  --rdf data/export.rdf \\\n  --output reports/pearltrees_targets.jsonl\n```\n\nThis generates JSONL training data with materialized paths (e.g., `account > Root > Science > Physics`) suitable for semantic search. Use `--query-style locate` for Prolog queries, `--query-style file` for bookmark filing, or other styles for different use cases. Filter with `--trees-only` or `--pearls-only` for specific content types. For multiple RDF files, pass each with `--rdf` and add `--cross-account` to enable cross-account linking.", "question_type": "medium", "topics": ["Quickstart", "Synthetic Data", "Pearl Dataset Generation"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["pearltrees", "dataset", "rdf", "training-data", "semantic-search"], "related_skills": ["skill_pearl_dataset.md", "skill_synthetic_data.md"], "related_docs": ["scripts/generate_pearl_dataset.py", "scripts/generate_tree_refpearls.py", "scripts/generate_account_training_data.py"], "original_answer": "Export your Pearltrees as RDF (from Settings > Export), then run:\n\n```bash\npython scripts/generate_pearl_dataset.py \\\n  --rdf data/export.rdf \\\n  --output reports/pearltrees_targets.jsonl\n```\n\nThis generates JSONL with materialized paths (e.g., `account > Root > Science > Physics`) suitable for semantic search training. Use `--query-style locate` for Prolog-style queries or `--query-style file` for bookmark filing. Add `--trees-only` or `--pearls-only` to filter content type.\n\nSee skill_pearl_dataset.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pearl_dataset_001_q1", "cluster_id": "skill_pearl_dataset_001", "question": "How do I export Pearltrees for machine learning?", "answer": "Export your Pearltrees as RDF from Settings > Export, then run:\n\n```bash\npython scripts/generate_pearl_dataset.py \\\n  --rdf data/export.rdf \\\n  --output reports/pearltrees_targets.jsonl\n```\n\nThis generates JSONL training data with materialized paths (e.g., `account > Root > Science > Physics`) suitable for semantic search, folder suggestion models, and bookmark filing assistants. Use `--query-style locate` for Prolog-style queries, `--query-style file` for bookmark filing, or other styles for different ML tasks. Filter with `--trees-only` or `--pearls-only` as needed. For multi-account datasets, add `--cross-account` flag and pass multiple RDF files.", "question_type": "medium", "topics": ["Quickstart", "Synthetic Data", "Pearl Dataset Generation"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["pearltrees", "dataset", "rdf", "training-data", "semantic-search"], "related_skills": ["skill_pearl_dataset.md", "skill_synthetic_data.md"], "related_docs": ["scripts/generate_pearl_dataset.py", "scripts/generate_tree_refpearls.py", "scripts/generate_account_training_data.py"], "original_answer": "Export your Pearltrees as RDF (from Settings > Export), then run:\n\n```bash\npython scripts/generate_pearl_dataset.py \\\n  --rdf data/export.rdf \\\n  --output reports/pearltrees_targets.jsonl\n```\n\nThis generates JSONL with materialized paths (e.g., `account > Root > Science > Physics`) suitable for semantic search training. Use `--query-style locate` for Prolog-style queries or `--query-style file` for bookmark filing. Add `--trees-only` or `--pearls-only` to filter content type.\n\nSee skill_pearl_dataset.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pearl_dataset_001_q2", "cluster_id": "skill_pearl_dataset_001", "question": "How do I generate a dataset from my Pearltrees bookmarks?", "answer": "Export your Pearltrees as RDF (from Settings > Export), then run:\n\n```bash\npython scripts/generate_pearl_dataset.py \\\n  --rdf data/export.rdf \\\n  --output reports/pearltrees_targets.jsonl\n```\n\nThis generates JSONL training data with materialized paths (e.g., `account > Root > Science > Physics`) suitable for semantic search. Use `--query-style locate` for Prolog-style queries or `--query-style file` for bookmark filing tasks. Add `--trees-only` or `--pearls-only` to filter by content type.", "question_type": "medium", "topics": ["Quickstart", "Synthetic Data", "Pearl Dataset Generation"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["pearltrees", "dataset", "rdf", "training-data", "semantic-search"], "related_skills": ["skill_pearl_dataset.md", "skill_synthetic_data.md"], "related_docs": ["scripts/generate_pearl_dataset.py", "scripts/generate_tree_refpearls.py", "scripts/generate_account_training_data.py"], "original_answer": "Export your Pearltrees as RDF (from Settings > Export), then run:\n\n```bash\npython scripts/generate_pearl_dataset.py \\\n  --rdf data/export.rdf \\\n  --output reports/pearltrees_targets.jsonl\n```\n\nThis generates JSONL with materialized paths (e.g., `account > Root > Science > Physics`) suitable for semantic search training. Use `--query-style locate` for Prolog-style queries or `--query-style file` for bookmark filing. Add `--trees-only` or `--pearls-only` to filter content type.\n\nSee skill_pearl_dataset.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pearl_dataset_001_q3", "cluster_id": "skill_pearl_dataset_001", "question": "Can I use Pearltrees exports for semantic search training?", "answer": "Yes, you can use Pearltrees exports for semantic search training. Export your Pearltrees as RDF (from Settings > Export), then run:\n\n```bash\npython scripts/generate_pearl_dataset.py \\\n  --rdf data/export.rdf \\\n  --output reports/pearltrees_targets.jsonl\n```\n\nThis generates JSONL training data with materialized paths (e.g., `account > Root > Science > Physics`) optimized for semantic search. You can customize the output with `--query-style` (choose from raw, locate, file, similar, or browse), and filter by `--trees-only` or `--pearls-only`. For multi-account setups, use `--cross-account` to enable cross-reference linking.", "question_type": "medium", "topics": ["Quickstart", "Synthetic Data", "Pearl Dataset Generation"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["pearltrees", "dataset", "rdf", "training-data", "semantic-search"], "related_skills": ["skill_pearl_dataset.md", "skill_synthetic_data.md"], "related_docs": ["scripts/generate_pearl_dataset.py", "scripts/generate_tree_refpearls.py", "scripts/generate_account_training_data.py"], "original_answer": "Export your Pearltrees as RDF (from Settings > Export), then run:\n\n```bash\npython scripts/generate_pearl_dataset.py \\\n  --rdf data/export.rdf \\\n  --output reports/pearltrees_targets.jsonl\n```\n\nThis generates JSONL with materialized paths (e.g., `account > Root > Science > Physics`) suitable for semantic search training. Use `--query-style locate` for Prolog-style queries or `--query-style file` for bookmark filing. Add `--trees-only` or `--pearls-only` to filter content type.\n\nSee skill_pearl_dataset.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pearl_dataset_002_q0", "cluster_id": "skill_pearl_dataset_002", "question": "How do I generate targets for semantic search from my bookmarks?", "answer": "Use `generate_pearl_dataset.py` to transform Pearltrees RDF exports into JSONL training data for semantic search:\n\n```bash\npython scripts/generate_pearl_dataset.py \\\n  --rdf data/s243a.rdf \\\n  --output reports/pearltrees_targets.jsonl\n```\n\nEach generated entry contains:\n- `target_text`: Materialized hierarchy path (e.g., \"s243a > Root > Science > Physics\")\n- `query`: Formatted query string for the target\n- `cluster_id`: Parent folder URI for grouping\n- `type`: Node type (Tree, PagePearl, NotePearl, RefPearl)\n- `uri`: Unique Pearltrees identifier\n\nFor different use cases, choose a query style:\n- `raw`: Plain title (default embedding)\n- `locate`: Prolog-style `locate_node(\"title\")` queries\n- `file`: Bookmark filing format\n- `similar`: Similarity search queries\n\nFilter your dataset with:\n- `--pearls-only`: Bookmarks only\n- `--trees-only`: Folders only\n- `--cross-account`: Include cross-references across Pearltrees accounts\n\nExample for bookmark filing training:\n```bash\npython scripts/generate_pearl_dataset.py \\\n  --rdf data/s243a.rdf \\\n  --query-style file \\\n  --pearls-only \\\n  --output reports/targets_filing.jsonl\n```", "question_type": "medium", "topics": ["Quickstart", "Synthetic Data", "Pearl Dataset Generation"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["semantic-search", "embeddings", "targets", "pearltrees", "bookmarks"], "related_skills": ["skill_pearl_dataset.md", "skill_train_model.md"], "related_docs": ["scripts/generate_pearl_dataset.py"], "original_answer": "Use `generate_pearl_dataset.py` to transform Pearltrees RDF into JSONL targets:\n\n```bash\npython scripts/generate_pearl_dataset.py \\\n  --rdf data/s243a.rdf \\\n  --query-style locate \\\n  --output reports/targets.jsonl\n```\n\nEach entry includes:\n- `target_text`: Materialized path (e.g., `s243a > Root > Science > Physics`)\n- `query`: Formatted query based on style (`locate_node(\"Physics\")`)\n- `cluster_id`: Parent folder URI\n- `type`: Tree, PagePearl, NotePearl, or RefPearl\n\nQuery styles: `raw` (title only), `locate` (Prolog), `file` (bookmark filing), `similar` (similarity search). Use `--pearls-only` for bookmarks only.\n\nSee skill_pearl_dataset.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pearl_dataset_002_q1", "cluster_id": "skill_pearl_dataset_002", "question": "How do I prepare bookmark data for embedding models?", "answer": "To prepare bookmark data for embedding models, use `generate_pearl_dataset.py` to transform Pearltrees RDF into JSONL format:\n\n```bash\npython scripts/generate_pearl_dataset.py \\\n  --rdf data/s243a.rdf \\\n  --pearls-only \\\n  --query-style raw \\\n  --output reports/bookmarks.jsonl\n```\n\nEach entry contains:\n- `raw_title`: The bookmark title for embedding\n- `external_url`: The bookmark URL\n- `target_text`: Full materialized path (e.g., \"s243a > Root > Science > Physics\")\n- `data_type`: \"pearl\" (PagePearl, NotePearl, or RefPearl)\n- `cluster_id`: Parent folder URI for context\n\nFor embedding, use `--query-style raw` to get just titles, or choose `locate`, `file`, or `similar` for task-specific query formats. The `--pearls-only` flag excludes folder structures and focuses only on bookmarkable items.", "question_type": "medium", "topics": ["Quickstart", "Synthetic Data", "Pearl Dataset Generation"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["semantic-search", "embeddings", "targets", "pearltrees", "bookmarks"], "related_skills": ["skill_pearl_dataset.md", "skill_train_model.md"], "related_docs": ["scripts/generate_pearl_dataset.py"], "original_answer": "Use `generate_pearl_dataset.py` to transform Pearltrees RDF into JSONL targets:\n\n```bash\npython scripts/generate_pearl_dataset.py \\\n  --rdf data/s243a.rdf \\\n  --query-style locate \\\n  --output reports/targets.jsonl\n```\n\nEach entry includes:\n- `target_text`: Materialized path (e.g., `s243a > Root > Science > Physics`)\n- `query`: Formatted query based on style (`locate_node(\"Physics\")`)\n- `cluster_id`: Parent folder URI\n- `type`: Tree, PagePearl, NotePearl, or RefPearl\n\nQuery styles: `raw` (title only), `locate` (Prolog), `file` (bookmark filing), `similar` (similarity search). Use `--pearls-only` for bookmarks only.\n\nSee skill_pearl_dataset.md for details.", "answer_tailored": true, "confidence": 0.82, "confidence_issues": "The base answer focuses on query styles and dataset structure rather than embedding-specific concerns like text preprocessing, tokenization, or model input formats. The tailored answer assumes 'raw' query style is best for embeddings, but optimal preprocessing depends on the specific embedding model being used."}
{"pair_id": "skill_pearl_dataset_002_q2", "cluster_id": "skill_pearl_dataset_002", "question": "What's the format for semantic search training data?", "answer": "Semantic search training data uses JSONL format generated from Pearltrees RDF exports. Each entry contains: `target_text` (materialized path like \"s243a > Root > Science > Physics\"), `query` (formatted query based on style), `cluster_id` (parent folder URI), `type` (Tree, PagePearl, NotePearl, or RefPearl), and `data_type` (\"tree\" or \"pearl\"). Generate with: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --query-style locate --output reports/targets.jsonl`. Query styles available: `raw` (title only), `locate` (Prolog-style), `file` (bookmark filing), `similar` (similarity search). Use `--pearls-only` for bookmarks only or `--trees-only` for folders only.", "question_type": "medium", "topics": ["Quickstart", "Synthetic Data", "Pearl Dataset Generation"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["semantic-search", "embeddings", "targets", "pearltrees", "bookmarks"], "related_skills": ["skill_pearl_dataset.md", "skill_train_model.md"], "related_docs": ["scripts/generate_pearl_dataset.py"], "original_answer": "Use `generate_pearl_dataset.py` to transform Pearltrees RDF into JSONL targets:\n\n```bash\npython scripts/generate_pearl_dataset.py \\\n  --rdf data/s243a.rdf \\\n  --query-style locate \\\n  --output reports/targets.jsonl\n```\n\nEach entry includes:\n- `target_text`: Materialized path (e.g., `s243a > Root > Science > Physics`)\n- `query`: Formatted query based on style (`locate_node(\"Physics\")`)\n- `cluster_id`: Parent folder URI\n- `type`: Tree, PagePearl, NotePearl, or RefPearl\n\nQuery styles: `raw` (title only), `locate` (Prolog), `file` (bookmark filing), `similar` (similarity search). Use `--pearls-only` for bookmarks only.\n\nSee skill_pearl_dataset.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pearl_dataset_002_q3", "cluster_id": "skill_pearl_dataset_002", "question": "How do I create hierarchical training targets?", "answer": "To create hierarchical training targets from Pearltrees, use the `generate_pearl_dataset.py` script:\n\n```bash\npython scripts/generate_pearl_dataset.py \\\n  --rdf data/s243a.rdf \\\n  --output reports/targets.jsonl\n```\n\nEach target entry includes a materialized path hierarchy in `target_text` (e.g., `s243a > Root > Science > Physics`), a formatted `query` field, and `cluster_id` pointing to the parent folder. Choose a `--query-style`:\n\n- `raw`: Just the title\n- `locate`: Prolog-style `locate_node(\"Title\")` format\n- `locate_object`: Typed `locate_object(tree, \"Title\")` format\n- `file`: Bookmark filing `file_bookmark(\"url\", \"title\")` format\n- `similar`: Similarity search format\n- `browse`: Folder navigation format\n\nFor multi-level hierarchies with cross-references across multiple Pearltrees accounts, add `--rdf data/account1.rdf data/account2.rdf --cross-account`. Use `--pearls-only` to include only bookmarks or `--trees-only` for folders only.", "question_type": "medium", "topics": ["Quickstart", "Synthetic Data", "Pearl Dataset Generation"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["semantic-search", "embeddings", "targets", "pearltrees", "bookmarks"], "related_skills": ["skill_pearl_dataset.md", "skill_train_model.md"], "related_docs": ["scripts/generate_pearl_dataset.py"], "original_answer": "Use `generate_pearl_dataset.py` to transform Pearltrees RDF into JSONL targets:\n\n```bash\npython scripts/generate_pearl_dataset.py \\\n  --rdf data/s243a.rdf \\\n  --query-style locate \\\n  --output reports/targets.jsonl\n```\n\nEach entry includes:\n- `target_text`: Materialized path (e.g., `s243a > Root > Science > Physics`)\n- `query`: Formatted query based on style (`locate_node(\"Physics\")`)\n- `cluster_id`: Parent folder URI\n- `type`: Tree, PagePearl, NotePearl, or RefPearl\n\nQuery styles: `raw` (title only), `locate` (Prolog), `file` (bookmark filing), `similar` (similarity search). Use `--pearls-only` for bookmarks only.\n\nSee skill_pearl_dataset.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pearl_dataset_003_q0", "cluster_id": "skill_pearl_dataset_003", "question": "How do I handle multiple Pearltrees accounts in my dataset?", "answer": "To handle multiple Pearltrees accounts in your dataset, use the `--cross-account` flag with multiple RDF files:\n\n```bash\npython scripts/generate_pearl_dataset.py \\\n  --rdf data/s243a.rdf data/groups.rdf \\\n  --cross-account \\\n  --output reports/multi_targets.jsonl\n```\n\nThis processes all accounts together and tracks cross-account references. RefPearls that reference items in other accounts will show the boundary marker (e.g., `s243a > Root > Shared > Physics \u2192 @other_account`).\n\nTo extract training data for a single account from the multi-account dataset:\n\n```bash\npython scripts/generate_account_training_data.py \\\n  --input reports/multi_targets.jsonl \\\n  --account s243a \\\n  --output reports/s243a_only.jsonl\n```\n\nThis allows you to generate both unified multi-account datasets and isolated single-account subsets as needed.", "question_type": "long", "topics": ["Quickstart", "Synthetic Data", "Pearl Dataset Generation", "Multi-Account"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["multi-account", "cross-references", "pearltrees", "rdf"], "related_skills": ["skill_pearl_dataset.md"], "related_docs": ["scripts/generate_pearl_dataset.py", "scripts/generate_account_training_data.py", "scripts/pearltrees_multi_account_generator.py"], "original_answer": "Process multiple RDF files with `--cross-account` to track references between accounts:\n\n```bash\npython scripts/generate_pearl_dataset.py \\\n  --rdf data/s243a.rdf data/groups.rdf \\\n  --cross-account \\\n  --output reports/multi_targets.jsonl\n```\n\nCross-account RefPearls show account boundaries: `s243a > Root > Shared > Physics \u2192 @other_account`\n\nTo extract single account:\n```bash\npython scripts/generate_account_training_data.py \\\n  --input reports/multi_targets.jsonl \\\n  --account s243a \\\n  --output reports/s243a_only.jsonl\n```\n\nSee skill_pearl_dataset.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pearl_dataset_003_q1", "cluster_id": "skill_pearl_dataset_003", "question": "Can I combine datasets from different Pearltrees accounts?", "answer": "Yes, you can combine datasets from different Pearltrees accounts. Process multiple RDF files together with the `--cross-account` flag:\n\n```bash\npython scripts/generate_pearl_dataset.py \\\n  --rdf data/s243a.rdf data/groups.rdf \\\n  --cross-account \\\n  --output reports/multi_targets.jsonl\n```\n\nThis generates a combined dataset where cross-account RefPearls show account boundaries (e.g., `s243a > Root > Shared > Physics \u2192 @other_account`). If you later need to extract data for a single account:\n\n```bash\npython scripts/generate_account_training_data.py \\\n  --input reports/multi_targets.jsonl \\\n  --account s243a \\\n  --output reports/s243a_only.jsonl\n```", "question_type": "long", "topics": ["Quickstart", "Synthetic Data", "Pearl Dataset Generation", "Multi-Account"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["multi-account", "cross-references", "pearltrees", "rdf"], "related_skills": ["skill_pearl_dataset.md"], "related_docs": ["scripts/generate_pearl_dataset.py", "scripts/generate_account_training_data.py", "scripts/pearltrees_multi_account_generator.py"], "original_answer": "Process multiple RDF files with `--cross-account` to track references between accounts:\n\n```bash\npython scripts/generate_pearl_dataset.py \\\n  --rdf data/s243a.rdf data/groups.rdf \\\n  --cross-account \\\n  --output reports/multi_targets.jsonl\n```\n\nCross-account RefPearls show account boundaries: `s243a > Root > Shared > Physics \u2192 @other_account`\n\nTo extract single account:\n```bash\npython scripts/generate_account_training_data.py \\\n  --input reports/multi_targets.jsonl \\\n  --account s243a \\\n  --output reports/s243a_only.jsonl\n```\n\nSee skill_pearl_dataset.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pearl_dataset_003_q2", "cluster_id": "skill_pearl_dataset_003", "question": "How do I track cross-account references in Pearltrees?", "answer": "Track cross-account references in Pearltrees by processing multiple RDF files with the `--cross-account` flag. Run: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf data/groups.rdf --cross-account --output reports/multi_targets.jsonl`. Cross-account RefPearls display as boundaries like `s243a > Root > Shared > Physics \u2192 @other_account`, showing which account the reference points to. To later extract a single account's data: `python scripts/generate_account_training_data.py --input reports/multi_targets.jsonl --account s243a --output reports/s243a_only.jsonl`.", "question_type": "long", "topics": ["Quickstart", "Synthetic Data", "Pearl Dataset Generation", "Multi-Account"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["multi-account", "cross-references", "pearltrees", "rdf"], "related_skills": ["skill_pearl_dataset.md"], "related_docs": ["scripts/generate_pearl_dataset.py", "scripts/generate_account_training_data.py", "scripts/pearltrees_multi_account_generator.py"], "original_answer": "Process multiple RDF files with `--cross-account` to track references between accounts:\n\n```bash\npython scripts/generate_pearl_dataset.py \\\n  --rdf data/s243a.rdf data/groups.rdf \\\n  --cross-account \\\n  --output reports/multi_targets.jsonl\n```\n\nCross-account RefPearls show account boundaries: `s243a > Root > Shared > Physics \u2192 @other_account`\n\nTo extract single account:\n```bash\npython scripts/generate_account_training_data.py \\\n  --input reports/multi_targets.jsonl \\\n  --account s243a \\\n  --output reports/s243a_only.jsonl\n```\n\nSee skill_pearl_dataset.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pearl_dataset_003_q3", "cluster_id": "skill_pearl_dataset_003", "question": "How do I process multiple RDF files together?", "answer": "Process multiple RDF files with `--cross-account` to track references between accounts:\n\n```bash\npython scripts/generate_pearl_dataset.py \\\n  --rdf data/s243a.rdf data/groups.rdf \\\n  --cross-account \\\n  --output reports/multi_targets.jsonl\n```\n\nThis generates a single JSONL file containing entries from all provided RDF files. Cross-account RefPearls show account boundaries using the notation: `s243a > Root > Shared > Physics \u2192 @other_account`\n\nTo later extract data from a single account:\n\n```bash\npython scripts/generate_account_training_data.py \\\n  --input reports/multi_targets.jsonl \\\n  --account s243a \\\n  --output reports/s243a_only.jsonl\n```", "question_type": "long", "topics": ["Quickstart", "Synthetic Data", "Pearl Dataset Generation", "Multi-Account"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["multi-account", "cross-references", "pearltrees", "rdf"], "related_skills": ["skill_pearl_dataset.md"], "related_docs": ["scripts/generate_pearl_dataset.py", "scripts/generate_account_training_data.py", "scripts/pearltrees_multi_account_generator.py"], "original_answer": "Process multiple RDF files with `--cross-account` to track references between accounts:\n\n```bash\npython scripts/generate_pearl_dataset.py \\\n  --rdf data/s243a.rdf data/groups.rdf \\\n  --cross-account \\\n  --output reports/multi_targets.jsonl\n```\n\nCross-account RefPearls show account boundaries: `s243a > Root > Shared > Physics \u2192 @other_account`\n\nTo extract single account:\n```bash\npython scripts/generate_account_training_data.py \\\n  --input reports/multi_targets.jsonl \\\n  --account s243a \\\n  --output reports/s243a_only.jsonl\n```\n\nSee skill_pearl_dataset.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pearl_dataset_004_q0", "cluster_id": "skill_pearl_dataset_004", "question": "How do I add folder relationships to my Pearltrees dataset?", "answer": "To add folder relationships to your Pearltrees dataset, generate synthetic RefPearls from your existing hierarchy using the `generate_tree_refpearls.py` script:\n\n```bash\npython scripts/generate_tree_refpearls.py \\\n  --input reports/pearltrees_targets.jsonl \\\n  --output reports/targets_with_refs.jsonl\n```\n\nThis script infers parent-child relationships from the `cluster_id` field in your dataset and creates RefPearl entries marked with `_source: \"hierarchy_inference\"`. RefPearls represent folder references and cross-account links, which enriches your dataset for training folder suggestion models.\n\nFor a complete workflow: (1) Generate your base dataset with `generate_pearl_dataset.py`, (2) add synthetic folder relationships with `generate_tree_refpearls.py`, (3) generate embeddings, and (4) train your model.", "question_type": "long", "topics": ["Quickstart", "Synthetic Data", "Pearl Dataset Generation", "RefPearl Generation"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["refpearls", "hierarchy", "synthetic-data", "relationships", "pearltrees"], "related_skills": ["skill_pearl_dataset.md", "skill_train_model.md", "skill_bookmark_filing.md"], "related_docs": ["scripts/generate_tree_refpearls.py", "scripts/train_pearltrees_federated.py"], "original_answer": "Generate synthetic RefPearls from existing hierarchy using `cluster_id` relationships:\n\n```bash\npython scripts/generate_tree_refpearls.py \\\n  --input reports/pearltrees_targets.jsonl \\\n  --output reports/targets_with_refs.jsonl\n```\n\nThis infers parent-child relationships and creates RefPearl entries marked with `_source: \"hierarchy_inference\"`. RefPearls represent folder references and cross-account links, enriching the dataset for training folder suggestion models.\n\nFull workflow:\n1. Generate base dataset with `generate_pearl_dataset.py`\n2. Add synthetic refs with `generate_tree_refpearls.py`\n3. Generate embeddings with `generate_embeddings.py`\n4. Train model with `train_pearltrees_federated.py`\n\nSee skill_pearl_dataset.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pearl_dataset_004_q1", "cluster_id": "skill_pearl_dataset_004", "question": "How do I generate RefPearls from hierarchy?", "answer": "Generate synthetic RefPearls from existing hierarchy using the `cluster_id` relationships. Run `python scripts/generate_tree_refpearls.py --input reports/pearltrees_targets.jsonl --output reports/targets_with_refs.jsonl`. This script infers parent-child relationships from the base dataset and creates RefPearl entries marked with `_source: \"hierarchy_inference\"`. RefPearls represent folder references and cross-account links, which enriches the dataset for training folder suggestion models. Use this as step 2 after generating your base dataset with `generate_pearl_dataset.py`, before generating embeddings or training.", "question_type": "long", "topics": ["Quickstart", "Synthetic Data", "Pearl Dataset Generation", "RefPearl Generation"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["refpearls", "hierarchy", "synthetic-data", "relationships", "pearltrees"], "related_skills": ["skill_pearl_dataset.md", "skill_train_model.md", "skill_bookmark_filing.md"], "related_docs": ["scripts/generate_tree_refpearls.py", "scripts/train_pearltrees_federated.py"], "original_answer": "Generate synthetic RefPearls from existing hierarchy using `cluster_id` relationships:\n\n```bash\npython scripts/generate_tree_refpearls.py \\\n  --input reports/pearltrees_targets.jsonl \\\n  --output reports/targets_with_refs.jsonl\n```\n\nThis infers parent-child relationships and creates RefPearl entries marked with `_source: \"hierarchy_inference\"`. RefPearls represent folder references and cross-account links, enriching the dataset for training folder suggestion models.\n\nFull workflow:\n1. Generate base dataset with `generate_pearl_dataset.py`\n2. Add synthetic refs with `generate_tree_refpearls.py`\n3. Generate embeddings with `generate_embeddings.py`\n4. Train model with `train_pearltrees_federated.py`\n\nSee skill_pearl_dataset.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pearl_dataset_004_q2", "cluster_id": "skill_pearl_dataset_004", "question": "Can I infer parent-child relationships from my data?", "answer": "Yes, you can infer parent-child relationships from your Pearltrees data using the `cluster_id` field. Each pearl and tree node includes a `cluster_id` that links it to its parent folder. To automatically generate synthetic RefPearls that represent these inferred parent-child relationships, use: `python scripts/generate_tree_refpearls.py --input reports/pearltrees_targets.jsonl --output reports/targets_with_refs.jsonl`. This creates RefPearl entries marked with `_source: \"hierarchy_inference\"` that capture folder relationships. These synthetic relationships enrich your dataset for training folder suggestion models and can be combined with embeddings for semantic search tasks.", "question_type": "long", "topics": ["Quickstart", "Synthetic Data", "Pearl Dataset Generation", "RefPearl Generation"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["refpearls", "hierarchy", "synthetic-data", "relationships", "pearltrees"], "related_skills": ["skill_pearl_dataset.md", "skill_train_model.md", "skill_bookmark_filing.md"], "related_docs": ["scripts/generate_tree_refpearls.py", "scripts/train_pearltrees_federated.py"], "original_answer": "Generate synthetic RefPearls from existing hierarchy using `cluster_id` relationships:\n\n```bash\npython scripts/generate_tree_refpearls.py \\\n  --input reports/pearltrees_targets.jsonl \\\n  --output reports/targets_with_refs.jsonl\n```\n\nThis infers parent-child relationships and creates RefPearl entries marked with `_source: \"hierarchy_inference\"`. RefPearls represent folder references and cross-account links, enriching the dataset for training folder suggestion models.\n\nFull workflow:\n1. Generate base dataset with `generate_pearl_dataset.py`\n2. Add synthetic refs with `generate_tree_refpearls.py`\n3. Generate embeddings with `generate_embeddings.py`\n4. Train model with `train_pearltrees_federated.py`\n\nSee skill_pearl_dataset.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_pearl_dataset_004_q3", "cluster_id": "skill_pearl_dataset_004", "question": "How do I enrich my Pearltrees dataset with synthetic references?", "answer": "Enrich your Pearltrees dataset with synthetic references by generating RefPearls from existing hierarchy relationships:\n\n```bash\npython scripts/generate_tree_refpearls.py \\\n  --input reports/pearltrees_targets.jsonl \\\n  --output reports/targets_with_refs.jsonl\n```\n\nThis script infers parent-child relationships from `cluster_id` fields and creates RefPearl entries marked with `_source: \"hierarchy_inference\"`. RefPearls represent folder references and cross-account links, enriching your dataset for training folder suggestion and semantic search models.\n\nWorkflow: (1) Generate base dataset with `generate_pearl_dataset.py`, (2) Add synthetic refs with `generate_tree_refpearls.py`, (3) Generate embeddings, (4) Train your model.", "question_type": "long", "topics": ["Quickstart", "Synthetic Data", "Pearl Dataset Generation", "RefPearl Generation"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["refpearls", "hierarchy", "synthetic-data", "relationships", "pearltrees"], "related_skills": ["skill_pearl_dataset.md", "skill_train_model.md", "skill_bookmark_filing.md"], "related_docs": ["scripts/generate_tree_refpearls.py", "scripts/train_pearltrees_federated.py"], "original_answer": "Generate synthetic RefPearls from existing hierarchy using `cluster_id` relationships:\n\n```bash\npython scripts/generate_tree_refpearls.py \\\n  --input reports/pearltrees_targets.jsonl \\\n  --output reports/targets_with_refs.jsonl\n```\n\nThis infers parent-child relationships and creates RefPearl entries marked with `_source: \"hierarchy_inference\"`. RefPearls represent folder references and cross-account links, enriching the dataset for training folder suggestion models.\n\nFull workflow:\n1. Generate base dataset with `generate_pearl_dataset.py`\n2. Add synthetic refs with `generate_tree_refpearls.py`\n3. Generate embeddings with `generate_embeddings.py`\n4. Train model with `train_pearltrees_federated.py`\n\nSee skill_pearl_dataset.md for details.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_synthetic_data_001_q0", "cluster_id": "skill_synthetic_data_001", "question": "How do I generate training data from skill files?", "answer": "Use generate_qa_from_skills.py to generate training data from skill files. Run `python training-data/scripts/generate_qa_from_skills.py --skill skill_mindmap_linking.md --model haiku` for a single skill, or `--all` to process all skills. The tool supports both Claude and Gemini providers. Generated Q&A pairs are saved to by-topic/<topic>/skills-generated.jsonl with fields: question, question_variants, level, tree_path, answer, related_skills, and related_docs.", "question_type": "medium", "topics": ["Data", "Synthetic Data", "Q&A Generation"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["training", "qa", "generation", "skills"], "related_skills": ["skill_synthetic_data.md", "skill_qa_generation.md"], "related_docs": ["training-data/scripts/generate_qa_from_skills.py"], "original_answer": "Use generate_qa_from_skills.py: `python training-data/scripts/generate_qa_from_skills.py --skill skill_mindmap_linking.md --model haiku`. For all skills: `--all`. Supports Claude and Gemini providers. Output goes to by-topic/<topic>/skills-generated.jsonl with question, variants, level, tree_path, answer, and related_skills fields.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_synthetic_data_001_q1", "cluster_id": "skill_synthetic_data_001", "question": "Can I create Q&A pairs automatically?", "answer": "Yes, use generate_qa_from_skills.py to automatically create Q&A pairs from skill documents. Run `python training-data/scripts/generate_qa_from_skills.py --skill skill_mindmap_linking.md --model haiku` for a single skill, or use `--all` to generate from all skills. The tool supports both Claude and Gemini providers and outputs JSONL files to by-topic/<topic>/skills-generated.jsonl with question variants, confidence levels, hierarchy paths, answers, and related skill references.", "question_type": "medium", "topics": ["Data", "Synthetic Data", "Q&A Generation"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["training", "qa", "generation", "skills"], "related_skills": ["skill_synthetic_data.md", "skill_qa_generation.md"], "related_docs": ["training-data/scripts/generate_qa_from_skills.py"], "original_answer": "Use generate_qa_from_skills.py: `python training-data/scripts/generate_qa_from_skills.py --skill skill_mindmap_linking.md --model haiku`. For all skills: `--all`. Supports Claude and Gemini providers. Output goes to by-topic/<topic>/skills-generated.jsonl with question, variants, level, tree_path, answer, and related_skills fields.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_synthetic_data_001_q2", "cluster_id": "skill_synthetic_data_001", "question": "How do I bootstrap training data?", "answer": "To bootstrap training data, use generate_qa_from_skills.py. Run `python training-data/scripts/generate_qa_from_skills.py --skill skill_mindmap_linking.md --model haiku` for a single skill, or `--all` to generate from all skills. The tool supports Claude and Gemini providers and outputs JSONL files to by-topic/<topic>/skills-generated.jsonl containing question, variants, level, tree_path, answer, and related_skills fields.", "question_type": "medium", "topics": ["Data", "Synthetic Data", "Q&A Generation"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["training", "qa", "generation", "skills"], "related_skills": ["skill_synthetic_data.md", "skill_qa_generation.md"], "related_docs": ["training-data/scripts/generate_qa_from_skills.py"], "original_answer": "Use generate_qa_from_skills.py: `python training-data/scripts/generate_qa_from_skills.py --skill skill_mindmap_linking.md --model haiku`. For all skills: `--all`. Supports Claude and Gemini providers. Output goes to by-topic/<topic>/skills-generated.jsonl with question, variants, level, tree_path, answer, and related_skills fields.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_synthetic_data_002_q0", "cluster_id": "skill_synthetic_data_002", "question": "How do I reword or tailor generated answers?", "answer": "Use the `generate_tailored_answers.py` script to reword answers: `python scripts/generate_tailored_answers.py --input training-data/expanded --model sonnet`. This tool uses LLMs to create reworded versions of existing answers, increasing training data diversity. You can specify Claude (default with `--provider claude`) or Gemini (`--provider gemini`) as your LLM backend, and choose from available models like sonnet, haiku, or gemini-2.5-flash-preview.", "question_type": "long", "topics": ["Data", "Synthetic Data", "Answer Tailoring"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["training", "tailoring", "answers", "llm"], "related_skills": ["skill_synthetic_data.md", "skill_answer_tailoring.md"], "related_docs": ["scripts/generate_tailored_answers.py"], "original_answer": "Use generate_tailored_answers.py: `python scripts/generate_tailored_answers.py --input training-data/expanded --model sonnet`. This uses LLMs to create reworded versions of existing answers for training diversity. Supports both Claude (--provider claude) and Gemini (--provider gemini) backends.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_synthetic_data_002_q1", "cluster_id": "skill_synthetic_data_002", "question": "Can I improve generated answers?", "answer": "Yes, you can improve generated answers using the generate_tailored_answers.py script. Run: `python scripts/generate_tailored_answers.py --input training-data/expanded --model sonnet`. This uses LLMs to reword and enhance existing answers for better training diversity. You can choose between Claude (default with --provider claude) or Gemini (--provider gemini) backends, selecting models like sonnet, opus, or haiku for Claude.", "question_type": "long", "topics": ["Data", "Synthetic Data", "Answer Tailoring"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["training", "tailoring", "answers", "llm"], "related_skills": ["skill_synthetic_data.md", "skill_answer_tailoring.md"], "related_docs": ["scripts/generate_tailored_answers.py"], "original_answer": "Use generate_tailored_answers.py: `python scripts/generate_tailored_answers.py --input training-data/expanded --model sonnet`. This uses LLMs to create reworded versions of existing answers for training diversity. Supports both Claude (--provider claude) and Gemini (--provider gemini) backends.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_synthetic_data_002_q2", "cluster_id": "skill_synthetic_data_002", "question": "How do I create answer variations?", "answer": "Use the `generate_tailored_answers.py` script to create answer variations: `python scripts/generate_tailored_answers.py --input training-data/expanded --model sonnet`. This tool uses LLMs to generate reworded versions of existing answers, increasing training diversity. You can choose between Claude (default, with sonnet/opus/haiku models) or Gemini backends using the `--provider` flag.", "question_type": "long", "topics": ["Data", "Synthetic Data", "Answer Tailoring"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["training", "tailoring", "answers", "llm"], "related_skills": ["skill_synthetic_data.md", "skill_answer_tailoring.md"], "related_docs": ["scripts/generate_tailored_answers.py"], "original_answer": "Use generate_tailored_answers.py: `python scripts/generate_tailored_answers.py --input training-data/expanded --model sonnet`. This uses LLMs to create reworded versions of existing answers for training diversity. Supports both Claude (--provider claude) and Gemini (--provider gemini) backends.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_synthetic_data_003_q0", "cluster_id": "skill_synthetic_data_003", "question": "How do I generate Pearltrees training datasets?", "answer": "Use the `generate_pearl_dataset.py` script to extract Pearltrees training data: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --output reports/pearltrees_targets.jsonl --query-style locate`. This generates JSONL training data containing hierarchical tree paths, questions, and answers suitable for training embedding models or fine-tuning semantic search systems.", "question_type": "long", "topics": ["Data", "Synthetic Data", "Pearltrees"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["pearltrees", "rdf", "training", "dataset"], "related_skills": ["skill_synthetic_data.md", "skill_pearl_dataset.md"], "related_docs": ["scripts/generate_pearl_dataset.py"], "original_answer": "Use generate_pearl_dataset.py: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --output reports/pearltrees_targets.jsonl --query-style locate`. This extracts hierarchical paths and generates JSONL with question, tree_path, and answer fields suitable for training embedding models or fine-tuning.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_synthetic_data_003_q1", "cluster_id": "skill_synthetic_data_003", "question": "Can I create training data from my Pearltrees?", "answer": "Yes, you can create training data from your Pearltrees using generate_pearl_dataset.py. Run: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --output reports/pearltrees_targets.jsonl --query-style locate`. This extracts your Pearltrees hierarchy and generates JSONL training data with question, tree_path, and answer fields suitable for training embedding models or fine-tuning.", "question_type": "long", "topics": ["Data", "Synthetic Data", "Pearltrees"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["pearltrees", "rdf", "training", "dataset"], "related_skills": ["skill_synthetic_data.md", "skill_pearl_dataset.md"], "related_docs": ["scripts/generate_pearl_dataset.py"], "original_answer": "Use generate_pearl_dataset.py: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --output reports/pearltrees_targets.jsonl --query-style locate`. This extracts hierarchical paths and generates JSONL with question, tree_path, and answer fields suitable for training embedding models or fine-tuning.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_synthetic_data_003_q2", "cluster_id": "skill_synthetic_data_003", "question": "How do I export Pearltrees for training?", "answer": "Use generate_pearl_dataset.py to export Pearltrees for training: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --output reports/pearltrees_targets.jsonl --query-style locate`. This script extracts hierarchical paths from your Pearltrees RDF export and generates JSONL training data with question, tree_path, and answer fields optimized for embedding models or fine-tuning.", "question_type": "long", "topics": ["Data", "Synthetic Data", "Pearltrees"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["pearltrees", "rdf", "training", "dataset"], "related_skills": ["skill_synthetic_data.md", "skill_pearl_dataset.md"], "related_docs": ["scripts/generate_pearl_dataset.py"], "original_answer": "Use generate_pearl_dataset.py: `python scripts/generate_pearl_dataset.py --rdf data/s243a.rdf --output reports/pearltrees_targets.jsonl --query-style locate`. This extracts hierarchical paths and generates JSONL with question, tree_path, and answer fields suitable for training embedding models or fine-tuning.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_qa_generation_001_q0", "cluster_id": "skill_qa_generation_001", "question": "What's the difference between generate_qa_from_skills and generate_quickstart_qa?", "answer": "generate_qa_from_skills.py generates task-oriented Q&A pairs by reading skill markdown files and extracting their 'When to Use' sections and command examples. generate_quickstart_qa.py generates capability-based Q&A pairs by reading SOURCE_MAPPING.md and source code references. Use skills for procedural 'how do I' questions, and quickstart for exploratory 'what can it do' questions.", "question_type": "long", "topics": ["Data", "Synthetic Data", "Q&A Tools"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["qa", "generation", "comparison"], "related_skills": ["skill_qa_generation.md"], "related_docs": ["training-data/scripts/generate_qa_from_skills.py", "training-data/scripts/generate_quickstart_qa.py"], "original_answer": "generate_qa_from_skills.py reads skill markdown files and generates task-oriented Q&A. generate_quickstart_qa.py reads SOURCE_MAPPING.md and generates capability-based Q&A from source code references. Use skills for 'how do I' questions, quickstart for 'what can it do' questions.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_qa_generation_001_q1", "cluster_id": "skill_qa_generation_001", "question": "Which Q&A generator should I use?", "answer": "Use generate_qa_from_skills.py for task-oriented Q&A pairs from skill markdown files (answering 'how do I' questions). Use generate_quickstart_qa.py for capability-based Q&A pairs from SOURCE_MAPPING.md source code references (answering 'what can it do' questions). Choose based on whether your training data needs procedural knowledge or capability discovery.", "question_type": "long", "topics": ["Data", "Synthetic Data", "Q&A Tools"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["qa", "generation", "comparison"], "related_skills": ["skill_qa_generation.md"], "related_docs": ["training-data/scripts/generate_qa_from_skills.py", "training-data/scripts/generate_quickstart_qa.py"], "original_answer": "generate_qa_from_skills.py reads skill markdown files and generates task-oriented Q&A. generate_quickstart_qa.py reads SOURCE_MAPPING.md and generates capability-based Q&A from source code references. Use skills for 'how do I' questions, quickstart for 'what can it do' questions.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_qa_generation_001_q2", "cluster_id": "skill_qa_generation_001", "question": "How do the Q&A tools differ?", "answer": "The Q&A tools differ in their sources and question types. generate_qa_from_skills.py reads skill markdown files and generates task-oriented Q&A pairs (best for 'how do I' questions), while generate_quickstart_qa.py reads SOURCE_MAPPING.md and generates capability-based Q&A from source code references (best for 'what can it do' questions). Skills focus on concrete usage patterns and commands, whereas quickstart focuses on capabilities and their implementation.", "question_type": "long", "topics": ["Data", "Synthetic Data", "Q&A Tools"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["qa", "generation", "comparison"], "related_skills": ["skill_qa_generation.md"], "related_docs": ["training-data/scripts/generate_qa_from_skills.py", "training-data/scripts/generate_quickstart_qa.py"], "original_answer": "generate_qa_from_skills.py reads skill markdown files and generates task-oriented Q&A. generate_quickstart_qa.py reads SOURCE_MAPPING.md and generates capability-based Q&A from source code references. Use skills for 'how do I' questions, quickstart for 'what can it do' questions.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_qa_generation_002_q0", "cluster_id": "skill_qa_generation_002", "question": "How do I check which skills are missing training data?", "answer": "Run `python training-data/scripts/generate_qa_from_skills.py --coverage` to check which skills are missing training data. This command analyzes skill coverage gaps and displays existing skills with checkmarks, missing skills (capability tree items without corresponding skill files), and suggests new skills to create. Use this output to prioritize your Q&A generation efforts.", "question_type": "long", "topics": ["Data", "Synthetic Data", "Coverage"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["coverage", "analysis", "skills", "gaps"], "related_skills": ["skill_qa_generation.md"], "related_docs": ["training-data/scripts/generate_qa_from_skills.py"], "original_answer": "Run coverage analysis: `python training-data/scripts/generate_qa_from_skills.py --coverage`. This shows existing skills with checkmarks, missing skills (capability tree items without skill files), and suggests new skills to create. Use to prioritize Q&A generation efforts.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_qa_generation_002_q1", "cluster_id": "skill_qa_generation_002", "question": "How do I find gaps in training coverage?", "answer": "Run the coverage analysis command: `python training-data/scripts/generate_qa_from_skills.py --coverage`. This will identify which capabilities in the skill tree have corresponding skill files (marked with checkmarks) and which are missing skills. The output also suggests new skills you should create to fill coverage gaps, helping you prioritize Q&A generation efforts.", "question_type": "long", "topics": ["Data", "Synthetic Data", "Coverage"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["coverage", "analysis", "skills", "gaps"], "related_skills": ["skill_qa_generation.md"], "related_docs": ["training-data/scripts/generate_qa_from_skills.py"], "original_answer": "Run coverage analysis: `python training-data/scripts/generate_qa_from_skills.py --coverage`. This shows existing skills with checkmarks, missing skills (capability tree items without skill files), and suggests new skills to create. Use to prioritize Q&A generation efforts.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_qa_generation_002_q2", "cluster_id": "skill_qa_generation_002", "question": "Which skills need Q&A pairs?", "answer": "Run `python training-data/scripts/generate_qa_from_skills.py --coverage` to identify which skills need Q&A pairs. This command analyzes skill coverage gaps and shows: existing skills with checkmarks, missing skills (capability tree items without skill files), and suggests new skills to prioritize for Q&A generation.", "question_type": "long", "topics": ["Data", "Synthetic Data", "Coverage"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["coverage", "analysis", "skills", "gaps"], "related_skills": ["skill_qa_generation.md"], "related_docs": ["training-data/scripts/generate_qa_from_skills.py"], "original_answer": "Run coverage analysis: `python training-data/scripts/generate_qa_from_skills.py --coverage`. This shows existing skills with checkmarks, missing skills (capability tree items without skill files), and suggests new skills to create. Use to prioritize Q&A generation efforts.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_qa_generation_003_q0", "cluster_id": "skill_qa_generation_003", "question": "What do the level numbers mean in training data?", "answer": "In training data, levels indicate the specificity of questions: Level 0 covers identity (fundamental definitions like 'What is UnifyWeaver?'), Level 1 covers capabilities (general abilities like 'What can it compile to?'), Level 2 covers general tasks (broader usage patterns like 'How do I organize mindmaps?'), Level 3 covers specific tasks (concrete procedures like 'How do I use MST clustering?'), and Level 4 covers implementation details (specific parameters like 'What's the --target-size parameter?'). Use this hierarchy to match question types with appropriate training data levels for consistency.", "question_type": "medium", "topics": ["Data", "Synthetic Data", "Levels"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["levels", "specificity", "training"], "related_skills": ["skill_qa_generation.md"], "related_docs": ["training-data/by-topic/SOURCE_MAPPING.md"], "original_answer": "Levels indicate question specificity: 0=Identity ('What is UnifyWeaver?'), 1=Capabilities ('What can it compile to?'), 2=General task ('How do I organize mindmaps?'), 3=Specific task ('How do I use MST clustering?'), 4=Details ('What's the --target-size parameter?'). Match level to question type for consistent training data.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_qa_generation_003_q1", "cluster_id": "skill_qa_generation_003", "question": "How are Q&A levels defined?", "answer": "Q&A levels are defined by question specificity: Level 0 asks about identity ('What is UnifyWeaver?'), Level 1 about capabilities ('What can it compile to?'), Level 2 about general tasks ('How do I organize mindmaps?'), Level 3 about specific tasks ('How do I use MST clustering?'), and Level 4 about implementation details ('What's the --target-size parameter?'). Select the appropriate level based on the type of question you're asking to ensure consistent training data.", "question_type": "medium", "topics": ["Data", "Synthetic Data", "Levels"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["levels", "specificity", "training"], "related_skills": ["skill_qa_generation.md"], "related_docs": ["training-data/by-topic/SOURCE_MAPPING.md"], "original_answer": "Levels indicate question specificity: 0=Identity ('What is UnifyWeaver?'), 1=Capabilities ('What can it compile to?'), 2=General task ('How do I organize mindmaps?'), 3=Specific task ('How do I use MST clustering?'), 4=Details ('What's the --target-size parameter?'). Match level to question type for consistent training data.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_qa_generation_003_q2", "cluster_id": "skill_qa_generation_003", "question": "What's level 2 vs level 3?", "answer": "In UnifyWeaver's training data classification, level 2 questions are general task-oriented questions (e.g., 'How do I organize mindmaps?'), while level 3 questions are specific task-oriented questions that drill deeper into particular techniques or workflows (e.g., 'How do I use MST clustering?'). Levels 0-1 handle identity and capability questions, while level 4 addresses detailed parameter-specific questions. Choose the appropriate level based on the specificity and scope of what's being asked.", "question_type": "medium", "topics": ["Data", "Synthetic Data", "Levels"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["levels", "specificity", "training"], "related_skills": ["skill_qa_generation.md"], "related_docs": ["training-data/by-topic/SOURCE_MAPPING.md"], "original_answer": "Levels indicate question specificity: 0=Identity ('What is UnifyWeaver?'), 1=Capabilities ('What can it compile to?'), 2=General task ('How do I organize mindmaps?'), 3=Specific task ('How do I use MST clustering?'), 4=Details ('What's the --target-size parameter?'). Match level to question type for consistent training data.", "answer_tailored": true, "confidence": 0.88, "confidence_issues": null}
{"pair_id": "skill_json_sources_001_q0", "cluster_id": "skill_json_sources_001", "question": "How do I read JSON data in UnifyWeaver?", "answer": "To read JSON data in UnifyWeaver, declare a JSON source using the `source/3` predicate with `json_file()` and `columns()` options. For simple field access, use dot notation and array indices in column names (e.g., `'order.customer.name'`, `'items[0].total'`). For complex selections, use JSONPath syntax like `'$.orders[*].total'`. The predicate arity must match the number of columns you project. Alternatively, use `schema/1` to declare typed records with field definitions, or `return_object(true)` for full JSON objects.", "question_type": "medium", "topics": ["Data", "Sources", "JSON"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["json", "source", "data", "query"], "related_skills": ["skill_json_sources.md", "skill_transpiler_extension.md"], "related_docs": ["src/unifyweaver/sources/json_source.pl"], "original_answer": "Declare a JSON source: `:- source(json, order_totals, [json_file('data/orders.json'), columns(['order.customer.name', 'items[0].product', 'items[0].total'])])`. Column names support dot notation and array indices. Use jsonpath('$.orders[*].total') for complex selectors. The predicate arity matches the column count.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_001_q1", "cluster_id": "skill_json_sources_001", "question": "Can I use JSON files as data sources?", "answer": "Yes, you can use JSON files as data sources. Declare a JSON source using the `source/3` predicate with `json_file('path/to/file.json')`. Use `columns/1` to specify which fields to extract, with support for dot notation (e.g., 'order.customer.name') and array indices (e.g., 'items[0].product'). For complex selections, use JSONPath selectors like `jsonpath('$.orders[*].total')`. The predicate arity must match the number of columns you project.", "question_type": "medium", "topics": ["Data", "Sources", "JSON"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["json", "source", "data", "query"], "related_skills": ["skill_json_sources.md", "skill_transpiler_extension.md"], "related_docs": ["src/unifyweaver/sources/json_source.pl"], "original_answer": "Declare a JSON source: `:- source(json, order_totals, [json_file('data/orders.json'), columns(['order.customer.name', 'items[0].product', 'items[0].total'])])`. Column names support dot notation and array indices. Use jsonpath('$.orders[*].total') for complex selectors. The predicate arity matches the column count.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_001_q2", "cluster_id": "skill_json_sources_001", "question": "How do I query JSON with Prolog?", "answer": "To query JSON with Prolog, declare a JSON source using the `source/3` directive. For column projection, specify `json_file('path/to/file.json')` and list the columns you want to extract using dot notation (e.g., `'order.customer.name'`) or array indices (e.g., `'items[0].product'`). For complex selections, use JSONPath syntax like `'$.orders[*].total'`. The predicate arity must match your column count. Once declared, query the predicate normally: `?- order_totals(Name, Product, Total).` returns rows matching your column projection.", "question_type": "medium", "topics": ["Data", "Sources", "JSON"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["json", "source", "data", "query"], "related_skills": ["skill_json_sources.md", "skill_transpiler_extension.md"], "related_docs": ["src/unifyweaver/sources/json_source.pl"], "original_answer": "Declare a JSON source: `:- source(json, order_totals, [json_file('data/orders.json'), columns(['order.customer.name', 'items[0].product', 'items[0].total'])])`. Column names support dot notation and array indices. Use jsonpath('$.orders[*].total') for complex selectors. The predicate arity matches the column count.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_002_q0", "cluster_id": "skill_json_sources_002", "question": "How do I handle JSON Lines (JSONL) files?", "answer": "To handle JSON Lines (JSONL) files, use the `record_format(jsonl)` parameter in your source declaration. Each line in the file is treated as an independent JSON object. Example: `:- source(json, events, [json_file('data/events.jsonl'), record_format(jsonl), columns([jsonpath('$.type'), jsonpath('$.timestamp')])])`. Control null handling with `null_policy(fail)` to reject records with nulls, `null_policy(skip)` to exclude them, or `null_policy(default('N/A'))` to provide a default value.", "question_type": "long", "topics": ["Data", "Sources", "JSON Lines"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["jsonl", "streaming", "source"], "related_skills": ["skill_json_sources.md"], "related_docs": ["src/unifyweaver/sources/json_source.pl"], "original_answer": "Use record_format(jsonl): `:- source(json, events, [json_file('data/events.jsonl'), record_format(jsonl), columns([jsonpath('$.type'), jsonpath('$.timestamp')])])`. This treats each line as an independent object. Control null handling with null_policy(fail), null_policy(skip), or null_policy(default('N/A')).", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_002_q1", "cluster_id": "skill_json_sources_002", "question": "Can I read JSONL files?", "answer": "Yes, you can read JSONL files using `record_format(jsonl)` in your source declaration. Set up your source like this: `:- source(json, events, [json_file('data/events.jsonl'), record_format(jsonl), columns([jsonpath('$.type'), jsonpath('$.timestamp')])])`. This treats each line as an independent JSON object. You can also control null handling with `null_policy(fail)`, `null_policy(skip)`, or `null_policy(default('N/A'))`.", "question_type": "long", "topics": ["Data", "Sources", "JSON Lines"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["jsonl", "streaming", "source"], "related_skills": ["skill_json_sources.md"], "related_docs": ["src/unifyweaver/sources/json_source.pl"], "original_answer": "Use record_format(jsonl): `:- source(json, events, [json_file('data/events.jsonl'), record_format(jsonl), columns([jsonpath('$.type'), jsonpath('$.timestamp')])])`. This treats each line as an independent object. Control null handling with null_policy(fail), null_policy(skip), or null_policy(default('N/A')).", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_002_q2", "cluster_id": "skill_json_sources_002", "question": "How do I stream newline-delimited JSON?", "answer": "Use `record_format(jsonl)` to stream newline-delimited JSON. Example: `:- source(json, events, [json_file('data/events.jsonl'), record_format(jsonl), columns([jsonpath('$.type'), jsonpath('$.timestamp')])])`. Each line is treated as an independent JSON object. Control null handling with `null_policy(fail)`, `null_policy(skip)`, or `null_policy(default('N/A'))`.", "question_type": "long", "topics": ["Data", "Sources", "JSON Lines"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["jsonl", "streaming", "source"], "related_skills": ["skill_json_sources.md"], "related_docs": ["src/unifyweaver/sources/json_source.pl"], "original_answer": "Use record_format(jsonl): `:- source(json, events, [json_file('data/events.jsonl'), record_format(jsonl), columns([jsonpath('$.type'), jsonpath('$.timestamp')])])`. This treats each line as an independent object. Control null handling with null_policy(fail), null_policy(skip), or null_policy(default('N/A')).", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_003_q0", "cluster_id": "skill_json_sources_003", "question": "How do I get typed records from JSON?", "answer": "Use `schema/1` to declare typed records from JSON. Define a schema with `field(name, jsonpath, type)` entries, set `arity(1)`, and optionally name the record with `record_type('YourRecordName')`. The C# backend automatically generates a POCO class. Example: `:- source(json, products, [json_file('products.json'), schema([field(id, 'id', string), field(name, 'name', string), field(price, 'price', double)]), record_type('ProductRecord')])`. Query with `?- products(Row)` to get strongly-typed ProductRecord objects.", "question_type": "long", "topics": ["Data", "Sources", "JSON Schema"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["json", "schema", "record", "typed"], "related_skills": ["skill_json_sources.md"], "related_docs": ["src/unifyweaver/sources/json_source.pl"], "original_answer": "Use schema/1 for typed records: `:- source(json, products, [json_file('products.json'), schema([field(id, 'id', string), field(name, 'name', string), field(price, 'price', double)]), record_type('ProductRecord')])`. The C# backend generates a POCO; predicate arity must be 1 with return_object(true) implied.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
{"pair_id": "skill_json_sources_003_q1", "cluster_id": "skill_json_sources_003", "question": "Can I generate POCOs from JSON?", "answer": "Yes, you can generate POCOs from JSON using the `schema/1` declaration. Define a schema with `field()` entries specifying field names, JSON paths, and types. Set `record_type('YourRecordName')` to name the generated POCO. The C# backend will automatically generate a typed record class. Example: `:- source(json, products, [json_file('products.json'), schema([field(id, 'id', string), field(name, 'name', string), field(price, 'price', double)]), record_type('ProductRecord')])`. The predicate arity must be 1; `return_object(true)` is implied.", "question_type": "long", "topics": ["Data", "Sources", "JSON Schema"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["json", "schema", "record", "typed"], "related_skills": ["skill_json_sources.md"], "related_docs": ["src/unifyweaver/sources/json_source.pl"], "original_answer": "Use schema/1 for typed records: `:- source(json, products, [json_file('products.json'), schema([field(id, 'id', string), field(name, 'name', string), field(price, 'price', double)]), record_type('ProductRecord')])`. The C# backend generates a POCO; predicate arity must be 1 with return_object(true) implied.", "answer_tailored": true, "confidence": 0.95, "confidence_issues": null}
{"pair_id": "skill_json_sources_003_q2", "cluster_id": "skill_json_sources_003", "question": "How do I use schema with JSON sources?", "answer": "To use schema with JSON sources, declare a `schema/1` parameter with an array of `field(Name, Path, Type)` entries. The predicate arity must be 1, and optionally specify `record_type('YourRecordName')` to name the generated POCO. Example: `:- source(json, products, [json_file('products.json'), schema([field(id, 'id', string), field(name, 'name', string), field(price, 'price', double)]), record_type('ProductRecord')])`. The C# backend automatically generates typed records from the schema definition.", "question_type": "long", "topics": ["Data", "Sources", "JSON Schema"], "source_file": "by-topic/synthetic-data/skills-generated.jsonl", "tags": ["json", "schema", "record", "typed"], "related_skills": ["skill_json_sources.md"], "related_docs": ["src/unifyweaver/sources/json_source.pl"], "original_answer": "Use schema/1 for typed records: `:- source(json, products, [json_file('products.json'), schema([field(id, 'id', string), field(name, 'name', string), field(price, 'price', double)]), record_type('ProductRecord')])`. The C# backend generates a POCO; predicate arity must be 1 with return_object(true) implied.", "answer_tailored": true, "confidence": 0.92, "confidence_issues": null}
