{"cluster_id": "partitioning-overview", "seed_level": 2, "source_files": ["education/book-02-bash-target/10_partitioning_and_parallel_execution.md"], "topics": ["partitioning", "parallelism", "data-processing"], "questions": ["What is partitioning in UnifyWeaver?", "Why partition data?", "What partitioning strategies are available?", "How does partitioning enable parallelism?"], "answer": {"text": "## Partitioning and Parallelism\n\n**Partitioning** divides data into smaller, manageable chunks for:\n\n1. **Parallelism** - Process multiple chunks across CPU cores\n2. **Divide-and-Conquer** - Break complex problems into subproblems\n\n### Core Concepts\n\n```prolog\n% A partition\npartition(0, [item1, item2, item3]).\npartition(1, [item4, item5, item6]).\n```\n\n### Plugin Interface\n\nAll strategies implement:\n\n```prolog\nstrategy_init(+Config, -State).\nstrategy_partition(+State, +Data, -Partitions).\nstrategy_assign(+State, +Item, -PartitionID).\nstrategy_cleanup(+State).\n```\n\n### Available Strategies\n\n| Strategy | Description | Use Case |\n|----------|-------------|----------|\n| `fixed_size` | Equal-sized chunks | Simple parallelism |\n| `hash_based` | By key hash | MapReduce, distributed joins |\n| `key_based` | Group by key | GROUP BY aggregation |\n\n### Example\n\n```prolog\n% Partition 1000 items into chunks of 100\nnumlist(1, 1000, Data),\npartitioner_init(fixed_size(rows(100)), [], Handle),\npartitioner_partition(Handle, Data, Partitions).\n% Result: 10 partitions of 100 items each\n```", "anchor_question_hash": "10a1b2c3d4e50001"}}
{"cluster_id": "partitioning-strategies", "seed_level": 2, "source_files": ["education/book-02-bash-target/10_partitioning_and_parallel_execution.md"], "topics": ["fixed-size", "hash-based", "key-based", "strategies"], "questions": ["How does fixed-size partitioning work?", "What is hash-based partitioning?", "How does key-based partitioning differ from hash-based?", "When should I use each partitioning strategy?"], "answer": {"text": "## Partitioning Strategies\n\n### 1. Fixed-Size Partitioning\n\nSplit into equal-sized chunks:\n\n```prolog\npartitioner_init(fixed_size(rows(100)), [], H),\npartitioner_partition(H, Data, Parts).\n% Each partition has ~100 items\n```\n\n**Modes:** `rows(N)` or `bytes(B)`\n\n### 2. Hash-Based Partitioning\n\nDistribute by hashing a key (MapReduce-compatible):\n\n```prolog\npartitioner_init(\n    hash_based(key(column(2)), num_partitions(4)),\n    [], H),\npartitioner_partition(H, Data, Parts).\n% Same key always goes to same partition\n```\n\n**Key property:** Deterministic - enables co-location for distributed joins.\n\n### 3. Key-Based Partitioning\n\nGroup all items with same key (SQL GROUP BY):\n\n```prolog\npartitioner_init(key_based(key(column(1))), [], H),\npartitioner_partition(H, Logs, Parts).\n% One partition per unique key value\n```\n\n### Comparison\n\n| Strategy | Partition Count | Use Case |\n|----------|-----------------|----------|\n| `fixed_size` | Data size / chunk size | Simple parallelism |\n| `hash_based` | Fixed (configured) | MapReduce shuffle |\n| `key_based` | Unique key count | GROUP BY aggregation |", "anchor_question_hash": "10b2c3d4e5f60002"}}
{"cluster_id": "gnu-parallel-backend", "seed_level": 2, "source_files": ["education/book-02-bash-target/10_partitioning_and_parallel_execution.md"], "topics": ["gnu-parallel", "parallel-execution", "backend", "workers"], "questions": ["How does UnifyWeaver execute partitions in parallel?", "What is the GNU Parallel backend?", "How do I configure parallel workers?", "How are partition results collected?"], "answer": {"text": "## GNU Parallel Backend\n\nUnifyWeaver uses **GNU Parallel** for parallel execution.\n\n### Why GNU Parallel?\n\n- Battle-tested command-line tool\n- Handles process management, error handling, resource limits\n- Available on all Unix-like systems\n\n### Backend Interface\n\n```prolog\n% Initialize with 4 workers\nbackend_init(gnu_parallel(workers(4)), Handle).\n\n% Execute script on partitions\nbackend_execute(Handle, Partitions, 'process.sh', Results).\n\n% Clean up\nbackend_cleanup(Handle).\n```\n\n### Behind the Scenes\n\n1. Write partition data to temp files\n2. Build GNU Parallel command:\n   ```bash\n   parallel --jobs 4 \\\n     \"bash process.sh < {}\" \\\n     ::: batch_0.txt batch_1.txt ...\n   ```\n3. Execute in parallel (4 workers)\n4. Collect results from output files\n\n### Complete Example\n\n```prolog\n% 1. Partition data\nnumlist(1, 100, Data),\npartitioner_init(fixed_size(rows(10)), [], PH),\npartitioner_partition(PH, Data, Partitions),\n\n% 2. Execute in parallel\nbackend_init(gnu_parallel(workers(4)), BH),\nbackend_execute(BH, Partitions, 'double.sh', Results),\nbackend_cleanup(BH).\n\n% Results = [result(0, \"2\\n4\\n...\"), result(1, ...), ...]\n```", "anchor_question_hash": "10c3d4e5f6a70003"}}
{"cluster_id": "batch-vs-streaming", "seed_level": 3, "source_files": ["education/book-02-bash-target/10_partitioning_and_parallel_execution.md"], "topics": ["batch", "streaming", "data-flow", "memory"], "questions": ["What is batch vs streaming partitioning?", "When should I use batch partitioning?", "What are the advantages of streaming partitioning?", "How does UnifyWeaver handle large datasets?"], "answer": {"text": "## Batch vs Streaming Partitioning\n\n### Batch (Current Implementation)\n\nScan entire dataset, then partition, then process:\n\n```\nData → [Read All] → [Partition] → [Process in Parallel] → Results\n```\n\n**Advantages:**\n- Simple to implement\n- Can balance partition sizes\n- Easy to test and debug\n\n**Disadvantages:**\n- Must fit dataset in memory\n- Latency before processing starts\n- Not suitable for infinite streams\n\n### Streaming (Future Design)\n\nPartition items as they arrive:\n\n```\nItem1, Item2, ... → [Assign] → [Worker 0, Worker 1, ...] → Results\n```\n\n**Advantages:**\n- Constant memory usage\n- Low latency\n- Supports infinite streams\n\n**Disadvantages:**\n- More complex\n- Harder to balance partitions\n\n### Decision Guide\n\n| Use Case | Approach |\n|----------|----------|\n| Small dataset (fits in RAM) | Batch |\n| Large dataset, full scan | Batch |\n| Large dataset, subset needed | Streaming |\n| Infinite stream | Streaming |\n| Need balanced partitions | Batch |\n| Low latency requirement | Streaming |", "anchor_question_hash": "10d4e5f6a7b80004"}}
