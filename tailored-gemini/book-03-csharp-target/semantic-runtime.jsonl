{"pair_id": "semantic-crawling_p0", "cluster_id": "semantic-crawling", "question": "What is semantic crawling in UnifyWeaver?", "question_type": "medium", "answer": "Semantic crawling in UnifyWeaver is an intelligent discovery process that uses **vector embeddings** to navigate and categorize content based on meaning rather than just link structures. It enables the creation of highly relevant datasets by calculating the semantic distance between content and a target topic during the crawl.\n\n### Architectural Framework\nThe system relies on four primary C# components:\n*   **`PtCrawler`**: The orchestrator responsible for retrieving and parsing raw content.\n*   **`OnnxEmbeddingProvider`**: The engine that runs local ONNX transformer models to generate text vectors.\n*   **`PtImporter`**: A storage wrapper for LiteDB that saves both objects and their embeddings.\n*   **`PtSearcher`**: A retriever that performs cosine similarity searches across the stored vectors.\n\n### Operational Flow\nContent from XML or HTTP sources is fetched by the `PtCrawler` and transformed into vectors by the `OnnxEmbeddingProvider`. These are stored in LiteDB via the `PtImporter`. To maintain focus, the crawler evaluates child links and only follows them if their titles meet a similarity threshold (typically `> 0.4`). This results in a targeted knowledge base suitable for semantic search.\n\nDetailed documentation and configuration examples can be found in `education/book-03-csharp-target/05_semantic_crawling.md`.", "answer_variant": "default", "answer_source": "education/book-03-csharp-target/05_semantic_crawling.md", "topics": ["semantic", "crawling", "embeddings", "onnx"], "original_answer": "## Semantic Crawling\n\nUnlike traditional crawlers, semantic crawlers use **vector embeddings** to understand content meaning.\n\n### Architecture Components\n\n1. **`PtCrawler`**: Orchestrator - fetches and parses content\n2. **`PtImporter`**: Storage - wraps LiteDB for objects + embeddings\n3. **`OnnxEmbeddingProvider`**: Brain - runs local ONNX transformer model\n4. **`PtSearcher`**: Retriever - cosine similarity search\n\n### Data Flow\n\n```\nSource (XML/HTTP) \u2192 PtCrawler \u2192 OnnxEmbeddingProvider\n                            \u2193\n              Object + Vector \u2192 PtImporter/LiteDB\n                            \u2193\nUser Query \u2192 PtSearcher \u2192 Vector Similarity \u2192 Results\n```\n\n### Configuring the Embedder\n\n```csharp\nvar embedder = new OnnxEmbeddingProvider(\n    modelPath: \"models/model.onnx\",\n    vocabPath: \"models/vocab.txt\"\n);\n```\n\n### Focused Crawling\n\n1. **Seed**: Start with topic category\n2. **Crawl**: Fetch children, embed titles\n3. **Filter**: Only follow if `CosineSimilarity > 0.4`\n4. **Store**: Save relevant pages\n\nCreates highly focused datasets without downloading everything.", "answer_tailored": true}
{"pair_id": "semantic-crawling_p1", "cluster_id": "semantic-crawling", "question": "How does the semantic runtime work?", "question_type": "medium", "answer": "The semantic runtime operates as a coordinated system of specialized components that utilize vector embeddings to process, store, and retrieve information based on conceptual meaning.\n\n### Core Architecture\n- **Orchestration (`PtCrawler`)**: Manages the fetching and parsing of source content (such as XML or HTTP).\n- **Intelligence (`OnnxEmbeddingProvider`)**: Serves as the system's \"brain\" by running local ONNX transformer models to generate embeddings.\n- **Persistence (`PtImporter`)**: A storage wrapper for LiteDB that handles the management of both objects and their corresponding vector embeddings.\n- **Retrieval (`PtSearcher`)**: The search engine that executes cosine similarity comparisons to find the most relevant matches for a query.\n\n### Data Processing Flow\nContent is first ingested by the **PtCrawler** and passed to the **OnnxEmbeddingProvider** for vectorization. These vectors and their source objects are persisted via the **PtImporter**. When a search is initiated, the **PtSearcher** converts the user query into a vector and performs a similarity search against the stored data to return relevant results.\n\n### Focused Crawling Mechanism\nThe runtime supports efficient data gathering by starting with a seed category and fetching child content. It calculates the `CosineSimilarity` of content titles and only persists or follows links that meet a specific relevance threshold (e.g., `> 0.4`), preventing the download of irrelevant data.\n\nFor a detailed breakdown of the implementation, see `education/book-03-csharp-target/05_semantic_crawling.md`.", "answer_variant": "default", "answer_source": "education/book-03-csharp-target/05_semantic_crawling.md", "topics": ["semantic", "crawling", "embeddings", "onnx"], "original_answer": "## Semantic Crawling\n\nUnlike traditional crawlers, semantic crawlers use **vector embeddings** to understand content meaning.\n\n### Architecture Components\n\n1. **`PtCrawler`**: Orchestrator - fetches and parses content\n2. **`PtImporter`**: Storage - wraps LiteDB for objects + embeddings\n3. **`OnnxEmbeddingProvider`**: Brain - runs local ONNX transformer model\n4. **`PtSearcher`**: Retriever - cosine similarity search\n\n### Data Flow\n\n```\nSource (XML/HTTP) \u2192 PtCrawler \u2192 OnnxEmbeddingProvider\n                            \u2193\n              Object + Vector \u2192 PtImporter/LiteDB\n                            \u2193\nUser Query \u2192 PtSearcher \u2192 Vector Similarity \u2192 Results\n```\n\n### Configuring the Embedder\n\n```csharp\nvar embedder = new OnnxEmbeddingProvider(\n    modelPath: \"models/model.onnx\",\n    vocabPath: \"models/vocab.txt\"\n);\n```\n\n### Focused Crawling\n\n1. **Seed**: Start with topic category\n2. **Crawl**: Fetch children, embed titles\n3. **Filter**: Only follow if `CosineSimilarity > 0.4`\n4. **Store**: Save relevant pages\n\nCreates highly focused datasets without downloading everything.", "answer_tailored": true}
{"pair_id": "semantic-crawling_p2", "cluster_id": "semantic-crawling", "question": "What is OnnxEmbeddingProvider?", "question_type": "medium", "answer": "The `OnnxEmbeddingProvider` is a core component of the UnifyWeaver C# target's semantic crawling architecture, serving as the system's \"brain\" by executing local ONNX transformer models to generate vector embeddings.\n\n### Core Functionality\nIt is responsible for transforming raw text or parsed content into high-dimensional vectors that represent the semantic meaning of the data. This allows the system to perform cosine similarity searches rather than relying on simple keyword matching.\n\n### Technical Requirements\nTo initialize the provider, you must specify the paths to the local model and its vocabulary:\n\n```csharp\nvar embedder = new OnnxEmbeddingProvider(\n    modelPath: \"models/model.onnx\",\n    vocabPath: \"models/vocab.txt\"\n);\n```\n\n### Role in the Data Pipeline\nIn a standard workflow, the `PtCrawler` fetches content and passes it to the `OnnxEmbeddingProvider`. The resulting vectors, along with their source objects, are then handed off to the `PtImporter` for storage in a LiteDB instance. This enables the `PtSearcher` to later retrieve relevant information based on semantic intent.\n\nFor more details on implementing semantic search and crawling, see `education/book-03-csharp-target/`.", "answer_variant": "default", "answer_source": "education/book-03-csharp-target/05_semantic_crawling.md", "topics": ["semantic", "crawling", "embeddings", "onnx"], "original_answer": "## Semantic Crawling\n\nUnlike traditional crawlers, semantic crawlers use **vector embeddings** to understand content meaning.\n\n### Architecture Components\n\n1. **`PtCrawler`**: Orchestrator - fetches and parses content\n2. **`PtImporter`**: Storage - wraps LiteDB for objects + embeddings\n3. **`OnnxEmbeddingProvider`**: Brain - runs local ONNX transformer model\n4. **`PtSearcher`**: Retriever - cosine similarity search\n\n### Data Flow\n\n```\nSource (XML/HTTP) \u2192 PtCrawler \u2192 OnnxEmbeddingProvider\n                            \u2193\n              Object + Vector \u2192 PtImporter/LiteDB\n                            \u2193\nUser Query \u2192 PtSearcher \u2192 Vector Similarity \u2192 Results\n```\n\n### Configuring the Embedder\n\n```csharp\nvar embedder = new OnnxEmbeddingProvider(\n    modelPath: \"models/model.onnx\",\n    vocabPath: \"models/vocab.txt\"\n);\n```\n\n### Focused Crawling\n\n1. **Seed**: Start with topic category\n2. **Crawl**: Fetch children, embed titles\n3. **Filter**: Only follow if `CosineSimilarity > 0.4`\n4. **Store**: Save relevant pages\n\nCreates highly focused datasets without downloading everything.", "answer_tailored": true}
{"pair_id": "semantic-crawling_p3", "cluster_id": "semantic-crawling", "question": "How does focused crawling work?", "question_type": "medium", "answer": "Focused crawling works by using vector embeddings to guide the traversal of content, ensuring only semantically relevant data is ingested. Unlike traditional broad-spectrum crawlers, this targeted approach utilizes local transformer models to evaluate the meaning of links and content in real-time.\n\nThe operational flow follows these key stages:\n1. **Seeding**: The process begins with a specific topic category or seed identifier.\n2. **Discovery & Embedding**: As the `PtCrawler` fetches child links, it uses the `OnnxEmbeddingProvider` to generate vector representations of titles and metadata.\n3. **Similarity Filtering**: The crawler evaluates the **Cosine Similarity** between the discovered content and the target topic. It only follows links or stores data if the similarity score is greater than **0.4**.\n4. **Storage**: Relevant objects and their associated vectors are persisted to LiteDB via the `PtImporter`.\n\nThe system architecture relies on four primary components:\n* **`PtCrawler`**: The orchestrator responsible for fetching and parsing.\n* **`OnnxEmbeddingProvider`**: The \"brain\" that runs local ONNX transformer models for embedding generation.\n* **`PtImporter`**: The storage layer that wraps LiteDB for objects and vectors.\n* **`PtSearcher`**: The retriever that performs cosine similarity searches.\n\nThis focused methodology creates high-quality datasets without the resource overhead of downloading irrelevant information. For comprehensive details on the C# implementation, refer to `education/book-03-csharp-target/`.", "answer_variant": "default", "answer_source": "education/book-03-csharp-target/05_semantic_crawling.md", "topics": ["semantic", "crawling", "embeddings", "onnx"], "original_answer": "## Semantic Crawling\n\nUnlike traditional crawlers, semantic crawlers use **vector embeddings** to understand content meaning.\n\n### Architecture Components\n\n1. **`PtCrawler`**: Orchestrator - fetches and parses content\n2. **`PtImporter`**: Storage - wraps LiteDB for objects + embeddings\n3. **`OnnxEmbeddingProvider`**: Brain - runs local ONNX transformer model\n4. **`PtSearcher`**: Retriever - cosine similarity search\n\n### Data Flow\n\n```\nSource (XML/HTTP) \u2192 PtCrawler \u2192 OnnxEmbeddingProvider\n                            \u2193\n              Object + Vector \u2192 PtImporter/LiteDB\n                            \u2193\nUser Query \u2192 PtSearcher \u2192 Vector Similarity \u2192 Results\n```\n\n### Configuring the Embedder\n\n```csharp\nvar embedder = new OnnxEmbeddingProvider(\n    modelPath: \"models/model.onnx\",\n    vocabPath: \"models/vocab.txt\"\n);\n```\n\n### Focused Crawling\n\n1. **Seed**: Start with topic category\n2. **Crawl**: Fetch children, embed titles\n3. **Filter**: Only follow if `CosineSimilarity > 0.4`\n4. **Store**: Save relevant pages\n\nCreates highly focused datasets without downloading everything.", "answer_tailored": true}
{"pair_id": "vector-search_p0", "cluster_id": "vector-search", "question": "How does vector search work in UnifyWeaver?", "question_type": "medium", "answer": "Vector search in UnifyWeaver facilitates document retrieval based on conceptual similarity rather than literal keyword matching. The system transforms query text into 384-dimensional vectors using an embedding model\u2014by default, `all-MiniLM-L6-v2`\u2014which runs locally via the ONNX Runtime for improved performance and privacy.\n\nThe search process involves three primary steps:\n1. **Embedding**: The input query is processed by the embedder to create a high-dimensional vector.\n2. **Comparison**: This vector is compared against stored document embeddings using cosine similarity.\n3. **Ranking**: The system identifies and returns the top-K most similar documents based on their similarity scores.\n\nIn the C# target, you can perform searches using the `PtSearcher` class:\n```csharp\nvar searcher = new PtSearcher(\"data.db\", embedder);\nvar results = searcher.SearchSimilar(\"quantum physics applications\", topK: 5);\n\nforeach (var result in results)\n{\n    Console.WriteLine($\"{result.Score:F4}: {result.Title}\");\n}\n```\n\nThis functionality is also accessible within Prolog definitions, allowing semantic search to drive logic-based workflows like web crawling:\n```prolog\nfind_relevant_seeds(Query, Seeds) :-\n    semantic_search(Query, 10, Results),\n    extract_ids(Results, Seeds).\n\ncrawl_topic(Topic) :-\n    find_relevant_seeds(Topic, Seeds),\n    crawler_run(Seeds, 3).\n```\n\nFor more implementation details on the C# backend and semantic crawling, see `education/book-03-csharp-target/`.", "answer_variant": "default", "answer_source": "education/book-03-csharp-target/05_semantic_crawling.md", "topics": ["vector-search", "embeddings", "cosine-similarity", "litedb"], "original_answer": "## Vector Search\n\nFind documents **conceptually similar** to your query, not just keyword matches.\n\n### Performing a Search\n\n```csharp\nvar searcher = new PtSearcher(\"data.db\", embedder);\nvar results = searcher.SearchSimilar(\n    \"quantum physics applications\",\n    topK: 5\n);\n\nforeach (var result in results)\n{\n    Console.WriteLine($\"{result.Score:F4}: {result.Title}\");\n}\n```\n\n### Embedding Model\n\nDefault: `all-MiniLM-L6-v2`\n- 384-dimensional vectors\n- From HuggingFace sentence-transformers\n- Runs locally via ONNX Runtime\n\n### How It Works\n\n1. Query text \u2192 Embedder \u2192 384-dim vector\n2. Compare to stored vectors using cosine similarity\n3. Return top-K most similar documents\n\n### Prolog Definition\n\n```prolog\nfind_relevant_seeds(Query, Seeds) :-\n    semantic_search(Query, 10, Results),\n    extract_ids(Results, Seeds).\n\ncrawl_topic(Topic) :-\n    find_relevant_seeds(Topic, Seeds),\n    crawler_run(Seeds, 3).  % Depth 3\n```", "answer_tailored": true}
{"pair_id": "vector-search_p1", "cluster_id": "vector-search", "question": "What is cosine similarity search?", "question_type": "medium", "answer": "Cosine similarity search is a vector-based retrieval method used by UnifyWeaver to identify documents that are conceptually related to a query rather than just matching keywords. As detailed in the C# target documentation (`education/book-03-csharp-target/05_semantic_crawling.md`), this process enables semantic retrieval by calculating the mathematical \"closeness\" between high-dimensional text representations.\n\n### How It Works\n1. **Vectorization**: Query text is processed through an embedding model\u2014specifically the `all-MiniLM-L6-v2` model, which generates 384-dimensional vectors. This model runs locally using the ONNX Runtime.\n2. **Comparison**: The resulting query vector is compared against stored document vectors using the cosine similarity metric.\n3. **Retrieval**: The system returns the top-K documents that exhibit the highest similarity scores.\n\n### C# Implementation\nIn the C# target, the `PtSearcher` class manages these operations:\n```csharp\nvar searcher = new PtSearcher(\"data.db\", embedder);\nvar results = searcher.SearchSimilar(\"quantum physics applications\", topK: 5);\n\nforeach (var result in results)\n{\n    Console.WriteLine($\"{result.Score:F4}: {result.Title}\");\n}\n```\n\n### Prolog Integration\nYou can leverage these semantic capabilities within Prolog rules to find relevant data \"seeds\" for operations like crawling:\n```prolog\nfind_relevant_seeds(Query, Seeds) :-\n    semantic_search(Query, 10, Results),\n    extract_ids(Results, Seeds).\n\ncrawl_topic(Topic) :-\n    find_relevant_seeds(Topic, Seeds),\n    crawler_run(Seeds, 3).\n```\n\nFor a deeper dive into semantic crawling and vector search implementation, see `education/book-03-csharp-target/05_semantic_crawling.md`.", "answer_variant": "default", "answer_source": "education/book-03-csharp-target/05_semantic_crawling.md", "topics": ["vector-search", "embeddings", "cosine-similarity", "litedb"], "original_answer": "## Vector Search\n\nFind documents **conceptually similar** to your query, not just keyword matches.\n\n### Performing a Search\n\n```csharp\nvar searcher = new PtSearcher(\"data.db\", embedder);\nvar results = searcher.SearchSimilar(\n    \"quantum physics applications\",\n    topK: 5\n);\n\nforeach (var result in results)\n{\n    Console.WriteLine($\"{result.Score:F4}: {result.Title}\");\n}\n```\n\n### Embedding Model\n\nDefault: `all-MiniLM-L6-v2`\n- 384-dimensional vectors\n- From HuggingFace sentence-transformers\n- Runs locally via ONNX Runtime\n\n### How It Works\n\n1. Query text \u2192 Embedder \u2192 384-dim vector\n2. Compare to stored vectors using cosine similarity\n3. Return top-K most similar documents\n\n### Prolog Definition\n\n```prolog\nfind_relevant_seeds(Query, Seeds) :-\n    semantic_search(Query, 10, Results),\n    extract_ids(Results, Seeds).\n\ncrawl_topic(Topic) :-\n    find_relevant_seeds(Topic, Seeds),\n    crawler_run(Seeds, 3).  % Depth 3\n```", "answer_tailored": true}
{"pair_id": "vector-search_p2", "cluster_id": "vector-search", "question": "How do I search embedded data?", "question_type": "medium", "answer": "To search embedded data in UnifyWeaver, you utilize vector-based semantic search to identify documents that are conceptually related to your query, moving beyond simple keyword matching.\n\n### C# Implementation\nIn the C# target, you use the `PtSearcher` class to perform similarity lookups against your embedded dataset:\n\n```csharp\n// Initialize searcher with your database and embedder\nvar searcher = new PtSearcher(\"data.db\", embedder);\n\n// Execute conceptual search\nvar matches = searcher.SearchSimilar(\n    \"quantum physics applications\",\n    topK: 5\n);\n\nforeach (var match in matches)\n{\n    Console.WriteLine($\"Score: {match.Score:F4} | Title: {match.Title}\");\n}\n```\n\n### Technical Workflow\n1.  **Vectorization**: The query text is transformed into a 384-dimensional vector using the default `all-MiniLM-L6-v2` model.\n2.  **Local Inference**: The model runs locally via the ONNX Runtime for high performance and privacy.\n3.  **Similarity Ranking**: The system calculates the cosine similarity between the query vector and your stored document embeddings, returning the top-K results.\n\n### Prolog Integration\nYou can define search and crawling logic directly in Prolog:\n\n```prolog\n% Find relevant documents and start a crawl\nfind_and_crawl(Query) :-\n    semantic_search(Query, 10, Results),\n    extract_ids(Results, Seeds),\n    crawler_run(Seeds, 3).\n```\n\nFor more details on implementing these features, see `education/book-03-csharp-target/05_semantic_crawling.md`.", "answer_variant": "default", "answer_source": "education/book-03-csharp-target/05_semantic_crawling.md", "topics": ["vector-search", "embeddings", "cosine-similarity", "litedb"], "original_answer": "## Vector Search\n\nFind documents **conceptually similar** to your query, not just keyword matches.\n\n### Performing a Search\n\n```csharp\nvar searcher = new PtSearcher(\"data.db\", embedder);\nvar results = searcher.SearchSimilar(\n    \"quantum physics applications\",\n    topK: 5\n);\n\nforeach (var result in results)\n{\n    Console.WriteLine($\"{result.Score:F4}: {result.Title}\");\n}\n```\n\n### Embedding Model\n\nDefault: `all-MiniLM-L6-v2`\n- 384-dimensional vectors\n- From HuggingFace sentence-transformers\n- Runs locally via ONNX Runtime\n\n### How It Works\n\n1. Query text \u2192 Embedder \u2192 384-dim vector\n2. Compare to stored vectors using cosine similarity\n3. Return top-K most similar documents\n\n### Prolog Definition\n\n```prolog\nfind_relevant_seeds(Query, Seeds) :-\n    semantic_search(Query, 10, Results),\n    extract_ids(Results, Seeds).\n\ncrawl_topic(Topic) :-\n    find_relevant_seeds(Topic, Seeds),\n    crawler_run(Seeds, 3).  % Depth 3\n```", "answer_tailored": true}
{"pair_id": "vector-search_p3", "cluster_id": "vector-search", "question": "What model is used for embeddings?", "question_type": "medium", "answer": "UnifyWeaver uses the `all-MiniLM-L6-v2` model as its default for generating text embeddings. This model, sourced from HuggingFace's sentence-transformers, produces 384-dimensional vectors and is executed locally via the ONNX Runtime. These embeddings allow the system to perform conceptual vector searches by comparing the query vector to stored document vectors using cosine similarity. For implementation details regarding semantic crawling and search within the C# target, see `education/book-03-csharp-target/05_semantic_crawling.md`.", "answer_variant": "default", "answer_source": "education/book-03-csharp-target/05_semantic_crawling.md", "topics": ["vector-search", "embeddings", "cosine-similarity", "litedb"], "original_answer": "## Vector Search\n\nFind documents **conceptually similar** to your query, not just keyword matches.\n\n### Performing a Search\n\n```csharp\nvar searcher = new PtSearcher(\"data.db\", embedder);\nvar results = searcher.SearchSimilar(\n    \"quantum physics applications\",\n    topK: 5\n);\n\nforeach (var result in results)\n{\n    Console.WriteLine($\"{result.Score:F4}: {result.Title}\");\n}\n```\n\n### Embedding Model\n\nDefault: `all-MiniLM-L6-v2`\n- 384-dimensional vectors\n- From HuggingFace sentence-transformers\n- Runs locally via ONNX Runtime\n\n### How It Works\n\n1. Query text \u2192 Embedder \u2192 384-dim vector\n2. Compare to stored vectors using cosine similarity\n3. Return top-K most similar documents\n\n### Prolog Definition\n\n```prolog\nfind_relevant_seeds(Query, Seeds) :-\n    semantic_search(Query, 10, Results),\n    extract_ids(Results, Seeds).\n\ncrawl_topic(Topic) :-\n    find_relevant_seeds(Topic, Seeds),\n    crawler_run(Seeds, 3).  % Depth 3\n```", "answer_tailored": true}
{"pair_id": "powershell-semantic_p0", "cluster_id": "powershell-semantic", "question": "What is the PowerShell Semantic Target?", "question_type": "medium", "answer": "The PowerShell Semantic Target is the component of UnifyWeaver that bridges Prolog logic with the .NET ecosystem on Windows, specifically optimized for enterprise integration. While the Python target is often characterized as \"Scripted AI,\" the PowerShell target focuses on leveraging Windows-native capabilities for data processing and retrieval.\n\nTechnical capabilities include:\n- **XML Streaming with .NET:** It utilizes `[System.Xml.XmlReader]` to efficiently process large XML files, using `ReadSubtree()` and `[System.Xml.XmlDocument]` to emit structured objects to the PowerShell pipeline without loading the entire file into memory.\n- **Vector Search Strategies:**\n    - **Pure PowerShell:** For smaller datasets (under 10,000 items), it implements native cosine similarity calculations using standard loops and `[Math]` functions.\n    - **ONNX Runtime:** For production environments, it integrates directly with the .NET ONNX Runtime (`Microsoft.ML.OnnxRuntime.dll`) to perform high-performance model inference.\n\nFor a deep dive into PowerShell integration and .NET semantic strategies, refer to the documentation in `education/book-03-csharp-target/`.", "answer_variant": "default", "answer_source": "education/book-03-csharp-target/06_powershell_semantic.md", "topics": ["powershell", "xml", "vector", "dotnet"], "original_answer": "## PowerShell Semantic Target\n\nBridges Prolog logic with .NET ecosystem on Windows.\n\n**Python:** \"Scripted AI\"\n**PowerShell:** \"Enterprise Integration\"\n\n### XML Streaming with .NET\n\n```powershell\nfunction Get-XmlStream {\n    param($Path, $Tags)\n    $reader = [System.Xml.XmlReader]::Create($Path)\n    try {\n        while ($reader.Read()) {\n            if ($reader.NodeType -eq 'Element' -and\n                $Tags -contains $reader.Name) {\n                $subReader = $reader.ReadSubtree()\n                $doc = [System.Xml.XmlDocument]::new()\n                $doc.Load($subReader)\n                # Emit to pipeline\n                @{ 'tag' = $doc.DocumentElement.Name }\n            }\n        }\n    } finally {\n        $reader.Dispose()\n    }\n}\n```\n\n### Vector Search Strategies\n\n**Strategy A: Pure PowerShell (< 10k items)**\n```powershell\nfunction Get-CosineSimilarity ($v1, $v2) {\n    $dot = 0.0; $mag1 = 0.0; $mag2 = 0.0\n    for ($i = 0; $i -lt $v1.Count; $i++) {\n        $dot += $v1[$i] * $v2[$i]\n        $mag1 += $v1[$i] * $v1[$i]\n        $mag2 += $v2[$i] * $v2[$i]\n    }\n    return $dot / ([Math]::Sqrt($mag1) * [Math]::Sqrt($mag2))\n}\n```\n\n**Strategy B: ONNX Runtime (Production)**\n```powershell\nAdd-Type -Path \"bin/Microsoft.ML.OnnxRuntime.dll\"\n$session = [Microsoft.ML.OnnxRuntime.InferenceSession]::new(\"model.onnx\")\n```", "answer_tailored": true}
{"pair_id": "powershell-semantic_p1", "cluster_id": "powershell-semantic", "question": "How does PowerShell handle XML streaming?", "question_type": "medium", "answer": "PowerShell handles XML streaming by leveraging the .NET `System.Xml.XmlReader` class, which allows for efficient, memory-safe processing of large datasets. This approach enables the PowerShell target to bridge Prolog logic with the .NET ecosystem, facilitating enterprise-level integration.\n\nTo implement streaming, an `XmlReader` is created to iterate through nodes without loading the entire file into memory. When specific tags are identified using the `Read()` method, `ReadSubtree()` captures that fragment, which can then be converted into an `XmlDocument` for object-based processing and emitted directly to the PowerShell pipeline.\n\n```powershell\nfunction Get-XmlStream {\n    param($Path, $Tags)\n    $reader = [System.Xml.XmlReader]::Create($Path)\n    try {\n        while ($reader.Read()) {\n            if ($reader.NodeType -eq 'Element' -and\n                $Tags -contains $reader.Name) {\n                $subReader = $reader.ReadSubtree()\n                $doc = [System.Xml.XmlDocument]::new()\n                $doc.Load($subReader)\n                # Emit structured object to pipeline\n                @{ 'tag' = $doc.DocumentElement.Name; 'data' = $doc.DocumentElement.InnerText }\n            }\n        }\n    } finally {\n        $reader.Dispose()\n    }\n}\n```\n\nThis streaming methodology is a core part of the PowerShell Semantic Target's strategy for handling large-scale data ingestion. For more comprehensive details on .NET integration and vector search strategies within this target, see `education/book-03-csharp-target/06_powershell_semantic.md`.", "answer_variant": "default", "answer_source": "education/book-03-csharp-target/06_powershell_semantic.md", "topics": ["powershell", "xml", "vector", "dotnet"], "original_answer": "## PowerShell Semantic Target\n\nBridges Prolog logic with .NET ecosystem on Windows.\n\n**Python:** \"Scripted AI\"\n**PowerShell:** \"Enterprise Integration\"\n\n### XML Streaming with .NET\n\n```powershell\nfunction Get-XmlStream {\n    param($Path, $Tags)\n    $reader = [System.Xml.XmlReader]::Create($Path)\n    try {\n        while ($reader.Read()) {\n            if ($reader.NodeType -eq 'Element' -and\n                $Tags -contains $reader.Name) {\n                $subReader = $reader.ReadSubtree()\n                $doc = [System.Xml.XmlDocument]::new()\n                $doc.Load($subReader)\n                # Emit to pipeline\n                @{ 'tag' = $doc.DocumentElement.Name }\n            }\n        }\n    } finally {\n        $reader.Dispose()\n    }\n}\n```\n\n### Vector Search Strategies\n\n**Strategy A: Pure PowerShell (< 10k items)**\n```powershell\nfunction Get-CosineSimilarity ($v1, $v2) {\n    $dot = 0.0; $mag1 = 0.0; $mag2 = 0.0\n    for ($i = 0; $i -lt $v1.Count; $i++) {\n        $dot += $v1[$i] * $v2[$i]\n        $mag1 += $v1[$i] * $v1[$i]\n        $mag2 += $v2[$i] * $v2[$i]\n    }\n    return $dot / ([Math]::Sqrt($mag1) * [Math]::Sqrt($mag2))\n}\n```\n\n**Strategy B: ONNX Runtime (Production)**\n```powershell\nAdd-Type -Path \"bin/Microsoft.ML.OnnxRuntime.dll\"\n$session = [Microsoft.ML.OnnxRuntime.InferenceSession]::new(\"model.onnx\")\n```", "answer_tailored": true}
{"pair_id": "powershell-semantic_p2", "cluster_id": "powershell-semantic", "question": "How does vector search work in PowerShell?", "question_type": "medium", "answer": "Vector search in PowerShell within the UnifyWeaver ecosystem works by bridging Prolog logic with the .NET ecosystem, primarily focusing on enterprise integration rather than simple scripting. The implementation relies on two main strategies for performing semantic lookups:\n\n### Vector Search Strategies\n\n**1. Pure PowerShell (Datasets < 10k items)**\nFor smaller scale deployments, a native PowerShell implementation of cosine similarity is used to calculate distance between vectors without external dependencies:\n\n```powershell\nfunction Get-CosineSimilarity ($v1, $v2) {\n    $dot = 0.0; $mag1 = 0.0; $mag2 = 0.0\n    for ($i = 0; $i -lt $v1.Count; $i++) {\n        $dot += $v1[$i] * $v2[$i]\n        $mag1 += $v1[$i] * $v1[$i]\n        $mag2 += $v2[$i] * $v2[$i]\n    }\n    return $dot / ([Math]::Sqrt($mag1) * [Math]::Sqrt($mag2))\n}\n```\n\n**2. ONNX Runtime (Production environments)**\nFor high-performance production needs, UnifyWeaver leverages .NET interop to utilize the Microsoft ML ONNX Runtime, enabling efficient model inference directly within the PowerShell target:\n\n```powershell\nAdd-Type -Path \"bin/Microsoft.ML.OnnxRuntime.dll\"\n$session = [Microsoft.ML.OnnxRuntime.InferenceSession]::new(\"model.onnx\")\n```\n\n### Data Integration with .NET\nTo support these searches, UnifyWeaver often employs XML streaming via `[System.Xml.XmlReader]` for memory-efficient data processing:\n\n```powershell\nfunction Get-XmlStream {\n    param($Path, $Tags)\n    $reader = [System.Xml.XmlReader]::Create($Path)\n    try {\n        while ($reader.Read()) {\n            if ($reader.NodeType -eq 'Element' -and $Tags -contains $reader.Name) {\n                $subReader = $reader.ReadSubtree()\n                $doc = [System.Xml.XmlDocument]::new()\n                $doc.Load($subReader)\n                @{ 'tag' = $doc.DocumentElement.Name }\n            }\n        }\n    } finally { $reader.Dispose() }\n}\n```\n\nWhile Python is designated for \"Scripted AI\" tasks, the PowerShell target is optimized for \"Enterprise Integration.\" For more details on this implementation, see the documentation in `education/book-03-csharp-target/`.", "answer_variant": "default", "answer_source": "education/book-03-csharp-target/06_powershell_semantic.md", "topics": ["powershell", "xml", "vector", "dotnet"], "original_answer": "## PowerShell Semantic Target\n\nBridges Prolog logic with .NET ecosystem on Windows.\n\n**Python:** \"Scripted AI\"\n**PowerShell:** \"Enterprise Integration\"\n\n### XML Streaming with .NET\n\n```powershell\nfunction Get-XmlStream {\n    param($Path, $Tags)\n    $reader = [System.Xml.XmlReader]::Create($Path)\n    try {\n        while ($reader.Read()) {\n            if ($reader.NodeType -eq 'Element' -and\n                $Tags -contains $reader.Name) {\n                $subReader = $reader.ReadSubtree()\n                $doc = [System.Xml.XmlDocument]::new()\n                $doc.Load($subReader)\n                # Emit to pipeline\n                @{ 'tag' = $doc.DocumentElement.Name }\n            }\n        }\n    } finally {\n        $reader.Dispose()\n    }\n}\n```\n\n### Vector Search Strategies\n\n**Strategy A: Pure PowerShell (< 10k items)**\n```powershell\nfunction Get-CosineSimilarity ($v1, $v2) {\n    $dot = 0.0; $mag1 = 0.0; $mag2 = 0.0\n    for ($i = 0; $i -lt $v1.Count; $i++) {\n        $dot += $v1[$i] * $v2[$i]\n        $mag1 += $v1[$i] * $v1[$i]\n        $mag2 += $v2[$i] * $v2[$i]\n    }\n    return $dot / ([Math]::Sqrt($mag1) * [Math]::Sqrt($mag2))\n}\n```\n\n**Strategy B: ONNX Runtime (Production)**\n```powershell\nAdd-Type -Path \"bin/Microsoft.ML.OnnxRuntime.dll\"\n$session = [Microsoft.ML.OnnxRuntime.InferenceSession]::new(\"model.onnx\")\n```", "answer_tailored": true}
{"pair_id": "powershell-semantic_p3", "cluster_id": "powershell-semantic", "question": "When should I use PowerShell vs C#?", "question_type": "medium", "answer": "You should use PowerShell when you need to bridge Prolog logic with the .NET ecosystem on Windows for enterprise integration. While Python is often favored for \"Scripted AI,\" PowerShell is the primary choice for \"Enterprise Integration\" within UnifyWeaver, offering a flexible scripting interface to .NET's robust libraries.\n\nTechnical capabilities and strategies include:\n- **XML Streaming:** Efficiently process large XML files using the .NET `[System.Xml.XmlReader]` class. This allows you to stream nodes and emit specific tags to the pipeline without loading the entire document into memory.\n- **Vector Search:** For smaller datasets (under 10,000 items), you can implement cosine similarity functions directly in pure PowerShell. For production-scale AI tasks, PowerShell can interface with the ONNX Runtime by loading the `Microsoft.ML.OnnxRuntime.dll` to run high-performance inference sessions.\n\nFor more details on PowerShell and C# semantic targets, see `education/book-03-csharp-target/06_powershell_semantic.md`.", "answer_variant": "default", "answer_source": "education/book-03-csharp-target/06_powershell_semantic.md", "topics": ["powershell", "xml", "vector", "dotnet"], "original_answer": "## PowerShell Semantic Target\n\nBridges Prolog logic with .NET ecosystem on Windows.\n\n**Python:** \"Scripted AI\"\n**PowerShell:** \"Enterprise Integration\"\n\n### XML Streaming with .NET\n\n```powershell\nfunction Get-XmlStream {\n    param($Path, $Tags)\n    $reader = [System.Xml.XmlReader]::Create($Path)\n    try {\n        while ($reader.Read()) {\n            if ($reader.NodeType -eq 'Element' -and\n                $Tags -contains $reader.Name) {\n                $subReader = $reader.ReadSubtree()\n                $doc = [System.Xml.XmlDocument]::new()\n                $doc.Load($subReader)\n                # Emit to pipeline\n                @{ 'tag' = $doc.DocumentElement.Name }\n            }\n        }\n    } finally {\n        $reader.Dispose()\n    }\n}\n```\n\n### Vector Search Strategies\n\n**Strategy A: Pure PowerShell (< 10k items)**\n```powershell\nfunction Get-CosineSimilarity ($v1, $v2) {\n    $dot = 0.0; $mag1 = 0.0; $mag2 = 0.0\n    for ($i = 0; $i -lt $v1.Count; $i++) {\n        $dot += $v1[$i] * $v2[$i]\n        $mag1 += $v1[$i] * $v1[$i]\n        $mag2 += $v2[$i] * $v2[$i]\n    }\n    return $dot / ([Math]::Sqrt($mag1) * [Math]::Sqrt($mag2))\n}\n```\n\n**Strategy B: ONNX Runtime (Production)**\n```powershell\nAdd-Type -Path \"bin/Microsoft.ML.OnnxRuntime.dll\"\n$session = [Microsoft.ML.OnnxRuntime.InferenceSession]::new(\"model.onnx\")\n```", "answer_tailored": true}
