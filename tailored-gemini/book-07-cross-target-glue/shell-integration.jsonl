{"pair_id": "b7-c5-shell-glue_p0", "cluster_id": "b7-c5-shell-glue", "question": "What is the shell glue module?", "question_type": "medium", "answer": "The shell glue module (`shell_glue`) is a core component of UnifyWeaver designed to handle script generation and pipeline orchestration across various shell-based targets. It enables the compilation of Prolog logic into complete, executable scripts for AWK, Python, and Bash.\n\nKey predicates within the module include:\n- `generate_awk_script/4`: Compiles logic into a full AWK script, including `BEGIN` blocks for field separators and schema-aware variable mapping.\n- `generate_python_script/4`: Produces Python scripts for data processing.\n- `generate_bash_script/4`: Generates Bash scripts for system orchestration.\n- `generate_pipeline/3`: Manages the orchestration of multi-stage processing pipelines.\n\nFor example, when generating an AWK script, the module automatically maps positional fields (e.g., `$1`, `$2`) to meaningful names (e.g., `ip`, `timestamp`) based on the input schema and wraps the logic in the appropriate boilerplate.\n\nFor further details on cross-target integration, refer to `education/book-07-cross-target-glue/05_shell_glue.md`.", "answer_variant": "default", "answer_source": "education/book-07-cross-target-glue/05_shell_glue.md", "topics": ["shell-glue", "awk-generation", "python-generation"], "original_answer": "## Shell Script Generation\n\n### Shell Glue Module\n\n```prolog\n:- module(shell_glue, [\n    generate_awk_script/4,      % Complete AWK script\n    generate_python_script/4,   % Complete Python script\n    generate_bash_script/4,     % Complete Bash script\n    generate_pipeline/3         % Pipeline orchestration\n]).\n```\n\n### AWK Generation Example\n\n```prolog\n?- generate_awk_script(\n    'if (status >= 400) print ip, timestamp, status',\n    [ip, timestamp, method, path, status],\n    [format(tsv)],\n    Script\n).\n```\n\n**Generated AWK:**\n\n```awk\nBEGIN { FS = \"\\t\"; OFS = \"\\t\" }\n{\n    ip = $1; timestamp = $2; status = $5\n    if (status >= 400) print ip, timestamp, status\n}\n```", "answer_tailored": true}
{"pair_id": "b7-c5-shell-glue_p1", "cluster_id": "b7-c5-shell-glue", "question": "How do I generate AWK scripts?", "question_type": "medium", "answer": "You can generate AWK scripts by using the `generate_awk_script/4` predicate provided by the `shell_glue` module. This predicate allows you to define filter logic and field mappings in Prolog, which are then compiled into a functional AWK script with appropriate field separators and variable assignments.\n\n### Implementation Example\n\nTo create a script that filters log data, you would call the generator with your logic and field list:\n\n```prolog\n?- generate_awk_script(\n    'if (status >= 400) print ip, timestamp, status',\n    [ip, timestamp, method, path, status],\n    [format(tsv)],\n    Script\n).\n```\n\n### Resulting AWK Output\n\nThe generator produces a complete script including the `BEGIN` block and field mapping:\n\n```awk\nBEGIN { FS = \"\\t\"; OFS = \"\\t\" }\n{\n    ip = $1; timestamp = $2; status = $5\n    if (status >= 400) print ip, timestamp, status\n}\n```\n\nFor further details on generating shell-based target scripts, refer to the documentation in `education/book-07-cross-target-glue/05_shell_glue.md`.", "answer_variant": "default", "answer_source": "education/book-07-cross-target-glue/05_shell_glue.md", "topics": ["shell-glue", "awk-generation", "python-generation"], "original_answer": "## Shell Script Generation\n\n### Shell Glue Module\n\n```prolog\n:- module(shell_glue, [\n    generate_awk_script/4,      % Complete AWK script\n    generate_python_script/4,   % Complete Python script\n    generate_bash_script/4,     % Complete Bash script\n    generate_pipeline/3         % Pipeline orchestration\n]).\n```\n\n### AWK Generation Example\n\n```prolog\n?- generate_awk_script(\n    'if (status >= 400) print ip, timestamp, status',\n    [ip, timestamp, method, path, status],\n    [format(tsv)],\n    Script\n).\n```\n\n**Generated AWK:**\n\n```awk\nBEGIN { FS = \"\\t\"; OFS = \"\\t\" }\n{\n    ip = $1; timestamp = $2; status = $5\n    if (status >= 400) print ip, timestamp, status\n}\n```", "answer_tailored": true}
{"pair_id": "b7-c5-shell-glue_p2", "cluster_id": "b7-c5-shell-glue", "question": "What does generate_awk_script/4 do?", "question_type": "medium", "answer": "`generate_awk_script/4` is a predicate in the `shell_glue` module used to generate a complete, executable AWK script from UnifyWeaver logic. It takes four arguments: the filter logic or query body, a list of field names for variable mapping, a list of options (such as output formatting), and the output variable for the generated script.\n\nThe predicate automates the creation of the AWK `BEGIN` block\u2014configuring field separators like `FS` and `OFS`\u2014and handles the boilerplate of mapping positional input fields (e.g., `$1`, `$2`) to named variables before executing the specified logic.\n\n**Example Prolog Call:**\n```prolog\n?- generate_awk_script(\n    'if (status >= 400) print ip, timestamp, status',\n    [ip, timestamp, method, path, status],\n    [format(tsv)],\n    Script\n).\n```\n\n**Resulting AWK Script:**\n```awk\nBEGIN { FS = \"\\t\"; OFS = \"\\t\" }\n{\n    ip = $1; timestamp = $2; status = $5\n    if (status >= 400) print ip, timestamp, status\n}\n```\n\nFor more comprehensive details on shell script generation and the `shell_glue` module, see `education/book-07-cross-target-glue/05_shell_glue.md`.", "answer_variant": "default", "answer_source": "education/book-07-cross-target-glue/05_shell_glue.md", "topics": ["shell-glue", "awk-generation", "python-generation"], "original_answer": "## Shell Script Generation\n\n### Shell Glue Module\n\n```prolog\n:- module(shell_glue, [\n    generate_awk_script/4,      % Complete AWK script\n    generate_python_script/4,   % Complete Python script\n    generate_bash_script/4,     % Complete Bash script\n    generate_pipeline/3         % Pipeline orchestration\n]).\n```\n\n### AWK Generation Example\n\n```prolog\n?- generate_awk_script(\n    'if (status >= 400) print ip, timestamp, status',\n    [ip, timestamp, method, path, status],\n    [format(tsv)],\n    Script\n).\n```\n\n**Generated AWK:**\n\n```awk\nBEGIN { FS = \"\\t\"; OFS = \"\\t\" }\n{\n    ip = $1; timestamp = $2; status = $5\n    if (status >= 400) print ip, timestamp, status\n}\n```", "answer_tailored": true}
{"pair_id": "b7-c6-pipeline-orchestration_p0", "cluster_id": "b7-c6-pipeline-orchestration", "question": "How do I generate a multi-stage pipeline?", "question_type": "medium", "answer": "To generate a multi-stage pipeline in UnifyWeaver, you use the `generate_pipeline/3` predicate. This tool allows you to orchestrate a sequence of operations across multiple target languages (such as Bash, Python, and AWK) into a unified shell script that utilizes standard pipes.\n\n### The `generate_pipeline/3` Predicate\n\nThe predicate takes a list of step definitions, global options, and returns the generated script:\n\n```prolog\ngenerate_pipeline(\n    [step(Name, Target, Script, Options), ...],\n    PipelineOptions,\n    OutputScript\n).\n```\n\n### Example: Multi-Stage ETL Pipeline\n\nThe following example demonstrates how to create a pipeline that reads from a log file, fetches data via Bash, processes it with Python, and finalizes storage with AWK:\n\n```prolog\nbuild_etl_pipeline(Script) :-\n    generate_pipeline(\n        [\n            step(fetch, bash, 'fetch.sh', []),\n            step(transform, python, 'transform.py', []),\n            step(store, awk, 'store.awk', [])\n        ],\n        [input('access.log')],\n        Script\n    ).\n```\n\n### Generated Output\n\nWhen compiled, UnifyWeaver produces a robust Bash script that handles the data flow:\n\n```bash\n#!/bin/bash\nset -euo pipefail\n\ncat \"access.log\" \\\n    | bash \"fetch.sh\" \\\n    | python3 \"transform.py\" \\\n    | awk -f \"store.awk\"\n```\n\nFor more comprehensive details on cross-target orchestration and pipeline options, see `education/book-07-cross-target-glue/06_shell_pipelines.md`.", "answer_variant": "default", "answer_source": "education/book-07-cross-target-glue/06_shell_pipelines.md", "topics": ["generate-pipeline", "step", "orchestration"], "original_answer": "## Pipeline Orchestration\n\n### generate_pipeline/3\n\n```prolog\ngenerate_pipeline(\n    [step(Name, Target, Script, Opts), ...],\n    Options,\n    OutputScript\n).\n```\n\n### Example: ETL Pipeline\n\n```prolog\nexample_pipeline(Script) :-\n    generate_pipeline(\n        [\n            step(fetch_stage, bash, 'fetch.sh', []),\n            step(transform_stage, python, 'transform.py', []),\n            step(store_stage, awk, 'store.awk', [])\n        ],\n        [input('access.log')],\n        Script\n    ).\n```\n\n**Generated Bash:**\n\n```bash\n#!/bin/bash\nset -euo pipefail\n\ncat \"access.log\" \\\n    | bash \"fetch.sh\" \\\n    | python3 \"transform.py\" \\\n    | awk -f \"store.awk\"\n```", "answer_tailored": true}
{"pair_id": "b7-c6-pipeline-orchestration_p1", "cluster_id": "b7-c6-pipeline-orchestration", "question": "What is generate_pipeline/3?", "question_type": "medium", "answer": "`generate_pipeline/3` is the core Prolog predicate used for orchestrating multi-stage data pipelines across different target languages. It converts a high-level definition of processing steps into a functional shell script that utilizes Unix pipes for data flow.\n\nThe predicate uses the following structure:\n`generate_pipeline(Steps, Options, OutputScript)`\n\nWhere `Steps` is a list of `step(Name, Target, Script, Opts)` terms. This allows you to seamlessly chain scripts written in different languages (such as Bash, Python, AWK, or Go) into a single cohesive pipeline.\n\n### Example Implementation:\n```prolog\nexample_pipeline(Script) :-\n    generate_pipeline(\n        [\n            step(extraction, bash, 'fetch_data.sh', []),\n            step(transformation, python, 'process.py', []),\n            step(loading, awk, 'format_output.awk', [])\n        ],\n        [input('source_data.log')],\n        Script\n    ).\n```\n\n### Generated Output:\nThe resulting Bash script automatically manages the stream:\n```bash\n#!/bin/bash\nset -euo pipefail\n\ncat \"source_data.log\" \\\n    | bash \"fetch_data.sh\" \\\n    | python3 \"process.py\" \\\n    | awk -f \"format_output.awk\"\n```\n\nFor more comprehensive details on building cross-target workflows, refer to `education/book-07-cross-target-glue/06_shell_pipelines.md`.", "answer_variant": "default", "answer_source": "education/book-07-cross-target-glue/06_shell_pipelines.md", "topics": ["generate-pipeline", "step", "orchestration"], "original_answer": "## Pipeline Orchestration\n\n### generate_pipeline/3\n\n```prolog\ngenerate_pipeline(\n    [step(Name, Target, Script, Opts), ...],\n    Options,\n    OutputScript\n).\n```\n\n### Example: ETL Pipeline\n\n```prolog\nexample_pipeline(Script) :-\n    generate_pipeline(\n        [\n            step(fetch_stage, bash, 'fetch.sh', []),\n            step(transform_stage, python, 'transform.py', []),\n            step(store_stage, awk, 'store.awk', [])\n        ],\n        [input('access.log')],\n        Script\n    ).\n```\n\n**Generated Bash:**\n\n```bash\n#!/bin/bash\nset -euo pipefail\n\ncat \"access.log\" \\\n    | bash \"fetch.sh\" \\\n    | python3 \"transform.py\" \\\n    | awk -f \"store.awk\"\n```", "answer_tailored": true}
{"pair_id": "b7-c6-pipeline-orchestration_p2", "cluster_id": "b7-c6-pipeline-orchestration", "question": "How do I define pipeline steps?", "question_type": "medium", "answer": "In UnifyWeaver, pipeline steps are defined using the `step(Name, Target, Script, Opts)` structure within the `generate_pipeline/3` predicate. This allows you to orchestrate a sequence of operations where data flows between different target languages via standard shell pipes.\n\n### Defining Steps with `generate_pipeline/3`\n\nThe `generate_pipeline/3` predicate takes a list of step definitions, global options, and returns the compiled shell script:\n\n```prolog\ngenerate_pipeline(\n    [step(Name, Target, Script, Options), ...],\n    GlobalOptions,\n    OutputScript\n).\n```\n\n### Example: Multi-Target ETL\nYou can mix targets like Bash, Python, and AWK within a single pipeline definition:\n\n```prolog\ndefine_etl_pipeline(Script) :-\n    generate_pipeline(\n        [\n            step(ingest, bash, 'fetch.sh', []),\n            step(process, python, 'transform.py', []),\n            step(format, awk, 'cleanup.awk', [])\n        ],\n        [input('data.log')],\n        Script\n    ).\n```\n\n**Compiled Output Logic:**\nThe compiler generates a script that manages the execution flow and piping:\n\n```bash\n#!/bin/bash\ncat \"data.log\" \\\n    | bash \"fetch.sh\" \\\n    | python3 \"transform.py\" \\\n    | awk -f \"cleanup.awk\"\n```\n\nEach step definition requires a unique name, a valid target language (e.g., `bash`, `python`, `go`, `awk`), the source script, and any specific options for that stage. For more information on shell orchestration, see `education/book-07-cross-target-glue/06_shell_pipelines.md`.", "answer_variant": "default", "answer_source": "education/book-07-cross-target-glue/06_shell_pipelines.md", "topics": ["generate-pipeline", "step", "orchestration"], "original_answer": "## Pipeline Orchestration\n\n### generate_pipeline/3\n\n```prolog\ngenerate_pipeline(\n    [step(Name, Target, Script, Opts), ...],\n    Options,\n    OutputScript\n).\n```\n\n### Example: ETL Pipeline\n\n```prolog\nexample_pipeline(Script) :-\n    generate_pipeline(\n        [\n            step(fetch_stage, bash, 'fetch.sh', []),\n            step(transform_stage, python, 'transform.py', []),\n            step(store_stage, awk, 'store.awk', [])\n        ],\n        [input('access.log')],\n        Script\n    ).\n```\n\n**Generated Bash:**\n\n```bash\n#!/bin/bash\nset -euo pipefail\n\ncat \"access.log\" \\\n    | bash \"fetch.sh\" \\\n    | python3 \"transform.py\" \\\n    | awk -f \"store.awk\"\n```", "answer_tailored": true}
