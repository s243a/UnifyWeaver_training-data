{"pair_id": "accumulator-pattern_p0", "cluster_id": "accumulator-pattern", "question": "What is an accumulator in recursion?", "question_type": "medium", "answer": "In recursion, an accumulator is an auxiliary parameter used to carry intermediate or partial results forward through each successive call. This technique is the foundation of the \"Accumulator Pattern,\" which allows a recursive process to build its result on the \"forward\" path rather than waiting for the recursion to unwind.\n\n### Comparison of Recursive Patterns\n\n**1. Stack-based Recursion (No Accumulator)**\nIn this pattern, the final work is performed on the return path. The system must maintain a stack of \"waiting\" operations, which can lead to stack overflow for large inputs.\n\n```prolog\n% Result builds as the stack returns\nfactorial(0, 1).\nfactorial(N, F) :-\n    N > 0,\n    N1 is N - 1,\n    factorial(N1, F1),\n    F is N * F1.        % Multiplication happens AFTER the call returns\n```\n\n**2. Tail-recursive Recursion (With Accumulator)**\nBy using an accumulator, the calculation is performed before the next call. The base case simply returns the final accumulated value.\n\n```prolog\n% Result builds on the forward path\nfactorial_acc(0, Acc, Acc).     % Base case: return the final accumulator\nfactorial_acc(N, Acc, F) :-\n    N > 0,\n    NextAcc is Acc * N,         % Work happens BEFORE the call\n    N1 is N - 1,\n    factorial_acc(N1, NextAcc, F). \n```\n\n### Efficiency and Optimization\n\n| Aspect | Without Accumulator | With Accumulator |\n|--------|---------------------|------------------|\n| **Stack Space** | O(n) - Grows with input | O(1) - Constant |\n| **Risk** | Can cause stack overflow | Safe for deep recursion |\n| **Structure** | Linear Recursion | Tail Recursion |\n\n### UnifyWeaver's Implementation\nUnifyWeaver identifies accumulator patterns to perform Tail-Call Optimization (TCO). Instead of generating actual recursive function calls in languages like Bash or Go, it compiles these patterns into highly efficient iterative loops:\n\n```bash\n# Compiled logic (conceptual Bash):\nwhile [[ $N -gt 0 ]]; do\n    Acc=$((Acc * N))\n    N=$((N - 1))\ndone\n```\n\nThis ensures that recursive Prolog logic runs with the performance and safety of a native loop. For a deeper dive into how these patterns are compiled, see the documentation in `education/book-02-bash-target/06_advanced_recursion.md`.", "answer_variant": "default", "answer_source": "education/book-02-bash-target/06_advanced_recursion.md", "topics": ["accumulator", "tail-recursion", "intermediate-result", "optimization"], "original_answer": "## The Accumulator Pattern\n\nAn accumulator is an extra parameter that carries intermediate results through recursive calls.\n\n### Without Accumulator (Stack-based)\n\n```prolog\n% Result builds on return path\nfactorial(0, 1).\nfactorial(N, F) :-\n    N > 0,\n    N1 is N - 1,\n    factorial(N1, F1),\n    F is N * F1.        % Work AFTER recursive call\n```\n\nCall stack for `factorial(4, F)`:\n```\nfactorial(4, F) -> waiting for factorial(3)\n  factorial(3, F) -> waiting for factorial(2)\n    factorial(2, F) -> waiting for factorial(1)\n      factorial(1, F) -> waiting for factorial(0)\n        factorial(0, 1) -> returns 1\n      F = 1 * 1 = 1\n    F = 2 * 1 = 2\n  F = 3 * 2 = 6\nF = 4 * 6 = 24\n```\n\n### With Accumulator (Tail-recursive)\n\n```prolog\n% Result builds on forward path\nfactorial_acc(0, Acc, Acc).     % Base: return accumulator\nfactorial_acc(N, Acc, F) :-\n    N > 0,\n    Acc1 is Acc * N,\n    N1 is N - 1,\n    factorial_acc(N1, Acc1, F). % Tail call - no work after\n```\n\nExecution for `factorial_acc(4, 1, F)`:\n```\nfactorial_acc(4, 1, F)   -> Acc = 1*4 = 4\nfactorial_acc(3, 4, F)   -> Acc = 4*3 = 12\nfactorial_acc(2, 12, F)  -> Acc = 12*2 = 24\nfactorial_acc(1, 24, F)  -> Acc = 24*1 = 24\nfactorial_acc(0, 24, 24) -> F = 24\n```\n\n### Why Accumulators Are Efficient\n\n| Aspect | Without Acc | With Acc |\n|--------|-------------|----------|\n| Stack depth | O(n) | O(1)* |\n| Can overflow | Yes | No |\n| Compilable to loop | No | Yes |\n\n*With tail-call optimization\n\n### UnifyWeaver's Optimization\n\nUnifyWeaver detects accumulator patterns and generates iterative loops:\n\n```bash\n# Instead of recursive calls:\nwhile [[ \"$current_list\" != \"[]\" ]]; do\n    acc=$((acc + 1))\n    # advance to next element\ndone\n```", "answer_tailored": true}
{"pair_id": "accumulator-pattern_p1", "cluster_id": "accumulator-pattern", "question": "How does an accumulator enable tail recursion?", "question_type": "medium", "answer": "An accumulator enables tail recursion by shifting calculations from the return path to the forward path of the recursion. In a standard recursive function, the program must wait for the final call to return before it can perform the \"work\" (e.g., multiplication or addition), requiring a stack frame for every step. By using an accumulator to carry the intermediate state, the recursive call becomes the very last operation, allowing the compiler to reuse the current stack frame.\n\n### Comparison of Recursive Styles\n\n**Standard Recursion (Stack-based):**\nComputation occurs after the recursive call returns.\n```prolog\nfactorial(0, 1).\nfactorial(N, F) :-\n    N > 0,\n    N1 is N - 1,\n    factorial(N1, F1),\n    F is N * F1.        % Calculation happens on the return path\n```\n\n**Tail Recursion (Accumulator-based):**\nComputation occurs before the call, which is passed as an updated state.\n```prolog\nfactorial_acc(0, Acc, Acc).\nfactorial_acc(N, Acc, F) :-\n    N > 0,\n    NextAcc is Acc * N,\n    N1 is N - 1,\n    factorial_acc(N1, NextAcc, F). % Tail call: no pending work\n```\n\n### Efficiency and Optimization\nUsing an accumulator reduces stack depth from O(n) to O(1). This is critical for UnifyWeaver because it allows the compiler to transform recursive Prolog logic into iterative loops in the target language. For example, in the Bash target, a tail-recursive predicate is often compiled into a `while` loop, preventing \"maximum recursion depth\" errors and improving performance.\n\n| Feature | Standard Recursion | Accumulator Pattern |\n|---------|--------------------|---------------------|\n| Computation | After call (Return) | Before call (Forward) |\n| Stack Space | O(n) | O(1) |\n| Compilation | Recursive calls | Iterative loops |\n\nFor a deeper dive into these optimization patterns, refer to `education/book-02-bash-target/06_advanced_recursion.md`.", "answer_variant": "default", "answer_source": "education/book-02-bash-target/06_advanced_recursion.md", "topics": ["accumulator", "tail-recursion", "intermediate-result", "optimization"], "original_answer": "## The Accumulator Pattern\n\nAn accumulator is an extra parameter that carries intermediate results through recursive calls.\n\n### Without Accumulator (Stack-based)\n\n```prolog\n% Result builds on return path\nfactorial(0, 1).\nfactorial(N, F) :-\n    N > 0,\n    N1 is N - 1,\n    factorial(N1, F1),\n    F is N * F1.        % Work AFTER recursive call\n```\n\nCall stack for `factorial(4, F)`:\n```\nfactorial(4, F) -> waiting for factorial(3)\n  factorial(3, F) -> waiting for factorial(2)\n    factorial(2, F) -> waiting for factorial(1)\n      factorial(1, F) -> waiting for factorial(0)\n        factorial(0, 1) -> returns 1\n      F = 1 * 1 = 1\n    F = 2 * 1 = 2\n  F = 3 * 2 = 6\nF = 4 * 6 = 24\n```\n\n### With Accumulator (Tail-recursive)\n\n```prolog\n% Result builds on forward path\nfactorial_acc(0, Acc, Acc).     % Base: return accumulator\nfactorial_acc(N, Acc, F) :-\n    N > 0,\n    Acc1 is Acc * N,\n    N1 is N - 1,\n    factorial_acc(N1, Acc1, F). % Tail call - no work after\n```\n\nExecution for `factorial_acc(4, 1, F)`:\n```\nfactorial_acc(4, 1, F)   -> Acc = 1*4 = 4\nfactorial_acc(3, 4, F)   -> Acc = 4*3 = 12\nfactorial_acc(2, 12, F)  -> Acc = 12*2 = 24\nfactorial_acc(1, 24, F)  -> Acc = 24*1 = 24\nfactorial_acc(0, 24, 24) -> F = 24\n```\n\n### Why Accumulators Are Efficient\n\n| Aspect | Without Acc | With Acc |\n|--------|-------------|----------|\n| Stack depth | O(n) | O(1)* |\n| Can overflow | Yes | No |\n| Compilable to loop | No | Yes |\n\n*With tail-call optimization\n\n### UnifyWeaver's Optimization\n\nUnifyWeaver detects accumulator patterns and generates iterative loops:\n\n```bash\n# Instead of recursive calls:\nwhile [[ \"$current_list\" != \"[]\" ]]; do\n    acc=$((acc + 1))\n    # advance to next element\ndone\n```", "answer_tailored": true}
{"pair_id": "accumulator-pattern_p2", "cluster_id": "accumulator-pattern", "question": "What's the difference between accumulator and non-accumulator recursion?", "question_type": "medium", "answer": "The primary difference between accumulator and non-accumulator recursion is how the computation is structured and how memory is utilized during execution.\n\n### Non-Accumulator (Stack-based) Recursion\nIn this pattern, the computation is deferred until the recursive calls begin to return. Each call creates a new stack frame to hold state until the final operations can be performed on the \"return path.\"\n- **Memory Usage:** O(n) stack depth.\n- **Risk:** Large inputs can trigger stack overflows in target languages like Bash.\n```prolog\n% Result builds on return path\nfactorial(0, 1).\nfactorial(N, F) :-\n    N > 0, N1 is N - 1,\n    factorial(N1, F1),\n    F is N * F1.        % Computation happens AFTER the recursive call\n```\n\n### Accumulator (Tail-recursive) Recursion\nAn accumulator is an additional parameter that carries the running result forward through the recursive calls. Because the recursive call is the final operation in the clause, it is considered \"tail-recursive.\"\n- **Memory Usage:** O(1) stack space when optimized.\n- **Optimization:** UnifyWeaver detects these patterns and compiles them into efficient iterative loops (such as `while` loops) rather than nested function calls.\n```prolog\n% Result builds on forward path\nfactorial_acc(0, Acc, Acc).\nfactorial_acc(N, Acc, F) :-\n    N > 0, NewAcc is Acc * N, N1 is N - 1,\n    factorial_acc(N1, NewAcc, F). % Tail call - no work remains\n```\n\n### Comparison Table\n| Aspect | Non-Accumulator | Accumulator |\n|--------|-----------------|-------------|\n| **Result Building** | On return path | On forward path |\n| **Stack Space** | O(n) | O(1)* |\n| **Compilation** | Nested calls | Iterative loops |\n| **Efficiency** | Lower | Higher |\n\n*\\*With Tail-Call Optimization (TCO)*\n\nFor more details on how these patterns are transformed into target code, see `education/book-02-bash-target/`.", "answer_variant": "default", "answer_source": "education/book-02-bash-target/06_advanced_recursion.md", "topics": ["accumulator", "tail-recursion", "intermediate-result", "optimization"], "original_answer": "## The Accumulator Pattern\n\nAn accumulator is an extra parameter that carries intermediate results through recursive calls.\n\n### Without Accumulator (Stack-based)\n\n```prolog\n% Result builds on return path\nfactorial(0, 1).\nfactorial(N, F) :-\n    N > 0,\n    N1 is N - 1,\n    factorial(N1, F1),\n    F is N * F1.        % Work AFTER recursive call\n```\n\nCall stack for `factorial(4, F)`:\n```\nfactorial(4, F) -> waiting for factorial(3)\n  factorial(3, F) -> waiting for factorial(2)\n    factorial(2, F) -> waiting for factorial(1)\n      factorial(1, F) -> waiting for factorial(0)\n        factorial(0, 1) -> returns 1\n      F = 1 * 1 = 1\n    F = 2 * 1 = 2\n  F = 3 * 2 = 6\nF = 4 * 6 = 24\n```\n\n### With Accumulator (Tail-recursive)\n\n```prolog\n% Result builds on forward path\nfactorial_acc(0, Acc, Acc).     % Base: return accumulator\nfactorial_acc(N, Acc, F) :-\n    N > 0,\n    Acc1 is Acc * N,\n    N1 is N - 1,\n    factorial_acc(N1, Acc1, F). % Tail call - no work after\n```\n\nExecution for `factorial_acc(4, 1, F)`:\n```\nfactorial_acc(4, 1, F)   -> Acc = 1*4 = 4\nfactorial_acc(3, 4, F)   -> Acc = 4*3 = 12\nfactorial_acc(2, 12, F)  -> Acc = 12*2 = 24\nfactorial_acc(1, 24, F)  -> Acc = 24*1 = 24\nfactorial_acc(0, 24, 24) -> F = 24\n```\n\n### Why Accumulators Are Efficient\n\n| Aspect | Without Acc | With Acc |\n|--------|-------------|----------|\n| Stack depth | O(n) | O(1)* |\n| Can overflow | Yes | No |\n| Compilable to loop | No | Yes |\n\n*With tail-call optimization\n\n### UnifyWeaver's Optimization\n\nUnifyWeaver detects accumulator patterns and generates iterative loops:\n\n```bash\n# Instead of recursive calls:\nwhile [[ \"$current_list\" != \"[]\" ]]; do\n    acc=$((acc + 1))\n    # advance to next element\ndone\n```", "answer_tailored": true}
{"pair_id": "accumulator-pattern_p3", "cluster_id": "accumulator-pattern", "question": "Why are accumulators more efficient?", "question_type": "medium", "answer": "Accumulators improve efficiency by enabling **tail-call optimization (TCO)**, which allows recursive logic to execute in constant stack space (O(1)) rather than linear space (O(n)). This prevents stack overflows and reduces memory overhead when processing large datasets.\n\n### Standard vs. Accumulator Efficiency\n\nIn standard recursion, the execution environment must maintain a stack frame for every call because work remains to be done after the recursive call returns (the \"return path\"):\n\n```prolog\n% Standard: Work happens AFTER the call\nfactorial(N, F) :-\n    N > 0, N1 is N - 1,\n    factorial(N1, F1),\n    F is N * F1.        % Must wait for F1 to calculate F\n```\n\nIn contrast, the accumulator pattern performs calculations on the **forward path** and passes the intermediate result to the next call. Since the recursive call is the final operation, the current stack frame can be reused:\n\n```prolog\n% Accumulator: No work remains after the call\nfactorial_acc(N, Acc, F) :-\n    N > 0,\n    Acc1 is Acc * N,\n    N1 is N - 1,\n    factorial_acc(N1, Acc1, F). % Tail call\n```\n\n### Why This Matters for UnifyWeaver\n\nUnifyWeaver detects these tail-recursive patterns and compiles them into high-performance iterative loops in the target language. For example, in the Bash target, it generates a `while` loop:\n\n```bash\n# Compiled iterative loop\nwhile [[ $n -gt 0 ]]; do\n    acc=$((acc * n))\n    n=$((n - 1))\ndone\n```\n\n| Metric | Without Accumulator | With Accumulator |\n|--------|---------------------|------------------|\n| **Stack Depth** | O(n)                | O(1)*            |\n| **Risk**        | Stack Overflow      | Safe             |\n| **Structure**   | Deeply Nested       | Iterative Loop   |\n\n*\\*Requires tail-call optimization or loop compilation.*\n\nFor more details on how UnifyWeaver handles complex recursive patterns, see `education/book-02-bash-target/06_advanced_recursion.md`.", "answer_variant": "default", "answer_source": "education/book-02-bash-target/06_advanced_recursion.md", "topics": ["accumulator", "tail-recursion", "intermediate-result", "optimization"], "original_answer": "## The Accumulator Pattern\n\nAn accumulator is an extra parameter that carries intermediate results through recursive calls.\n\n### Without Accumulator (Stack-based)\n\n```prolog\n% Result builds on return path\nfactorial(0, 1).\nfactorial(N, F) :-\n    N > 0,\n    N1 is N - 1,\n    factorial(N1, F1),\n    F is N * F1.        % Work AFTER recursive call\n```\n\nCall stack for `factorial(4, F)`:\n```\nfactorial(4, F) -> waiting for factorial(3)\n  factorial(3, F) -> waiting for factorial(2)\n    factorial(2, F) -> waiting for factorial(1)\n      factorial(1, F) -> waiting for factorial(0)\n        factorial(0, 1) -> returns 1\n      F = 1 * 1 = 1\n    F = 2 * 1 = 2\n  F = 3 * 2 = 6\nF = 4 * 6 = 24\n```\n\n### With Accumulator (Tail-recursive)\n\n```prolog\n% Result builds on forward path\nfactorial_acc(0, Acc, Acc).     % Base: return accumulator\nfactorial_acc(N, Acc, F) :-\n    N > 0,\n    Acc1 is Acc * N,\n    N1 is N - 1,\n    factorial_acc(N1, Acc1, F). % Tail call - no work after\n```\n\nExecution for `factorial_acc(4, 1, F)`:\n```\nfactorial_acc(4, 1, F)   -> Acc = 1*4 = 4\nfactorial_acc(3, 4, F)   -> Acc = 4*3 = 12\nfactorial_acc(2, 12, F)  -> Acc = 12*2 = 24\nfactorial_acc(1, 24, F)  -> Acc = 24*1 = 24\nfactorial_acc(0, 24, 24) -> F = 24\n```\n\n### Why Accumulators Are Efficient\n\n| Aspect | Without Acc | With Acc |\n|--------|-------------|----------|\n| Stack depth | O(n) | O(1)* |\n| Can overflow | Yes | No |\n| Compilable to loop | No | Yes |\n\n*With tail-call optimization\n\n### UnifyWeaver's Optimization\n\nUnifyWeaver detects accumulator patterns and generates iterative loops:\n\n```bash\n# Instead of recursive calls:\nwhile [[ \"$current_list\" != \"[]\" ]]; do\n    acc=$((acc + 1))\n    # advance to next element\ndone\n```", "answer_tailored": true}
{"pair_id": "fold-pattern_p0", "cluster_id": "fold-pattern", "question": "What is a fold and why use it for compilation?", "question_type": "medium", "answer": "A fold (also known as reduce) is a functional programming pattern that accumulates a final result by iterating over a sequence of values and applying a specific operation at each step. In UnifyWeaver, this pattern is used to transform linear recursive Prolog predicates into efficient iterative structures in target languages.\n\n### Why Use Fold for Compilation?\n\nCompiling recursive logic into a fold pattern provides several key advantages:\n\n1.  **Separation of Concerns**: It decouples the generation of the sequence (the structure) from the accumulation logic (the operation). This allows the compiler to handle structure and computation as independent units.\n2.  **Reusability**: A single `fold_left` implementation in the target language can support diverse operations. For example, the same fold mechanism can be used for `factorial` (multiplication), `sum_list` (addition), or `length` (incrementing).\n3.  **Code Quality**: Folds result in generated code that is cleaner, more readable, and easier to debug than deeply nested recursive calls. It allows for easy inspection of the input sequence and the operation function.\n\n### Implementation in UnifyWeaver\n\nIn the Bash target, UnifyWeaver implements this using a `fold_left` utility:\n\n```bash\nfold_left() {\n    local acc=\"$1\"\n    local op_func=\"$2\"\n    shift 2\n    for item in \"$@\"; do\n        acc=$(\"$op_func\" \"$item\" \"$acc\")\n    done\n    echo \"$acc\"\n}\n```\n\nTo compile a predicate like `factorial(5, X)`, the compiler generates a sequence (5, 4, 3, 2, 1) and folds a multiplication operation over it:\n\n```bash\nfactorial_op() {\n    echo $(($1 * $2))\n}\n# Executed as: fold_left 1 factorial_op 5 4 3 2 1\n```\n\nFor a deeper dive into how recursive predicates are mapped to iterative folds, see **education/book-02-bash-target/06_advanced_recursion.md**.", "answer_variant": "default", "answer_source": "education/book-02-bash-target/06_advanced_recursion.md", "topics": ["fold", "reduce", "functional-programming", "compilation-strategy"], "original_answer": "## The Fold Pattern\n\nA fold (also called reduce) accumulates a result by iterating over a sequence.\n\n### Basic Concept\n\n```\nfold(operation, initial, [a, b, c])\n\nSteps:\n  acc = initial\n  acc = operation(a, acc)\n  acc = operation(b, acc)\n  acc = operation(c, acc)\n  return acc\n```\n\n### Example: Sum with Fold\n\n```bash\n# sum([1, 2, 3]) using fold\nfold_left 0 add 1 2 3\n\n# Steps:\n# acc = 0\n# acc = add(1, 0) = 1\n# acc = add(2, 1) = 3\n# acc = add(3, 3) = 6\n# Result: 6\n```\n\n### Left vs Right Fold\n\n```\nfold_left:  ((initial op a) op b) op c\nfold_right: a op (b op (c op initial))\n```\n\nFor associative operations (like +, *), both give same result.\n\n### Why Use Fold for Compilation?\n\n**1. Separation of Concerns**\n- Structure building: generate the sequence\n- Computation: apply the operation\n\n**2. Reusability**\n```bash\n# Same fold_left for many predicates\nfactorial: fold_left 1 multiply [n..1]\nsum_list:  fold_left 0 add [elements]\nlength:    fold_left 0 increment [elements]\n```\n\n### UnifyWeaver's Fold Implementation\n\n```bash\nfold_left() {\n    local acc=\"$1\"\n    local op_func=\"$2\"\n    shift 2\n    for item in \"$@\"; do\n        acc=$(\"$op_func\" \"$item\" \"$acc\")\n    done\n    echo \"$acc\"\n}\n\n# Usage for factorial\nbuild_range_down() {\n    seq \"$1\" -1 1\n}\n\nfactorial_op() {\n    echo $(($1 * $2))\n}\n\nfactorial() {\n    local range=$(build_range_down \"$1\")\n    fold_left 1 factorial_op $range\n}\n```\n\n### Benefits\n\n- Clear, readable generated code\n- Easy to debug (inspect sequence, operation)\n- Natural fit for linear recursion patterns", "answer_tailored": true}
{"pair_id": "fold-pattern_p1", "cluster_id": "fold-pattern", "question": "What's the difference between fold_left and fold_right?", "question_type": "medium", "answer": "The difference between `fold_left` and `fold_right` lies in the direction of evaluation and how the operation is applied across a sequence of elements.\n\n### Evaluation Order\n*   **fold_left**: Processes the sequence from left to right (from the first element to the last). The accumulator is updated at each step: `((initial op a) op b) op c`.\n*   **fold_right**: Processes the sequence from right to left (from the last element back to the first). The operation is nested from the end: `a op (b op (c op initial))`.\n\nFor associative operations like addition or multiplication, both methods yield the same result. However, for non-associative operations, the choice of fold direction is critical to the final value.\n\n### Usage in UnifyWeaver\nUnifyWeaver utilizes these patterns to translate recursive Prolog logic into iterative target code, such as Bash. This approach provides a clean separation between generating a sequence and performing computations on it.\n\n**Bash Implementation of fold_left:**\n```bash\nfold_left() {\n    local acc=\"$1\"\n    local op_func=\"$2\"\n    shift 2\n    for item in \"$@\"; do\n        acc=$(\"$op_func\" \"$item\" \"$acc\")\n    done\n    echo \"$acc\"\n}\n```\n\n### Benefits for Compilation\n1.  **Readability**: The generated code uses structured loops rather than complex jump logic.\n2.  **Reusability**: The same fold utility can implement various predicates, such as `factorial` (using a multiplication operator), `sum_list` (addition), or `length` (incrementing).\n3.  **Efficiency**: `fold_left` naturally maps to iterative loops in targets like Bash, avoiding the overhead of deep recursion.\n\nFor a deeper look at how UnifyWeaver handles complex recursion in shell environments, refer to `education/book-02-bash-target/06_advanced_recursion.md`.", "answer_variant": "default", "answer_source": "education/book-02-bash-target/06_advanced_recursion.md", "topics": ["fold", "reduce", "functional-programming", "compilation-strategy"], "original_answer": "## The Fold Pattern\n\nA fold (also called reduce) accumulates a result by iterating over a sequence.\n\n### Basic Concept\n\n```\nfold(operation, initial, [a, b, c])\n\nSteps:\n  acc = initial\n  acc = operation(a, acc)\n  acc = operation(b, acc)\n  acc = operation(c, acc)\n  return acc\n```\n\n### Example: Sum with Fold\n\n```bash\n# sum([1, 2, 3]) using fold\nfold_left 0 add 1 2 3\n\n# Steps:\n# acc = 0\n# acc = add(1, 0) = 1\n# acc = add(2, 1) = 3\n# acc = add(3, 3) = 6\n# Result: 6\n```\n\n### Left vs Right Fold\n\n```\nfold_left:  ((initial op a) op b) op c\nfold_right: a op (b op (c op initial))\n```\n\nFor associative operations (like +, *), both give same result.\n\n### Why Use Fold for Compilation?\n\n**1. Separation of Concerns**\n- Structure building: generate the sequence\n- Computation: apply the operation\n\n**2. Reusability**\n```bash\n# Same fold_left for many predicates\nfactorial: fold_left 1 multiply [n..1]\nsum_list:  fold_left 0 add [elements]\nlength:    fold_left 0 increment [elements]\n```\n\n### UnifyWeaver's Fold Implementation\n\n```bash\nfold_left() {\n    local acc=\"$1\"\n    local op_func=\"$2\"\n    shift 2\n    for item in \"$@\"; do\n        acc=$(\"$op_func\" \"$item\" \"$acc\")\n    done\n    echo \"$acc\"\n}\n\n# Usage for factorial\nbuild_range_down() {\n    seq \"$1\" -1 1\n}\n\nfactorial_op() {\n    echo $(($1 * $2))\n}\n\nfactorial() {\n    local range=$(build_range_down \"$1\")\n    fold_left 1 factorial_op $range\n}\n```\n\n### Benefits\n\n- Clear, readable generated code\n- Easy to debug (inspect sequence, operation)\n- Natural fit for linear recursion patterns", "answer_tailored": true}
{"pair_id": "fold-pattern_p2", "cluster_id": "fold-pattern", "question": "How does fold-based compilation work?", "question_type": "medium", "answer": "Fold-based compilation in UnifyWeaver works by transforming recursive predicates into a linear accumulation pattern, commonly known as a \"reduce\" operation. This technique decomposes a recursive task into two distinct parts: generating a sequence of items and applying a specific operation to accumulate a final result.\n\n### Core Logic\nThe compiler utilizes a fold (usually `fold_left`) to iterate over a list or range. In a left fold, the calculation follows the pattern `((initial op a) op b) op c`, whereas a right fold follows `a op (b op (c op initial))`. For associative operations like addition or multiplication, both directions yield the same result.\n\n### Implementation in Bash\nIn the Bash target, this is implemented using a helper function that iterates through arguments and updates an accumulator:\n\n```bash\nfold_left() {\n    local acc=\"$1\"\n    local op_func=\"$2\"\n    shift 2\n    for item in \"$@\"; do\n        acc=$(\"$op_func\" \"$item\" \"$acc\")\n    done\n    echo \"$acc\"\n}\n```\n\n### Application\nUnifyWeaver uses this pattern to compile common recursive predicates by generating a sequence and passing it to the fold function with a specific operator:\n- **Summation:** `fold_left 0 add [elements]`\n- **Factorial:** `fold_left 1 multiply [n..1]`\n- **List Length:** `fold_left 0 increment [elements]`\n\n### Benefits for Compilation\n- **Separation of Concerns:** It separates the structure (sequence generation) from the computation logic (the operation).\n- **Code Quality:** The resulting Bash code is cleaner, more idiomatic, and significantly easier to debug than deeply nested recursive calls.\n- **Natural Fit:** It provides an efficient way to handle linear recursion patterns while maintaining high readability in the target language.\n\nFor more detailed examples of how recursion is mapped to these patterns in the Bash target, see `education/book-02-bash-target/06_advanced_recursion.md`.", "answer_variant": "default", "answer_source": "education/book-02-bash-target/06_advanced_recursion.md", "topics": ["fold", "reduce", "functional-programming", "compilation-strategy"], "original_answer": "## The Fold Pattern\n\nA fold (also called reduce) accumulates a result by iterating over a sequence.\n\n### Basic Concept\n\n```\nfold(operation, initial, [a, b, c])\n\nSteps:\n  acc = initial\n  acc = operation(a, acc)\n  acc = operation(b, acc)\n  acc = operation(c, acc)\n  return acc\n```\n\n### Example: Sum with Fold\n\n```bash\n# sum([1, 2, 3]) using fold\nfold_left 0 add 1 2 3\n\n# Steps:\n# acc = 0\n# acc = add(1, 0) = 1\n# acc = add(2, 1) = 3\n# acc = add(3, 3) = 6\n# Result: 6\n```\n\n### Left vs Right Fold\n\n```\nfold_left:  ((initial op a) op b) op c\nfold_right: a op (b op (c op initial))\n```\n\nFor associative operations (like +, *), both give same result.\n\n### Why Use Fold for Compilation?\n\n**1. Separation of Concerns**\n- Structure building: generate the sequence\n- Computation: apply the operation\n\n**2. Reusability**\n```bash\n# Same fold_left for many predicates\nfactorial: fold_left 1 multiply [n..1]\nsum_list:  fold_left 0 add [elements]\nlength:    fold_left 0 increment [elements]\n```\n\n### UnifyWeaver's Fold Implementation\n\n```bash\nfold_left() {\n    local acc=\"$1\"\n    local op_func=\"$2\"\n    shift 2\n    for item in \"$@\"; do\n        acc=$(\"$op_func\" \"$item\" \"$acc\")\n    done\n    echo \"$acc\"\n}\n\n# Usage for factorial\nbuild_range_down() {\n    seq \"$1\" -1 1\n}\n\nfactorial_op() {\n    echo $(($1 * $2))\n}\n\nfactorial() {\n    local range=$(build_range_down \"$1\")\n    fold_left 1 factorial_op $range\n}\n```\n\n### Benefits\n\n- Clear, readable generated code\n- Easy to debug (inspect sequence, operation)\n- Natural fit for linear recursion patterns", "answer_tailored": true}
{"pair_id": "fold-pattern_p3", "cluster_id": "fold-pattern", "question": "Why does UnifyWeaver use fold for linear recursion?", "question_type": "medium", "answer": "UnifyWeaver utilizes the **fold pattern** (also known as reduction) for linear recursion primarily to separate sequence generation from computation logic, resulting in more readable and reusable generated code. By transforming recursive Prolog predicates into iterative fold operations in target languages like Bash, the compiler avoids stack depth issues and produces code that is easier to debug.\n\n### Core Mechanism\nA fold accumulates a result by iterating over a sequence. In a `fold_left` implementation, the process follows these steps:\n1. Initialize an accumulator with a starting value.\n2. Apply a specific operation to the first item and the accumulator.\n3. Use the result as the new accumulator for the next item.\n4. Return the final accumulated value once the sequence is exhausted.\n\n### Why Fold is Preferred for Compilation\n*   **Separation of Concerns:** It decouples the structure-building phase (generating the sequence) from the computation phase (applying the operation).\n*   **High Reusability:** The same fold utility can power various predicates. For instance:\n    *   **Factorial:** A fold using a multiplication operation over a range.\n    *   **Sum:** A fold using an addition operation over a list.\n    *   **Length:** A fold that increments the accumulator for every element.\n*   **Efficiency:** It maps naturally to iterative loops in target languages, which is often more efficient than native recursion in environments like Bash or Python.\n\n### Example Implementation (Bash)\nIn the Bash target, UnifyWeaver generates a generic `fold_left` function:\n```bash\nfold_left() {\n    local acc=\"$1\"\n    local op_func=\"$2\"\n    shift 2\n    for item in \"$@\"; do\n        acc=$(\"$op_func\" \"$item\" \"$acc\")\n    done\n    echo \"$acc\"\n}\n```\nThis allows the compiler to implement a predicate like `factorial` by simply piping a sequence of numbers (e.g., from `seq`) into `fold_left` with a multiplication operator.\n\nFor a detailed breakdown of how linear recursion is optimized for the Bash target, see **education/book-02-bash-target/06_advanced_recursion.md**.", "answer_variant": "default", "answer_source": "education/book-02-bash-target/06_advanced_recursion.md", "topics": ["fold", "reduce", "functional-programming", "compilation-strategy"], "original_answer": "## The Fold Pattern\n\nA fold (also called reduce) accumulates a result by iterating over a sequence.\n\n### Basic Concept\n\n```\nfold(operation, initial, [a, b, c])\n\nSteps:\n  acc = initial\n  acc = operation(a, acc)\n  acc = operation(b, acc)\n  acc = operation(c, acc)\n  return acc\n```\n\n### Example: Sum with Fold\n\n```bash\n# sum([1, 2, 3]) using fold\nfold_left 0 add 1 2 3\n\n# Steps:\n# acc = 0\n# acc = add(1, 0) = 1\n# acc = add(2, 1) = 3\n# acc = add(3, 3) = 6\n# Result: 6\n```\n\n### Left vs Right Fold\n\n```\nfold_left:  ((initial op a) op b) op c\nfold_right: a op (b op (c op initial))\n```\n\nFor associative operations (like +, *), both give same result.\n\n### Why Use Fold for Compilation?\n\n**1. Separation of Concerns**\n- Structure building: generate the sequence\n- Computation: apply the operation\n\n**2. Reusability**\n```bash\n# Same fold_left for many predicates\nfactorial: fold_left 1 multiply [n..1]\nsum_list:  fold_left 0 add [elements]\nlength:    fold_left 0 increment [elements]\n```\n\n### UnifyWeaver's Fold Implementation\n\n```bash\nfold_left() {\n    local acc=\"$1\"\n    local op_func=\"$2\"\n    shift 2\n    for item in \"$@\"; do\n        acc=$(\"$op_func\" \"$item\" \"$acc\")\n    done\n    echo \"$acc\"\n}\n\n# Usage for factorial\nbuild_range_down() {\n    seq \"$1\" -1 1\n}\n\nfactorial_op() {\n    echo $(($1 * $2))\n}\n\nfactorial() {\n    local range=$(build_range_down \"$1\")\n    fold_left 1 factorial_op $range\n}\n```\n\n### Benefits\n\n- Clear, readable generated code\n- Easy to debug (inspect sequence, operation)\n- Natural fit for linear recursion patterns", "answer_tailored": true}
{"pair_id": "scc-tarjan_p0", "cluster_id": "scc-tarjan", "question": "What is a Strongly Connected Component (SCC)?", "question_type": "medium", "answer": "A Strongly Connected Component (SCC) is a maximal subgraph where every node is reachable from every other node within that set. In the context of UnifyWeaver, SCCs are used to identify and group mutually recursive predicates during the compilation process.\n\n### Visual Representation\nAn SCC essentially forms a cycle in the call graph:\n```\n    A \u2192 B \u2192 C\n    \u2191       \u2193\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\nIn this example, {A, B, C} constitutes an SCC because a path exists between any two nodes in the set.\n\n### SCCs and Mutual Recursion\nWhen predicates are mutually recursive, they form an SCC in the program's call graph. For example:\n```prolog\nis_even(0).\nis_even(N) :- N > 0, N1 is N - 1, is_odd(N1).\n\nis_odd(1).\nis_odd(N) :- N > 1, N1 is N - 1, is_even(N1).\n```\nThe call graph shows `is_even \u2194 is_odd`, forming an SCC. UnifyWeaver detects these components to ensure they are compiled together with shared resources.\n\n### Detection via Tarjan's Algorithm\nUnifyWeaver utilizes Tarjan's algorithm to identify these components by performing a Depth-First Search (DFS) and tracking:\n1.  **Discovery Time**: When a node was first visited.\n2.  **Low-link Value**: The lowest discovery time reachable from the node.\n3.  **Stack State**: To keep track of nodes in the current DFS traversal.\n\nIf a node's discovery time matches its low-link value after its subtree is explored, an SCC has been identified.\n\n### Implementation in UnifyWeaver\nThe compiler logic follows this pattern:\n1.  **Graph Construction**: Map predicates to a directed call graph.\n2.  **SCC Identification**: Apply Tarjan\u2019s to find all components.\n3.  **Mutual Recursion Filtering**: Identify \"non-trivial\" SCCs (those containing cycles or self-loops) for specialized compilation.\n\n### Shared Memoization\nSCC detection is critical for performance. Because predicates in an SCC are interdependent, UnifyWeaver implements **shared memoization**. Instead of separate caches, all predicates within the same SCC share a single memoization table. This ensures that if `is_even(4)` triggers a call to `is_odd(3)`, the results for both are cached in a way that avoids redundant computation across the entire recursive group.\n\nFor more details on handling recursive call graphs in the Bash target, see `education/book-02-bash-target/06_advanced_recursion.md`.", "answer_variant": "default", "answer_source": "education/book-02-bash-target/06_advanced_recursion.md", "topics": ["scc", "tarjan", "mutual-recursion", "graph-algorithm"], "original_answer": "## Strongly Connected Components (SCC)\n\nAn SCC is a maximal group of nodes where every node can reach every other node.\n\n### Visual Example\n\n```\n    A \u2192 B \u2192 C\n    \u2191       \u2193\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nA, B, C form an SCC: A\u2192B\u2192C\u2192A (cycle)\n```\n\n### Why SCCs Matter for Mutual Recursion\n\n```prolog\nis_even(0).\nis_even(N) :- N > 0, N1 is N - 1, is_odd(N1).\n\nis_odd(1).\nis_odd(N) :- N > 1, N1 is N - 1, is_even(N1).\n```\n\nCall graph:\n```\nis_even \u2192 is_odd\n   \u2191         \u2193\n   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nThese form an SCC - they're mutually recursive and must be compiled together.\n\n### Tarjan's Algorithm (Simplified)\n\n1. **DFS traversal** - visit each node\n2. **Track discovery time** - when node was first seen\n3. **Track low-link** - lowest reachable node\n4. **Stack-based detection** - nodes in current path\n\n```\nVisit A (disc=1, low=1)\n  Visit B (disc=2, low=2)\n    Visit C (disc=3, low=3)\n      C can reach A (disc=1)\n      Update C.low = 1\n    Update B.low = 1\n  Update A.low = 1\nA.disc == A.low \u2192 SCC found: {A, B, C}\n```\n\n### UnifyWeaver's SCC Detection\n\n```prolog\n% Build call graph from clauses\nbuild_call_graph(Predicates, Graph),\n\n% Find SCCs using Tarjan\nfind_sccs(Graph, SCCs),\n\n% Non-trivial SCCs = mutual recursion\ninclude(non_trivial_scc, SCCs, MutualGroups).\n```\n\n### Why Shared Memoization?\n\nWithout shared memo:\n```\nis_even(4) \u2192 is_odd(3) \u2192 is_even(2) \u2192 is_odd(1) \u2192 true\n              ^ if is_odd has separate memo, \n                is_even's results aren't cached\n```\n\nWith shared memo:\n```\nis_even_is_odd_memo[\"is_even:4\"] = true\nis_even_is_odd_memo[\"is_odd:3\"] = true\n... all results cached in one table\n```", "answer_tailored": true}
{"pair_id": "scc-tarjan_p1", "cluster_id": "scc-tarjan", "question": "Why does SCC detection matter for mutual recursion?", "question_type": "medium", "answer": "SCC (Strongly Connected Component) detection is essential for mutual recursion because it identifies clusters of predicates that are interdependent and must be compiled together. In UnifyWeaver, these groups are treated as a single unit to ensure correct execution and optimization.\n\n### Identifying Mutual Recursion\nWhen predicates call each other in a cycle (e.g., `is_even` calling `is_odd` and vice versa), they form an SCC in the call graph:\n```prolog\nis_even(0).\nis_even(N) :- N > 0, N1 is N - 1, is_odd(N1).\n\nis_odd(1).\nis_odd(N) :- N > 1, N1 is N - 1, is_even(N1).\n```\nUnifyWeaver detects these cycles using **Tarjan\u2019s Algorithm**, which performs a Depth First Search (DFS) while tracking discovery times and \"low-link\" values (the lowest reachable node in the stack). When a node's discovery time equals its low-link value, a complete SCC\u2014representing a mutually recursive group\u2014is identified.\n\n### The Role of Shared Memoization\nThe primary technical reason for detecting SCCs is the implementation of **shared memoization**. \n- **Without SCC Detection:** If `is_even` and `is_odd` used separate memoization tables, the results of one would not be visible to the other, leading to redundant computations and broken recursion logic.\n- **With SCC Detection:** All predicates within the same SCC share a unified memoization table. This ensures that if `is_even(2)` is computed during the evaluation of `is_odd(3)`, the result is cached in a central table accessible to every predicate in that recursive group.\n\nFor a deeper look at the implementation of recursive compilation, see `education/book-02-bash-target/06_advanced_recursion.md`.", "answer_variant": "default", "answer_source": "education/book-02-bash-target/06_advanced_recursion.md", "topics": ["scc", "tarjan", "mutual-recursion", "graph-algorithm"], "original_answer": "## Strongly Connected Components (SCC)\n\nAn SCC is a maximal group of nodes where every node can reach every other node.\n\n### Visual Example\n\n```\n    A \u2192 B \u2192 C\n    \u2191       \u2193\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nA, B, C form an SCC: A\u2192B\u2192C\u2192A (cycle)\n```\n\n### Why SCCs Matter for Mutual Recursion\n\n```prolog\nis_even(0).\nis_even(N) :- N > 0, N1 is N - 1, is_odd(N1).\n\nis_odd(1).\nis_odd(N) :- N > 1, N1 is N - 1, is_even(N1).\n```\n\nCall graph:\n```\nis_even \u2192 is_odd\n   \u2191         \u2193\n   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nThese form an SCC - they're mutually recursive and must be compiled together.\n\n### Tarjan's Algorithm (Simplified)\n\n1. **DFS traversal** - visit each node\n2. **Track discovery time** - when node was first seen\n3. **Track low-link** - lowest reachable node\n4. **Stack-based detection** - nodes in current path\n\n```\nVisit A (disc=1, low=1)\n  Visit B (disc=2, low=2)\n    Visit C (disc=3, low=3)\n      C can reach A (disc=1)\n      Update C.low = 1\n    Update B.low = 1\n  Update A.low = 1\nA.disc == A.low \u2192 SCC found: {A, B, C}\n```\n\n### UnifyWeaver's SCC Detection\n\n```prolog\n% Build call graph from clauses\nbuild_call_graph(Predicates, Graph),\n\n% Find SCCs using Tarjan\nfind_sccs(Graph, SCCs),\n\n% Non-trivial SCCs = mutual recursion\ninclude(non_trivial_scc, SCCs, MutualGroups).\n```\n\n### Why Shared Memoization?\n\nWithout shared memo:\n```\nis_even(4) \u2192 is_odd(3) \u2192 is_even(2) \u2192 is_odd(1) \u2192 true\n              ^ if is_odd has separate memo, \n                is_even's results aren't cached\n```\n\nWith shared memo:\n```\nis_even_is_odd_memo[\"is_even:4\"] = true\nis_even_is_odd_memo[\"is_odd:3\"] = true\n... all results cached in one table\n```", "answer_tailored": true}
{"pair_id": "scc-tarjan_p2", "cluster_id": "scc-tarjan", "question": "How does Tarjan's algorithm work?", "question_type": "medium", "answer": "Tarjan's algorithm is a graph theory procedure used to identify Strongly Connected Components (SCCs)\u2014maximal subgraphs where every node is reachable from every other node. In the context of UnifyWeaver, this algorithm is essential for detecting mutual recursion in Prolog predicates so they can be compiled correctly.\n\nThe algorithm functions through a Depth First Search (DFS) traversal using the following mechanics:\n\n1.  **Discovery Time:** Each node is assigned a unique, incrementing timestamp when first visited.\n2.  **Low-link Values:** The algorithm tracks the lowest discovery time reachable from a node (including itself). If a node can reach an ancestor in the DFS tree, its low-link value is updated to match that ancestor's discovery time.\n3.  **Stack-based Detection:** Nodes are pushed onto a stack as they are visited. When a node's discovery time matches its low-link value (`disc == low`), it serves as the root of an SCC. All nodes currently above it on the stack are popped to form that specific component.\n\n### Example in UnifyWeaver\n\nUnifyWeaver uses Tarjan's to analyze the call graph of Prolog clauses:\n\n```prolog\n% Extract the call graph and apply Tarjan's\nbuild_call_graph(Predicates, Graph),\nfind_sccs(Graph, SCCs),\n\n% Identify non-trivial SCCs as mutually recursive groups\ninclude(non_trivial_scc, SCCs, MutualGroups).\n```\n\nBy identifying these groups, the compiler can implement shared memoization. For instance, if `is_even` and `is_odd` form an SCC, they are compiled to share a single memoization table. This ensures that results for one predicate are available to the other, preventing redundant calculations during recursive descent.\n\nFor more information on handling mutual recursion and SCC detection, see `education/book-02-bash-target/06_advanced_recursion.md`.", "answer_variant": "default", "answer_source": "education/book-02-bash-target/06_advanced_recursion.md", "topics": ["scc", "tarjan", "mutual-recursion", "graph-algorithm"], "original_answer": "## Strongly Connected Components (SCC)\n\nAn SCC is a maximal group of nodes where every node can reach every other node.\n\n### Visual Example\n\n```\n    A \u2192 B \u2192 C\n    \u2191       \u2193\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nA, B, C form an SCC: A\u2192B\u2192C\u2192A (cycle)\n```\n\n### Why SCCs Matter for Mutual Recursion\n\n```prolog\nis_even(0).\nis_even(N) :- N > 0, N1 is N - 1, is_odd(N1).\n\nis_odd(1).\nis_odd(N) :- N > 1, N1 is N - 1, is_even(N1).\n```\n\nCall graph:\n```\nis_even \u2192 is_odd\n   \u2191         \u2193\n   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nThese form an SCC - they're mutually recursive and must be compiled together.\n\n### Tarjan's Algorithm (Simplified)\n\n1. **DFS traversal** - visit each node\n2. **Track discovery time** - when node was first seen\n3. **Track low-link** - lowest reachable node\n4. **Stack-based detection** - nodes in current path\n\n```\nVisit A (disc=1, low=1)\n  Visit B (disc=2, low=2)\n    Visit C (disc=3, low=3)\n      C can reach A (disc=1)\n      Update C.low = 1\n    Update B.low = 1\n  Update A.low = 1\nA.disc == A.low \u2192 SCC found: {A, B, C}\n```\n\n### UnifyWeaver's SCC Detection\n\n```prolog\n% Build call graph from clauses\nbuild_call_graph(Predicates, Graph),\n\n% Find SCCs using Tarjan\nfind_sccs(Graph, SCCs),\n\n% Non-trivial SCCs = mutual recursion\ninclude(non_trivial_scc, SCCs, MutualGroups).\n```\n\n### Why Shared Memoization?\n\nWithout shared memo:\n```\nis_even(4) \u2192 is_odd(3) \u2192 is_even(2) \u2192 is_odd(1) \u2192 true\n              ^ if is_odd has separate memo, \n                is_even's results aren't cached\n```\n\nWith shared memo:\n```\nis_even_is_odd_memo[\"is_even:4\"] = true\nis_even_is_odd_memo[\"is_odd:3\"] = true\n... all results cached in one table\n```", "answer_tailored": true}
{"pair_id": "scc-tarjan_p3", "cluster_id": "scc-tarjan", "question": "How does UnifyWeaver detect mutual recursion?", "question_type": "medium", "answer": "UnifyWeaver detects mutual recursion by identifying **Strongly Connected Components (SCCs)** within the program's call graph using **Tarjan\u2019s Algorithm**.\n\n### Detection Mechanism\nThe compiler analyzes the relationships between predicates to find cycles where multiple nodes can reach one another:\n\n1.  **Graph Construction**: The compiler builds a call graph where nodes represent predicates and edges represent calls between them.\n2.  **Tarjan\u2019s Algorithm**: A Depth-First Search (DFS) is performed to track the \"discovery time\" and \"low-link\" value (the lowest discovery time reachable) for each node.\n3.  **SCC Extraction**: Predicates that share the same low-link value and are part of a cycle are grouped into an SCC. Any \"non-trivial\" SCC (one containing multiple predicates or a self-referencing loop) is identified as a mutually recursive group.\n\n### Implementation Logic\nThe detection is implemented in the compiler's Prolog core:\n```prolog\n% Build call graph from clauses\nbuild_call_graph(Predicates, Graph),\n% Find SCCs using Tarjan's algorithm\nfind_sccs(Graph, SCCs),\n% Filter for non-trivial groups to find mutual recursion\ninclude(non_trivial_scc, SCCs, MutualGroups).\n```\n\n### Significance for Compilation\nDetecting these groups is critical for implementing **shared memoization**. In cases like `is_even` and `is_odd`, the predicates are compiled together so they can share a single memo table. This ensures that a result cached by one predicate is immediately available to the other, preventing redundant computations within the recursive cycle.\n\nFor more information on call graph analysis and recursion handling, see `education/book-02-bash-target/06_advanced_recursion.md`.", "answer_variant": "default", "answer_source": "education/book-02-bash-target/06_advanced_recursion.md", "topics": ["scc", "tarjan", "mutual-recursion", "graph-algorithm"], "original_answer": "## Strongly Connected Components (SCC)\n\nAn SCC is a maximal group of nodes where every node can reach every other node.\n\n### Visual Example\n\n```\n    A \u2192 B \u2192 C\n    \u2191       \u2193\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nA, B, C form an SCC: A\u2192B\u2192C\u2192A (cycle)\n```\n\n### Why SCCs Matter for Mutual Recursion\n\n```prolog\nis_even(0).\nis_even(N) :- N > 0, N1 is N - 1, is_odd(N1).\n\nis_odd(1).\nis_odd(N) :- N > 1, N1 is N - 1, is_even(N1).\n```\n\nCall graph:\n```\nis_even \u2192 is_odd\n   \u2191         \u2193\n   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nThese form an SCC - they're mutually recursive and must be compiled together.\n\n### Tarjan's Algorithm (Simplified)\n\n1. **DFS traversal** - visit each node\n2. **Track discovery time** - when node was first seen\n3. **Track low-link** - lowest reachable node\n4. **Stack-based detection** - nodes in current path\n\n```\nVisit A (disc=1, low=1)\n  Visit B (disc=2, low=2)\n    Visit C (disc=3, low=3)\n      C can reach A (disc=1)\n      Update C.low = 1\n    Update B.low = 1\n  Update A.low = 1\nA.disc == A.low \u2192 SCC found: {A, B, C}\n```\n\n### UnifyWeaver's SCC Detection\n\n```prolog\n% Build call graph from clauses\nbuild_call_graph(Predicates, Graph),\n\n% Find SCCs using Tarjan\nfind_sccs(Graph, SCCs),\n\n% Non-trivial SCCs = mutual recursion\ninclude(non_trivial_scc, SCCs, MutualGroups).\n```\n\n### Why Shared Memoization?\n\nWithout shared memo:\n```\nis_even(4) \u2192 is_odd(3) \u2192 is_even(2) \u2192 is_odd(1) \u2192 true\n              ^ if is_odd has separate memo, \n                is_even's results aren't cached\n```\n\nWith shared memo:\n```\nis_even_is_odd_memo[\"is_even:4\"] = true\nis_even_is_odd_memo[\"is_odd:3\"] = true\n... all results cached in one table\n```", "answer_tailored": true}
{"pair_id": "recursion-types_p0", "cluster_id": "recursion-types", "question": "How do I know if my code is tail/linear/tree recursive?", "question_type": "medium", "answer": "To determine whether your code uses tail, linear, or tree recursion, you should analyze the number of recursive calls in each clause and whether any operations occur after those calls return.\n\n### Identification Process\n\n**1. Count the recursive calls per clause:**\n*   **1 call:** This indicates either **Tail** or **Linear** recursion.\n*   **2 or more calls:** This is **Tree** recursion, typically used for branching structures like trees or graphs (e.g., `tree_sum`).\n\n**2. Check for work after the call:**\n*   **Tail Recursion:** The recursive call is the absolute **last action**. Once the call returns, the predicate is finished. This is the most efficient form because UnifyWeaver can compile it into an iterative loop.\n*   **Linear Recursion:** There is one recursive call, but computation happens **after** it returns (e.g., `factorial`, where multiplication occurs after the recursive result is obtained).\n\n**3. Verify the call target:**\n*   If the call is to a different predicate that eventually calls the original one back, you are dealing with **Mutual Recursion** (e.g., an `is_even` predicate calling `is_odd`).\n\n### Pattern Summary\n\n| Pattern | Calls | Work After Call? | UnifyWeaver Handling |\n| :--- | :--- | :--- | :--- |\n| **Tail** | 1 | No | Iterative loop (Highest Priority) |\n| **Linear** | 1 | Yes | Fold-based with memoization |\n| **Tree** | 2+ | Yes | Recursive structure parsing |\n| **Mutual** | 1+ | Varies | SCC detection and shared memoization |\n\nUnifyWeaver optimizes for performance by prioritizing Tail Recursion. For a deeper dive into how these patterns are transformed into target code, see the documentation in `education/book-02-bash-target/06_advanced_recursion.md`.", "answer_variant": "default", "answer_source": "education/book-02-bash-target/06_advanced_recursion.md", "topics": ["tail-recursion", "linear-recursion", "tree-recursion", "classification"], "original_answer": "## Recursion Pattern Classification\n\n### Quick Reference\n\n| Pattern | Recursive Calls | Work After Call? | Example |\n|---------|-----------------|------------------|--------|\n| Tail | 1 | No | count_items |\n| Linear | 1 | Yes | factorial |\n| Tree | 2+ | Yes | tree_sum |\n| Mutual | 1+ (to different pred) | Varies | is_even/is_odd |\n\n### Tail Recursion\n\nThe recursive call is the **last action** - no computation after it returns.\n\n```prolog\n% TAIL: recursive call is last\ncount([], Acc, Acc).\ncount([_|T], Acc, N) :-\n    Acc1 is Acc + 1,\n    count(T, Acc1, N).    % Nothing after this\n```\n\n### Linear Recursion\n\nExactly **one recursive call**, but work happens **after** it returns.\n\n```prolog\n% LINEAR: work after recursive call\nfactorial(0, 1).\nfactorial(N, F) :-\n    N1 is N - 1,\n    factorial(N1, F1),\n    F is N * F1.          % Multiplication AFTER return\n```\n\n### Tree Recursion\n\n**Multiple recursive calls** on structural parts.\n\n```prolog\n% TREE: two recursive calls\ntree_sum([], 0).\ntree_sum([V, L, R], Sum) :-\n    tree_sum(L, LS),      % Call 1\n    tree_sum(R, RS),      % Call 2\n    Sum is V + LS + RS.\n```\n\n### How to Identify\n\n**Step 1:** Count recursive calls per clause\n- 0 = base case\n- 1 = tail or linear\n- 2+ = tree\n\n**Step 2:** If 1 call, check if it's last\n- Last action \u2192 tail\n- Work after \u2192 linear\n\n**Step 3:** Check if calls are to same predicate\n- Different predicate \u2192 possibly mutual\n\n### UnifyWeaver's Priority\n\n1. **Tail** (most efficient \u2192 iterative loop)\n2. **Linear** (fold-based with memoization)\n3. **Tree** (recursive with structure parsing)\n4. **Mutual** (SCC detection, shared memo)\n5. **Basic** (fallback BFS)", "answer_tailored": true}
{"pair_id": "recursion-types_p1", "cluster_id": "recursion-types", "question": "What's the difference between tail and linear recursion?", "question_type": "medium", "answer": "Tail recursion and linear recursion both involve a single recursive call per clause, but the primary difference lies in whether any computation occurs after that call returns.\n\n### Tail Recursion\nIn tail recursion, the recursive call is the **absolute last action** in the predicate. Since no work remains once the call returns, UnifyWeaver optimizes this pattern by compiling it into an efficient **iterative loop** in the target language.\n\n**Example (Tail):**\n```prolog\n% The recursive call to count/3 is the final goal\ncount([], Acc, Acc).\ncount([_|T], Acc, N) :-\n    Acc1 is Acc + 1,\n    count(T, Acc1, N).\n```\n\n### Linear Recursion\nLinear recursion also features exactly one recursive call, but it performs additional work **after** the recursive call has finished. Because these pending operations must be managed, UnifyWeaver typically compiles these using **fold-based logic** or memoization.\n\n**Example (Linear):**\n```prolog\n% Multiplication occurs AFTER factorial/2 returns\nfactorial(0, 1).\nfactorial(N, F) :-\n    N1 is N - 1,\n    factorial(N1, F1),\n    F is N * F1.\n```\n\n### Comparison Summary\n| Feature | Tail Recursion | Linear Recursion |\n|---------|----------------|------------------|\n| **Recursive Calls** | 1 | 1 |\n| **Final Action** | The recursive call itself | A different operation (e.g., math) |\n| **UnifyWeaver Target** | Iterative loop (Highest Priority) | Fold-based / Memoized |\n\nTo identify the pattern, check the clause body: if the recursive call is the terminal goal, it is Tail; if there are goals following it, it is Linear. For more details on recursion patterns and their compilation strategies, see `education/book-02-bash-target/06_advanced_recursion.md`.", "answer_variant": "default", "answer_source": "education/book-02-bash-target/06_advanced_recursion.md", "topics": ["tail-recursion", "linear-recursion", "tree-recursion", "classification"], "original_answer": "## Recursion Pattern Classification\n\n### Quick Reference\n\n| Pattern | Recursive Calls | Work After Call? | Example |\n|---------|-----------------|------------------|--------|\n| Tail | 1 | No | count_items |\n| Linear | 1 | Yes | factorial |\n| Tree | 2+ | Yes | tree_sum |\n| Mutual | 1+ (to different pred) | Varies | is_even/is_odd |\n\n### Tail Recursion\n\nThe recursive call is the **last action** - no computation after it returns.\n\n```prolog\n% TAIL: recursive call is last\ncount([], Acc, Acc).\ncount([_|T], Acc, N) :-\n    Acc1 is Acc + 1,\n    count(T, Acc1, N).    % Nothing after this\n```\n\n### Linear Recursion\n\nExactly **one recursive call**, but work happens **after** it returns.\n\n```prolog\n% LINEAR: work after recursive call\nfactorial(0, 1).\nfactorial(N, F) :-\n    N1 is N - 1,\n    factorial(N1, F1),\n    F is N * F1.          % Multiplication AFTER return\n```\n\n### Tree Recursion\n\n**Multiple recursive calls** on structural parts.\n\n```prolog\n% TREE: two recursive calls\ntree_sum([], 0).\ntree_sum([V, L, R], Sum) :-\n    tree_sum(L, LS),      % Call 1\n    tree_sum(R, RS),      % Call 2\n    Sum is V + LS + RS.\n```\n\n### How to Identify\n\n**Step 1:** Count recursive calls per clause\n- 0 = base case\n- 1 = tail or linear\n- 2+ = tree\n\n**Step 2:** If 1 call, check if it's last\n- Last action \u2192 tail\n- Work after \u2192 linear\n\n**Step 3:** Check if calls are to same predicate\n- Different predicate \u2192 possibly mutual\n\n### UnifyWeaver's Priority\n\n1. **Tail** (most efficient \u2192 iterative loop)\n2. **Linear** (fold-based with memoization)\n3. **Tree** (recursive with structure parsing)\n4. **Mutual** (SCC detection, shared memo)\n5. **Basic** (fallback BFS)", "answer_tailored": true}
{"pair_id": "recursion-types_p2", "cluster_id": "recursion-types", "question": "What makes recursion 'tree' recursion?", "question_type": "medium", "answer": "Recursion is classified as **tree recursion** when a predicate clause contains two or more recursive calls. This pattern is primarily used for traversing hierarchical data structures where a problem is split into multiple independent branches.\n\n### Identifying Tree Recursion\nYou can identify tree recursion by following these criteria:\n1.  **Multiple Recursive Calls:** Each recursive clause makes at least two calls to the same predicate (e.g., processing both the left and right children of a node).\n2.  **Structural Decomposition:** The calls operate on different parts of a complex structure.\n3.  **Post-Call Work:** Computation (like summation or aggregation) typically happens after the recursive calls return.\n\n### Example: Structural Tree Sum\nIn this snippet, `tree_sum` makes two distinct recursive calls to process branches:\n```prolog\n% TREE: Two recursive calls per clause\ntree_sum([], 0).\ntree_sum([Val, Left, Right], Sum) :-\n    tree_sum(Left, LSum),      % Call 1\n    tree_sum(Right, RSum),     % Call 2\n    Sum is Val + LSum + RSum.  % Work happens after returns\n```\n\n### UnifyWeaver Classification & Priority\nUnifyWeaver analyzes the number of recursive calls per clause to determine the compilation strategy. While Tail and Linear recursion are prioritized for their optimization potential (iterative loops and fold-based memoization respectively), Tree recursion is handled using specialized recursive structure parsing.\n\n| Pattern | Recursive Calls | Work After Call? | UnifyWeaver Strategy |\n|---------|-----------------|------------------|---------------------|\n| **Tree** | **2+** | **Yes** | **Recursive with structure parsing** |\n\nFor more details on how these patterns are compiled and optimized, see the documentation in `education/book-02-bash-target/06_advanced_recursion.md`.", "answer_variant": "default", "answer_source": "education/book-02-bash-target/06_advanced_recursion.md", "topics": ["tail-recursion", "linear-recursion", "tree-recursion", "classification"], "original_answer": "## Recursion Pattern Classification\n\n### Quick Reference\n\n| Pattern | Recursive Calls | Work After Call? | Example |\n|---------|-----------------|------------------|--------|\n| Tail | 1 | No | count_items |\n| Linear | 1 | Yes | factorial |\n| Tree | 2+ | Yes | tree_sum |\n| Mutual | 1+ (to different pred) | Varies | is_even/is_odd |\n\n### Tail Recursion\n\nThe recursive call is the **last action** - no computation after it returns.\n\n```prolog\n% TAIL: recursive call is last\ncount([], Acc, Acc).\ncount([_|T], Acc, N) :-\n    Acc1 is Acc + 1,\n    count(T, Acc1, N).    % Nothing after this\n```\n\n### Linear Recursion\n\nExactly **one recursive call**, but work happens **after** it returns.\n\n```prolog\n% LINEAR: work after recursive call\nfactorial(0, 1).\nfactorial(N, F) :-\n    N1 is N - 1,\n    factorial(N1, F1),\n    F is N * F1.          % Multiplication AFTER return\n```\n\n### Tree Recursion\n\n**Multiple recursive calls** on structural parts.\n\n```prolog\n% TREE: two recursive calls\ntree_sum([], 0).\ntree_sum([V, L, R], Sum) :-\n    tree_sum(L, LS),      % Call 1\n    tree_sum(R, RS),      % Call 2\n    Sum is V + LS + RS.\n```\n\n### How to Identify\n\n**Step 1:** Count recursive calls per clause\n- 0 = base case\n- 1 = tail or linear\n- 2+ = tree\n\n**Step 2:** If 1 call, check if it's last\n- Last action \u2192 tail\n- Work after \u2192 linear\n\n**Step 3:** Check if calls are to same predicate\n- Different predicate \u2192 possibly mutual\n\n### UnifyWeaver's Priority\n\n1. **Tail** (most efficient \u2192 iterative loop)\n2. **Linear** (fold-based with memoization)\n3. **Tree** (recursive with structure parsing)\n4. **Mutual** (SCC detection, shared memo)\n5. **Basic** (fallback BFS)", "answer_tailored": true}
{"pair_id": "recursion-types_p3", "cluster_id": "recursion-types", "question": "How does UnifyWeaver classify recursion patterns?", "question_type": "medium", "answer": "UnifyWeaver classifies recursion patterns by analyzing the number of recursive calls within a clause and determining if any computation occurs after those calls return. This classification is critical for the compiler to select the optimal execution strategy, such as transforming tail recursion into efficient iterative loops.\n\n### Recursive Pattern Categories\n\n*   **Tail Recursion**: The recursive call is the final action in the clause. UnifyWeaver prioritizes this pattern because it can be compiled into high-performance iterative loops without stack overhead.\n*   **Linear Recursion**: Contains exactly one recursive call, but performs additional work (like arithmetic or data construction) after the call returns. These are often handled via fold-based transformations or memoization.\n*   **Tree Recursion**: Involves two or more recursive calls on structural sub-parts (e.g., processing both branches of a tree). This requires structure-aware recursive parsing.\n*   **Mutual Recursion**: Occurs when predicates call each other in a cycle. UnifyWeaver uses Strongly Connected Component (SCC) detection and shared memoization to manage these dependencies.\n\n### Classification Logic\n\nThe compiler follows a structured identification process:\n1.  **Count Calls**: 0 calls identify a base case, 1 call indicates tail or linear recursion, and 2+ calls signify tree recursion.\n2.  **Check Call Position**: For single-call predicates, if the call is the terminal action, it is classified as **Tail**. If work remains after the call returns, it is **Linear**.\n3.  **Analyze Targets**: If the call targets a different predicate that eventually calls the original, it is flagged for **Mutual** recursion analysis.\n\n### Compilation Priority\nUnifyWeaver attempts to match patterns in the following order of efficiency:\n1. **Tail** (Iterative)\n2. **Linear** (Fold/Memoized)\n3. **Tree** (Recursive)\n4. **Mutual** (SCC/Shared Memo)\n5. **Basic** (BFS Fallback)\n\nDetailed implementation examples and target-specific behaviors can be found in `education/book-02-bash-target/06_advanced_recursion.md`.", "answer_variant": "default", "answer_source": "education/book-02-bash-target/06_advanced_recursion.md", "topics": ["tail-recursion", "linear-recursion", "tree-recursion", "classification"], "original_answer": "## Recursion Pattern Classification\n\n### Quick Reference\n\n| Pattern | Recursive Calls | Work After Call? | Example |\n|---------|-----------------|------------------|--------|\n| Tail | 1 | No | count_items |\n| Linear | 1 | Yes | factorial |\n| Tree | 2+ | Yes | tree_sum |\n| Mutual | 1+ (to different pred) | Varies | is_even/is_odd |\n\n### Tail Recursion\n\nThe recursive call is the **last action** - no computation after it returns.\n\n```prolog\n% TAIL: recursive call is last\ncount([], Acc, Acc).\ncount([_|T], Acc, N) :-\n    Acc1 is Acc + 1,\n    count(T, Acc1, N).    % Nothing after this\n```\n\n### Linear Recursion\n\nExactly **one recursive call**, but work happens **after** it returns.\n\n```prolog\n% LINEAR: work after recursive call\nfactorial(0, 1).\nfactorial(N, F) :-\n    N1 is N - 1,\n    factorial(N1, F1),\n    F is N * F1.          % Multiplication AFTER return\n```\n\n### Tree Recursion\n\n**Multiple recursive calls** on structural parts.\n\n```prolog\n% TREE: two recursive calls\ntree_sum([], 0).\ntree_sum([V, L, R], Sum) :-\n    tree_sum(L, LS),      % Call 1\n    tree_sum(R, RS),      % Call 2\n    Sum is V + LS + RS.\n```\n\n### How to Identify\n\n**Step 1:** Count recursive calls per clause\n- 0 = base case\n- 1 = tail or linear\n- 2+ = tree\n\n**Step 2:** If 1 call, check if it's last\n- Last action \u2192 tail\n- Work after \u2192 linear\n\n**Step 3:** Check if calls are to same predicate\n- Different predicate \u2192 possibly mutual\n\n### UnifyWeaver's Priority\n\n1. **Tail** (most efficient \u2192 iterative loop)\n2. **Linear** (fold-based with memoization)\n3. **Tree** (recursive with structure parsing)\n4. **Mutual** (SCC detection, shared memo)\n5. **Basic** (fallback BFS)", "answer_tailored": true}
{"pair_id": "memoization-strategy_p0", "cluster_id": "memoization-strategy", "question": "What is memoization and why use it?", "question_type": "medium", "answer": "Memoization is an optimization technique that caches the results of function calls based on their input parameters. By storing these results, the system can bypass redundant computations and immediately return the cached value when the same inputs are encountered again. In UnifyWeaver's Bash target, this is essential for performance and for ensuring the stability of translated Prolog queries.\n\n### Why Use Memoization?\n\n1.  **Eliminating Redundant Work**: Without memoization, recursive functions like Fibonacci calculate the same branches multiple times. Caching ensures each unique input is processed only once, significantly improving execution time.\n2.  **Mutual Recursion Efficiency**: When predicates are mutually recursive (e.g., `is_even` and `is_odd`), UnifyWeaver utilizes a shared memoization table for the entire Strongly Connected Component (SCC). This allows results to be shared across different functions.\n3.  **Infinite Loop and Cycle Detection**: Memoization helps identify circular dependencies in Prolog rules (e.g., `a :- b. b :- a.`). By tracking when a specific call is currently \"in progress,\" UnifyWeaver can detect cycles and prevent the Bash script from entering an infinite loop.\n\n### Implementation Example (Bash)\n\nUnifyWeaver implements this using global associative arrays to store computation results:\n\n```bash\ndeclare -gA predicate_memo\n\nmy_predicate() {\n    local key=\"$*\"\n    \n    # Check cache for existing result\n    if [[ -n \"${predicate_memo[$key]}\" ]]; then\n        echo \"${predicate_memo[$key]}\"\n        return 0\n    fi\n    \n    # Compute the result and store it\n    local result=$(compute_logic \"$@\")\n    predicate_memo[$key]=\"$result\"\n    echo \"$result\"\n}\n```\n\n### Shared Memo for SCC Groups\n\nFor mutually recursive functions, a single table prevents cache misses that would occur if each function had its own independent memo:\n\n```bash\n# Shared table for related predicates\ndeclare -gA scc_group_memo\n\nis_even() {\n    local key=\"is_even:$*\"\n    [[ -n \"${scc_group_memo[$key]}\" ]] && echo \"${scc_group_memo[$key]}\" && return 0\n    # ... logic ...\n}\n\nis_odd() {\n    local key=\"is_odd:$*\"\n    [[ -n \"${scc_group_memo[$key]}\" ]] && echo \"${scc_group_memo[$key]}\" && return 0\n    # ... logic ...\n}\n```\n\nFor more details on how these strategies are applied to the Bash target, refer to `education/book-02-bash-target/06_advanced_recursion.md`.", "answer_variant": "default", "answer_source": "education/book-02-bash-target/06_advanced_recursion.md", "topics": ["memoization", "caching", "performance", "mutual-recursion"], "original_answer": "## Memoization Strategy\n\nMemoization caches function results to avoid redundant computation.\n\n### Basic Concept\n\n```bash\ndeclare -gA factorial_memo\n\nfactorial() {\n    local n=\"$1\"\n    \n    # Check cache first\n    if [[ -n \"${factorial_memo[$n]}\" ]]; then\n        echo \"${factorial_memo[$n]}\"\n        return 0\n    fi\n    \n    # Compute result\n    local result=$(compute_factorial \"$n\")\n    \n    # Cache it\n    factorial_memo[$n]=\"$result\"\n    echo \"$result\"\n}\n```\n\n### Why Memoization Helps\n\n```\nWithout memo: fib(5) computes fib(3) twice\n  fib(5)\n  \u251c\u2500\u2500 fib(4)\n  \u2502   \u251c\u2500\u2500 fib(3)  \u2190 computed\n  \u2502   \u2514\u2500\u2500 fib(2)\n  \u2514\u2500\u2500 fib(3)      \u2190 computed AGAIN\n\nWith memo: fib(3) computed once, cached\n  fib(5)\n  \u251c\u2500\u2500 fib(4)\n  \u2502   \u251c\u2500\u2500 fib(3)  \u2190 computed, cached\n  \u2502   \u2514\u2500\u2500 fib(2)\n  \u2514\u2500\u2500 fib(3)      \u2190 cache hit!\n```\n\n### Why Mutual Recursion Needs Shared Memo\n\nSeparate tables would miss cross-function caching:\n\n```\nis_even(4) \u2192 is_odd(3) \u2192 is_even(2) \u2192 is_odd(1) \u2192 true\n\nSeparate memos:\n  is_even_memo: {4: ?, 2: ?}  \u2190 waiting for is_odd\n  is_odd_memo: {3: ?, 1: true}\n  \nShared memo:\n  shared_memo: {\n    \"is_even:4\": true,\n    \"is_odd:3\": true,\n    \"is_even:2\": true,\n    \"is_odd:1\": true\n  }\n```\n\n### Without Shared Memo: Infinite Loop Risk\n\n```prolog\na(X) :- b(X).\nb(X) :- a(X).  % Circular!\n```\n\nShared memo detects the cycle:\n```bash\na(5):  Check memo[\"a:5\"] - not found, mark as computing\nb(5):  Check memo[\"b:5\"] - not found, mark as computing  \na(5):  Check memo[\"a:5\"] - FOUND (computing) \u2192 cycle detected!\n```\n\n### UnifyWeaver's Implementation\n\n```bash\n# Shared memo for SCC group\ndeclare -gA is_even_is_odd_memo\n\nis_even() {\n    local key=\"is_even:$*\"\n    [[ -n \"${is_even_is_odd_memo[$key]}\" ]] && ...\n}\n\nis_odd() {\n    local key=\"is_odd:$*\"\n    [[ -n \"${is_even_is_odd_memo[$key]}\" ]] && ...\n}\n```", "answer_tailored": true}
{"pair_id": "memoization-strategy_p1", "cluster_id": "memoization-strategy", "question": "Why must mutual recursive functions share a memo table?", "question_type": "medium", "answer": "Mutual recursive functions must share a memo table to ensure a unified view of the computation state across interdependent function calls. This shared visibility is necessary for two primary reasons: maximizing caching efficiency and enabling cycle detection to prevent infinite recursion.\n\n### Cross-Function Caching\nWhen functions depend on each other (such as an `is_even` and `is_odd` pair), a shared memo table allows the results of one function to be leveraged by its partner. If each function maintained a private table, the system would fail to recognize that a specific sub-state was already computed by the other function, leading to redundant calculations and diminished performance.\n\n### Cycle Detection and Loop Prevention\nA shared table is the only reliable way to detect circular dependencies in logic where `a(X)` calls `b(X)` and `b(X)` calls `a(X)`. \n- When `a(X)` is invoked, it is marked in the memo table as \"computing.\"\n- If the subsequent call to `b(X)` attempts to call `a(X)` again, the shared table allows `b` to see that `a(X)` is already active on the stack, signaling a cycle.\n- Without this shared context, the functions would continue calling each other indefinitely until the system triggers a stack overflow.\n\n### UnifyWeaver Implementation\nThe UnifyWeaver compiler groups mutually recursive predicates into Strongly Connected Components (SCCs). For each SCC, the compiler generates a single global associative array. To avoid collisions, keys in this shared table are prefixed with the specific function name:\n\n```bash\n# Shared memo for an SCC group in Bash\ndeclare -gA scc_group_memo\n\nis_even() {\n    local key=\"is_even:$1\"\n    [[ -n \"${scc_group_memo[$key]}\" ]] && return_cached_value\n    # ... logic to compute and cache\n}\n\nis_odd() {\n    local key=\"is_odd:$1\"\n    [[ -n \"${scc_group_memo[$key]}\" ]] && return_cached_value\n    # ... logic to compute and cache\n}\n```\n\nFor a detailed breakdown of how the compiler manages these recursive structures, see `education/book-02-bash-target/06_advanced_recursion.md`.", "answer_variant": "default", "answer_source": "education/book-02-bash-target/06_advanced_recursion.md", "topics": ["memoization", "caching", "performance", "mutual-recursion"], "original_answer": "## Memoization Strategy\n\nMemoization caches function results to avoid redundant computation.\n\n### Basic Concept\n\n```bash\ndeclare -gA factorial_memo\n\nfactorial() {\n    local n=\"$1\"\n    \n    # Check cache first\n    if [[ -n \"${factorial_memo[$n]}\" ]]; then\n        echo \"${factorial_memo[$n]}\"\n        return 0\n    fi\n    \n    # Compute result\n    local result=$(compute_factorial \"$n\")\n    \n    # Cache it\n    factorial_memo[$n]=\"$result\"\n    echo \"$result\"\n}\n```\n\n### Why Memoization Helps\n\n```\nWithout memo: fib(5) computes fib(3) twice\n  fib(5)\n  \u251c\u2500\u2500 fib(4)\n  \u2502   \u251c\u2500\u2500 fib(3)  \u2190 computed\n  \u2502   \u2514\u2500\u2500 fib(2)\n  \u2514\u2500\u2500 fib(3)      \u2190 computed AGAIN\n\nWith memo: fib(3) computed once, cached\n  fib(5)\n  \u251c\u2500\u2500 fib(4)\n  \u2502   \u251c\u2500\u2500 fib(3)  \u2190 computed, cached\n  \u2502   \u2514\u2500\u2500 fib(2)\n  \u2514\u2500\u2500 fib(3)      \u2190 cache hit!\n```\n\n### Why Mutual Recursion Needs Shared Memo\n\nSeparate tables would miss cross-function caching:\n\n```\nis_even(4) \u2192 is_odd(3) \u2192 is_even(2) \u2192 is_odd(1) \u2192 true\n\nSeparate memos:\n  is_even_memo: {4: ?, 2: ?}  \u2190 waiting for is_odd\n  is_odd_memo: {3: ?, 1: true}\n  \nShared memo:\n  shared_memo: {\n    \"is_even:4\": true,\n    \"is_odd:3\": true,\n    \"is_even:2\": true,\n    \"is_odd:1\": true\n  }\n```\n\n### Without Shared Memo: Infinite Loop Risk\n\n```prolog\na(X) :- b(X).\nb(X) :- a(X).  % Circular!\n```\n\nShared memo detects the cycle:\n```bash\na(5):  Check memo[\"a:5\"] - not found, mark as computing\nb(5):  Check memo[\"b:5\"] - not found, mark as computing  \na(5):  Check memo[\"a:5\"] - FOUND (computing) \u2192 cycle detected!\n```\n\n### UnifyWeaver's Implementation\n\n```bash\n# Shared memo for SCC group\ndeclare -gA is_even_is_odd_memo\n\nis_even() {\n    local key=\"is_even:$*\"\n    [[ -n \"${is_even_is_odd_memo[$key]}\" ]] && ...\n}\n\nis_odd() {\n    local key=\"is_odd:$*\"\n    [[ -n \"${is_even_is_odd_memo[$key]}\" ]] && ...\n}\n```", "answer_tailored": true}
{"pair_id": "memoization-strategy_p2", "cluster_id": "memoization-strategy", "question": "How does UnifyWeaver implement memoization?", "question_type": "medium", "answer": "UnifyWeaver implements memoization by utilizing global associative arrays to cache predicate results, which optimizes recursive calls and prevents redundant computations.\n\n### Core Implementation\nIn the Bash target, UnifyWeaver generates a memoization table using `declare -gA`. Each entry uses a structured key\u2014typically combining the predicate name and its arguments\u2014to ensure unique lookups.\n\nThe generated functions follow this logic:\n1. **Lookup**: Check the global associative array for an existing result using the generated key.\n2. **Cycle Detection**: If the key exists but is marked as \"computing,\" a circular dependency is detected.\n3. **Execution**: If the result is missing, the function performs the computation.\n4. **Caching**: The final result is stored in the array before being returned.\n\n### Shared Memoization for Mutual Recursion\nWhen dealing with mutual recursion (Strongly Connected Components), UnifyWeaver uses a **shared memo table** across all involved functions. This ensures that results from one function are available to others in the same group, which is critical for efficiency and preventing infinite loops.\n\n```bash\n# Shared memo for an SCC containing is_even and is_odd\ndeclare -gA even_odd_memo\n\nis_even() {\n    local key=\"is_even:$*\"\n    if [[ -n \"${even_odd_memo[$key]}\" ]]; then\n        echo \"${even_odd_memo[$key]}\"\n        return 0\n    fi\n    # ... computation ...\n    even_odd_memo[$key]=\"$result\"\n}\n```\n\n### Why This Strategy is Used\n*   **Performance**: Avoids exponential growth in calls for problems like Fibonacci sequences by ensuring each unique call is computed only once.\n*   **Safety**: Detects circular logic (e.g., `a :- b. b :- a.`) by tracking the state of active computations within the memo table.\n\nDetailed implementation patterns for the Bash target can be found in `education/book-02-bash-target/06_advanced_recursion.md`.", "answer_variant": "default", "answer_source": "education/book-02-bash-target/06_advanced_recursion.md", "topics": ["memoization", "caching", "performance", "mutual-recursion"], "original_answer": "## Memoization Strategy\n\nMemoization caches function results to avoid redundant computation.\n\n### Basic Concept\n\n```bash\ndeclare -gA factorial_memo\n\nfactorial() {\n    local n=\"$1\"\n    \n    # Check cache first\n    if [[ -n \"${factorial_memo[$n]}\" ]]; then\n        echo \"${factorial_memo[$n]}\"\n        return 0\n    fi\n    \n    # Compute result\n    local result=$(compute_factorial \"$n\")\n    \n    # Cache it\n    factorial_memo[$n]=\"$result\"\n    echo \"$result\"\n}\n```\n\n### Why Memoization Helps\n\n```\nWithout memo: fib(5) computes fib(3) twice\n  fib(5)\n  \u251c\u2500\u2500 fib(4)\n  \u2502   \u251c\u2500\u2500 fib(3)  \u2190 computed\n  \u2502   \u2514\u2500\u2500 fib(2)\n  \u2514\u2500\u2500 fib(3)      \u2190 computed AGAIN\n\nWith memo: fib(3) computed once, cached\n  fib(5)\n  \u251c\u2500\u2500 fib(4)\n  \u2502   \u251c\u2500\u2500 fib(3)  \u2190 computed, cached\n  \u2502   \u2514\u2500\u2500 fib(2)\n  \u2514\u2500\u2500 fib(3)      \u2190 cache hit!\n```\n\n### Why Mutual Recursion Needs Shared Memo\n\nSeparate tables would miss cross-function caching:\n\n```\nis_even(4) \u2192 is_odd(3) \u2192 is_even(2) \u2192 is_odd(1) \u2192 true\n\nSeparate memos:\n  is_even_memo: {4: ?, 2: ?}  \u2190 waiting for is_odd\n  is_odd_memo: {3: ?, 1: true}\n  \nShared memo:\n  shared_memo: {\n    \"is_even:4\": true,\n    \"is_odd:3\": true,\n    \"is_even:2\": true,\n    \"is_odd:1\": true\n  }\n```\n\n### Without Shared Memo: Infinite Loop Risk\n\n```prolog\na(X) :- b(X).\nb(X) :- a(X).  % Circular!\n```\n\nShared memo detects the cycle:\n```bash\na(5):  Check memo[\"a:5\"] - not found, mark as computing\nb(5):  Check memo[\"b:5\"] - not found, mark as computing  \na(5):  Check memo[\"a:5\"] - FOUND (computing) \u2192 cycle detected!\n```\n\n### UnifyWeaver's Implementation\n\n```bash\n# Shared memo for SCC group\ndeclare -gA is_even_is_odd_memo\n\nis_even() {\n    local key=\"is_even:$*\"\n    [[ -n \"${is_even_is_odd_memo[$key]}\" ]] && ...\n}\n\nis_odd() {\n    local key=\"is_odd:$*\"\n    [[ -n \"${is_even_is_odd_memo[$key]}\" ]] && ...\n}\n```", "answer_tailored": true}
{"pair_id": "memoization-strategy_p3", "cluster_id": "memoization-strategy", "question": "What would happen without shared memoization?", "question_type": "medium", "answer": "Without shared memoization, the generated code would suffer from significant performance degradation due to redundant computations and, more critically, would be unable to detect cycles in mutually recursive predicates, leading to infinite loops.\n\n### Redundant Computation in Mutual Recursion\nWhen functions are mutually recursive (e.g., `is_even` calling `is_odd`), separate memoization tables prevent them from sharing results. This forces the system to re-evaluate the same sub-problems across different function boundaries. \n\nWith a **shared memo**, results are cached using a unique key combining the predicate name and arguments:\n```bash\n# Shared memo for an SCC (Strongly Connected Component) group\ndeclare -gA is_even_is_odd_memo\n\nis_even() {\n    local key=\"is_even:$*\"\n    [[ -n \"${is_even_is_odd_memo[$key]}\" ]] && echo \"${is_even_is_odd_memo[$key]}\" && return\n    # ... compute and cache ...\n}\n```\n\n### Infinite Loop Risk and Cycle Detection\nShared memoization is the primary mechanism for detecting circular dependencies. In a scenario where `a(X) :- b(X)` and `b(X) :- a(X)`, a shared table allows the system to track \"in-progress\" calls across the entire recursion group:\n\n1.  **a(5)**: Checks the shared memo for \"a:5\". Not found; marks it as \"computing\".\n2.  **b(5)**: Checks the shared memo for \"b:5\". Not found; marks it as \"computing\".\n3.  **a(5)**: Checks the shared memo for \"a:5\". Found (status: \"computing\") \u2192 **Cycle detected!**\n\nWithout this shared state, each function would only be aware of its own call stack, failing to recognize the cross-function recursion and resulting in a stack overflow.\n\n### UnifyWeaver Implementation\nUnifyWeaver identifies Strongly Connected Components (SCCs) during compilation and generates a single shared associative array for each group to ensure efficient and safe execution.\n\nFor a deeper dive into how Bash handles these recursive structures, see `education/book-02-bash-target/06_advanced_recursion.md`.", "answer_variant": "default", "answer_source": "education/book-02-bash-target/06_advanced_recursion.md", "topics": ["memoization", "caching", "performance", "mutual-recursion"], "original_answer": "## Memoization Strategy\n\nMemoization caches function results to avoid redundant computation.\n\n### Basic Concept\n\n```bash\ndeclare -gA factorial_memo\n\nfactorial() {\n    local n=\"$1\"\n    \n    # Check cache first\n    if [[ -n \"${factorial_memo[$n]}\" ]]; then\n        echo \"${factorial_memo[$n]}\"\n        return 0\n    fi\n    \n    # Compute result\n    local result=$(compute_factorial \"$n\")\n    \n    # Cache it\n    factorial_memo[$n]=\"$result\"\n    echo \"$result\"\n}\n```\n\n### Why Memoization Helps\n\n```\nWithout memo: fib(5) computes fib(3) twice\n  fib(5)\n  \u251c\u2500\u2500 fib(4)\n  \u2502   \u251c\u2500\u2500 fib(3)  \u2190 computed\n  \u2502   \u2514\u2500\u2500 fib(2)\n  \u2514\u2500\u2500 fib(3)      \u2190 computed AGAIN\n\nWith memo: fib(3) computed once, cached\n  fib(5)\n  \u251c\u2500\u2500 fib(4)\n  \u2502   \u251c\u2500\u2500 fib(3)  \u2190 computed, cached\n  \u2502   \u2514\u2500\u2500 fib(2)\n  \u2514\u2500\u2500 fib(3)      \u2190 cache hit!\n```\n\n### Why Mutual Recursion Needs Shared Memo\n\nSeparate tables would miss cross-function caching:\n\n```\nis_even(4) \u2192 is_odd(3) \u2192 is_even(2) \u2192 is_odd(1) \u2192 true\n\nSeparate memos:\n  is_even_memo: {4: ?, 2: ?}  \u2190 waiting for is_odd\n  is_odd_memo: {3: ?, 1: true}\n  \nShared memo:\n  shared_memo: {\n    \"is_even:4\": true,\n    \"is_odd:3\": true,\n    \"is_even:2\": true,\n    \"is_odd:1\": true\n  }\n```\n\n### Without Shared Memo: Infinite Loop Risk\n\n```prolog\na(X) :- b(X).\nb(X) :- a(X).  % Circular!\n```\n\nShared memo detects the cycle:\n```bash\na(5):  Check memo[\"a:5\"] - not found, mark as computing\nb(5):  Check memo[\"b:5\"] - not found, mark as computing  \na(5):  Check memo[\"a:5\"] - FOUND (computing) \u2192 cycle detected!\n```\n\n### UnifyWeaver's Implementation\n\n```bash\n# Shared memo for SCC group\ndeclare -gA is_even_is_odd_memo\n\nis_even() {\n    local key=\"is_even:$*\"\n    [[ -n \"${is_even_is_odd_memo[$key]}\" ]] && ...\n}\n\nis_odd() {\n    local key=\"is_odd:$*\"\n    [[ -n \"${is_even_is_odd_memo[$key]}\" ]] && ...\n}\n```", "answer_tailored": true}
