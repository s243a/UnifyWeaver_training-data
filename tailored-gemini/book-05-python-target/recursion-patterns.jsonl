{"pair_id": "b5-c4-recursion-overview_p0", "cluster_id": "b5-c4-recursion-overview", "question": "What recursion patterns does the Python target support?", "question_type": "medium", "answer": "The Python target supports and optimizes three primary recursion patterns: **Tail**, **Linear**, and **Mutual** recursion.\n\n*   **Tail Recursion:** The compiler transforms tail-recursive predicates into iterative `while` loops. This optimization provides $O(1)$ space complexity, making it ideal for accumulators and iterative processes.\n*   **Linear Recursion:** For predicates with a single recursive call that isn't in the tail position, the target utilizes `@functools.cache` for memoization. This results in $O(n)$ space complexity.\n*   **Mutual Recursion:** When multiple predicates call each other, the compiler implements a shared dispatcher to manage the execution flow, also operating at $O(n)$ space.\n\nFor recursion that is deep or unbounded and doesn't fit these specific optimizations, the compiler employs a **Generator mode** to prevent stack overflow. The compiler automatically detects these patterns during the compilation phase to select the most efficient Pythonic representation.\n\nFor a deep dive into the detection logic and code generation examples, refer to `education/book-05-python-target/04_recursion_patterns.md`.", "answer_variant": "default", "answer_source": "education/book-05-python-target/04_recursion_patterns.md", "topics": ["recursion", "optimization", "tail-recursion", "memoization"], "original_answer": "## Recursion Patterns\n\nThe Python target recognizes and optimizes three recursion patterns:\n\n| Pattern | Optimization | Space | Use Case |\n|---------|-------------|-------|----------|\n| Tail | While loops | O(1) | Accumulators, iterative |\n| Linear | Memoization | O(n) | Single recursive call |\n| Mutual | Shared dispatcher | O(n) | Predicates calling each other |\n\n### Pattern Detection\n\nThe compiler automatically detects patterns:\n\n```\nIs the predicate recursive?\n\u251c\u2500\u2500 No \u2192 Simple streaming\n\u2514\u2500\u2500 Yes \u2192 What kind?\n    \u251c\u2500\u2500 Tail recursive? \u2192 while loop\n    \u251c\u2500\u2500 Linear recursive? \u2192 @functools.cache\n    \u251c\u2500\u2500 Mutual recursive? \u2192 shared dispatcher\n    \u2514\u2500\u2500 Deep/unbounded? \u2192 Generator mode\n```", "answer_tailored": true}
{"pair_id": "b5-c4-recursion-overview_p1", "cluster_id": "b5-c4-recursion-overview", "question": "How does UnifyWeaver optimize different recursion types?", "question_type": "medium", "answer": "UnifyWeaver optimizes recursion in its Python target by automatically detecting recursive structures and applying specific transformations to ensure efficiency and prevent stack overflows.\n\n- **Tail Recursion:** The compiler transforms tail-recursive predicates into iterative `while` loops. This optimization provides $O(1)$ space complexity, making it ideal for iterative logic and predicates using accumulators.\n- **Linear Recursion:** For predicates with a single recursive call, UnifyWeaver applies memoization via `@functools.cache`. This results in $O(n)$ space complexity and avoids redundant computations.\n- **Mutual Recursion:** When multiple predicates call each other, the compiler generates a shared dispatcher. This maintains $O(n)$ space complexity while supporting complex inter-predicate dependencies.\n- **Deep or Unbounded Recursion:** In cases where recursion depth is unknown or potentially massive, the compiler utilizes a Generator-based mode to safely handle processing without hitting Python's recursion limit.\n\nFor more technical details on these optimization strategies, see `education/book-05-python-target/04_recursion_patterns.md`.", "answer_variant": "default", "answer_source": "education/book-05-python-target/04_recursion_patterns.md", "topics": ["recursion", "optimization", "tail-recursion", "memoization"], "original_answer": "## Recursion Patterns\n\nThe Python target recognizes and optimizes three recursion patterns:\n\n| Pattern | Optimization | Space | Use Case |\n|---------|-------------|-------|----------|\n| Tail | While loops | O(1) | Accumulators, iterative |\n| Linear | Memoization | O(n) | Single recursive call |\n| Mutual | Shared dispatcher | O(n) | Predicates calling each other |\n\n### Pattern Detection\n\nThe compiler automatically detects patterns:\n\n```\nIs the predicate recursive?\n\u251c\u2500\u2500 No \u2192 Simple streaming\n\u2514\u2500\u2500 Yes \u2192 What kind?\n    \u251c\u2500\u2500 Tail recursive? \u2192 while loop\n    \u251c\u2500\u2500 Linear recursive? \u2192 @functools.cache\n    \u251c\u2500\u2500 Mutual recursive? \u2192 shared dispatcher\n    \u2514\u2500\u2500 Deep/unbounded? \u2192 Generator mode\n```", "answer_tailored": true}
{"pair_id": "b5-c4-recursion-overview_p2", "cluster_id": "b5-c4-recursion-overview", "question": "What is the difference between tail and linear recursion?", "question_type": "medium", "answer": "In the UnifyWeaver Python target, the primary difference between tail and linear recursion lies in how the compiler optimizes the execution and the resulting memory footprint. Tail recursion is optimized into an iterative `while` loop, providing $O(1)$ constant space complexity, which is ideal for accumulators and iterative logic. Linear recursion, where a single recursive call exists but not necessarily in the tail position, is optimized using memoization (via `@functools.cache`), resulting in $O(n)$ space complexity. For a deeper dive into these optimization strategies, refer to `education/book-05-python-target/04_recursion_patterns.md`.", "answer_variant": "default", "answer_source": "education/book-05-python-target/04_recursion_patterns.md", "topics": ["recursion", "optimization", "tail-recursion", "memoization"], "original_answer": "## Recursion Patterns\n\nThe Python target recognizes and optimizes three recursion patterns:\n\n| Pattern | Optimization | Space | Use Case |\n|---------|-------------|-------|----------|\n| Tail | While loops | O(1) | Accumulators, iterative |\n| Linear | Memoization | O(n) | Single recursive call |\n| Mutual | Shared dispatcher | O(n) | Predicates calling each other |\n\n### Pattern Detection\n\nThe compiler automatically detects patterns:\n\n```\nIs the predicate recursive?\n\u251c\u2500\u2500 No \u2192 Simple streaming\n\u2514\u2500\u2500 Yes \u2192 What kind?\n    \u251c\u2500\u2500 Tail recursive? \u2192 while loop\n    \u251c\u2500\u2500 Linear recursive? \u2192 @functools.cache\n    \u251c\u2500\u2500 Mutual recursive? \u2192 shared dispatcher\n    \u2514\u2500\u2500 Deep/unbounded? \u2192 Generator mode\n```", "answer_tailored": true}
{"pair_id": "b5-c4-tail-recursion_p0", "cluster_id": "b5-c4-tail-recursion", "question": "How is tail recursion compiled to Python?", "question_type": "medium", "answer": "UnifyWeaver compiles tail-recursive Prolog predicates into Python `while` loops to ensure $O(1)$ space complexity and avoid Python's default recursion depth limits.\n\nThe compiler recognizes this pattern when the recursive call is the final goal in a clause (tail position). It requires a base case for termination and typically utilizes accumulator variables to pass state downward. During compilation, the recursive logic is transformed into a `while True` loop where arguments are updated and the loop is restarted using `continue`.\n\n### Example Transformation\n\n**Prolog Source:**\n```prolog\nfactorial_acc(0, Acc, Acc).\nfactorial_acc(N, Acc, F) :-\n    N > 0, N1 is N - 1, Acc1 is Acc * N,\n    factorial_acc(N1, Acc1, F).\n```\n\n**Compiled Python:**\n```python\ndef _factorial_acc_worker(n, acc):\n    while True:\n        if n == 0:\n            return acc\n        if n > 0:\n            n, acc = n - 1, acc * n\n            continue\n        return None\n```\n\n### Benefits of this Approach\n*   **Constant Space:** Prevents stack growth and `RecursionError`.\n*   **Performance:** Eliminates the overhead associated with repeated function calls.\n*   **Safety:** Allows for processing deep recursive structures that would otherwise fail in standard Python.\n\nFor more information on these patterns, see `education/book-05-python-target/04_recursion_patterns.md`.", "answer_variant": "default", "answer_source": "education/book-05-python-target/04_recursion_patterns.md", "topics": ["tail-recursion", "while-loop", "accumulator"], "original_answer": "## Tail Recursion\n\nTail recursion is converted to `while` loops for O(1) space.\n\n### Pattern Recognition\n\n- Recursive call is in tail position (last goal)\n- Base case that doesn't recurse\n- Accumulator variables pass results downward\n\n### Example\n\n```prolog\nfactorial_acc(0, Acc, Acc).\nfactorial_acc(N, Acc, F) :-\n    N > 0, N1 is N - 1, Acc1 is Acc * N,\n    factorial_acc(N1, Acc1, F).\n```\n\n```python\ndef _factorial_acc_worker(n, acc):\n    while True:\n        if n == 0:\n            return acc\n        if n > 0:\n            n, acc = n - 1, acc * n\n            continue\n        return None\n```\n\n### Benefits\n\n- O(1) space - no stack growth\n- No recursion limit\n- Fast - no function call overhead", "answer_tailored": true}
{"pair_id": "b5-c4-tail-recursion_p1", "cluster_id": "b5-c4-tail-recursion", "question": "What is the accumulator pattern?", "question_type": "medium", "answer": "The accumulator pattern is a technique used in tail recursion where intermediate results are passed forward through recursive calls via a dedicated variable. Instead of building up a stack of deferred operations, the final result is computed as the recursion descends and is returned immediately once the base case is reached.\n\nIn UnifyWeaver's Python target, this pattern is critical because it allows the compiler to transform recursive Prolog definitions into efficient `while True` loops. This transformation provides O(1) space complexity, bypasses Python's default recursion depth limits, and eliminates the overhead of repeated function calls.\n\n### Pattern Requirements\n- **Tail Position**: The recursive call must be the final goal in the clause.\n- **Downward Flow**: State is updated in the arguments of the recursive call.\n- **Identity Base Case**: The base case simply unifies the final result with the current accumulator value.\n\n### Example: Tail-Recursive Factorial\n```prolog\n% Prolog source with accumulator\nfactorial_acc(0, Acc, Acc).\nfactorial_acc(N, Acc, F) :-\n    N > 0, \n    N1 is N - 1, \n    NewAcc is Acc * N,\n    factorial_acc(N1, NewAcc, F).\n```\n\n```python\n# Compiled Python output using a loop\ndef _factorial_acc_worker(n, acc):\n    while True:\n        if n == 0:\n            return acc\n        if n > 0:\n            n, acc = n - 1, acc * n\n            continue\n        return None\n```\n\nFor more details on how recursion is optimized for the Python runtime, see `education/book-05-python-target/04_recursion_patterns.md`.", "answer_variant": "default", "answer_source": "education/book-05-python-target/04_recursion_patterns.md", "topics": ["tail-recursion", "while-loop", "accumulator"], "original_answer": "## Tail Recursion\n\nTail recursion is converted to `while` loops for O(1) space.\n\n### Pattern Recognition\n\n- Recursive call is in tail position (last goal)\n- Base case that doesn't recurse\n- Accumulator variables pass results downward\n\n### Example\n\n```prolog\nfactorial_acc(0, Acc, Acc).\nfactorial_acc(N, Acc, F) :-\n    N > 0, N1 is N - 1, Acc1 is Acc * N,\n    factorial_acc(N1, Acc1, F).\n```\n\n```python\ndef _factorial_acc_worker(n, acc):\n    while True:\n        if n == 0:\n            return acc\n        if n > 0:\n            n, acc = n - 1, acc * n\n            continue\n        return None\n```\n\n### Benefits\n\n- O(1) space - no stack growth\n- No recursion limit\n- Fast - no function call overhead", "answer_tailored": true}
{"pair_id": "b5-c4-tail-recursion_p2", "cluster_id": "b5-c4-tail-recursion", "question": "Why do while loops have O(1) space?", "question_type": "medium", "answer": "While loops maintain O(1) space complexity because they execute logic iteratively within a single stack frame, avoiding the creation of new frames for every recursive step. In UnifyWeaver's Python target, tail-recursive Prolog predicates are transformed into `while` loops to ensure memory consumption remains constant regardless of the recursion depth.\n\nThis iterative approach provides several technical advantages:\n- **No Stack Growth:** Since the process stays within one function call frame, there is no risk of hitting Python's recursion limit.\n- **In-place Variable Updates:** State is maintained by updating variables at the end of each loop iteration (using the `continue` keyword) rather than passing them to a new function instance.\n- **Accumulator Patterns:** Results are passed downward through accumulator variables, allowing the final result to be returned directly from the base case.\n\nBy eliminating function call overhead and stack allocation, this transformation yields fast, memory-efficient code. Detailed documentation on these transformation patterns is available in `education/book-05-python-target/04_recursion_patterns.md`.\n\n### Example Transformation\n\n**Prolog Source:**\n```prolog\nfactorial_acc(0, Acc, Acc).\nfactorial_acc(N, Acc, F) :-\n    N > 0, N1 is N - 1, Acc1 is Acc * N,\n    factorial_acc(N1, Acc1, F).\n```\n\n**Compiled Python Worker:**\n```python\ndef _factorial_acc_worker(n, acc):\n    while True:\n        if n == 0:\n            return acc\n        if n > 0:\n            # Reassigning variables in-place ensures O(1) space\n            n, acc = n - 1, acc * n\n            continue\n        return None\n```", "answer_variant": "default", "answer_source": "education/book-05-python-target/04_recursion_patterns.md", "topics": ["tail-recursion", "while-loop", "accumulator"], "original_answer": "## Tail Recursion\n\nTail recursion is converted to `while` loops for O(1) space.\n\n### Pattern Recognition\n\n- Recursive call is in tail position (last goal)\n- Base case that doesn't recurse\n- Accumulator variables pass results downward\n\n### Example\n\n```prolog\nfactorial_acc(0, Acc, Acc).\nfactorial_acc(N, Acc, F) :-\n    N > 0, N1 is N - 1, Acc1 is Acc * N,\n    factorial_acc(N1, Acc1, F).\n```\n\n```python\ndef _factorial_acc_worker(n, acc):\n    while True:\n        if n == 0:\n            return acc\n        if n > 0:\n            n, acc = n - 1, acc * n\n            continue\n        return None\n```\n\n### Benefits\n\n- O(1) space - no stack growth\n- No recursion limit\n- Fast - no function call overhead", "answer_tailored": true}
{"pair_id": "b5-c4-memoization_p0", "cluster_id": "b5-c4-memoization", "question": "How does memoization work in the Python target?", "question_type": "medium", "answer": "In the UnifyWeaver Python target, memoization is implemented by decorating recursive worker functions with `@functools.cache`. This optimization is specifically designed to handle predicates with overlapping subproblems, ensuring that results for previously computed inputs are stored and reused rather than recalculated.\n\nA classic example is the Fibonacci sequence:\n\n```prolog\nfib(0, 0).\nfib(1, 1).\nfib(N, F) :-\n    N > 1, N1 is N - 1, N2 is N - 2,\n    fib(N1, F1), fib(N2, F2), F is F1 + F2.\n```\n\nWhen compiled to Python, the worker function utilizes the cache decorator:\n\n```python\nimport functools\n\n@functools.cache\ndef _fib_worker(n):\n    if n == 0: return 0\n    if n == 1: return 1\n    if n > 1:\n        f1 = _fib_worker(n - 1)\n        f2 = _fib_worker(n - 2)\n        if f1 is not None and f2 is not None:\n            return f1 + f2\n    return None\n```\n\n### Technical Impact\n- **Efficiency:** Memoization significantly improves performance for tree-recursive functions, such as reducing Fibonacci's time complexity from $O(2^n)$ to $O(n)$.\n- **Resource Usage:** It trades memory for speed, requiring $O(n)$ space to maintain the cache.\n- **Triggers:** The compiler applies this pattern when it detects multiple recursive calls or overlapping inputs where caching provides a clear algorithmic advantage.\n\nFor a comprehensive guide on these optimization strategies, refer to `education/book-05-python-target/04_recursion_patterns.md`.", "answer_variant": "default", "answer_source": "education/book-05-python-target/04_recursion_patterns.md", "topics": ["memoization", "functools-cache", "linear-recursion"], "original_answer": "## Memoization for Linear Recursion\n\nLinear recursion uses `@functools.cache` for memoization.\n\n### Example: Fibonacci\n\n```prolog\nfib(0, 0).\nfib(1, 1).\nfib(N, F) :-\n    N > 1, N1 is N - 1, N2 is N - 2,\n    fib(N1, F1), fib(N2, F2), F is F1 + F2.\n```\n\n```python\n@functools.cache\ndef _fib_worker(n):\n    if n == 0: return 0\n    if n == 1: return 1\n    if n > 1:\n        f1 = _fib_worker(n - 1)\n        f2 = _fib_worker(n - 2)\n        if f1 is not None and f2 is not None:\n            return f1 + f2\n    return None\n```\n\n### Complexity\n\n- Without memoization: O(2^n)\n- With memoization: O(n) time, O(n) space\n\n### When Memoization Helps\n\n- Multiple recursive calls (fib(N-1) + fib(N-2))\n- Overlapping subproblems\n- Same inputs called multiple times", "answer_tailored": true}
{"pair_id": "b5-c4-memoization_p1", "cluster_id": "b5-c4-memoization", "question": "When is memoization most effective?", "question_type": "medium", "answer": "Memoization is most effective when a recursive algorithm encounters **overlapping subproblems** where the same input values are processed multiple times across different branches of the execution tree. In the UnifyWeaver Python target, this optimization is primarily achieved by applying the `@functools.cache` decorator to the generated worker functions.\n\nKey scenarios where memoization provides the greatest benefit include:\n- **Multiple recursive calls** within a single rule, such as the classic Fibonacci sequence (`fib(N-1)` and `fib(N-2)`).\n- **Reducing computational complexity**, where caching can transform an exponential O(2^n) time complexity into linear O(n) performance.\n- **Redundant calculations** where the same intermediate results are required frequently.\n\nFor a comprehensive guide on implementing these patterns in the Python target, see the documentation in `education/book-05-python-target/04_recursion_patterns.md`.", "answer_variant": "default", "answer_source": "education/book-05-python-target/04_recursion_patterns.md", "topics": ["memoization", "functools-cache", "linear-recursion"], "original_answer": "## Memoization for Linear Recursion\n\nLinear recursion uses `@functools.cache` for memoization.\n\n### Example: Fibonacci\n\n```prolog\nfib(0, 0).\nfib(1, 1).\nfib(N, F) :-\n    N > 1, N1 is N - 1, N2 is N - 2,\n    fib(N1, F1), fib(N2, F2), F is F1 + F2.\n```\n\n```python\n@functools.cache\ndef _fib_worker(n):\n    if n == 0: return 0\n    if n == 1: return 1\n    if n > 1:\n        f1 = _fib_worker(n - 1)\n        f2 = _fib_worker(n - 2)\n        if f1 is not None and f2 is not None:\n            return f1 + f2\n    return None\n```\n\n### Complexity\n\n- Without memoization: O(2^n)\n- With memoization: O(n) time, O(n) space\n\n### When Memoization Helps\n\n- Multiple recursive calls (fib(N-1) + fib(N-2))\n- Overlapping subproblems\n- Same inputs called multiple times", "answer_tailored": true}
{"pair_id": "b5-c4-memoization_p2", "cluster_id": "b5-c4-memoization", "question": "How is Fibonacci compiled with memoization?", "question_type": "medium", "answer": "UnifyWeaver compiles the Fibonacci sequence with memoization by applying the `@functools.cache` decorator to the generated Python worker function. This strategy is specifically employed for linear recursion where overlapping subproblems\u2014such as calculating the same `N` value multiple times\u2014would otherwise result in exponential execution time.\n\n### Implementation Example\n\n**Prolog Source:**\n```prolog\nfib(0, 0).\nfib(1, 1).\nfib(N, F) :-\n    N > 1, N1 is N - 1, N2 is N - 2,\n    fib(N1, F1), fib(N2, F2), F is F1 + F2.\n```\n\n**Compiled Python Output:**\n```python\n@functools.cache\ndef _fib_worker(n):\n    if n == 0: return 0\n    if n == 1: return 1\n    if n > 1:\n        f1 = _fib_worker(n - 1)\n        f2 = _fib_worker(n - 2)\n        if f1 is not None and f2 is not None:\n            return f1 + f2\n    return None\n```\n\n### Performance Impact\nBy caching the results of recursive calls, the time complexity is reduced from O(2^n) to O(n), with a space complexity of O(n). This optimization ensures that each unique input is only computed once, making the recursive approach efficient for larger values of `N`.\n\nFor more information on recursion optimizations in the Python target, refer to `education/book-05-python-target/04_recursion_patterns.md`.", "answer_variant": "default", "answer_source": "education/book-05-python-target/04_recursion_patterns.md", "topics": ["memoization", "functools-cache", "linear-recursion"], "original_answer": "## Memoization for Linear Recursion\n\nLinear recursion uses `@functools.cache` for memoization.\n\n### Example: Fibonacci\n\n```prolog\nfib(0, 0).\nfib(1, 1).\nfib(N, F) :-\n    N > 1, N1 is N - 1, N2 is N - 2,\n    fib(N1, F1), fib(N2, F2), F is F1 + F2.\n```\n\n```python\n@functools.cache\ndef _fib_worker(n):\n    if n == 0: return 0\n    if n == 1: return 1\n    if n > 1:\n        f1 = _fib_worker(n - 1)\n        f2 = _fib_worker(n - 2)\n        if f1 is not None and f2 is not None:\n            return f1 + f2\n    return None\n```\n\n### Complexity\n\n- Without memoization: O(2^n)\n- With memoization: O(n) time, O(n) space\n\n### When Memoization Helps\n\n- Multiple recursive calls (fib(N-1) + fib(N-2))\n- Overlapping subproblems\n- Same inputs called multiple times", "answer_tailored": true}
{"pair_id": "b5-c4-mutual-recursion_p0", "cluster_id": "b5-c4-mutual-recursion", "question": "How is mutual recursion compiled to Python?", "question_type": "medium", "answer": "Mutual recursion in UnifyWeaver's Python target is implemented using a shared dispatcher function combined with memoization via `@functools.cache`. This pattern ensures that mutually recursive calls are routed through a central hub to manage state and optimize performance.\n\n### Implementation Pattern\n\nThe compiler generates a `_mutual_dispatch` function that routes calls to the appropriate predicate implementations:\n\n```prolog\n% Prolog Source\nis_even(0).\nis_even(N) :- N > 0, N1 is N - 1, is_odd(N1).\nis_odd(N) :- N > 0, N1 is N - 1, is_even(N1).\n```\n\n```python\n# Compiled Python\n@functools.cache\ndef _mutual_dispatch(pred_name, arg):\n    if pred_name == 'is_even':\n        return _is_even_impl(arg)\n    elif pred_name == 'is_odd':\n        return _is_odd_impl(arg)\n    return None\n\ndef _is_even_impl(n):\n    if n == 0: return True\n    if n > 0:\n        return _mutual_dispatch('is_odd', n - 1)\n    return None\n```\n\n### Key Considerations\n\n*   **Arity Restriction:** The current implementation is limited to **arity 1 predicates**. \n*   **Multi-argument Workaround:** To handle predicates with multiple arguments, you must wrap the arguments into a single tuple.\n*   **Performance:** The use of `@functools.cache` on the dispatcher provides automatic memoization for the recursive chain.\n\nFor a deeper look at how different recursion styles are handled, refer to `education/book-05-python-target/04_recursion_patterns.md`.", "answer_variant": "default", "answer_source": "education/book-05-python-target/04_recursion_patterns.md", "topics": ["mutual-recursion", "shared-dispatcher", "even-odd"], "original_answer": "## Mutual Recursion\n\nMutual recursion compiles to a shared dispatcher with memoization.\n\n### Example: Even/Odd\n\n```prolog\nis_even(0).\nis_even(N) :- N > 0, N1 is N - 1, is_odd(N1).\n\nis_odd(N) :- N > 0, N1 is N - 1, is_even(N1).\n```\n\n```python\n@functools.cache\ndef _mutual_dispatch(pred_name, arg):\n    if pred_name == 'is_even':\n        return _is_even_impl(arg)\n    elif pred_name == 'is_odd':\n        return _is_odd_impl(arg)\n    return None\n\ndef _is_even_impl(n):\n    if n == 0: return True\n    if n > 0:\n        return _mutual_dispatch('is_odd', n - 1)\n    return None\n```\n\n### Limitation\n\nCurrently supports **arity 1 predicates only**. For multi-argument mutual recursion, encode arguments as a tuple.", "answer_tailored": true}
{"pair_id": "b5-c4-mutual-recursion_p1", "cluster_id": "b5-c4-mutual-recursion", "question": "What is the shared dispatcher pattern?", "question_type": "medium", "answer": "The shared dispatcher pattern is the mechanism UnifyWeaver uses to implement mutual recursion in the Python target. This pattern centralizes recursive calls through a single dispatcher function\u2014typically decorated with `@functools.cache` for memoization\u2014which routes execution to specific predicate implementations based on the predicate name.\n\nWhen mutually recursive predicates like `is_even/1` and `is_odd/1` are compiled, they do not call each other directly; instead, they call a `_mutual_dispatch(pred_name, arg)` function. This dispatcher acts as a traffic controller, ensuring that recursive state and caching are managed consistently across all involved predicates.\n\n**Key Technical Details:**\n*   **Memoization:** The dispatcher uses Python's `functools.cache` to prevent redundant computations in recursive branches.\n*   **Arity Constraint:** Currently, the dispatcher supports only arity-1 predicates. For mutual recursion involving multiple arguments, the values must be packed into a single tuple.\n\nFurther details on implementation and examples can be found in `education/book-05-python-target/04_recursion_patterns.md`.", "answer_variant": "default", "answer_source": "education/book-05-python-target/04_recursion_patterns.md", "topics": ["mutual-recursion", "shared-dispatcher", "even-odd"], "original_answer": "## Mutual Recursion\n\nMutual recursion compiles to a shared dispatcher with memoization.\n\n### Example: Even/Odd\n\n```prolog\nis_even(0).\nis_even(N) :- N > 0, N1 is N - 1, is_odd(N1).\n\nis_odd(N) :- N > 0, N1 is N - 1, is_even(N1).\n```\n\n```python\n@functools.cache\ndef _mutual_dispatch(pred_name, arg):\n    if pred_name == 'is_even':\n        return _is_even_impl(arg)\n    elif pred_name == 'is_odd':\n        return _is_odd_impl(arg)\n    return None\n\ndef _is_even_impl(n):\n    if n == 0: return True\n    if n > 0:\n        return _mutual_dispatch('is_odd', n - 1)\n    return None\n```\n\n### Limitation\n\nCurrently supports **arity 1 predicates only**. For multi-argument mutual recursion, encode arguments as a tuple.", "answer_tailored": true}
{"pair_id": "b5-c4-mutual-recursion_p2", "cluster_id": "b5-c4-mutual-recursion", "question": "What are the limitations of mutual recursion support?", "question_type": "medium", "answer": "The primary limitation of mutual recursion support in the Python target is that it is currently restricted to predicates with an arity of 1. If your logic requires multi-argument mutual recursion, you must work around this by encoding the multiple arguments into a single tuple.\n\nIn the implementation, mutually recursive predicates are compiled into a shared dispatcher function that leverages `@functools.cache` for efficient memoization. This dispatcher routes calls between the participating predicate implementations (such as `is_even` and `is_odd`).\n\nFor further technical details and examples of these implementation patterns, refer to `education/book-05-python-target/04_recursion_patterns.md`.", "answer_variant": "default", "answer_source": "education/book-05-python-target/04_recursion_patterns.md", "topics": ["mutual-recursion", "shared-dispatcher", "even-odd"], "original_answer": "## Mutual Recursion\n\nMutual recursion compiles to a shared dispatcher with memoization.\n\n### Example: Even/Odd\n\n```prolog\nis_even(0).\nis_even(N) :- N > 0, N1 is N - 1, is_odd(N1).\n\nis_odd(N) :- N > 0, N1 is N - 1, is_even(N1).\n```\n\n```python\n@functools.cache\ndef _mutual_dispatch(pred_name, arg):\n    if pred_name == 'is_even':\n        return _is_even_impl(arg)\n    elif pred_name == 'is_odd':\n        return _is_odd_impl(arg)\n    return None\n\ndef _is_even_impl(n):\n    if n == 0: return True\n    if n > 0:\n        return _mutual_dispatch('is_odd', n - 1)\n    return None\n```\n\n### Limitation\n\nCurrently supports **arity 1 predicates only**. For multi-argument mutual recursion, encode arguments as a tuple.", "answer_tailored": true}
